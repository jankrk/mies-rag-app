ANSWERS = [
    {
        "id": 1,
        "job_id": 1,
        "file_id": 1,
        "question_id": 1,
        "status": "done",
        "answer_text": "The study utilized two specific AI algorithms: Logistic Regression (LR) and Random Forests (RF). Logistic Regression, enhanced with LASSO regularization, was selected for its scalability and effectiveness in managing large datasets, serving as a baseline for classification performance. Random Forests, being a more complex model, improved prediction accuracy by utilizing multiple decision trees to refine the quality of splits based on the Gini coefficient.\n\nThese algorithms contributed to the overall findings by achieving high prediction performance across various tasks, with AUC scores ranging from 72% to 93%. This indicates the effectiveness of machine learning methods in analyzing social media data related to extremist activities. Additionally, the study emphasized the significance of feature engineering, identifying key predictors such as user activity metrics, which further informed the understanding of extremist content production and online interactions.",
        "answer_encoded": "RF",
        "answer_contexts": [
                {
                    "context": "We tapped into the power of a crowd-sourcing project that aimed at manually identifying and reporting suspicious or abusive activity related to ISIS radicalization and propaganda agenda, and collected annotations to build a ground-truth of over 25 thousand suspended Twitter accounts. We extracted over three million tweets related to the activity of these accounts in the period of time between January and June 2015. We also randomly identified an equal-sized set of regular users exposed to the extremist content generated by the ISIS accounts, and collected almost 30 million tweets generated by the regular users in the same period of time.\n\nBy means of state-of-the-art learning models we managed to accomplish predictions in two types of scenarios, a static one that ignores temporal dependencies, and a simulated real-time case in which data are processed for training and testing by respecting the timeline of content availability. The two learning models, and the set of 52 features that we carefully crafted, proved very effective in all of the six combinations of forecasts (three prediction tasks each with two prediction modalities, static and real-time). The best performance in terms of AUC ranges between 72% and 93%, depending on the complexity of the considered task and the amount of training data available to the system.\n\nWe concluded our analysis by investigating the predictive power of different features. We focused on the top 11 most significant features, and we discovered that some of them, such as the ratio of retweets to tweets, the average number of hashtags adopted, the sheer number of tweets, and the average number of retweets generated by each user, systematically rank very high in terms of predictive power. Our insights shed light on the dynamics of extremist content production as well as some of the network and timing patterns that emerge in this type of online conversation.\n\nOur work is far from concluded: for the future, we plan to identify more realistic and complex prediction tasks, to analyze the network and temporal dynamics of extremist discussion, and to deploy a prototype system that allows for real-time detection of signatures of abuse on social media.",
                    "score": 0.685748972615056
                },
                {
                    "context": "Predicting online extremism, content adopters, and interaction reciprocity\n\n Emilio Ferrara∗, Wen-Qiang Wang∗, Onur Varol†, Alessandro Flammini† and Aram Galstyan∗\n\n ∗Information Sciences Institute, University of Southern California, Marina del Rey, CA 90292, USA\n\n †School of Informatics and Computing, Indiana University, Bloomington, IN 47401, USA\n\n emiliofe@usc.edu, wenqianw@usc.edu, ovarol@indiana.edu, aflammin@indiana.edu, galstyan@isi.edu\n\n Abstract\n\nWe present a machine learning framework that leverages a mixture of metadata, network, and temporal features to detect extremist users, and predict content adopters and interaction reciprocity in social media. We exploit a unique dataset containing millions of tweets generated by more than 25 thousand users who have been manually identified, reported, and suspended by Twitter due to their involvement with extremist campaigns. We also leverage millions of tweets generated by a random sample of 25 thousand regular users who were exposed to, or consumed, extremist content. We carry out three forecasting tasks, (i) to detect extremist users, (ii) to estimate whether regular users will adopt extremist content, and finally (iii) to predict whether users will reciprocate contacts initiated by extremists. All forecasting tasks are set up in two scenarios: a post hoc (time independent) prediction task on aggregated data, and a simulated real-time prediction task. The performance of our framework is extremely promising, yielding in the different forecasting scenarios up to 93% AUC for extremist user detection, up to 80% AUC for content adoption prediction, and finally up to 72% AUC for interaction reciprocity forecasting. We conclude by providing a thorough feature analysis that helps determine which are the emerging signals that provide predictive power in different scenarios.\n\n Contributions of this work\n\nThe main contributions of our work can be summarized as:\n\n- We formalize three different forecasting tasks related to online extremism, namely the detection of extremist users, the prediction of adoption of extremist content, and the forecasting of interaction reciprocity between regular users and extremists.\n- We propose a machine prediction framework that analyzes social media data and generates features across multiple dimensions, including user metadata, network statistics, and temporal patterns of activity, to perform the three forecasting tasks above.\n- We leverage an unprecedented dataset that contains over 3 million tweets generated by over 25 thousand extremist accounts, who have been manually identified, reported, and suspended by Twitter. We also use around 30 million tweets generated by a random sample of 25 thousand regular users who were exposed to, or consumed, extremist content.\n- For each forecasting task, we design two variants: a post-hoc (time independent) prediction task performed on aggregated data, and a simulated real-time forecast where the learning models are trained as if data were available up to a certain point in time, and the system must generate predictions on the future.\n- We conclude our analysis by studying the predictive power of the different features employed for prediction, to determine their role in the three forecasts.\n\n 1. Introduction\n\nResearchers are devoting increasing attention to the issues related to online extremism, terrorist propaganda and radicalization campaigns. Social media play a central role in these endeavors, as increasing evidence from social science research suggests. For example, a widespread consensus on the relationship between social media usage and the rise of extremist groups like the Islamic State of Iraq and al-Sham (viz. ISIS) has emerged among policymakers and security experts. ISIS’ success in increasing its roster to thousands of members has been related in part to a savvy use of social media for propaganda and recruitment purposes. One reason is that, until recently, social media platform like Twitter provided a public venue where single individuals, interest groups, or organizations, were given the ability to carry out extremist discussions and terrorist recruitment, without any form of restrictions, and with the possibility of gathering audiences of potentially millions. Only recently, some mechanisms have been put into place, based on manual reporting, to limit these abusive forms of communications. Based on this evidence, we argue in favor of developing computational tools capable of effectively analyzing massive social data streams, to detect extremist users, to predict who will become involved in interactions with radicalized users, and finally to determine who is likely to consume extremist content.",
                    "score": 0.5175014502975298
                },
                {
                    "context": "4.1. T1: Detection of extremist supporters\n\nIn the following we discuss the static (T1A) and real-time (T1B) scenarios for the first prediction task, namely detecting extremist accounts on Twitter. For example, in the first column, the learning models are trained on data from January 2015, and the prediction are performed and evaluated on future data in the interval February-June 2015.\n\n 4.1.1. T1A: Time-independent detection.\n\nThe detection of extremist user accounts is the most natural task to start the performance evaluation of our framework. Our analysis aims at verifying that the 52 features we carefully hand-crafted indeed carry some predictive signal useful to separate extremist users from regular ones. The dataset at hand contains two roughly equal-sized classes (about 25 thousand instances each), where ISIS accounts are labeled as positive instances, and regular users as negative ones. Each instance is characterized by a 52-dimensional vector, and positive and negative examples are fed to the two learning models (LR and RF). The first task, in short T1A, is agnostic of time dependencies: data are aggregated throughout the entire 6 months period (January-June 2015) and training/testing is performed in a traditional 5-fold cross-validated fashion (cf. §3.1.1).",
                    "score": 0.5149532774202504
                },
                {
                    "context": "ISIS among the Arabic-speaking population. Their analysis seems to suggest that supporters of the extremist group have been discussing about Arab Spring uprisings in the past significantly more than those who oppose ISIS on Twitter. Although their method to separate ISIS supporters from opposers is simplistic, the findings relating narrative framing and recruitment mechanisms are compatible with the literature on social protest phenomena [24], [25], [26].\n\nA few studies explored alternative data sources: one interesting example is the work by Vergani and Bliuc [27] that uses sentiment analysis (Linguistic Inquiry and Word Count [28]) to investigate how language evolved across the first 11 Issues of Dabiq, the flagship ISIS propaganda magazine. Their analysis offers some insights about ISIS radicalization motives, emotions and concerns. For example, the authors found that ISIS has become increasingly concerned with females, reflecting their need to attract women to create their utopia society, not revolving around warriors but around families. ISIS also seems to have increased the use of internet jargon, possibly to connect with the identities of young individuals online.\n\n Computer science research\n\nThis research stream concerns more with the machine learning and data aspects, to model, detect, and/or predict social phenomena such as extremism or radicalization often with newly-developed techniques.\n\nOne of the first computational frameworks, proposed by Bermingham et al. [29] in 2009, combined social network analysis with sentiment detection tools to study the agenda of a radical YouTube group: the authors examined the topics discussed within the group and their polarity, to model individuals’ behavior and spot signs of extremism and intolerance, seemingly more prominent among female users. The detection of extremist content (on the Web) was also the focus of a 2010 work by Qi et al. [30]. The authors applied hierarchical clustering to extremist Web pages to divide them into different categories (religious, politics, etc.).\n\nScanlon and Gerber proposed the first method to detect cyber-recruitment efforts in 2014 [31]. They exploited data retrieved from the Dark Web Portal Project [32], a repository of posts compiled from 28 different online fora on extremist religious discussions (e.g., Jihadist) translated from Arabic to English. After annotating a sample of posts as recruitment efforts or not, the authors use Bayesian criteria and a set of textual features to classify the rest of the corpus, obtaining good accuracy, and highlighted the most predictive terms.\n\nAlong the same trend, Agarwal and Sureka proposed different machine learning strategies [33], [34], [35], [36] aimed at detecting radicalization efforts, cyber recruitment, hate promotion, and extremist support in a variety of online platforms, including YouTube, Twitter and Tumblr. Their frameworks leverage features of contents and metadata, and combinations of crawling and unsupervised clustering methods, to study the online activity of Jihadist groups on the platforms mentioned above.\n\nConcluding, two very recent articles [37], [38] explore the activity of ISIS on social media. The former [37] focuses on Twitter and aims at detecting users who exhibit signals of behavioral change in line with radicalization: the authors suggest that out of 154K users only about 700 show significant signs of possible radicalization, and that may be due to social homophily rather than the mere exposure to propaganda content. The latter study [38] explores a set of 196 pro-ISIS aggregates operating on VKontakte (the most popular Russian online social network) and involving about 100K users, to study the dynamics of survival of such groups online: the authors suggest that the development of large and potentially influential pro-ISIS groups can be hindered by targeting and shutting down smaller ones. For additional pointers we refer the interested reader to two recent literature reviews on this topic [39], [40].\n\n 6. Conclusions\n\nIn this article we presented the problem of predicting online extremism in social media. We defined three machine learning tasks, namely the detection of extremist users, the prediction of extremist content adoption, and the forecasting of interactions between extremist users and regular users. We tapped into the power of a crowd-sourcing project that aimed at manually identifying and reporting suspicious or abusive activity related to ISIS radicalization and propaganda agenda, and collected annotations to build a ground-truth of over 25 thousand suspended Twitter accounts. We extracted over three million tweets related to the activity of these accounts in the period of time between January and June 2015. We also randomly identified an equal-sized set of regular users exposed to the extremist content generated by the ISIS accounts, and collected almost 30 million tweets generated by the regular users in the same period of time.\n\nBy means of state-of-the-art learning models we managed to accomplish predictions in two types of scenarios, a static one that ignores temporal dependencies, and a simulated real-time case in which data are processed for training and testing by respecting the timeline of content availability.",
                    "score": 0.5148371118786751
                },
                {
                    "context": "The problem is to test whether any predictive signal is present in the set of features we designed to characterize social media activity related to extremism, and serves as a yardstick for the next two more complex problems.\n\nTask II (T2): Predicting extremist content adoption. The set of 25 thousand users we randomly sampled among followers of ISIS accounts can be leveraged to perform the prediction of extremist content adoption. We define as a positive instance of adoption in this context when a regular user retweets some content s/he is exposed to that is generated by an ISIS account.\n\nTask III (T3): Predicting interactions with extremists. The third task presents likely the most difficult challenge: predicting whether a regular user will engage into interactions with extremists. A positive instance of interaction is represented by a regular user replying to a contact initiated by an ISIS account.\n\nStatic versus real-time predictions. For each of the three prediction tasks described above, we identified two modalities, namely a static (time independent) and a simulated real-time prediction. In the former scenario, a static prediction ignores temporal dependencies in that the system aggregates all data available across the entire time range (January-June 2015), and then performs training and testing using the 5-fold cross validation strategy by randomly splitting datapoints into the 5 folds and averaging the prediction performance across folds. In the latter scenario, a real-time prediction is simulated in which data are processed for training and testing purposes by respecting the timeline of content availability: for example, the system can exploit the first month of available data (January 2015) for training, and then producing predictions for the remainder 5 months (Feb-Jun 2015), for which performance is tested.\n\nThe performance of our framework in the three tasks, each with the two prediction modalities, is discussed in the following. The section concludes with the analysis of feature predictive power (see §4.4).",
                    "score": 0.34504159549448826
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific AI algorithm was utilized in the study, and how does it contribute to the overall findings presented in the article?",
                    "answer": "The study utilized two specific AI algorithms: Logistic Regression (LR) and Random Forests (RF). These algorithms were employed to classify and predict the behavior of Twitter users in relation to extremist content. Logistic Regression, with LASSO regularization, was chosen for its scalability and effectiveness in handling large datasets, providing a baseline for classification performance. Random Forests, a more complex model, was used to enhance prediction accuracy by leveraging multiple decision trees to improve the quality of splits based on the Gini coefficient.\n\nThe contributions of these algorithms to the overall findings include the ability to achieve high prediction performance across various tasks, with AUC scores ranging from 72% to 93%. This demonstrates the effectiveness of existing machine learning methods in analyzing social media data related to extremist activities. Additionally, the study highlighted the importance of feature engineering, revealing significant predictors such as user activity metrics, which further informed the dynamics of extremist content production and online interactions."
                },
                {
                    "question": "[SQ] What were the specific features used in the Logistic Regression and Random Forest models, and how did they impact the results?",
                    "answer": "The specific features used in the Logistic Regression and Random Forest models are not detailed in the provided information. Consequently, it is not possible to assess how these features impacted the results of the models. The performance metrics available focus on Precision, Recall, F1 Score, and AUC, but do not include any information regarding the features themselves."
                },
                {
                    "question": "[SQ] How did the performance of the AI algorithms compare to traditional methods in predicting extremist behavior on social media?",
                    "answer": "The performance of the AI algorithms demonstrated significant effectiveness in predicting extremist behavior on social media, achieving an area under the curve (AUC) ranging from 72% to 93% across various forecasting tasks. This performance was notably higher than traditional methods, which typically lack the sophisticated feature analysis and machine learning techniques employed in this framework. The use of a comprehensive dataset and advanced learning models allowed for more accurate detection of extremist users, prediction of content adoption, and forecasting of interactions, indicating a clear advantage over conventional approaches."
                },
                {
                    "question": "[SQ] What limitations were identified in the study regarding the use of these AI algorithms for analyzing extremist content?",
                    "answer": "The study acknowledges that the method used to separate ISIS supporters from opposers is simplistic, which may limit the accuracy of the findings. Additionally, while the machine learning models demonstrated promising performance, the complexity of the prediction tasks and the amount of training data available could affect the results. Future work is planned to address more realistic and complex prediction tasks, indicating that the current models may not fully capture the dynamics of extremist discussions and behaviors."
                },
                {
                    "question": "[MQ] What AI algorithms were employed in the study to classify Twitter users' behavior regarding extremist content, and how did their performance metrics, such as AUC scores ranging from 72% to 93%, contribute to the findings?",
                    "answer": "The study utilized state-of-the-art learning models, specifically logistic regression (LR) and random forests (RF), to classify Twitter users' behavior concerning extremist content. The performance metrics, particularly the area under the curve (AUC) scores, demonstrated the effectiveness of these models across different prediction tasks. The AUC scores ranged from 72% to 93%, indicating a strong ability to distinguish between extremist users and regular users, predict content adoption, and forecast interaction reciprocity. These metrics provided valuable insights into the predictive power of various features and underscored the potential of the framework in addressing online extremism."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 1.0000000000000004,
                "llm_context_precision_without_reference": 0.6756802720991909,
                "llm_context_precision_with_reference": 0.6756802720991909,
                "answer_relevancy": 0.0,
                "answer_correctness": 1.0
            },
            "deepeval": {
                "contextual_precision": 0.4583333333333333,
                "contextual_recall": 0.0,
                "contextual_relevancy": 0.12307692307692308,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 2,
        "job_id": 1,
        "file_id": 1,
        "question_id": 2,
        "status": "done",
        "answer_text": "The analysis focused on the top 11 features selected for their predictive power in real-time prediction tasks. These features included the ratio of retweets over tweets, the average number of hashtags, the number of tweets, and the average number of retweets. Their justification lies in their consistent ranking across three different prediction tasks, demonstrating their effectiveness in capturing relevant signals related to extremist behavior on social media. Additionally, these features can be easily computed from Twitter metadata, making them suitable for implementation in a real-time detection and prediction system, which aligns with the research objectives of detecting extremist activity and understanding user interactions on social media platforms.",
        "answer_encoded": "[response not coded] The analysis selected 11 features for their predictive power, including the ratio of retweets to tweets, average number of hashtags, number of tweets, and average number of retweets, due to their effectiveness in capturing signals related to extremist behavior on social media.",
        "answer_contexts": [
                {
                    "context": "4.4. Feature predictive-power analysis\n\nWe conclude our analysis by discussing the predictive power of the features adopted by our framework. First, the choice to focus on the top 11 features, rather than the more traditional top 10, is justified by the occurrence of two ex aequo in the final ranking of top features, displayed in Table 8. Here, we report the ranking of the top 11 features in the three tasks above. Feature selection is performed on the real-time prediction tasks (not on the time-aggregated ones). This analysis captures the essence of the predictive value of our hand-crafted features in the context of real-time predictions. A clear pattern emerges: (1) ratio of retweets over tweets, (2) average number of hashtags, (2 ex-aequo) number of tweets, and (4) average number of retweets, consistently ranked in the top features for the three different prediction tasks. This insight is encouraging: all these features can be easily computed from the metadata reported by the Twitter API, and therefore could be potentially implemented in a real-time detection and prediction system operating on the Twitter stream with unparalleled efficiency.\n\nUsing Twitter data as a historical archive, some researchers recently tried to unveil the roots of support for extremist propaganda using online data as a proxy to study individual and group behaviors. Various recent studies focus on English- and Arabic-speaking audiences online to study the effect of ISIS’ propaganda and radicalization. One example of the former is the work by Berger and collaborators that provided quantitative evidence of ISIS’ use of social media for propaganda. In a 2015 study [21], the authors characterized the Twitter population of ISIS supporters, quantifying its size, provenance, and organization. They argued that most of ISIS’ success on Twitter is due to a restricted number of highly-active accounts (500-1000 users). Our analysis illustrates that indeed a limited number of ISIS accounts achieved a very high visibility and followership. Berger’s subsequent work [22] however suggested that ISIS’ reach (at least among English speakers) has stalled for months as of the beginning of 2016, due to more aggressive account suspension policies enacted by Twitter. Again, a limited amount of English accounts sympathetic to ISIS was found (less than one thousand), and these users were mostly interacting with each other, while being only marginally successful at acquiring other users’ attention. This analysis suggests a mechanism of diminishing returns for extremist social media propaganda.",
                    "score": 0.8534468807002331
                },
                {
                    "context": "The problem is to test whether any predictive signal is present in the set of features we designed to characterize social media activity related to extremism, and serves as a yardstick for the next two more complex problems.\n\nTask II (T2): Predicting extremist content adoption. The set of 25 thousand users we randomly sampled among followers of ISIS accounts can be leveraged to perform the prediction of extremist content adoption. We define as a positive instance of adoption in this context when a regular user retweets some content s/he is exposed to that is generated by an ISIS account.\n\nTask III (T3): Predicting interactions with extremists. The third task presents likely the most difficult challenge: predicting whether a regular user will engage into interactions with extremists. A positive instance of interaction is represented by a regular user replying to a contact initiated by an ISIS account.\n\nStatic versus real-time predictions. For each of the three prediction tasks described above, we identified two modalities, namely a static (time independent) and a simulated real-time prediction. In the former scenario, a static prediction ignores temporal dependencies in that the system aggregates all data available across the entire time range (January-June 2015), and then performs training and testing using the 5-fold cross validation strategy by randomly splitting datapoints into the 5 folds and averaging the prediction performance across folds. In the latter scenario, a real-time prediction is simulated in which data are processed for training and testing purposes by respecting the timeline of content availability: for example, the system can exploit the first month of available data (January 2015) for training, and then producing predictions for the remainder 5 months (Feb-Jun 2015), for which performance is tested.\n\nThe performance of our framework in the three tasks, each with the two prediction modalities, is discussed in the following. The section concludes with the analysis of feature predictive power (see §4.4).",
                    "score": 0.7517001359332381
                },
                {
                    "context": "We tapped into the power of a crowd-sourcing project that aimed at manually identifying and reporting suspicious or abusive activity related to ISIS radicalization and propaganda agenda, and collected annotations to build a ground-truth of over 25 thousand suspended Twitter accounts. We extracted over three million tweets related to the activity of these accounts in the period of time between January and June 2015. We also randomly identified an equal-sized set of regular users exposed to the extremist content generated by the ISIS accounts, and collected almost 30 million tweets generated by the regular users in the same period of time.\n\nBy means of state-of-the-art learning models we managed to accomplish predictions in two types of scenarios, a static one that ignores temporal dependencies, and a simulated real-time case in which data are processed for training and testing by respecting the timeline of content availability. The two learning models, and the set of 52 features that we carefully crafted, proved very effective in all of the six combinations of forecasts (three prediction tasks each with two prediction modalities, static and real-time). The best performance in terms of AUC ranges between 72% and 93%, depending on the complexity of the considered task and the amount of training data available to the system.\n\nWe concluded our analysis by investigating the predictive power of different features. We focused on the top 11 most significant features, and we discovered that some of them, such as the ratio of retweets to tweets, the average number of hashtags adopted, the sheer number of tweets, and the average number of retweets generated by each user, systematically rank very high in terms of predictive power. Our insights shed light on the dynamics of extremist content production as well as some of the network and timing patterns that emerge in this type of online conversation.\n\nOur work is far from concluded: for the future, we plan to identify more realistic and complex prediction tasks, to analyze the network and temporal dynamics of extremist discussion, and to deploy a prototype system that allows for real-time detection of signatures of abuse on social media.",
                    "score": 0.6687316332146714
                },
                {
                    "context": "TABLE 1. LIST OF 52 FEATURES EXTRACTED BY OUR FRAMEWORK\n\nNumber of followersNumber of friends (i.e., followees)Number of posted tweetsNumber of favorite tweetsRatio of retweets / tweetsRatio of mentions / tweetsAvg number of hashtags(avg, var) number of retweetsAvg. number of mentionsAvg. number of mentions (excluding retweets)Number of URLs in profile descriptionUser metadata & activity(avg, std, min, max, proportion) URLs in tweetsLength of username(avg, var) number of tweets per day(avg, std, min, max) interval between two consecutive tweets(avg, std, min, max) interval between two consecutive retweetsTiming(avg, std, min, max) interval between two consecutive mentions(avg, std, min, max) distribution of retweeters’ number of followers(avg, std, min, max) distribution of retweeters’ number of friends(avg, std, min, max) distribution of mentioners’ number of followers(avg, std, min, max) distribution of mentioners’ number of friendsNetw. stats(avg, std, min, max) number of retweets of the tweets by others\nauthor of each tweet, as well as the source of each retweet. User features include the number of tweets, followers and friends associated to each users, the frequency of adoption of hashtags, mentions, and URLs, and finally some profile descriptors. In total, 18 user metadata and activity features are computed (cf. Table 1).\n\nTiming features: Important insights may be concealed by the temporal dimension of content production and consumption, as illustrated by recent work [14], [15]. A basic timing feature is the average number of tweets posted per day. Other timing features include statistics (average, standard deviation, minimum, maximum) of the intervals between two consecutive events, e.g., two tweets, retweets, or mentions. Our framework generates 14 timing features (cf. Table 1).\n\nNetwork statistics: Twitter content spreads from person to person via retweets and mentions. We expect that the emerging network structure carries important information to characterize different types of communication. Prior work shows that using network features significantly helps prediction tasks like social bot detection [8], [13], [15], and campaign detection [16], [17]. Our framework focuses on two types of networks: (i) retweet, and (ii) mention networks. Users are nodes of such networks, and retweets or mentions are directed links between pairs of users. For each user, our framework computes the distribution of followers and friends of all users who retweet and mention that user, and extracts some descriptive statistics (average, standard deviation, minimum, maximum) of these distributions. Our system builds 20 network statistics features (cf. Table 1).\n\n 3.2.1. Greedy feature selection.\n\nOur framework generates a set F of |F | = 52 features. In our type of prediction tasks, some features exhibit more predictive power than others: temporal dependencies introduce strong correlations among some features, thus some possible redundancy. Among the different existing ways to select the most relevant features for the prediction task at hand [18], in the interest of computational efficiency, we adopted a simple greedy forward feature selection method, as follows: (i) initialize the set of selected features S = ∅; (ii) for each feature f ∈ F − S, consider the union set U = S ∪ f; (iii) train the classifier using the features in U; (iv) test the average performance of the classifier trained on this set; (v) add to S the feature that provides the best performance; (vi) repeat (ii)-(v) as long as a significant performance increase is yield.\n\n 4. Experiments\n\nIn the following, we formalize three different prediction problems related to online extremism:\n\nTask I (T1): Detection of extremist supporters. The first task that our system will face is a binary classification aimed to detect ISIS accounts and separate them from those of regular users. The problem is to test whether any predictive signal is present in the set of features we designed to characterize social media activity related to extremism, and serves as a yardstick for the next two more complex problems.\n\nTask II (T2): Predicting extremist content adoption. The set of 25 thousand users we randomly sampled among followers of ISIS accounts can be leveraged to perform the prediction of extremist content adoption. We define as a positive instance of adoption in this context when a regular user retweets some content s/he is exposed to that is generated by an ISIS account.\n\nTask III (T3): Predicting interactions with extremists. The third task presents likely the most difficult challenge: predicting whether a regular user will engage into interactions with extremists. A positive instance of interaction is represented by a regular user replying to a contact initiated by an ISIS account.\n\nStatic versus real-time predictions.",
                    "score": 0.4596841546161578
                },
                {
                    "context": "4.1. T1: Detection of extremist supporters\n\nIn the following we discuss the static (T1A) and real-time (T1B) scenarios for the first prediction task, namely detecting extremist accounts on Twitter. For example, in the first column, the learning models are trained on data from January 2015, and the prediction are performed and evaluated on future data in the interval February-June 2015.\n\n 4.1.1. T1A: Time-independent detection.\n\nThe detection of extremist user accounts is the most natural task to start the performance evaluation of our framework. Our analysis aims at verifying that the 52 features we carefully hand-crafted indeed carry some predictive signal useful to separate extremist users from regular ones. The dataset at hand contains two roughly equal-sized classes (about 25 thousand instances each), where ISIS accounts are labeled as positive instances, and regular users as negative ones. Each instance is characterized by a 52-dimensional vector, and positive and negative examples are fed to the two learning models (LR and RF). The first task, in short T1A, is agnostic of time dependencies: data are aggregated throughout the entire 6 months period (January-June 2015) and training/testing is performed in a traditional 5-fold cross-validated fashion (cf. §3.1.1).",
                    "score": 0.29519294373996274
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific features or characteristics were selected for analysis in the study, and how were they justified in the context of the research objectives?",
                    "answer": "The analysis focused on the top 11 features, which were selected based on their predictive power in real-time prediction tasks. The justification for selecting these features stems from their consistent ranking across three different prediction tasks. The top features included the ratio of retweets over tweets, the average number of hashtags, the number of tweets, and the average number of retweets. These features were particularly valuable because they could be easily computed from the metadata provided by the Twitter API, making them suitable for implementation in a real-time detection and prediction system. This efficiency aligns with the research objectives of detecting extremist activity and understanding user interactions on social media platforms."
                },
                {
                    "question": "[SQ] What criteria were used to determine the predictive power of the selected features?",
                    "answer": "The predictive power of the selected features was determined by analyzing their consistent ranking across three different prediction tasks. Specifically, the top features were evaluated based on their performance in real-time prediction tasks, focusing on metrics such as the ratio of retweets over tweets, average number of hashtags, number of tweets, and average number of retweets. These features were found to rank highly across all tasks, indicating their significant predictive value. Additionally, the analysis involved using k-fold cross validation to ensure robust performance evaluation and benchmarking against standard prediction quality measures like Precision, Recall, F1 score, and AUC."
                },
                {
                    "question": "[SQ] How do the selected features compare to other potential features that were not included in the analysis?",
                    "answer": "The selected features demonstrate a strong predictive power for the tasks at hand, consistently ranking among the top features across different prediction tasks. This suggests that they are particularly effective in capturing the relevant signals related to extremist behavior on social media. However, the analysis does not provide a direct comparison to other potential features that were not included. It is possible that other features could exist, but their predictive value may not have been validated or may not have shown the same level of effectiveness as the chosen features. The focus on the top features indicates a deliberate selection process aimed at maximizing performance while maintaining computational efficiency."
                },
                {
                    "question": "[SQ] What specific research objectives were prioritized in the selection of these features?",
                    "answer": "The selection of features prioritized the predictive power relevant to real-time prediction tasks related to online extremism. The focus was on identifying features that could effectively characterize social media activity associated with extremist content, particularly in the context of detecting extremist supporters, predicting extremist content adoption, and forecasting interactions with extremists. Additionally, the features chosen were those that could be easily computed from Twitter metadata, ensuring efficiency for implementation in a real-time detection and prediction system. The analysis aimed to uncover significant patterns and dynamics in extremist content production and user interactions on social media."
                },
                {
                    "question": "[MQ] What top features were selected for analysis in the study based on their predictive power in real-time prediction tasks, and how do they align with the research objectives of detecting extremist activity on social media?",
                    "answer": "The analysis focused on the top 11 features, which were identified for their predictive power in real-time prediction tasks. These features include the ratio of retweets over tweets, the average number of hashtags, the number of tweets, and the average number of retweets. Their consistent ranking across different prediction tasks indicates their significance in understanding user behavior related to extremist content on social media. This aligns with the research objectives of detecting extremist activity, as these features can be easily computed from Twitter metadata, facilitating efficient real-time detection and prediction systems."
                },
                {
                    "question": "[SQ] What methodologies were employed to evaluate the effectiveness of the selected features in predicting extremist activity?",
                    "answer": "The evaluation of the effectiveness of the selected features in predicting extremist activity involved the use of state-of-the-art learning models and two distinct prediction scenarios: static and simulated real-time. In the static scenario, data from the entire time range (January to June 2015) was aggregated, and a 5-fold cross-validation strategy was employed to train and test the models. This approach allowed for the assessment of the predictive signal carried by the features without considering temporal dependencies.\n\nIn the simulated real-time scenario, the models were trained on data available up to a certain point in time (e.g., January 2015) and then used to make predictions on future data (February to June 2015). This method respected the timeline of content availability and aimed to mimic real-world conditions.\n\nThe performance of the models was measured using the Area Under the Curve (AUC) metric, with results indicating varying effectiveness across different tasks and scenarios. Additionally, a feature predictive power analysis was conducted, focusing on the top 11 most significant features to determine their role in the predictive capabilities of the framework. This analysis highlighted the consistent ranking of certain features across different prediction tasks, demonstrating their potential for real-time detection and prediction systems."
                },
                {
                    "question": "[SQ] How do the selected features facilitate the identification of specific patterns in extremist behavior on social media?",
                    "answer": "The selected features enable the identification of specific patterns in extremist behavior on social media by analyzing various dimensions of user activity. Key features such as the ratio of retweets to tweets, the average number of hashtags used, the total number of tweets, and the average number of retweets provide insights into user engagement and content dissemination. These metrics help to highlight how actively users interact with extremist content and the extent to which they amplify such messages within their networks. By focusing on these features, the framework can effectively capture the dynamics of extremist discussions, revealing trends in user behavior that are indicative of potential radicalization or engagement with extremist ideologies. This analysis not only aids in detecting extremist users but also in predicting content adoption and interaction reciprocity, thereby enhancing the understanding of online extremism patterns."
                },
                {
                    "question": "[SQ] What limitations were identified in the study regarding the selected features and their predictive capabilities?",
                    "answer": "The study identified that some features exhibited more predictive power than others, indicating potential redundancy due to strong correlations among certain features influenced by temporal dependencies. This suggests that while the selected features were effective, their interrelationships could limit the overall predictive capability and efficiency of the model. Additionally, the analysis focused on a limited set of top features, which may not encompass all relevant aspects of social media activity related to extremism. Future work aims to explore more complex prediction tasks and further analyze the dynamics of extremist discussions, indicating that the current feature set may not fully capture the intricacies of the problem."
                },
                {
                    "question": "[MQ] What are the top 11 features selected for analysis based on their predictive power in real-time prediction tasks related to detecting extremist activity on social media, and how do these features, such as the ratio of retweets to tweets and the average number of hashtags, align with the research objectives?",
                    "answer": "The top 11 features selected for analysis based on their predictive power in real-time prediction tasks related to detecting extremist activity on social media include:\n\n1. Ratio of retweets over tweets\n2. Average number of hashtags\n3. Number of tweets (two features due to ex aequo ranking)\n4. Average number of retweets\n\nThese features consistently ranked high across different prediction tasks, indicating their strong predictive value. They can be easily computed from the metadata provided by the Twitter API, which aligns with the research objectives of developing an efficient real-time detection and prediction system for extremist content on social media. The focus on these features highlights the importance of user engagement metrics and content characteristics in understanding and predicting extremist behavior online."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0.8333333333333334,
                "semantic_similarity": 0.7954353226233744,
                "llm_context_precision_without_reference": 0.7438492063368088,
                "llm_context_precision_with_reference": 0.4027777777643518,
                "answer_relevancy": 0.8291304088341502,
                "answer_correctness": 0.1988588306558436
            },
            "deepeval": {
                "contextual_precision": 0.6,
                "contextual_recall": 0.0,
                "contextual_relevancy": 0.010752688172043012,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 3,
        "job_id": 1,
        "file_id": 1,
        "question_id": 3,
        "status": "done",
        "answer_text": "The social network utilized for data collection in the analyzed article is Twitter.",
        "answer_encoded": "Twitter",
        "answer_contexts": [
                {
                    "context": "We tapped into the power of a crowd-sourcing project that aimed at manually identifying and reporting suspicious or abusive activity related to ISIS radicalization and propaganda agenda, and collected annotations to build a ground-truth of over 25 thousand suspended Twitter accounts. We extracted over three million tweets related to the activity of these accounts in the period of time between January and June 2015. We also randomly identified an equal-sized set of regular users exposed to the extremist content generated by the ISIS accounts, and collected almost 30 million tweets generated by the regular users in the same period of time.\n\nBy means of state-of-the-art learning models we managed to accomplish predictions in two types of scenarios, a static one that ignores temporal dependencies, and a simulated real-time case in which data are processed for training and testing by respecting the timeline of content availability. The two learning models, and the set of 52 features that we carefully crafted, proved very effective in all of the six combinations of forecasts (three prediction tasks each with two prediction modalities, static and real-time). The best performance in terms of AUC ranges between 72% and 93%, depending on the complexity of the considered task and the amount of training data available to the system.\n\nWe concluded our analysis by investigating the predictive power of different features. We focused on the top 11 most significant features, and we discovered that some of them, such as the ratio of retweets to tweets, the average number of hashtags adopted, the sheer number of tweets, and the average number of retweets generated by each user, systematically rank very high in terms of predictive power. Our insights shed light on the dynamics of extremist content production as well as some of the network and timing patterns that emerge in this type of online conversation.\n\nOur work is far from concluded: for the future, we plan to identify more realistic and complex prediction tasks, to analyze the network and temporal dynamics of extremist discussion, and to deploy a prototype system that allows for real-time detection of signatures of abuse on social media.",
                    "score": 0.8431105080539003
                },
                {
                    "context": "2. Data and Preliminary Analysis\n\nIn this section we describe our dataset, the curation strategy yielding the annotations, and some preliminary analysis.\n\n 2.1. Sample selection and curation\n\nIn this work we rely on data and labels constructed by using a procedure of manual curation and expert verification. We retrieved on a public Website a list of over 25 thousands Twitter accounts whose activity was labeled as supportive of the Islamic State by the crowd-sourcing initiative called Lucky Troll Club. The goal of this project was to leverage annotators with expertise in Arabic languages to identify ISIS accounts and report them to Twitter. Twitter’s anti-abuse team manually verifies all suspension requests, and grants some based on the active violation of Twitter’s Terms of Service policy against terrorist- or extremist-related activity. Here we focus on the 25,538 accounts that have been all suspended between January and June 2015 by Twitter as a consequence of evidence of activity supporting the Islamic State group. For each account, we also have at our disposal information about the suspension date, and the number of followers of that user as of the suspension date.\n\n 2.2. Twitter data collection\n\nThe next step of our study consisted in collecting data related to the activity of the 25,538 ISIS supporters on Twitter. To this purpose, we leveraged the Twitter gardenhose data source (roughly 10% of the Twitter stream) collected by Indiana University [8]. We decided to collect not only the tweets generated by these accounts prior to their suspension, but also to build a dataset of their targets. In particular, we are concerned with accounts unrelated to ISIS with whom the ISIS supporters tried to establish some forms of interaction. We therefore constructed the following two datasets:\n\n- ISIS accounts: this dataset contains 3,395,901 tweets generated in the time interval January-June 2015 by the 25,538 accounts identified by Twitter as supporters of ISIS. This is a significant portion of all the accounts suspended by Twitter in relation to ISIS.1\n- Users exposed to ISIS: this dataset contains 29,193,267 tweets generated during January-June 2015 by a set of 25 thousand users randomly sampled among the larger set of users that constitute ISIS accounts’ followers. This set is by choice of equal size to the former one, to avoid introducing class imbalance issues.\n\nFor prediction purposes, we will use as positive and negative labels the ISIS accounts group and the accounts in the users exposed to ISIS, respectively.\n\n1 The Guardian recently reported that between April 2015 and February 2016, Twitter’s anti-terror task force suspended about 125,000 accounts linked to ISIS extremists: http://www.theguardian.com/technology/2016/feb/05/twitter-deletes-isis-accounts-terrorism-online\n\n 3. Methodology\n\nIn this section we discuss the learning models and the features adopted by our framework. The complete prediction pipeline (learning models, cross validation, feature selection, and performance evaluation) is developed using Python and the scikit-learn library [9].\n\n 3.1. Learning models\n\nWe adopt two off-the-shelf learning models as a proof of concept for the three classification tasks that we will discuss later (see §4): Logistic Regression and Random Forests.\n\n Logistic Regression:\n\nThe first implemented algorithm is a simple Logistic Regression (LR) with LASSO regularization. The advantage of this approach is its scalability, which makes it very effective to (possibly real-time) classification tasks on large datasets. The only parameter to tune is the loss function C. We expect that LR will provide the baseline classification and prediction performance.\n\n Random Forests:\n\nWe also use a state-of-the-art implementation of Random Forests (RF) [10]. The vectors fed into the learning models represent each user’s features. Random Forests are trained using 100 estimators and adopting the Gini coefficient to measure the quality of splits. Optimal parameters setting is obtained via cross validation (see 3.1.1).\n\nNote that the goal of this work is not to provide new machine learning techniques, but to illustrate that existing methods can provide promising results. We also explored additional learning models (e.g., SVM, Stochastic Gradient Descent, etc.), which provide comparable prediction performance but are less computationally efficient and scalable.\n\n 3.1.1. Cross validation.\n\nThe results of our performance evaluation (see §4) are all obtained via k-fold cross validation. We adopt k = 5 folds, and therefore use 80% of data for training, and the remainder 20% for testing purpose, averaging performance scores across the 5 folds. We also use 5-fold cross validation to optimize the parameters of the two learning algorithms (LR and RF), by means of an exhaustive cross-validated grid search on the hyperparameter space.\n\n 3.1.2. Evaluation scores.",
                    "score": 0.8355894567174939
                },
                {
                    "context": "4.4. Feature predictive-power analysis\n\nWe conclude our analysis by discussing the predictive power of the features adopted by our framework. First, the choice to focus on the top 11 features, rather than the more traditional top 10, is justified by the occurrence of two ex aequo in the final ranking of top features, displayed in Table 8. Here, we report the ranking of the top 11 features in the three tasks above. Feature selection is performed on the real-time prediction tasks (not on the time-aggregated ones). This analysis captures the essence of the predictive value of our hand-crafted features in the context of real-time predictions. A clear pattern emerges: (1) ratio of retweets over tweets, (2) average number of hashtags, (2 ex-aequo) number of tweets, and (4) average number of retweets, consistently ranked in the top features for the three different prediction tasks. This insight is encouraging: all these features can be easily computed from the metadata reported by the Twitter API, and therefore could be potentially implemented in a real-time detection and prediction system operating on the Twitter stream with unparalleled efficiency.\n\nUsing Twitter data as a historical archive, some researchers recently tried to unveil the roots of support for extremist propaganda using online data as a proxy to study individual and group behaviors. Various recent studies focus on English- and Arabic-speaking audiences online to study the effect of ISIS’ propaganda and radicalization. One example of the former is the work by Berger and collaborators that provided quantitative evidence of ISIS’ use of social media for propaganda. In a 2015 study [21], the authors characterized the Twitter population of ISIS supporters, quantifying its size, provenance, and organization. They argued that most of ISIS’ success on Twitter is due to a restricted number of highly-active accounts (500-1000 users). Our analysis illustrates that indeed a limited number of ISIS accounts achieved a very high visibility and followership. Berger’s subsequent work [22] however suggested that ISIS’ reach (at least among English speakers) has stalled for months as of the beginning of 2016, due to more aggressive account suspension policies enacted by Twitter. Again, a limited amount of English accounts sympathetic to ISIS was found (less than one thousand), and these users were mostly interacting with each other, while being only marginally successful at acquiring other users’ attention. This analysis suggests a mechanism of diminishing returns for extremist social media propaganda.",
                    "score": 0.7396136869622709
                },
                {
                    "context": "ISIS among the Arabic-speaking population. Their analysis seems to suggest that supporters of the extremist group have been discussing about Arab Spring uprisings in the past significantly more than those who oppose ISIS on Twitter. Although their method to separate ISIS supporters from opposers is simplistic, the findings relating narrative framing and recruitment mechanisms are compatible with the literature on social protest phenomena [24], [25], [26].\n\nA few studies explored alternative data sources: one interesting example is the work by Vergani and Bliuc [27] that uses sentiment analysis (Linguistic Inquiry and Word Count [28]) to investigate how language evolved across the first 11 Issues of Dabiq, the flagship ISIS propaganda magazine. Their analysis offers some insights about ISIS radicalization motives, emotions and concerns. For example, the authors found that ISIS has become increasingly concerned with females, reflecting their need to attract women to create their utopia society, not revolving around warriors but around families. ISIS also seems to have increased the use of internet jargon, possibly to connect with the identities of young individuals online.\n\n Computer science research\n\nThis research stream concerns more with the machine learning and data aspects, to model, detect, and/or predict social phenomena such as extremism or radicalization often with newly-developed techniques.\n\nOne of the first computational frameworks, proposed by Bermingham et al. [29] in 2009, combined social network analysis with sentiment detection tools to study the agenda of a radical YouTube group: the authors examined the topics discussed within the group and their polarity, to model individuals’ behavior and spot signs of extremism and intolerance, seemingly more prominent among female users. The detection of extremist content (on the Web) was also the focus of a 2010 work by Qi et al. [30]. The authors applied hierarchical clustering to extremist Web pages to divide them into different categories (religious, politics, etc.).\n\nScanlon and Gerber proposed the first method to detect cyber-recruitment efforts in 2014 [31]. They exploited data retrieved from the Dark Web Portal Project [32], a repository of posts compiled from 28 different online fora on extremist religious discussions (e.g., Jihadist) translated from Arabic to English. After annotating a sample of posts as recruitment efforts or not, the authors use Bayesian criteria and a set of textual features to classify the rest of the corpus, obtaining good accuracy, and highlighted the most predictive terms.\n\nAlong the same trend, Agarwal and Sureka proposed different machine learning strategies [33], [34], [35], [36] aimed at detecting radicalization efforts, cyber recruitment, hate promotion, and extremist support in a variety of online platforms, including YouTube, Twitter and Tumblr. Their frameworks leverage features of contents and metadata, and combinations of crawling and unsupervised clustering methods, to study the online activity of Jihadist groups on the platforms mentioned above.\n\nConcluding, two very recent articles [37], [38] explore the activity of ISIS on social media. The former [37] focuses on Twitter and aims at detecting users who exhibit signals of behavioral change in line with radicalization: the authors suggest that out of 154K users only about 700 show significant signs of possible radicalization, and that may be due to social homophily rather than the mere exposure to propaganda content. The latter study [38] explores a set of 196 pro-ISIS aggregates operating on VKontakte (the most popular Russian online social network) and involving about 100K users, to study the dynamics of survival of such groups online: the authors suggest that the development of large and potentially influential pro-ISIS groups can be hindered by targeting and shutting down smaller ones. For additional pointers we refer the interested reader to two recent literature reviews on this topic [39], [40].\n\n 6. Conclusions\n\nIn this article we presented the problem of predicting online extremism in social media. We defined three machine learning tasks, namely the detection of extremist users, the prediction of extremist content adoption, and the forecasting of interactions between extremist users and regular users. We tapped into the power of a crowd-sourcing project that aimed at manually identifying and reporting suspicious or abusive activity related to ISIS radicalization and propaganda agenda, and collected annotations to build a ground-truth of over 25 thousand suspended Twitter accounts. We extracted over three million tweets related to the activity of these accounts in the period of time between January and June 2015. We also randomly identified an equal-sized set of regular users exposed to the extremist content generated by the ISIS accounts, and collected almost 30 million tweets generated by the regular users in the same period of time.\n\nBy means of state-of-the-art learning models we managed to accomplish predictions in two types of scenarios, a static one that ignores temporal dependencies, and a simulated real-time case in which data are processed for training and testing by respecting the timeline of content availability.",
                    "score": 0.6516380932848163
                },
                {
                    "context": "4.1. T1: Detection of extremist supporters\n\nIn the following we discuss the static (T1A) and real-time (T1B) scenarios for the first prediction task, namely detecting extremist accounts on Twitter. For example, in the first column, the learning models are trained on data from January 2015, and the prediction are performed and evaluated on future data in the interval February-June 2015.\n\n 4.1.1. T1A: Time-independent detection.\n\nThe detection of extremist user accounts is the most natural task to start the performance evaluation of our framework. Our analysis aims at verifying that the 52 features we carefully hand-crafted indeed carry some predictive signal useful to separate extremist users from regular ones. The dataset at hand contains two roughly equal-sized classes (about 25 thousand instances each), where ISIS accounts are labeled as positive instances, and regular users as negative ones. Each instance is characterized by a 52-dimensional vector, and positive and negative examples are fed to the two learning models (LR and RF). The first task, in short T1A, is agnostic of time dependencies: data are aggregated throughout the entire 6 months period (January-June 2015) and training/testing is performed in a traditional 5-fold cross-validated fashion (cf. §3.1.1).",
                    "score": 0.3603346456940421
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] Which social network or platform was utilized for data collection in the analyzed article?",
                    "answer": "The social network utilized for data collection in the analyzed article is Twitter."
                },
                {
                    "question": "[SQ] What specific data collection methods were employed on Twitter in the analyzed article?",
                    "answer": "The data collection methods employed involved retrieving a list of over 25,000 Twitter accounts identified as supportive of the Islamic State through a crowd-sourcing initiative. These accounts were manually curated and verified by experts in Arabic languages. The study focused on the 25,538 accounts that were suspended by Twitter between January and June 2015 due to their extremist activities. Data was collected using the Twitter gardenhose data source, which captures roughly 10% of the Twitter stream. This included gathering tweets generated by the identified ISIS accounts prior to their suspension, as well as tweets from a randomly sampled set of 25,000 users who followed these accounts, ensuring an equal-sized dataset to avoid class imbalance."
                },
                {
                    "question": "[SQ] How was the data from Twitter analyzed in the context of the study?",
                    "answer": "The data from Twitter was analyzed by collecting tweets from two distinct groups: over 25,000 suspended accounts identified as supportive of ISIS and an equal-sized set of regular users exposed to extremist content. The analysis involved extracting over three million tweets from the ISIS accounts and nearly 30 million tweets from the regular users during the period from January to June 2015. \n\nThe study employed state-of-the-art learning models to make predictions in both static and simulated real-time scenarios, utilizing a set of 52 carefully crafted features. The effectiveness of these features was evaluated through performance metrics, particularly focusing on the predictive power of the top features, such as the ratio of retweets to tweets and the average number of hashtags. The analysis aimed to uncover patterns in extremist content production and user interactions, ultimately contributing to the understanding of online extremism dynamics."
                },
                {
                    "question": "[SQ] What were the main findings derived from the Twitter data in the analyzed article?",
                    "answer": "The analysis revealed several key findings regarding the predictive power of features related to extremist content on Twitter. The top 11 features identified included the ratio of retweets to tweets, the average number of hashtags, the sheer number of tweets, and the average number of retweets, all of which consistently ranked high across different prediction tasks. These features can be easily computed from Twitter's metadata, suggesting their potential for implementation in real-time detection systems.\n\nAdditionally, the study highlighted that a limited number of highly active ISIS accounts achieved significant visibility and followership, indicating a mechanism of diminishing returns for extremist propaganda. The research also demonstrated effective predictions in both static and simulated real-time scenarios, achieving an AUC performance range between 72% and 93%, depending on task complexity and training data volume.\n\nFurthermore, the analysis underscored the dynamics of extremist content production and the network patterns emerging from online conversations, providing insights into user interactions and the potential for future research on more complex prediction tasks and real-time detection systems."
                },
                {
                    "question": "[MQ] Which social network was utilized for data collection in the analyzed article, specifically focusing on over 25,000 suspended accounts identified as supportive of the Islamic State?",
                    "answer": "The social network utilized for data collection in the analyzed article, focusing on over 25,000 suspended accounts identified as supportive of the Islamic State, is Twitter."
                },
                {
                    "question": "[SQ] What criteria were used to identify the suspended accounts as supportive of the Islamic State on Twitter?",
                    "answer": "The suspended accounts were identified as supportive of the Islamic State based on a crowd-sourcing initiative called Lucky Troll Club, which involved annotators with expertise in Arabic languages. These annotators manually identified and reported accounts that exhibited activity supportive of ISIS. The suspension requests were then verified by Twitter's anti-abuse team, which granted suspensions based on evidence of violations of Twitter's Terms of Service policy against terrorist or extremist-related activity."
                },
                {
                    "question": "[SQ] What time frame was analyzed for the suspended accounts and their activities on Twitter?",
                    "answer": "The time frame analyzed for the suspended accounts and their activities on Twitter was between January and June 2015."
                },
                {
                    "question": "[SQ] How did the researchers ensure the accuracy and reliability of the data collected from the suspended accounts?",
                    "answer": "The researchers ensured the accuracy and reliability of the data collected from the suspended accounts by employing a procedure of manual curation and expert verification. They utilized a crowd-sourcing initiative called Lucky Troll Club, which involved annotators with expertise in Arabic languages to identify and report ISIS accounts. Additionally, Twitter's anti-abuse team manually verified all suspension requests, granting suspensions based on active violations of Twitter’s Terms of Service policy against extremist-related activity. This rigorous process helped to confirm that the accounts labeled as supportive of ISIS were indeed accurately identified and suspended."
                },
                {
                    "question": "[MQ] Which social network was used for data collection in the study that analyzed over 25,000 suspended Twitter accounts identified as supportive of the Islamic State between January and June 2015?",
                    "answer": "The social network used for data collection in the study was Twitter."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 0.9999999999999996,
                "llm_context_precision_without_reference": 0.7099999999858,
                "llm_context_precision_with_reference": 0.7099999999858,
                "answer_relevancy": 0.8087136901956149,
                "answer_correctness": 0.9999999999999999
            },
            "deepeval": {
                "contextual_precision": 1.0,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.1206896551724138,
                "answer_relevancy": 1.0,
                "faithfulness": 0.5
            }
        },
    },
    {
        "id": 4,
        "job_id": 1,
        "file_id": 1,
        "question_id": 4,
        "status": "done",
        "answer_text": "The analyzed dataset included a total of 50,538 accounts, comprising 25,538 suspended Twitter accounts supportive of ISIS and 25,000 regular users exposed to ISIS content. The tweet counts associated with these accounts were 3,395,901 tweets generated by the ISIS accounts and 29,193,267 tweets generated by the regular users.",
        "answer_encoded": "[response not coded] The analyzed dataset consisted of 50,538 accounts, including 25,538 suspended ISIS-supportive accounts and 25,000 regular users.",
        "answer_contexts": [
                {
                    "context": "We tapped into the power of a crowd-sourcing project that aimed at manually identifying and reporting suspicious or abusive activity related to ISIS radicalization and propaganda agenda, and collected annotations to build a ground-truth of over 25 thousand suspended Twitter accounts. We extracted over three million tweets related to the activity of these accounts in the period of time between January and June 2015. We also randomly identified an equal-sized set of regular users exposed to the extremist content generated by the ISIS accounts, and collected almost 30 million tweets generated by the regular users in the same period of time.\n\nBy means of state-of-the-art learning models we managed to accomplish predictions in two types of scenarios, a static one that ignores temporal dependencies, and a simulated real-time case in which data are processed for training and testing by respecting the timeline of content availability. The two learning models, and the set of 52 features that we carefully crafted, proved very effective in all of the six combinations of forecasts (three prediction tasks each with two prediction modalities, static and real-time). The best performance in terms of AUC ranges between 72% and 93%, depending on the complexity of the considered task and the amount of training data available to the system.\n\nWe concluded our analysis by investigating the predictive power of different features. We focused on the top 11 most significant features, and we discovered that some of them, such as the ratio of retweets to tweets, the average number of hashtags adopted, the sheer number of tweets, and the average number of retweets generated by each user, systematically rank very high in terms of predictive power. Our insights shed light on the dynamics of extremist content production as well as some of the network and timing patterns that emerge in this type of online conversation.\n\nOur work is far from concluded: for the future, we plan to identify more realistic and complex prediction tasks, to analyze the network and temporal dynamics of extremist discussion, and to deploy a prototype system that allows for real-time detection of signatures of abuse on social media.",
                    "score": 0.850884639416053
                },
                {
                    "context": "2. Data and Preliminary Analysis\n\nIn this section we describe our dataset, the curation strategy yielding the annotations, and some preliminary analysis.\n\n 2.1. Sample selection and curation\n\nIn this work we rely on data and labels constructed by using a procedure of manual curation and expert verification. We retrieved on a public Website a list of over 25 thousands Twitter accounts whose activity was labeled as supportive of the Islamic State by the crowd-sourcing initiative called Lucky Troll Club. The goal of this project was to leverage annotators with expertise in Arabic languages to identify ISIS accounts and report them to Twitter. Twitter’s anti-abuse team manually verifies all suspension requests, and grants some based on the active violation of Twitter’s Terms of Service policy against terrorist- or extremist-related activity. Here we focus on the 25,538 accounts that have been all suspended between January and June 2015 by Twitter as a consequence of evidence of activity supporting the Islamic State group. For each account, we also have at our disposal information about the suspension date, and the number of followers of that user as of the suspension date.\n\n 2.2. Twitter data collection\n\nThe next step of our study consisted in collecting data related to the activity of the 25,538 ISIS supporters on Twitter. To this purpose, we leveraged the Twitter gardenhose data source (roughly 10% of the Twitter stream) collected by Indiana University [8]. We decided to collect not only the tweets generated by these accounts prior to their suspension, but also to build a dataset of their targets. In particular, we are concerned with accounts unrelated to ISIS with whom the ISIS supporters tried to establish some forms of interaction. We therefore constructed the following two datasets:\n\n- ISIS accounts: this dataset contains 3,395,901 tweets generated in the time interval January-June 2015 by the 25,538 accounts identified by Twitter as supporters of ISIS. This is a significant portion of all the accounts suspended by Twitter in relation to ISIS.1\n- Users exposed to ISIS: this dataset contains 29,193,267 tweets generated during January-June 2015 by a set of 25 thousand users randomly sampled among the larger set of users that constitute ISIS accounts’ followers. This set is by choice of equal size to the former one, to avoid introducing class imbalance issues.\n\nFor prediction purposes, we will use as positive and negative labels the ISIS accounts group and the accounts in the users exposed to ISIS, respectively.\n\n1 The Guardian recently reported that between April 2015 and February 2016, Twitter’s anti-terror task force suspended about 125,000 accounts linked to ISIS extremists: http://www.theguardian.com/technology/2016/feb/05/twitter-deletes-isis-accounts-terrorism-online\n\n 3. Methodology\n\nIn this section we discuss the learning models and the features adopted by our framework. The complete prediction pipeline (learning models, cross validation, feature selection, and performance evaluation) is developed using Python and the scikit-learn library [9].\n\n 3.1. Learning models\n\nWe adopt two off-the-shelf learning models as a proof of concept for the three classification tasks that we will discuss later (see §4): Logistic Regression and Random Forests.\n\n Logistic Regression:\n\nThe first implemented algorithm is a simple Logistic Regression (LR) with LASSO regularization. The advantage of this approach is its scalability, which makes it very effective to (possibly real-time) classification tasks on large datasets. The only parameter to tune is the loss function C. We expect that LR will provide the baseline classification and prediction performance.\n\n Random Forests:\n\nWe also use a state-of-the-art implementation of Random Forests (RF) [10]. The vectors fed into the learning models represent each user’s features. Random Forests are trained using 100 estimators and adopting the Gini coefficient to measure the quality of splits. Optimal parameters setting is obtained via cross validation (see 3.1.1).\n\nNote that the goal of this work is not to provide new machine learning techniques, but to illustrate that existing methods can provide promising results. We also explored additional learning models (e.g., SVM, Stochastic Gradient Descent, etc.), which provide comparable prediction performance but are less computationally efficient and scalable.\n\n 3.1.1. Cross validation.\n\nThe results of our performance evaluation (see §4) are all obtained via k-fold cross validation. We adopt k = 5 folds, and therefore use 80% of data for training, and the remainder 20% for testing purpose, averaging performance scores across the 5 folds. We also use 5-fold cross validation to optimize the parameters of the two learning algorithms (LR and RF), by means of an exhaustive cross-validated grid search on the hyperparameter space.\n\n 3.1.2. Evaluation scores.",
                    "score": 0.8361142575037643
                },
                {
                    "context": "4.1. T1: Detection of extremist supporters\n\nIn the following we discuss the static (T1A) and real-time (T1B) scenarios for the first prediction task, namely detecting extremist accounts on Twitter. For example, in the first column, the learning models are trained on data from January 2015, and the prediction are performed and evaluated on future data in the interval February-June 2015.\n\n 4.1.1. T1A: Time-independent detection.\n\nThe detection of extremist user accounts is the most natural task to start the performance evaluation of our framework. Our analysis aims at verifying that the 52 features we carefully hand-crafted indeed carry some predictive signal useful to separate extremist users from regular ones. The dataset at hand contains two roughly equal-sized classes (about 25 thousand instances each), where ISIS accounts are labeled as positive instances, and regular users as negative ones. Each instance is characterized by a 52-dimensional vector, and positive and negative examples are fed to the two learning models (LR and RF). The first task, in short T1A, is agnostic of time dependencies: data are aggregated throughout the entire 6 months period (January-June 2015) and training/testing is performed in a traditional 5-fold cross-validated fashion (cf. §3.1.1).",
                    "score": 0.8217466695851663
                },
                {
                    "context": "4.4. Feature predictive-power analysis\n\nWe conclude our analysis by discussing the predictive power of the features adopted by our framework. First, the choice to focus on the top 11 features, rather than the more traditional top 10, is justified by the occurrence of two ex aequo in the final ranking of top features, displayed in Table 8. Here, we report the ranking of the top 11 features in the three tasks above. Feature selection is performed on the real-time prediction tasks (not on the time-aggregated ones). This analysis captures the essence of the predictive value of our hand-crafted features in the context of real-time predictions. A clear pattern emerges: (1) ratio of retweets over tweets, (2) average number of hashtags, (2 ex-aequo) number of tweets, and (4) average number of retweets, consistently ranked in the top features for the three different prediction tasks. This insight is encouraging: all these features can be easily computed from the metadata reported by the Twitter API, and therefore could be potentially implemented in a real-time detection and prediction system operating on the Twitter stream with unparalleled efficiency.\n\nUsing Twitter data as a historical archive, some researchers recently tried to unveil the roots of support for extremist propaganda using online data as a proxy to study individual and group behaviors. Various recent studies focus on English- and Arabic-speaking audiences online to study the effect of ISIS’ propaganda and radicalization. One example of the former is the work by Berger and collaborators that provided quantitative evidence of ISIS’ use of social media for propaganda. In a 2015 study [21], the authors characterized the Twitter population of ISIS supporters, quantifying its size, provenance, and organization. They argued that most of ISIS’ success on Twitter is due to a restricted number of highly-active accounts (500-1000 users). Our analysis illustrates that indeed a limited number of ISIS accounts achieved a very high visibility and followership. Berger’s subsequent work [22] however suggested that ISIS’ reach (at least among English speakers) has stalled for months as of the beginning of 2016, due to more aggressive account suspension policies enacted by Twitter. Again, a limited amount of English accounts sympathetic to ISIS was found (less than one thousand), and these users were mostly interacting with each other, while being only marginally successful at acquiring other users’ attention. This analysis suggests a mechanism of diminishing returns for extremist social media propaganda.",
                    "score": 0.6603452667864421
                },
                {
                    "context": "ISIS among the Arabic-speaking population. Their analysis seems to suggest that supporters of the extremist group have been discussing about Arab Spring uprisings in the past significantly more than those who oppose ISIS on Twitter. Although their method to separate ISIS supporters from opposers is simplistic, the findings relating narrative framing and recruitment mechanisms are compatible with the literature on social protest phenomena [24], [25], [26].\n\nA few studies explored alternative data sources: one interesting example is the work by Vergani and Bliuc [27] that uses sentiment analysis (Linguistic Inquiry and Word Count [28]) to investigate how language evolved across the first 11 Issues of Dabiq, the flagship ISIS propaganda magazine. Their analysis offers some insights about ISIS radicalization motives, emotions and concerns. For example, the authors found that ISIS has become increasingly concerned with females, reflecting their need to attract women to create their utopia society, not revolving around warriors but around families. ISIS also seems to have increased the use of internet jargon, possibly to connect with the identities of young individuals online.\n\n Computer science research\n\nThis research stream concerns more with the machine learning and data aspects, to model, detect, and/or predict social phenomena such as extremism or radicalization often with newly-developed techniques.\n\nOne of the first computational frameworks, proposed by Bermingham et al. [29] in 2009, combined social network analysis with sentiment detection tools to study the agenda of a radical YouTube group: the authors examined the topics discussed within the group and their polarity, to model individuals’ behavior and spot signs of extremism and intolerance, seemingly more prominent among female users. The detection of extremist content (on the Web) was also the focus of a 2010 work by Qi et al. [30]. The authors applied hierarchical clustering to extremist Web pages to divide them into different categories (religious, politics, etc.).\n\nScanlon and Gerber proposed the first method to detect cyber-recruitment efforts in 2014 [31]. They exploited data retrieved from the Dark Web Portal Project [32], a repository of posts compiled from 28 different online fora on extremist religious discussions (e.g., Jihadist) translated from Arabic to English. After annotating a sample of posts as recruitment efforts or not, the authors use Bayesian criteria and a set of textual features to classify the rest of the corpus, obtaining good accuracy, and highlighted the most predictive terms.\n\nAlong the same trend, Agarwal and Sureka proposed different machine learning strategies [33], [34], [35], [36] aimed at detecting radicalization efforts, cyber recruitment, hate promotion, and extremist support in a variety of online platforms, including YouTube, Twitter and Tumblr. Their frameworks leverage features of contents and metadata, and combinations of crawling and unsupervised clustering methods, to study the online activity of Jihadist groups on the platforms mentioned above.\n\nConcluding, two very recent articles [37], [38] explore the activity of ISIS on social media. The former [37] focuses on Twitter and aims at detecting users who exhibit signals of behavioral change in line with radicalization: the authors suggest that out of 154K users only about 700 show significant signs of possible radicalization, and that may be due to social homophily rather than the mere exposure to propaganda content. The latter study [38] explores a set of 196 pro-ISIS aggregates operating on VKontakte (the most popular Russian online social network) and involving about 100K users, to study the dynamics of survival of such groups online: the authors suggest that the development of large and potentially influential pro-ISIS groups can be hindered by targeting and shutting down smaller ones. For additional pointers we refer the interested reader to two recent literature reviews on this topic [39], [40].\n\n 6. Conclusions\n\nIn this article we presented the problem of predicting online extremism in social media. We defined three machine learning tasks, namely the detection of extremist users, the prediction of extremist content adoption, and the forecasting of interactions between extremist users and regular users. We tapped into the power of a crowd-sourcing project that aimed at manually identifying and reporting suspicious or abusive activity related to ISIS radicalization and propaganda agenda, and collected annotations to build a ground-truth of over 25 thousand suspended Twitter accounts. We extracted over three million tweets related to the activity of these accounts in the period of time between January and June 2015. We also randomly identified an equal-sized set of regular users exposed to the extremist content generated by the ISIS accounts, and collected almost 30 million tweets generated by the regular users in the same period of time.\n\nBy means of state-of-the-art learning models we managed to accomplish predictions in two types of scenarios, a static one that ignores temporal dependencies, and a simulated real-time case in which data are processed for training and testing by respecting the timeline of content availability.",
                    "score": 0.5166459563451526
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What was the size of the dataset analyzed in the article?",
                    "answer": "The dataset analyzed in the article consisted of over 25,538 suspended Twitter accounts identified as supportive of ISIS, along with 3,395,901 tweets generated by these accounts. Additionally, there was a dataset of 25,000 regular users exposed to ISIS content, which included almost 30 million tweets generated by these users during the same period."
                },
                {
                    "question": "[SQ] What criteria were used to identify the suspended Twitter accounts as supportive of ISIS?",
                    "answer": "The suspended Twitter accounts were identified as supportive of ISIS through a crowd-sourcing initiative called Lucky Troll Club, which involved annotators with expertise in Arabic languages. These annotators manually identified and reported accounts that exhibited activity supportive of the Islamic State. The suspension requests were then verified by Twitter's anti-abuse team, which granted suspensions based on evidence of violations of Twitter's Terms of Service policy against terrorist- or extremist-related activity."
                },
                {
                    "question": "[SQ] How was the dataset of regular users exposed to ISIS content compiled?",
                    "answer": "The dataset of regular users exposed to ISIS content was compiled by randomly identifying a set of 25 thousand users from the larger group of users who followed the ISIS accounts. This selection was made to ensure that the dataset was of equal size to the dataset of ISIS accounts, thereby avoiding class imbalance issues. The tweets generated by these regular users during the same time period, from January to June 2015, were then collected, resulting in almost 30 million tweets."
                },
                {
                    "question": "[SQ] What time period does the dataset cover for the tweets generated by both suspended accounts and regular users?",
                    "answer": "The dataset covers the time period from January to June 2015 for the tweets generated by both suspended accounts and regular users."
                },
                {
                    "question": "[MQ] What was the size of the analyzed dataset, including the 25,538 suspended Twitter accounts supportive of ISIS and the 25,000 regular users exposed to ISIS content, along with their respective tweet counts?",
                    "answer": "The analyzed dataset included a total of 50,538 accounts, comprising 25,538 suspended Twitter accounts supportive of ISIS and 25,000 regular users exposed to ISIS content. The tweet counts associated with these accounts were 3,395,901 tweets generated by the ISIS accounts and 29,193,267 tweets generated by the regular users."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 1.0,
                "semantic_similarity": 0.8845409327269976,
                "llm_context_precision_without_reference": 0.7329365079242922,
                "llm_context_precision_with_reference": 0.5694444444254629,
                "answer_relevancy": 0.8613123038063275,
                "answer_correctness": 0.38780189984841607
            },
            "deepeval": {
                "contextual_precision": 0.7736111111111109,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.358974358974359,
                "answer_relevancy": 1.0,
                "faithfulness": 0.8181818181818182
            }
        },
    },
    {
        "id": 5,
        "job_id": 1,
        "file_id": 1,
        "question_id": 5,
        "status": "done",
        "answer_text": "The performance metrics evaluated in the study include Precision, Recall, F1 Score, and AUC. Here are the corresponding values for the models:\n\n1. **Logistic Regression:**\n   - Precision: 0.433\n   - Recall: 0.813\n   - F1 Score: 0.565\n   - AUC: 0.755\n\n2. **Random Forests:**\n   - Precision: 0.745\n   - Recall: 0.615\n   - F1 Score: 0.674\n   - AUC: 0.771\n\nAdditionally, for different training and testing periods, the metrics for Logistic Regression and Random Forests varied, with specific values provided for each period. For example, in one training/testing scenario:\n- Logistic Regression AUC: 0.610, Precision: 0.562, Recall: 0.720, F1: 0.631\n- Random Forest AUC: 0.628, Precision: 0.614, Recall: 0.779, F1: 0.687\n\nThese metrics reflect the models' effectiveness in classification tasks over time.",
        "answer_encoded": "[response not coded] The performance metrics in the study included Precision, Recall, F1 Score, and AUC, with values for Logistic Regression being Precision: 0.433, Recall: 0.813, F1 Score: 0.565, AUC: 0.755, and for Random Forests being Precision: 0.745, Recall: 0.615, F1 Score: 0.674, AUC: 0.771, with variations noted for different training/testing periods.",
        "answer_contexts": [
                {
                    "context": "This table presents the performance metrics of two machine learning models (Logistic Regression and Random Forest) across different training and testing periods. Metrics include AUC, Precision, Recall, and F1 score, indicating the models' effectiveness in classification tasks over time.,\nwith the following columns:\n- Training: Different training periods for the models.\n- Testing: Different testing periods for the models.\n- AUC (LR): Area Under the Curve for Logistic Regression.\n- Precision (LR): Precision for Logistic Regression.\n- Recall (LR): Recall for Logistic Regression.\n- F1 (LR): F1 score for Logistic Regression.\n- AUC (RF): Area Under the Curve for Random Forest.\n- Precision (RF): Precision for Random Forest.\n- Recall (RF): Recall for Random Forest.\n- F1 (RF): F1 score for Random Forest.\n\n| Training:      | Jan     | Jan-Feb | Jan-Mar | Jan-Apr | Jan-May |\n|---|---|---|---|---|---|\n| Testing:       | Feb-Jun | Mar-Jun | Apr-Jun | May-Jun | Jun     |\n| AUC (LR)       | 0.610   | 0.589   | 0.618   | 0.638   | 0.683   |\n| Precision (LR) | 0.562   | 0.560   | 0.574   | 0.553   | 0.367   |\n| Recall (LR)    | 0.720   | 0.775   | 0.813   | 0.783   | 0.647   |\n| F1 (LR)        | 0.631   | 0.650   | 0.672   | 0.649   | 0.468   |\n| AUC (RF)       | 0.628   | 0.633   | 0.649   | 0.671   | 0.726   |\n| Precision (RF) | 0.614   | 0.627   | 0.603   | 0.637   | 0.542   |\n| Recall (RF)    | 0.779   | 0.676   | 0.641   | 0.717   | 0.765   |\n| F1 (RF)        | 0.687   | 0.650   | 0.621   | 0.675   | 0.634   |",
                    "score": 0.8629644138511097
                },
                {
                    "context": "This table compares the performance metrics of two machine learning models: Logistic Regression and Random Forests, focusing on Precision, Recall, F1 Score, and AUC.,\nwith the following columns:\n- Model: The name of the machine learning model.\n- Precision: The precision score of the model.\n- Recall: The recall score of the model.\n- F1: The F1 score of the model.\n- AUC: The area under the curve score of the model.\n\n|                     | Precision | Recall | F1    | AUC   |\n|---|---|---|---|---|\n| Logistic Regression |0.697|0.69|0.693|0.658|\n| Random Forests      |0.686|0.83|0.751|0.692|",
                    "score": 0.8586486316266605
                },
                {
                    "context": "This table compares the performance metrics of two machine learning models, Logistic Regression and Random Forests, using Precision, Recall, F1 Score, and AUC as evaluation criteria.,\nwith the following columns:\n- Model: The name of the machine learning model.\n- Precision: The ratio of true positive predictions to the total predicted positives.\n- Recall: The ratio of true positive predictions to the total actual positives.\n- F1: The harmonic mean of Precision and Recall.\n- AUC: The area under the ROC curve, indicating the model's ability to distinguish between classes.\n\n|                     | Precision | Recall | F1    | AUC   |\n|---|---|---|---|---|\n| Logistic Regression |0.433|0.813|0.565|0.755|\n| Random Forests      |0.745|0.615|0.674|0.771|",
                    "score": 0.857604137954446
                },
                {
                    "context": "This table presents the performance metrics of two machine learning models (Logistic Regression and Random Forest) for real-time extremist detection across different training and testing periods. Metrics include AUC, Precision, Recall, and F1 score, indicating the effectiveness of each model over time.,\nwith the following table title:\nTABLE 3. REAL-TIME EXTREMISTS DETECTION (T1B),\nwith the following columns:\n- Training: Different training periods for the models.\n- Testing: Different testing periods for the models.\n- AUC (LR): Area Under the Curve for Logistic Regression.\n- Precision (LR): Precision for Logistic Regression.\n- Recall (LR): Recall for Logistic Regression.\n- F1 (LR): F1 score for Logistic Regression.\n- AUC (RF): Area Under the Curve for Random Forest.\n- Precision (RF): Precision for Random Forest.\n- Recall (RF): Recall for Random Forest.\n- F1 (RF): F1 score for Random Forest.\n\n|   |                |         | TABLE 3. REAL-TIME EXTREMISTS DETECTION (T1B) |         .1|         .2|         .3|\n|---|---|---|---|---|---|---|\n|   | Training:      | Jan     | Jan-Feb                                       | Jan-Mar | Jan-Apr | Jan-May |\n|   | Testing:       | Feb-Jun | Mar-Jun                                       | Apr-Jun | May-Jun | Jun     |\n|   | AUC (LR)       | 0.743   | 0.753                                         | 0.655   | 0.612   | 0.602   |\n|   | Precision (LR) | 0.476   | 0.532                                         | 0.792   | 0.816   | 0.796   |\n|   | Recall (LR)    | 0.629   | 0.675                                         | 0.377   | 0.289   | 0.275   |\n|   | F1 (LR)        | 0.542   | 0.595                                         | 0.511   | 0.427   | 0.409   |\n|   | AUC (RF)       | 0.838   | 0.858                                         | 0.791   | 0.942   | 0.932   |\n|   | Precision (RF) | 0.984   | 0.922                                         | 0.868   | 0.931   | 0.910   |\n|   | Recall (RF)    | 0.679   | 0.733                                         | 0.649   | 0.957   | 0.959   |\n|   | F1 (RF)        | 0.804   | 0.817                                         | 0.743   | 0.944   | 0.934   |",
                    "score": 0.6893299239298152
                },
                {
                    "context": "This table presents performance metrics of a logistic regression model across different training and testing time periods, including AUC, precision, recall, and F1 score.,\nwith the following columns:\n- Training: Time periods used for training the model.\n- Testing: Time periods used for testing the model.\n- AUC (LR): Area Under the Curve for the logistic regression model.\n- Precision (LR): Precision metric for the logistic regression model.\n- Recall (LR): Recall metric for the logistic regression model.\n- F1 (LR): F1 score for the logistic regression model.\n\n|   | Training | Testing | AUC (LR) | Precision (LR) | Recall (LR) | F1 (LR) |\n|---|---|---|---|---|---|---|\n|   | Jan      | Feb-Jun |0.682|0.188|0.814|0.305|\n|   | Jan-Feb  | Mar-Jun |0.674|0.24|0.367|0.29|\n|   | Jan-Mar  | Apr-Jun |0.673|0.148|0.345|0.207|\n|   | Jan-Apr  | May-Jun |0.703|0.116|0.725|0.199|\n|   | Jan-May  | Jun     |0.718|0.043|0.362|0.077|",
                    "score": 0.5198658357967348
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific performance metrics were evaluated in the study, and what were their corresponding values?",
                    "answer": "The performance metrics evaluated in the study include Precision, Recall, F1 Score, and AUC. Here are the corresponding values for the models:\n\n1. **Logistic Regression:**\n   - Precision: 0.433\n   - Recall: 0.813\n   - F1 Score: 0.565\n   - AUC: 0.755\n\n2. **Random Forests:**\n   - Precision: 0.745\n   - Recall: 0.615\n   - F1 Score: 0.674\n   - AUC: 0.771\n\nAdditionally, for different training and testing periods, the metrics for Logistic Regression and Random Forests varied, with specific values provided for each period. For example, in one training/testing scenario:\n- Logistic Regression AUC: 0.610, Precision: 0.562, Recall: 0.720, F1: 0.631\n- Random Forest AUC: 0.628, Precision: 0.614, Recall: 0.779, F1: 0.687\n\nThese metrics reflect the models' effectiveness in classification tasks over time."
                },
                {
                    "question": "[SQ] What were the performance metrics for the models evaluated during different training and testing periods?",
                    "answer": "The performance metrics for the models evaluated during different training and testing periods include the following:\n\nFor Logistic Regression:\n- AUC ranged from 0.610 to 0.683 across different training periods.\n- Precision varied from 0.367 to 0.574.\n- Recall ranged from 0.647 to 0.813.\n- F1 score fluctuated between 0.468 and 0.672.\n\nFor Random Forest:\n- AUC ranged from 0.628 to 0.726.\n- Precision varied from 0.542 to 0.637.\n- Recall ranged from 0.641 to 0.779.\n- F1 score fluctuated between 0.621 and 0.687.\n\nIn another evaluation for real-time extremist detection:\nFor Logistic Regression:\n- AUC ranged from 0.602 to 0.753.\n- Precision varied from 0.476 to 0.816.\n- Recall ranged from 0.275 to 0.675.\n- F1 score fluctuated between 0.409 and 0.595.\n\nFor Random Forest:\n- AUC ranged from 0.838 to 0.942.\n- Precision varied from 0.868 to 0.984.\n- Recall ranged from 0.649 to 0.959.\n- F1 score fluctuated between 0.743 and 0.944."
                },
                {
                    "question": "[SQ] How did the performance metrics of Logistic Regression compare to those of Random Forests in the study?",
                    "answer": "The performance metrics of Logistic Regression and Random Forests varied across different evaluations. In one comparison, Logistic Regression achieved a precision of 0.697, recall of 0.69, F1 score of 0.693, and AUC of 0.658, while Random Forests had a precision of 0.686, recall of 0.83, F1 score of 0.751, and AUC of 0.692. Here, Random Forests outperformed Logistic Regression in recall and F1 score, while Logistic Regression had a slightly higher precision.\n\nIn another evaluation, Logistic Regression scored a precision of 0.433, recall of 0.813, F1 score of 0.565, and AUC of 0.755, compared to Random Forests, which had a precision of 0.745, recall of 0.615, F1 score of 0.674, and AUC of 0.771. In this instance, Random Forests excelled in precision and AUC, while Logistic Regression had a higher recall.\n\nAcross different training and testing periods, the performance metrics also showed variability. For instance, in the real-time extremist detection task, Logistic Regression had an AUC ranging from 0.602 to 0.743, while Random Forests achieved AUC values between 0.791 and 0.942, indicating that Random Forests consistently outperformed Logistic Regression in this context as well.\n\nOverall, Random Forests generally demonstrated stronger performance in terms of AUC and F1 score, while Logistic Regression had instances of higher recall and precision depending on the specific evaluation."
                },
                {
                    "question": "[SQ] Were there any other models evaluated in the study, and what were their performance metrics?",
                    "answer": "The study explored additional learning models, including SVM and Stochastic Gradient Descent, which provided comparable prediction performance. However, specific performance metrics for these models were not detailed in the provided information. The focus was primarily on the performance of Logistic Regression and Random Forests, with their respective metrics outlined in the tables."
                },
                {
                    "question": "[MQ] What were the evaluated performance metrics, including Precision, Recall, F1 Score, and AUC, for Logistic Regression and Random Forests in the study, along with their corresponding values across different training and testing periods?",
                    "answer": "The evaluated performance metrics for Logistic Regression and Random Forests included Precision, Recall, F1 Score, and AUC across various training and testing periods. Here are the corresponding values:\n\n**Logistic Regression:**\n- **AUC:**\n  - Jan: 0.610\n  - Jan-Feb: 0.589\n  - Jan-Mar: 0.618\n  - Jan-Apr: 0.638\n  - Jan-May: 0.683\n- **Precision:**\n  - Jan: 0.562\n  - Jan-Feb: 0.560\n  - Jan-Mar: 0.574\n  - Jan-Apr: 0.553\n  - Jan-May: 0.367\n- **Recall:**\n  - Jan: 0.720\n  - Jan-Feb: 0.775\n  - Jan-Mar: 0.813\n  - Jan-Apr: 0.783\n  - Jan-May: 0.647\n- **F1 Score:**\n  - Jan: 0.631\n  - Jan-Feb: 0.650\n  - Jan-Mar: 0.672\n  - Jan-Apr: 0.649\n  - Jan-May: 0.468\n\n**Random Forests:**\n- **AUC:**\n  - Jan: 0.628\n  - Jan-Feb: 0.633\n  - Jan-Mar: 0.649\n  - Jan-Apr: 0.671\n  - Jan-May: 0.726\n- **Precision:**\n  - Jan: 0.614\n  - Jan-Feb: 0.627\n  - Jan-Mar: 0.603\n  - Jan-Apr: 0.637\n  - Jan-May: 0.542\n- **Recall:**\n  - Jan: 0.779\n  - Jan-Feb: 0.676\n  - Jan-Mar: 0.641\n  - Jan-Apr: 0.717\n  - Jan-May: 0.765\n- **F1 Score:**\n  - Jan: 0.687\n  - Jan-Feb: 0.650\n  - Jan-Mar: 0.621\n  - Jan-Apr: 0.675\n  - Jan-May: 0.634\n\nThese metrics reflect the models' effectiveness in classification tasks over the specified time periods."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 0.0,
                "faithfulness": 1.0,
                "semantic_similarity": 0.7913926406183261,
                "llm_context_precision_without_reference": 0.9999999999833333,
                "llm_context_precision_with_reference": 0.0,
                "answer_relevancy": 0.8746243004758223,
                "answer_correctness": 0.19784816015458154
            },
            "deepeval": {
                "contextual_precision": 0.7708333333333333,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.8923076923076924,
                "answer_relevancy": 0.391304347826087,
                "faithfulness": 1.0
            }
        }
    },
    {
        "id": 6,
        "job_id": 1,
        "file_id": 2,
        "question_id": 1,
        "status": "done",
        "answer_text": "The study utilized three specific one-class classifiers: Random Forest, Naive Bayes, and Decision Tree. These algorithms contributed to the overall findings by effectively classifying posts as having racist or radicalized intent based on their content. They were trained on a highly imbalanced dataset, where only a small percentage of posts were labeled as intent posts. The classifiers' ability to evaluate intent classification with a focus on high precision and recall allowed the researchers to demonstrate that these algorithms could accurately identify posts with such intent, thereby enhancing the understanding of intent mining in social media contexts.",
        "answer_encoded": "RF, Decision Trees, Naive Bayes",
        "answer_contexts": [
                {
                    "context": "Our training data contains only positive class (intent) posts. We implement three different one-class classifiers (Random Forest (RF), Naive Bayes (NB) and Decision Tree (DT)) and compare their accuracy for the posts classified as topic in Stage 1. We train our model for each classifier and perform 5 fold cross validation. As discussed in Section V and shown in Figure 2, only 12% of the posts are labeled as intent posts making our experimental dataset highly imbalanced. Further, intent classifier takes only the topic posts as an input classified by topic classifier which is again a small subset of whole dataset. Therefore, we select classification algorithms that works for small training data.\n\n VII. PERFORMANCE EVALUATION\n\nAs described in Section VI-B, proposed method is a cascaded ensemble learning classifier in which topic classifier uses complete experimental dataset as an input while intent classifier takes input from Stage 1. In this Section, we present the accuracy results of each classifier and also discuss the influence of topic classification’s accuracy on intent post classification. Based upon the inter-annotator agreement results, we evaluate the accuracy of our classifier by comparing the observed results against actual labeled class. We conduct our experiments on 2,419 posts, consistently labeled by both annotators. Proposed topic classifier classifies 346 posts as target (topic) class and 2,073 posts as unknown. Table IV reveals that there is a misclassification of 3.8% and 1.6% in identifying target and outliers (unknown) posts. Since, the focus of our study is to identify all such posts that have racist or radicalized intent, our aim is to achieve high precision as well as high recall. Our results reveal that for topic classification, we are able to achieve a precision of 73% (253/(253+93)) and a recall of 86% (253/(253+39)). Given that our data is highly imbalanced and only 12% of the posts are labeled as target (intent) class, we execute.",
                    "score": 0.5666765611463801
                },
                {
                    "context": "We exclude contextual metadata from our feature space as those are not discriminatory for intent or topic classification.\n\n B. Classification\n\nThe third phase of our proposed framework is a cascaded ensemble learning based classifier primarily consisting of two stages: topic classification and intent classification. We train our model from feature vectors created in Phase 2 and perform one-class classification on Tumblr posts.\n\n Topic Classification\n\nTo identify the posts that belong to a defined topic (Race or Religion), we use topic modeling linguistic features extracted using natural language processing. We take a random sample of 50 posts out of 292, annotated as topic posts and extract their taxonomy and concepts from the feature space. We create two independent lexicons of these concepts and labeled topics that has a confidence score above 0.40. We manually filter the list of taxonomy and finalize the following 6 labels that strictly belong to the topic of this study: religion and spirituality, society/unrest and war, society/racism, society/personal offense/hate crime, law, govt & politics/espionage and intelligence/terrorism and law, govt & politics/legal issues/human rights.\n\nWe use a look-up based method and check if the post belongs to any of these taxonomies and has a confidence score above 0.40. If yes, then we classify it as a topic post. However, if a post contains a wide range of taxonomies (>5) then we identify the top K concepts in the text and check if they exist in the concept lexicon of labeled topic posts. This stage of cascaded classifier is a one-class classifier that takes complete experimental dataset as an input and classifies topic related posts from unknown posts.\n\n Intent Classification\n\nAn intent of a post (consisting of free-form text) cannot be fully determined only by mining the keywords in the content. But it also requires to understand and predict the psychological tendency, sentiment tones and language of the narrative. It also requires to analyze the semantic role of topic related keywords used in the post. We perform classification on Tumblr posts by training our model on sentiment, semantic and language cues based features of a text. On a high level, we create a vector space of 5 features set (F1 to F5) which is further categorized into 15 unique vectors. Table III shows the list of all features extracted and grouped into 5 feature vectors. We define intent classification as a one-class classification problem. Therefore,",
                    "score": 0.47868411514581183
                },
                {
                    "context": "1) To the best of our knowledge, the study presented in this paper is the first work on racist and radicalization detection based on the intent of narrative unlike previous keyword spotting methods.\n\n2) We apply natural language processing techniques on Tumblr posts for identifying discriminatory features for intent classification.\n\n3) We publish the first ever semantically and sentimental enriched data of Tumblr posts and make our data publicly available for benchmarking and extension2 [11].\n\n4) The study presented in this paper is an extended version of our work Agarwal et al. accepted as a short paper in European Intelligence and Security Informatics Conference (EISIC 2016) [12]. Due to the small page limit for short papers (at most four pages) in EISIC 20163, several aspects including results and details of proposed approach are not covered. This paper presents the complete and detailed description of our work on intent based classification of racist and radicalized posts made on Tumblr micro-blogging website.\n\n IV. PROBLEM STATEMENT\n\nGiven a dataset D of Tumblr Posts Pi, D = {Pi | 1 ≤ i ≤ n}, a set of topics N = {Nj | 1 ≤ j ≤ m} and a target class C; identify the intent of Pi ∈ D when Pi ∈ N.\n\nBased on the definition of freedom of expression by Joshua Cohen [1], we define a Tumblr post P as a racist intent post if:\n\n1. the topic of the content belongs to a race or a religion and\n2. the post targets a community in an offensive or persuasive manner (in a recognizable way).\n\nIn order to identify a racist or radicalized intent post, we propose following two hypotheses:\n\n1. In the absence of topic related key-terms, natural language processing can be an efficient approach to identify hidden taxonomy of a Tumblr post.\n2. Sentiment and semantic enrichment of text can be two discriminatory features for identifying the language of narrative and classifying the intent posts.\n\n V. EXPERIMENTAL SETUP\n\nData Collection: We conduct our experiments on an open source and real time dataset extracted from Tumblr microblogging website. We perform a manual inspection and find most popular Tumblr posts having racist and radicalized intent. We extract the list of unique tags associated with these posts and create a lexicon of top K tags that are the most commonly used by racist or radicalized groups. For example, #islamophobia, #islam is evil, #supremacy, #blacklivesmatter, #white racism, #jihad, #isis and #white genocide. We implement a bootstrapping method to create our dataset and use this lexicon as seed tags for the Tumblr Search API4. For each tag, we extract only textual posts (text and quote) and extend our lexicon by acquiring other (unique) related tags associated with these posts. We execute our model until we get a desired number of posts or the model converges (it starts extracting duplicate posts). Using Tumblr Search API, we were able to extract a total of 3,228 text posts made by 2,224 unique bloggers consisting of 10,217 unique tags. Table I shows a complete schema of additional metadata extracted for each post and unique blogger. The aim of the study presented in this paper is to build a one-class text classifier for identifying racist and hate promoting intent posts. Therefore, we conduct our experiments on post content (referred as description in Tumblr). Since, Tumblr generates a new identification number for each post (re-blogged or posted), despite having the unique Post IDs, we discard 9% (273) of the posts having similar or duplicate content and remove the bias from our data.\n\nThe study presented in this paper focuses on intent mining on English language posts. We identify the language of each record by applying Alchemy language detection API5 on post description. Figure 2 reveals that only 83% (2,456...",
                    "score": 0.47447814339634065
                },
                {
                    "context": "VI. PROPOSED APPROACH\n\nFigure 3 shows the high-level architecture of proposed approach primarily consisting of three phases: Data Extraction, Feature Identification and Classification. Section V describes the bootstrapping method used for data collection and inter-annotator agreement used for creating ground truth. We describe the remaining two phases in the following sections:\n\n A. Features Identification\n\nBased on the prior literature and our hypothesis design, we create our feature space by analyzing the linguistic features (semantic and sentiment tone) of Tumblr posts. We divide our features set into three categories: Topic Modeling, Tone Analysis and Semantic Tagging. We also discuss other contextual metadata features that can be extracted from Tumblr posts but are not applicable in intent classification.\n\n Topic Modeling:\n\nThe existing literature shows that there has been a lot of work in the area of mining user generated content on social media related to offensive speech [13], racism and radicalization [14][15]. However, our analysis and annotation reveals that despite not having certain topic specific key-terms, a post can be an intent post for which keyword based classification method do not work accurately and generates a large number of false alarms [3]. Therefore, we use statistical and natural language processing techniques to perform topic modeling on Tumblr posts. We use Alchemy Taxonomy API7 to classify the post into the most likely topic and sub-topic categories. Alchemy API supports over 1000 categories broadly divided into 23 topics. Sub-topic categories allows us to identify the more focused and targeted topic of post (up to 5 levels of hierarchy).\n\nFor example, society/crime/personal offense/hate crime. We also use Alchemy Concept Tagging API8 to identify the hidden concepts in the text that are similar to human annotation. Alchemy API learns about a post from linked data resources9 such as freebase, dbpedia, yago and tags the concepts that are high likely to be related to the given text. For example, for a Tumblr post “If the Arabs put down their weapons today, there would be no more violence. If the Jews put down their weapons today, there would be no more Israel.”, Alchemy tags “Ashkenazi Jews”, “Palestinian people” and “Jewish ethnic divisions” with a confidence score of 0.74, 0.78 and 0.70 respectively. We use these concepts to perform the topic modeling of a text along with the taxonomy. Statistically, the API returns a confidence score of each taxonomy conveying how likely the post belongs to derived category. We discard a category from taxonomy and concept lists if the confidence score is below 40%.\n\n Sentiment and Tone Analysis:\n\nInspired by the prior literature [10], we investigate language of narrative by analyzing various types of sentiments and personality traits in a post such as document sentiment, social tone, writing tone and emotions. We use Alchemy Document Sentiment API10 to identify the document-level polarity of overall sentiment of a post. We define five categories of sentiment polarity: strongly negative, negative, neutral, positive and strongly positive and categorize each post based on its sentiment score. The sentiment of a document or post differs from the tone analysis of the content. Sentiment analysis can only identify the positive and negative polarity of a post while tone analysis measures the level of three categories including emotion, social and writing tones. We conduct a linguistic analysis on Tumblr posts using IBM Watson Tone Analyzer API11. Emotions tone analyzes the text of a post and gives a distribution of 5 emotions namely joy, fear, sadness, anger and disgust. Social tendencies analyze the personality traits from the text that includes openness, conscientiousness, extraversion, agreeableness and emotional range of a narrative. Writing tone identifies the language cues of the author in context to the content written in a Tumblr post. It includes analytical, confident and tentative style of writing. The Tone Analyzer API analyzes the content of a post and computes two scores (document level and sentence level) for all three categories of tones. Since, the text length of posts in our experimental dataset varies from 1 to 1200 words, we select only document level measures of these tones. Similar to sentiment score, we create a feature vector of each tone and categorize each post based on the confidence score: very low, low, medium, high, and very high. Figure 4 shows a concrete example of Tumblr post related to Race topic and shows the level of emotion tone, language and personality traits of author.\n\n Semantic Tagging:\n\nSemantic tagging of a post identifies the semantic role of each term present in the content. It also identifies the hidden phrases playing major role in the\n\n10 http://www.alchemyapi.com/api/sentiment-analysis\n\n11 https://tone-analyzer-demo.mybluemix.net",
                    "score": 0.36681113252990194
                },
                {
                    "context": "[12] A. Swati and S. Ashish, “But I did not mean it!- intent classification of racist posts on tumblr,” in 6th IEEE European Intelligence & Security Informatics Conference (EISIC), Uppsala, Sweden. IEEE, 2016.\n\n[13] Y. Chen, Y. Zhou, S. Zhu, and H. Xu, “Detecting offensive language in social media to protect adolescent online safety,” in Privacy, Security, Risk and Trust (PASSAT), SocialCom. IEEE, 2012, pp. 71–80.\n\n[14] S. Agarwal and A. Sureka, “Spider and the flies: Focused crawling on tumblr to detect hate promoting communities,” arXiv preprint arXiv:1603.09164, 2016.\n\n[15] P. Burnap and M. L. Williams, “Us and them: identifying cyber hate on twitter across multiple protected characteristics,” EPJ Data Science, vol. 5, no. 1, p. 1, 2016.\n\n Limitations:\n\nIn this paper, we conduct our analysis only on English language posts. Our proposed approach has dependencies with the open source APIs used for the feature extraction. If a post contains multi-lingual text (for example, Arabic + English) then the APIs might not be able to extract the taxonomy or semantic features accurately. We make our model generalized and it can be used to identify racist and radicalized intent for any given text. However, the model might require some pre-processing and large training data for microposts as the topic modeling and tone analysis might not be 100% accurate for very short text such as tweets.\n\n VIII. CONCLUSIONS AND FUTURE WORK\n\nIn this paper, we study the problem of identifying racist and radicalized Tumblr posts based on the intent of narrative. We formulate our problem as a cascaded ensemble learning problem and propose a two-stage one-class classification approach to solve the problem. Our result shows that the proposed approach is effective for identifying intent posts unlike previous keyword based techniques. Our experimental results shows that emotion tone, writing cues and social personality traits of an author are discriminatory features for identifying the intent of the post. Further, topic classification of posts and filtering non-topic based (or noisy) posts improves the performance of the proposed intent classification.\n\nFuture work includes addressing the limitations of present study and improving the accuracy of linguistic features. Identification of multi-lingual posts by doing a sentence level language detection and enhancing the translated content for identifying intent posts. As mentioned in the previous sections, Tumblr is popularly known for the use of reaction gif images. Therefore, our future work involves mining users’ reactions from attached external images and enrichment of linguistic.",
                    "score": 0.2879637444083478
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific AI algorithm was utilized in the study, and how does it contribute to the overall findings presented in the article?",
                    "answer": "The study utilized three different one-class classifiers: Random Forest (RF), Naive Bayes (NB), and Decision Tree (DT). These algorithms were implemented to classify posts as having racist or radicalized intent based on the content of the posts. The classifiers were trained on a highly imbalanced dataset, where only 12% of the posts were labeled as intent posts. The use of these classifiers allowed the researchers to evaluate the accuracy of intent classification, with a focus on achieving high precision and recall. The findings indicated that the classifiers could effectively identify posts with racist or radicalized intent, contributing to the understanding of intent mining in social media contexts."
                },
                {
                    "question": "[SQ] What were the performance metrics used to evaluate the effectiveness of the AI algorithms in the study?",
                    "answer": "The performance metrics used to evaluate the effectiveness of the AI algorithms in the study included Recall and Precision. Additionally, the analysis also considered true positives, false positives, false negatives, true negatives, and accuracy metrics for the classifiers."
                },
                {
                    "question": "[SQ] How did the researchers handle the imbalanced dataset during the training of the classifiers?",
                    "answer": "The researchers addressed the imbalanced dataset by implementing one-class classifiers, specifically Random Forest, Naive Bayes, and Decision Tree, which are suitable for small training data. They focused on training the classifiers using only the positive class (intent) posts, as only 12% of the posts were labeled as intent posts. Additionally, they performed 5-fold cross-validation to ensure robust evaluation of the classifiers' performance despite the imbalance. The intent classifier was designed to take input only from the topic posts identified by the topic classifier, which further narrowed down the dataset to a more manageable subset for training."
                },
                {
                    "question": "[SQ] What specific features or attributes of the posts were considered by the AI algorithms to classify intent?",
                    "answer": "The AI algorithms considered various linguistic features for intent classification, which were categorized into three main areas: Topic Modeling, Tone Analysis, and Semantic Tagging. \n\n1. **Topic Modeling**: This involved extracting taxonomies and concepts from the posts using natural language processing techniques. The classifiers utilized a set of predefined topics relevant to the study, such as religion, society, and law.\n\n2. **Tone Analysis**: This included analyzing the sentiment and emotional tones of the posts. Features assessed were document sentiment (overall sentiment polarity), emotional tone (distribution of emotions like joy, fear, sadness, anger, and disgust), social tone (personality traits such as openness and conscientiousness), and writing tone (language cues like analytical or confident writing).\n\n3. **Semantic Tagging**: This feature identified the semantic roles of terms within the posts, helping to understand the context and meaning behind the content.\n\nThese features were crucial for accurately classifying posts with intent, particularly in understanding the psychological tendencies and sentiments expressed in the text."
                },
                {
                    "question": "[MQ] What one-class classifiers were employed in the study, and how did their use of linguistic features like Topic Modeling, Tone Analysis, and Semantic Tagging enhance the classification of posts with racist or radicalized intent?",
                    "answer": "The study employed three one-class classifiers: Random Forest (RF), Naive Bayes (NB), and Decision Tree (DT). The use of linguistic features such as Topic Modeling, Tone Analysis, and Semantic Tagging significantly enhanced the classification of posts with racist or radicalized intent by providing a deeper understanding of the content beyond mere keyword spotting.\n\nTopic Modeling helped in identifying posts related to specific themes like race or religion by extracting relevant linguistic features, which allowed for the classification of posts into defined topics. Tone Analysis contributed by assessing the emotional tone of the narrative, which is crucial for understanding the intent behind the posts. Semantic Tagging enriched the text by identifying the meanings and relationships of words within the context, enabling the classifiers to discern subtle nuances in language that indicate discriminatory intent.\n\nTogether, these features improved the classifiers' ability to accurately identify posts that exhibit racist or radicalized intent, addressing the complexities and ambiguities often present in such content."
                },
                {
                    "question": "[SQ] What were the specific challenges faced in implementing Topic Modeling for classifying posts with racist or radicalized intent?",
                    "answer": "The implementation of Topic Modeling for classifying posts with racist or radicalized intent faced several specific challenges. One major challenge was the ambiguity present in the posts, as the intent of a post cannot be accurately determined solely by keyword spotting. This necessitated a deeper understanding of the psychological tendencies, sentiment tones, and language used in the narratives.\n\nAdditionally, the dataset was highly imbalanced, with only a small percentage of posts labeled as intent posts, making it difficult to train effective classification models. The reliance on open-source APIs for feature extraction also posed limitations, particularly when dealing with multi-lingual text, which could lead to inaccuracies in identifying taxonomy or semantic features.\n\nFurthermore, the need to filter out non-topic based or noisy posts added complexity to the classification process, as it required careful topic modeling to ensure that only relevant posts were considered. Overall, these challenges highlighted the necessity for a nuanced approach to topic classification that goes beyond simple keyword analysis."
                },
                {
                    "question": "[SQ] How did the researchers validate the effectiveness of Tone Analysis in distinguishing between neutral and intent-laden posts?",
                    "answer": "The researchers validated the effectiveness of Tone Analysis by categorizing posts based on their tone scores, which included document-level measures for emotions, social tendencies, and writing style. They analyzed the distribution of these tones across the posts and created a feature vector for each post based on the confidence scores assigned to different tone categories. By comparing the tone characteristics of neutral posts against those identified as having intent, they were able to demonstrate that specific emotional tones, writing cues, and social personality traits serve as discriminatory features for intent classification. This analysis helped in establishing a clear distinction between neutral and intent-laden posts."
                },
                {
                    "question": "[SQ] What role did Semantic Tagging play in improving the classifiers' performance compared to traditional keyword-based approaches?",
                    "answer": "Semantic tagging enhanced the classifiers' performance by providing a deeper understanding of the content beyond mere keyword identification. Unlike traditional keyword-based approaches, which often generate false alarms due to their reliance on specific terms, semantic tagging captures the nuanced meanings and relationships of words within the context of the posts. This method allows for the identification of multi-word units and the semantic roles of terms, which contributes to a more accurate classification of intent and topics. By incorporating semantic tags, the classifiers can better discern the emotional tone and social tendencies of the narratives, leading to improved precision and reduced false positives in identifying intent posts."
                },
                {
                    "question": "[MQ] What specific one-class classifiers, including Random Forest, Naive Bayes, and Decision Tree, were utilized in the study, and how did their integration with linguistic features such as Topic Modeling, Tone Analysis, and Semantic Tagging enhance the classification of posts with racist or radicalized intent?",
                    "answer": "The study utilized three specific one-class classifiers: Random Forest, Naive Bayes, and Decision Tree. These classifiers were integrated with various linguistic features to enhance the classification of posts with racist or radicalized intent. \n\nTopic Modeling was employed to identify posts related to specific topics such as race or religion by extracting linguistic features and creating a lexicon of relevant concepts. This approach allowed for the classification of posts into defined categories based on their content.\n\nTone Analysis involved assessing the emotional tone of the posts, which helped in understanding the sentiment behind the narratives. Features related to writing tone and emotion were particularly influential, as they provided insights into the psychological tendencies expressed in the posts.\n\nSemantic Tagging was used to analyze the semantic roles of keywords within the posts. This feature facilitated the identification of intent by capturing the nuanced meanings and contexts of the language used, which is crucial for distinguishing between benign and harmful content.\n\nTogether, these linguistic features supported the classifiers in accurately identifying posts with racist or radicalized intent by providing a richer understanding of the text beyond mere keyword spotting. The integration of these features contributed to improved precision and recall in the classification process."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 1.0,
                "semantic_similarity": 0.8186832185686133,
                "llm_context_precision_without_reference": 0.5327380952292162,
                "llm_context_precision_with_reference": 0.6111111110988888,
                "answer_relevancy": 0.863320117187547,
                "answer_correctness": 0.20467080464215331
            },
            "deepeval": {
                "contextual_precision": 0.8055555555555555,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.17543859649122806,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 7,
        "job_id": 1,
        "file_id": 2,
        "question_id": 2,
        "status": "done",
        "answer_text": "The analysis in the study focused on several specific features categorized into three main areas: Topic Modeling, Tone Analysis, and Semantic Tagging.\n\n1. **Document Sentiment**: This feature assesses the overall sentiment polarity of a post, categorizing it into five levels: strongly negative, negative, neutral, positive, and strongly positive. This was justified as understanding sentiment is crucial for interpreting the emotional tone of user-generated content.\n\n2. **Semantic Tagging**: This feature identifies the semantic roles of terms within the content, allowing for a deeper understanding of the context and meaning behind the posts. It was justified by the need to capture hidden concepts that may not be evident through keyword analysis alone.\n\n3. **Emotion Detection**: The study analyzed five specific emotions—anger, fear, joy, disgust, and sadness. This feature was included to provide insights into the emotional responses elicited by the posts, which is important for understanding user intent and engagement.\n\n4. **Writing Styles**: The analysis included three writing styles: analytical, confident, and tentative. This feature was justified as it helps to characterize the author's tone and approach, which can influence the interpretation of the content.\n\nThese features were selected based on prior literature and the research objectives, which aimed to enhance the understanding of user-generated content on social media platforms, particularly in relation to intent classification and topic relevance. The combination of sentiment, semantic, and emotional analysis provided a comprehensive framework for evaluating the posts effectively.",
        "answer_encoded": "[response not coded] The analysis selected features in Topic Modeling, Tone Analysis, and Semantic Tagging, including Document Sentiment, Semantic Tagging, Emotion Detection, and Writing Styles, to enhance understanding of user-generated content on social media.",
        "answer_contexts": [
                {
                    "context": "VI. PROPOSED APPROACH\n\nFigure 3 shows the high-level architecture of proposed approach primarily consisting of three phases: Data Extraction, Feature Identification and Classification. Section V describes the bootstrapping method used for data collection and inter-annotator agreement used for creating ground truth. We describe the remaining two phases in the following sections:\n\n A. Features Identification\n\nBased on the prior literature and our hypothesis design, we create our feature space by analyzing the linguistic features (semantic and sentiment tone) of Tumblr posts. We divide our features set into three categories: Topic Modeling, Tone Analysis and Semantic Tagging. We also discuss other contextual metadata features that can be extracted from Tumblr posts but are not applicable in intent classification.\n\n Topic Modeling:\n\nThe existing literature shows that there has been a lot of work in the area of mining user generated content on social media related to offensive speech [13], racism and radicalization [14][15]. However, our analysis and annotation reveals that despite not having certain topic specific key-terms, a post can be an intent post for which keyword based classification method do not work accurately and generates a large number of false alarms [3]. Therefore, we use statistical and natural language processing techniques to perform topic modeling on Tumblr posts. We use Alchemy Taxonomy API7 to classify the post into the most likely topic and sub-topic categories. Alchemy API supports over 1000 categories broadly divided into 23 topics. Sub-topic categories allows us to identify the more focused and targeted topic of post (up to 5 levels of hierarchy).\n\nFor example, society/crime/personal offense/hate crime. We also use Alchemy Concept Tagging API8 to identify the hidden concepts in the text that are similar to human annotation. Alchemy API learns about a post from linked data resources9 such as freebase, dbpedia, yago and tags the concepts that are high likely to be related to the given text. For example, for a Tumblr post “If the Arabs put down their weapons today, there would be no more violence. If the Jews put down their weapons today, there would be no more Israel.”, Alchemy tags “Ashkenazi Jews”, “Palestinian people” and “Jewish ethnic divisions” with a confidence score of 0.74, 0.78 and 0.70 respectively. We use these concepts to perform the topic modeling of a text along with the taxonomy. Statistically, the API returns a confidence score of each taxonomy conveying how likely the post belongs to derived category. We discard a category from taxonomy and concept lists if the confidence score is below 40%.\n\n Sentiment and Tone Analysis:\n\nInspired by the prior literature [10], we investigate language of narrative by analyzing various types of sentiments and personality traits in a post such as document sentiment, social tone, writing tone and emotions. We use Alchemy Document Sentiment API10 to identify the document-level polarity of overall sentiment of a post. We define five categories of sentiment polarity: strongly negative, negative, neutral, positive and strongly positive and categorize each post based on its sentiment score. The sentiment of a document or post differs from the tone analysis of the content. Sentiment analysis can only identify the positive and negative polarity of a post while tone analysis measures the level of three categories including emotion, social and writing tones. We conduct a linguistic analysis on Tumblr posts using IBM Watson Tone Analyzer API11. Emotions tone analyzes the text of a post and gives a distribution of 5 emotions namely joy, fear, sadness, anger and disgust. Social tendencies analyze the personality traits from the text that includes openness, conscientiousness, extraversion, agreeableness and emotional range of a narrative. Writing tone identifies the language cues of the author in context to the content written in a Tumblr post. It includes analytical, confident and tentative style of writing. The Tone Analyzer API analyzes the content of a post and computes two scores (document level and sentence level) for all three categories of tones. Since, the text length of posts in our experimental dataset varies from 1 to 1200 words, we select only document level measures of these tones. Similar to sentiment score, we create a feature vector of each tone and categorize each post based on the confidence score: very low, low, medium, high, and very high. Figure 4 shows a concrete example of Tumblr post related to Race topic and shows the level of emotion tone, language and personality traits of author.\n\n Semantic Tagging:\n\nSemantic tagging of a post identifies the semantic role of each term present in the content. It also identifies the hidden phrases playing major role in the\n\n10 http://www.alchemyapi.com/api/sentiment-analysis\n\n11 https://tone-analyzer-demo.mybluemix.net",
                    "score": 0.8336658087298368
                },
                {
                    "context": "We exclude contextual metadata from our feature space as those are not discriminatory for intent or topic classification.\n\n B. Classification\n\nThe third phase of our proposed framework is a cascaded ensemble learning based classifier primarily consisting of two stages: topic classification and intent classification. We train our model from feature vectors created in Phase 2 and perform one-class classification on Tumblr posts.\n\n Topic Classification\n\nTo identify the posts that belong to a defined topic (Race or Religion), we use topic modeling linguistic features extracted using natural language processing. We take a random sample of 50 posts out of 292, annotated as topic posts and extract their taxonomy and concepts from the feature space. We create two independent lexicons of these concepts and labeled topics that has a confidence score above 0.40. We manually filter the list of taxonomy and finalize the following 6 labels that strictly belong to the topic of this study: religion and spirituality, society/unrest and war, society/racism, society/personal offense/hate crime, law, govt & politics/espionage and intelligence/terrorism and law, govt & politics/legal issues/human rights.\n\nWe use a look-up based method and check if the post belongs to any of these taxonomies and has a confidence score above 0.40. If yes, then we classify it as a topic post. However, if a post contains a wide range of taxonomies (>5) then we identify the top K concepts in the text and check if they exist in the concept lexicon of labeled topic posts. This stage of cascaded classifier is a one-class classifier that takes complete experimental dataset as an input and classifies topic related posts from unknown posts.\n\n Intent Classification\n\nAn intent of a post (consisting of free-form text) cannot be fully determined only by mining the keywords in the content. But it also requires to understand and predict the psychological tendency, sentiment tones and language of the narrative. It also requires to analyze the semantic role of topic related keywords used in the post. We perform classification on Tumblr posts by training our model on sentiment, semantic and language cues based features of a text. On a high level, we create a vector space of 5 features set (F1 to F5) which is further categorized into 15 unique vectors. Table III shows the list of all features extracted and grouped into 5 feature vectors. We define intent classification as a one-class classification problem. Therefore,",
                    "score": 0.6312226245444853
                },
                {
                    "context": "This table lists various features related to document analysis, including sentiment analysis, semantic tagging, emotional detection, and writing styles.,\nwith the following columns:\n- Code: Unique identifier for each feature.\n- Grouped Features: Descriptions of the features related to document analysis.\n\n| Code | Grouped Features                             |\n|---|---|\n| F1   | Document Sentiment                           |\n| F2   | Semantic Tagging                             |\n| F3   | Emotion {Anger, Fear, Joy, Disgust, Sadness} |\n| F4   |                                              |\n| F5   | Writing {Analytical, Confident, Tentative}   |",
                    "score": 0.5449728143414032
                },
                {
                    "context": "1) To the best of our knowledge, the study presented in this paper is the first work on racist and radicalization detection based on the intent of narrative unlike previous keyword spotting methods.\n\n2) We apply natural language processing techniques on Tumblr posts for identifying discriminatory features for intent classification.\n\n3) We publish the first ever semantically and sentimental enriched data of Tumblr posts and make our data publicly available for benchmarking and extension2 [11].\n\n4) The study presented in this paper is an extended version of our work Agarwal et al. accepted as a short paper in European Intelligence and Security Informatics Conference (EISIC 2016) [12]. Due to the small page limit for short papers (at most four pages) in EISIC 20163, several aspects including results and details of proposed approach are not covered. This paper presents the complete and detailed description of our work on intent based classification of racist and radicalized posts made on Tumblr micro-blogging website.\n\n IV. PROBLEM STATEMENT\n\nGiven a dataset D of Tumblr Posts Pi, D = {Pi | 1 ≤ i ≤ n}, a set of topics N = {Nj | 1 ≤ j ≤ m} and a target class C; identify the intent of Pi ∈ D when Pi ∈ N.\n\nBased on the definition of freedom of expression by Joshua Cohen [1], we define a Tumblr post P as a racist intent post if:\n\n1. the topic of the content belongs to a race or a religion and\n2. the post targets a community in an offensive or persuasive manner (in a recognizable way).\n\nIn order to identify a racist or radicalized intent post, we propose following two hypotheses:\n\n1. In the absence of topic related key-terms, natural language processing can be an efficient approach to identify hidden taxonomy of a Tumblr post.\n2. Sentiment and semantic enrichment of text can be two discriminatory features for identifying the language of narrative and classifying the intent posts.\n\n V. EXPERIMENTAL SETUP\n\nData Collection: We conduct our experiments on an open source and real time dataset extracted from Tumblr microblogging website. We perform a manual inspection and find most popular Tumblr posts having racist and radicalized intent. We extract the list of unique tags associated with these posts and create a lexicon of top K tags that are the most commonly used by racist or radicalized groups. For example, #islamophobia, #islam is evil, #supremacy, #blacklivesmatter, #white racism, #jihad, #isis and #white genocide. We implement a bootstrapping method to create our dataset and use this lexicon as seed tags for the Tumblr Search API4. For each tag, we extract only textual posts (text and quote) and extend our lexicon by acquiring other (unique) related tags associated with these posts. We execute our model until we get a desired number of posts or the model converges (it starts extracting duplicate posts). Using Tumblr Search API, we were able to extract a total of 3,228 text posts made by 2,224 unique bloggers consisting of 10,217 unique tags. Table I shows a complete schema of additional metadata extracted for each post and unique blogger. The aim of the study presented in this paper is to build a one-class text classifier for identifying racist and hate promoting intent posts. Therefore, we conduct our experiments on post content (referred as description in Tumblr). Since, Tumblr generates a new identification number for each post (re-blogged or posted), despite having the unique Post IDs, we discard 9% (273) of the posts having similar or duplicate content and remove the bias from our data.\n\nThe study presented in this paper focuses on intent mining on English language posts. We identify the language of each record by applying Alchemy language detection API5 on post description. Figure 2 reveals that only 83% (2,456...",
                    "score": 0.2927612945762324
                },
                {
                    "context": "[12] A. Swati and S. Ashish, “But I did not mean it!- intent classification of racist posts on tumblr,” in 6th IEEE European Intelligence & Security Informatics Conference (EISIC), Uppsala, Sweden. IEEE, 2016.\n\n[13] Y. Chen, Y. Zhou, S. Zhu, and H. Xu, “Detecting offensive language in social media to protect adolescent online safety,” in Privacy, Security, Risk and Trust (PASSAT), SocialCom. IEEE, 2012, pp. 71–80.\n\n[14] S. Agarwal and A. Sureka, “Spider and the flies: Focused crawling on tumblr to detect hate promoting communities,” arXiv preprint arXiv:1603.09164, 2016.\n\n[15] P. Burnap and M. L. Williams, “Us and them: identifying cyber hate on twitter across multiple protected characteristics,” EPJ Data Science, vol. 5, no. 1, p. 1, 2016.\n\n Limitations:\n\nIn this paper, we conduct our analysis only on English language posts. Our proposed approach has dependencies with the open source APIs used for the feature extraction. If a post contains multi-lingual text (for example, Arabic + English) then the APIs might not be able to extract the taxonomy or semantic features accurately. We make our model generalized and it can be used to identify racist and radicalized intent for any given text. However, the model might require some pre-processing and large training data for microposts as the topic modeling and tone analysis might not be 100% accurate for very short text such as tweets.\n\n VIII. CONCLUSIONS AND FUTURE WORK\n\nIn this paper, we study the problem of identifying racist and radicalized Tumblr posts based on the intent of narrative. We formulate our problem as a cascaded ensemble learning problem and propose a two-stage one-class classification approach to solve the problem. Our result shows that the proposed approach is effective for identifying intent posts unlike previous keyword based techniques. Our experimental results shows that emotion tone, writing cues and social personality traits of an author are discriminatory features for identifying the intent of the post. Further, topic classification of posts and filtering non-topic based (or noisy) posts improves the performance of the proposed intent classification.\n\nFuture work includes addressing the limitations of present study and improving the accuracy of linguistic features. Identification of multi-lingual posts by doing a sentence level language detection and enhancing the translated content for identifying intent posts. As mentioned in the previous sections, Tumblr is popularly known for the use of reaction gif images. Therefore, our future work involves mining users’ reactions from attached external images and enrichment of linguistic.",
                    "score": 0.29083403837390975
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific features or characteristics were selected for analysis in the study, and how were they justified in the context of the research objectives?",
                    "answer": "The analysis in the study focused on several specific features related to document analysis, which were categorized into three main areas: Topic Modeling, Tone Analysis, and Semantic Tagging. \n\n1. **Document Sentiment**: This feature assesses the overall sentiment polarity of a post, categorizing it into five levels: strongly negative, negative, neutral, positive, and strongly positive. This was justified as understanding sentiment is crucial for interpreting the emotional tone of user-generated content.\n\n2. **Semantic Tagging**: This feature identifies the semantic roles of terms within the content, allowing for a deeper understanding of the context and meaning behind the posts. It was justified by the need to capture hidden concepts that may not be evident through keyword analysis alone.\n\n3. **Emotion Detection**: The study analyzed five specific emotions—anger, fear, joy, disgust, and sadness. This feature was included to provide insights into the emotional responses elicited by the posts, which is important for understanding user intent and engagement.\n\n4. **Writing Styles**: The analysis included three writing styles: analytical, confident, and tentative. This feature was justified as it helps to characterize the author's tone and approach, which can influence the interpretation of the content.\n\nThese features were selected based on prior literature and the research objectives, which aimed to enhance the understanding of user-generated content on social media platforms, particularly in relation to intent classification and topic relevance. The combination of sentiment, semantic, and emotional analysis provided a comprehensive framework for evaluating the posts effectively."
                },
                {
                    "question": "[SQ] What methodologies were employed to analyze the selected features in the study?",
                    "answer": "The study employed several methodologies to analyze the selected features, which included:\n\n1. **Data Extraction**: This phase involved collecting data from Tumblr posts using a bootstrapping method and establishing inter-annotator agreement to create ground truth.\n\n2. **Feature Identification**: The feature space was created by analyzing linguistic features, specifically focusing on sentiment and semantic tones. This was divided into three categories:\n   - **Topic Modeling**: Statistical and natural language processing techniques were used to classify posts into topics and sub-topics using the Alchemy Taxonomy API and Alchemy Concept Tagging API.\n   - **Sentiment and Tone Analysis**: The Alchemy Document Sentiment API was utilized to determine the overall sentiment polarity of posts, while the IBM Watson Tone Analyzer API was used to analyze various tones, including emotional, social, and writing tones.\n   - **Semantic Tagging**: This involved identifying the semantic roles of terms within the content and recognizing hidden phrases that play significant roles.\n\n3. **Classification**: The classification phase consisted of a cascaded ensemble learning-based classifier with two stages:\n   - **Topic Classification**: This used linguistic features extracted from topic modeling to classify posts into defined topics based on confidence scores.\n   - **Intent Classification**: This involved training a model on sentiment, semantic, and language cues to classify the intent of posts, treating it as a one-class classification problem. \n\nThese methodologies collectively facilitated a comprehensive analysis of the features related to document analysis."
                },
                {
                    "question": "[SQ] How do the selected features align with the specific research objectives outlined in the study?",
                    "answer": "The selected features are designed to comprehensively analyze the linguistic aspects of Tumblr posts, aligning with the research objectives of understanding sentiment, tone, and intent. Document sentiment captures the overall emotional polarity of posts, which is crucial for assessing user sentiment. Semantic tagging enhances the understanding of the content by identifying relevant topics and concepts, facilitating deeper insights into the narrative. Emotional detection focuses on specific feelings expressed in the text, providing a nuanced view of the emotional landscape. Lastly, the analysis of writing styles helps in categorizing the author's tone and approach, which is essential for intent classification. Together, these features support the study's aim of accurately classifying posts based on their content and underlying sentiments."
                },
                {
                    "question": "[SQ] What prior literature or studies influenced the selection of these features for analysis?",
                    "answer": "The selection of features for analysis was influenced by prior literature that explored various aspects of language and sentiment in user-generated content on social media. Specifically, studies focused on offensive speech, racism, radicalization, and the analysis of sentiments and personality traits in narratives contributed to the development of the feature space. These studies highlighted the need for comprehensive approaches to topic modeling, sentiment analysis, and tone analysis, which informed the categorization and extraction of linguistic features from Tumblr posts."
                },
                {
                    "question": "[MQ] What specific features related to sentiment, tone, and semantic analysis were selected for the study of Tumblr posts, and how were these features justified in relation to the research objectives?",
                    "answer": "The study focused on several specific features related to sentiment, tone, and semantic analysis for the classification of Tumblr posts. \n\n1. **Sentiment Analysis**: The overall sentiment of a post was categorized into five polarity categories: strongly negative, negative, neutral, positive, and strongly positive. This categorization was justified as it helps in understanding the emotional stance of the post, which is crucial for identifying intent, particularly in the context of racist or radicalized content.\n\n2. **Tone Analysis**: The analysis included three categories of tone:\n   - **Emotion Tone**: This feature assessed the distribution of five emotions: joy, fear, sadness, anger, and disgust. This was justified as understanding emotional expressions can reveal underlying intentions in the narrative.\n   - **Social Tone**: This feature evaluated personality traits such as openness, conscientiousness, extraversion, agreeableness, and emotional range. These traits were considered important for understanding the author's perspective and potential biases in the content.\n   - **Writing Tone**: This feature identified language cues related to analytical, confident, and tentative writing styles. The justification for including writing tone lies in its ability to reflect the author's approach and attitude towards the subject matter.\n\n3. **Semantic Tagging**: This involved identifying the semantic roles of terms within the posts. The justification for this feature was that it helps in understanding the context and relationships between different terms, which is essential for accurately classifying the intent of the posts.\n\nThese features were selected based on their potential to provide a comprehensive understanding of the language used in the posts, thereby aiding in the identification of racist and radicalized intent. The combination of sentiment, tone, and semantic analysis was aimed at enriching the classification process beyond simple keyword spotting, addressing the research objectives of effectively identifying intent in user-generated content."
                },
                {
                    "question": "[SQ] What methodologies were used to validate the effectiveness of the selected features in the study?",
                    "answer": "The effectiveness of the selected features in the study was validated through the use of performance metrics such as true positives, false positives, false negatives, and true negatives. Additionally, various classification algorithms, including Decision Tree, Random Forest, and Naive Bayes, were evaluated across two test datasets to assess their recall and precision. This approach allowed for a comprehensive evaluation of the classification model's performance in relation to the identified features."
                },
                {
                    "question": "[SQ] How do the selected features compare to those used in similar studies on sentiment and tone analysis?",
                    "answer": "The selected features for sentiment and tone analysis include document sentiment, emotional detection (anger, fear, joy, disgust, sadness), and writing styles (analytical, confident, tentative). These features are designed to capture a comprehensive understanding of the emotional and linguistic nuances present in the text.\n\nIn similar studies, researchers often focus on sentiment polarity and emotional tones, similar to the document sentiment and emotion features here. However, many studies may not incorporate a detailed analysis of writing styles, which adds an additional layer of understanding regarding the author's intent and personality traits. The inclusion of semantic tagging further enhances the analysis by identifying the roles of terms within the text, which is less commonly emphasized in other studies.\n\nOverall, while there is overlap in the focus on sentiment and emotional tones, the combination of features in this approach, particularly the emphasis on writing styles and semantic tagging, provides a more nuanced framework for understanding the complexities of sentiment and tone in social media posts."
                },
                {
                    "question": "[SQ] What challenges were encountered in the analysis of sentiment, tone, and semantic features in Tumblr posts?",
                    "answer": "The analysis of sentiment, tone, and semantic features in Tumblr posts faced several challenges. One significant challenge was the reliance on open-source APIs for feature extraction, which may not perform accurately on posts containing multi-lingual text. This limitation could hinder the extraction of taxonomy or semantic features when posts include languages other than English. Additionally, the variability in text length, with posts ranging from very short to lengthy, posed difficulties in ensuring consistent analysis, particularly for very short texts like tweets. The imbalanced nature of the dataset, where intent posts constituted only a small percentage of the total posts, also complicated the classification process, making it harder to train models effectively. Lastly, the presence of noisy text, such as special characters and emoticons, required careful preprocessing to enhance the quality of the data for analysis."
                },
                {
                    "question": "[MQ] What specific features related to sentiment, tone, and semantic analysis were selected for the classification of Tumblr posts, and how do these features align with the research objectives of understanding user intent and emotional expression?",
                    "answer": "The classification of Tumblr posts involves several specific features related to sentiment, tone, and semantic analysis. These features are categorized into three main areas:\n\n1. **Sentiment Analysis**: The overall sentiment of a post is assessed using a document-level polarity score, which categorizes posts into five sentiment categories: strongly negative, negative, neutral, positive, and strongly positive. This helps in understanding the emotional stance of the post.\n\n2. **Tone Analysis**: This includes three categories:\n   - **Emotion Tone**: Analyzes the distribution of five emotions: joy, fear, sadness, anger, and disgust. This feature provides insight into the emotional expression of the author.\n   - **Social Tone**: Evaluates personality traits such as openness, conscientiousness, extraversion, agreeableness, and emotional range, which helps in understanding the social tendencies reflected in the narrative.\n   - **Writing Tone**: Identifies language cues related to the author's writing style, categorized into analytical, confident, and tentative styles. This feature aids in discerning the author's approach to the content.\n\n3. **Semantic Tagging**: This involves identifying the semantic roles of terms within the post, tagging them with hierarchical labels that reflect their meaning and context. This feature enriches the understanding of the narrative by highlighting key concepts and their relationships.\n\nThese features align with the research objectives by enabling a nuanced analysis of user intent and emotional expression. The sentiment and tone analyses provide a framework for understanding how users convey their feelings and attitudes, while semantic tagging enhances the ability to classify posts based on their underlying themes and intentions. Together, these features facilitate a comprehensive approach to identifying racist and radicalized intent in Tumblr posts."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 1.0,
                "semantic_similarity": 0.8817137800705448,
                "llm_context_precision_without_reference": 0.9379251700546283,
                "llm_context_precision_with_reference": 0.499999999975,
                "answer_relevancy": 0.9032240235432152,
                "answer_correctness": 0.2204284450176362
            },
            "deepeval": {
                "contextual_precision": 0.30952380952380953,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.06172839506172839,
                "answer_relevancy": 1.0,
                "faithfulness": 0.6
            }
        },
    },
    {
        "id": 8,
        "job_id": 1,
        "file_id": 2,
        "question_id": 3,
        "status": "done",
        "answer_text": "The social network utilized for data collection in the analyzed article is Tumblr.",
        "answer_encoded": "Tumblr",
        "answer_contexts": [
                {
                    "context": "1) To the best of our knowledge, the study presented in this paper is the first work on racist and radicalization detection based on the intent of narrative unlike previous keyword spotting methods.\n\n2) We apply natural language processing techniques on Tumblr posts for identifying discriminatory features for intent classification.\n\n3) We publish the first ever semantically and sentimental enriched data of Tumblr posts and make our data publicly available for benchmarking and extension2 [11].\n\n4) The study presented in this paper is an extended version of our work Agarwal et al. accepted as a short paper in European Intelligence and Security Informatics Conference (EISIC 2016) [12]. Due to the small page limit for short papers (at most four pages) in EISIC 20163, several aspects including results and details of proposed approach are not covered. This paper presents the complete and detailed description of our work on intent based classification of racist and radicalized posts made on Tumblr micro-blogging website.\n\n IV. PROBLEM STATEMENT\n\nGiven a dataset D of Tumblr Posts Pi, D = {Pi | 1 ≤ i ≤ n}, a set of topics N = {Nj | 1 ≤ j ≤ m} and a target class C; identify the intent of Pi ∈ D when Pi ∈ N.\n\nBased on the definition of freedom of expression by Joshua Cohen [1], we define a Tumblr post P as a racist intent post if:\n\n1. the topic of the content belongs to a race or a religion and\n2. the post targets a community in an offensive or persuasive manner (in a recognizable way).\n\nIn order to identify a racist or radicalized intent post, we propose following two hypotheses:\n\n1. In the absence of topic related key-terms, natural language processing can be an efficient approach to identify hidden taxonomy of a Tumblr post.\n2. Sentiment and semantic enrichment of text can be two discriminatory features for identifying the language of narrative and classifying the intent posts.\n\n V. EXPERIMENTAL SETUP\n\nData Collection: We conduct our experiments on an open source and real time dataset extracted from Tumblr microblogging website. We perform a manual inspection and find most popular Tumblr posts having racist and radicalized intent. We extract the list of unique tags associated with these posts and create a lexicon of top K tags that are the most commonly used by racist or radicalized groups. For example, #islamophobia, #islam is evil, #supremacy, #blacklivesmatter, #white racism, #jihad, #isis and #white genocide. We implement a bootstrapping method to create our dataset and use this lexicon as seed tags for the Tumblr Search API4. For each tag, we extract only textual posts (text and quote) and extend our lexicon by acquiring other (unique) related tags associated with these posts. We execute our model until we get a desired number of posts or the model converges (it starts extracting duplicate posts). Using Tumblr Search API, we were able to extract a total of 3,228 text posts made by 2,224 unique bloggers consisting of 10,217 unique tags. Table I shows a complete schema of additional metadata extracted for each post and unique blogger. The aim of the study presented in this paper is to build a one-class text classifier for identifying racist and hate promoting intent posts. Therefore, we conduct our experiments on post content (referred as description in Tumblr). Since, Tumblr generates a new identification number for each post (re-blogged or posted), despite having the unique Post IDs, we discard 9% (273) of the posts having similar or duplicate content and remove the bias from our data.\n\nThe study presented in this paper focuses on intent mining on English language posts. We identify the language of each record by applying Alchemy language detection API5 on post description. Figure 2 reveals that only 83% (2,456...",
                    "score": 0.8348705564605152
                },
                {
                    "context": "VI. PROPOSED APPROACH\n\nFigure 3 shows the high-level architecture of proposed approach primarily consisting of three phases: Data Extraction, Feature Identification and Classification. Section V describes the bootstrapping method used for data collection and inter-annotator agreement used for creating ground truth. We describe the remaining two phases in the following sections:\n\n A. Features Identification\n\nBased on the prior literature and our hypothesis design, we create our feature space by analyzing the linguistic features (semantic and sentiment tone) of Tumblr posts. We divide our features set into three categories: Topic Modeling, Tone Analysis and Semantic Tagging. We also discuss other contextual metadata features that can be extracted from Tumblr posts but are not applicable in intent classification.\n\n Topic Modeling:\n\nThe existing literature shows that there has been a lot of work in the area of mining user generated content on social media related to offensive speech [13], racism and radicalization [14][15]. However, our analysis and annotation reveals that despite not having certain topic specific key-terms, a post can be an intent post for which keyword based classification method do not work accurately and generates a large number of false alarms [3]. Therefore, we use statistical and natural language processing techniques to perform topic modeling on Tumblr posts. We use Alchemy Taxonomy API7 to classify the post into the most likely topic and sub-topic categories. Alchemy API supports over 1000 categories broadly divided into 23 topics. Sub-topic categories allows us to identify the more focused and targeted topic of post (up to 5 levels of hierarchy).\n\nFor example, society/crime/personal offense/hate crime. We also use Alchemy Concept Tagging API8 to identify the hidden concepts in the text that are similar to human annotation. Alchemy API learns about a post from linked data resources9 such as freebase, dbpedia, yago and tags the concepts that are high likely to be related to the given text. For example, for a Tumblr post “If the Arabs put down their weapons today, there would be no more violence. If the Jews put down their weapons today, there would be no more Israel.”, Alchemy tags “Ashkenazi Jews”, “Palestinian people” and “Jewish ethnic divisions” with a confidence score of 0.74, 0.78 and 0.70 respectively. We use these concepts to perform the topic modeling of a text along with the taxonomy. Statistically, the API returns a confidence score of each taxonomy conveying how likely the post belongs to derived category. We discard a category from taxonomy and concept lists if the confidence score is below 40%.\n\n Sentiment and Tone Analysis:\n\nInspired by the prior literature [10], we investigate language of narrative by analyzing various types of sentiments and personality traits in a post such as document sentiment, social tone, writing tone and emotions. We use Alchemy Document Sentiment API10 to identify the document-level polarity of overall sentiment of a post. We define five categories of sentiment polarity: strongly negative, negative, neutral, positive and strongly positive and categorize each post based on its sentiment score. The sentiment of a document or post differs from the tone analysis of the content. Sentiment analysis can only identify the positive and negative polarity of a post while tone analysis measures the level of three categories including emotion, social and writing tones. We conduct a linguistic analysis on Tumblr posts using IBM Watson Tone Analyzer API11. Emotions tone analyzes the text of a post and gives a distribution of 5 emotions namely joy, fear, sadness, anger and disgust. Social tendencies analyze the personality traits from the text that includes openness, conscientiousness, extraversion, agreeableness and emotional range of a narrative. Writing tone identifies the language cues of the author in context to the content written in a Tumblr post. It includes analytical, confident and tentative style of writing. The Tone Analyzer API analyzes the content of a post and computes two scores (document level and sentence level) for all three categories of tones. Since, the text length of posts in our experimental dataset varies from 1 to 1200 words, we select only document level measures of these tones. Similar to sentiment score, we create a feature vector of each tone and categorize each post based on the confidence score: very low, low, medium, high, and very high. Figure 4 shows a concrete example of Tumblr post related to Race topic and shows the level of emotion tone, language and personality traits of author.\n\n Semantic Tagging:\n\nSemantic tagging of a post identifies the semantic role of each term present in the content. It also identifies the hidden phrases playing major role in the\n\n10 http://www.alchemyapi.com/api/sentiment-analysis\n\n11 https://tone-analyzer-demo.mybluemix.net",
                    "score": 0.8313165613725317
                },
                {
                    "context": "[12] A. Swati and S. Ashish, “But I did not mean it!- intent classification of racist posts on tumblr,” in 6th IEEE European Intelligence & Security Informatics Conference (EISIC), Uppsala, Sweden. IEEE, 2016.\n\n[13] Y. Chen, Y. Zhou, S. Zhu, and H. Xu, “Detecting offensive language in social media to protect adolescent online safety,” in Privacy, Security, Risk and Trust (PASSAT), SocialCom. IEEE, 2012, pp. 71–80.\n\n[14] S. Agarwal and A. Sureka, “Spider and the flies: Focused crawling on tumblr to detect hate promoting communities,” arXiv preprint arXiv:1603.09164, 2016.\n\n[15] P. Burnap and M. L. Williams, “Us and them: identifying cyber hate on twitter across multiple protected characteristics,” EPJ Data Science, vol. 5, no. 1, p. 1, 2016.\n\n Limitations:\n\nIn this paper, we conduct our analysis only on English language posts. Our proposed approach has dependencies with the open source APIs used for the feature extraction. If a post contains multi-lingual text (for example, Arabic + English) then the APIs might not be able to extract the taxonomy or semantic features accurately. We make our model generalized and it can be used to identify racist and radicalized intent for any given text. However, the model might require some pre-processing and large training data for microposts as the topic modeling and tone analysis might not be 100% accurate for very short text such as tweets.\n\n VIII. CONCLUSIONS AND FUTURE WORK\n\nIn this paper, we study the problem of identifying racist and radicalized Tumblr posts based on the intent of narrative. We formulate our problem as a cascaded ensemble learning problem and propose a two-stage one-class classification approach to solve the problem. Our result shows that the proposed approach is effective for identifying intent posts unlike previous keyword based techniques. Our experimental results shows that emotion tone, writing cues and social personality traits of an author are discriminatory features for identifying the intent of the post. Further, topic classification of posts and filtering non-topic based (or noisy) posts improves the performance of the proposed intent classification.\n\nFuture work includes addressing the limitations of present study and improving the accuracy of linguistic features. Identification of multi-lingual posts by doing a sentence level language detection and enhancing the translated content for identifying intent posts. As mentioned in the previous sections, Tumblr is popularly known for the use of reaction gif images. Therefore, our future work involves mining users’ reactions from attached external images and enrichment of linguistic.",
                    "score": 0.6697195923632374
                },
                {
                    "context": "Data Extraction: We use 2,456 English language posts for annotation which spans only 83% of the extracted data. 459 posts were identified as non-English. The language of remaining 40 posts (2% of the data) was identified as 'unknown' due to the insufficient content in post description, for example, the posts containing only URLs. Figure 2 reveals that 35 out of 2,955 posts contain only URLs. We conduct our experiments on 2,456 English language posts and discard the other non-English or unknown language records. We apply various natural language processing techniques for semantic and sentiment enrichment of our data (discussed in Section VI-A). We enhance our data and make it publicly available so that our experiments can be used for benchmarking and comparison [11]. Our dataset is the first ever published data of Tumblr posts and bloggers labeled with various sentiment and semantic features and can be downloaded from Mendeley Data6.\n\nFigure 2 summarizes the statistics of our experimental dataset. Despite being a microblogging website, Tumblr has no word or character limit and allows users to make long posts and tag with any number or length of keywords. We remove all noisy text from the post descriptions and tags including special characters, emoticons, extra white spaces and compute their length. Data statistics reveals that 21% of the posts have word length between 100 and 1,000 while 25 posts have length greater than 1,000 words. Similarly, 4% (408 out of 10,217) of unique tags have a word length between 5 to 10 while 10 unique tags have a length between 20 to 30 words.\n\nFigure 2 shows that the intent posts are only 37% of topic posts and only 4% of the complete experimental dataset, revealing that the labeled data is highly imbalanced. Since, we use a tag...\n\n6 https://data.mendeley.com/datasets/hd3b6v659v/2",
                    "score": 0.6627290360452154
                },
                {
                    "context": "Characterizing Linguistic Attributes for Automatic Classification of Intent Based Racist/Radicalized Posts on Tumblr Micro-Blogging Website\n\n Swati Agarwal\n\n Ashish Sureka\n\nIndraprastha Institute of Information Technology, New Delhi, India\n\nABB Corporate Research, Bangalore, India\n\nEmail: swatia@iiitd.ac.in\n\nEmail: ashish.sureka@in.abb.com\n\n Abstract\n\nResearch shows that many like-minded people use popular microblogging websites for posting hateful speech against various religions and race. Automatic identification of and hate promoting posts is required for building social media intelligence and security informatics based solutions. However, just keyword spotting based techniques cannot be used to accurately identify the intent of a post. In this paper, we address the challenge of the presence of ambiguity in such posts by identifying the intent of author. We conduct our study on Tumblr microblogging website and develop a cascaded ensemble learning classifier for identifying the posts having racist or radicalized intent. We train our model by identifying various semantic, sentiment and linguistic features from free-form text. Our experimental results show that the proposed approach is effective and the emotion tone, social tendencies, language cues and personality traits of a narrative are discriminatory features for identifying the racist intent behind a post.\n\n Index Terms\n\nIntelligence and Security Informatics, Intent Classification, Machine Learning, Mining User Generated Content, Semantic Analysis, Sentiment and Tone Analysis, Social Media Analytics, Text Classification, Tumblr\n\n I. INTRODUCTION\n\nFreedom of expressions provides leverage to an individual to share their opinions and beliefs about anything. However, many like-minded people misuse freedom of expression to make offensive comments or promote their beliefs that can lead to a negative impact on society [1]. Research shows that these individuals or groups of people use popular microblogging websites (Twitter and Tumblr) for such activities [2][3]. We find that there are users who misuse freedom of speech to post abusive and aggressive comments about targeted people and other users who promote their beliefs about certain religion or community. Existing literature shows that racism is not specific to only minor communities. There are users who post racist comments targeting existing like-minded groups calling it as reverse racism [4]. For example, anti-white bias groups posting comments against white supremacy communities while Islamophobic groups posting hateful speech against Muslim communities. We will be using blogger, author, user and narrative terms interchangeably. Based on our analysis, we broadly define these groups into two categories: Religion and Race. Figure example, a post P1: \"All types of Jihad is to establish peace.\"",
                    "score": 0.5041019548942222
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] Which social network or platform was utilized for data collection in the analyzed article?",
                    "answer": "The social network utilized for data collection in the analyzed article is Tumblr."
                },
                {
                    "question": "[SQ] What specific features of Tumblr were leveraged for data collection in the article?",
                    "answer": "The data collection for the study utilized the Tumblr Search API to extract textual posts associated with specific tags identified as commonly used by racist or radicalized groups. The process involved creating a lexicon of top tags, such as #islamophobia and #blacklivesmatter, and using these as seed tags to gather posts. The study focused on extracting unique textual content, discarding posts with duplicate content, and ensuring that the dataset consisted of English language posts. Additionally, metadata associated with each post and unique blogger was collected to enhance the dataset."
                },
                {
                    "question": "[SQ] How was the data collected from Tumblr analyzed in the study?",
                    "answer": "The data collected from Tumblr was analyzed through a structured approach involving several phases. Initially, data extraction was performed to gather posts, focusing on English language content while discarding non-English and unknown language records. The analysis included the application of various natural language processing techniques for semantic and sentiment enrichment.\n\nThe analysis was divided into three main categories: Topic Modeling, Tone Analysis, and Semantic Tagging. Topic modeling involved using APIs to classify posts into relevant topics and sub-topics, identifying hidden concepts within the text. Tone analysis assessed the sentiment and emotional tone of the posts, categorizing them based on sentiment polarity and various emotional and social tones. Semantic tagging involved identifying the semantic roles of terms within the posts, enhancing the understanding of the content.\n\nAdditionally, a cascaded ensemble learning classifier was employed for topic and intent classification, utilizing feature vectors created from the linguistic features extracted during the analysis. This comprehensive approach aimed to identify racist and radicalized intent in Tumblr posts effectively."
                },
                {
                    "question": "[SQ] What were the main findings derived from the data collected on Tumblr?",
                    "answer": "The main findings from the data collected on Tumblr indicate that the dataset is imbalanced, with only 37% of topic posts identified as intent posts, and just 4% of the complete dataset classified as such. The study highlights that traditional keyword spotting methods are insufficient for accurately identifying intent, as many posts lack specific key-terms yet still convey intent. The research demonstrates that semantic and sentiment features, including emotion tone, writing cues, and social personality traits, are effective in classifying posts with racist or radicalized intent. Additionally, the analysis reveals that a significant portion of posts contains lengthy content, with 21% having word lengths between 100 and 1,000, and some exceeding 1,000 words. The study also emphasizes the importance of filtering out noisy posts to improve classification performance."
                },
                {
                    "question": "[MQ] Which social network was utilized for data collection in the analyzed article, specifically using the Tumblr Search API to extract posts associated with tags related to racist or radicalized groups?",
                    "answer": "The social network utilized for data collection in the analyzed article is Tumblr."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 1.0000000000000002,
                "llm_context_precision_without_reference": 0.9999999999857143,
                "llm_context_precision_with_reference": 0.9999999999857143,
                "answer_relevancy": 0.8163357522628522,
                "answer_correctness": 1.0
            },
            "deepeval": {
                "contextual_precision": 0.8095238095238094,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.7681159420289855,
                "answer_relevancy": 1.0,
                "faithfulness": 0.75
            }
        },
    },
    {
        "id": 9,
        "job_id": 1,
        "file_id": 2,
        "question_id": 4,
        "status": "done",
        "answer_text": "The size of the dataset analyzed in the article consisted of 2,456 English language posts.",
        "answer_encoded": "[response not coded] The analyzed dataset consisted of 2,456 English language posts.",
        "answer_contexts": [
                {
                    "context": "Fig. 2. Basic Statistics of English Language Posts from Experimental Dataset",
                    "score": 0.8281255625118721
                },
                {
                    "context": "Data Extraction: We use 2,456 English language posts for annotation which spans only 83% of the extracted data. 459 posts were identified as non-English. The language of remaining 40 posts (2% of the data) was identified as 'unknown' due to the insufficient content in post description, for example, the posts containing only URLs. Figure 2 reveals that 35 out of 2,955 posts contain only URLs. We conduct our experiments on 2,456 English language posts and discard the other non-English or unknown language records. We apply various natural language processing techniques for semantic and sentiment enrichment of our data (discussed in Section VI-A). We enhance our data and make it publicly available so that our experiments can be used for benchmarking and comparison [11]. Our dataset is the first ever published data of Tumblr posts and bloggers labeled with various sentiment and semantic features and can be downloaded from Mendeley Data6.\n\nFigure 2 summarizes the statistics of our experimental dataset. Despite being a microblogging website, Tumblr has no word or character limit and allows users to make long posts and tag with any number or length of keywords. We remove all noisy text from the post descriptions and tags including special characters, emoticons, extra white spaces and compute their length. Data statistics reveals that 21% of the posts have word length between 100 and 1,000 while 25 posts have length greater than 1,000 words. Similarly, 4% (408 out of 10,217) of unique tags have a word length between 5 to 10 while 10 unique tags have a length between 20 to 30 words.\n\nFigure 2 shows that the intent posts are only 37% of topic posts and only 4% of the complete experimental dataset, revealing that the labeled data is highly imbalanced. Since, we use a tag...\n\n6 https://data.mendeley.com/datasets/hd3b6v659v/2",
                    "score": 0.6645447714434718
                },
                {
                    "context": "This table presents data on distinct posts categorized by various attributes, including language, content quality, topic relevance, and intent.,\nwith the following columns:\n- Distinct Posts: Total number of distinct posts.\n- English Language: Number of posts in English.\n- Too Less Content: Posts identified as having insufficient content.\n- Topic Related: Posts that are relevant to the specified topic.\n- Intent- Yes: Posts that have a clear intent.\n\n| Distinct Posts | English Language | Too Less Content | Topic Related | Intent- Yes |\n|---|---|---|---|---|\n|2955|2456|40|292|103|",
                    "score": 0.664254148631293
                },
                {
                    "context": "This table provides statistics on post characteristics, including average lengths of posts and tags, as well as the number of posts containing URLs.,\nwith the following columns:\n- Average Post Length: The average length of posts is 121.5 characters.\n- Average Tag Length: The average length of tags is 2.2 characters.\n- Posts Consisting of URLs: Total number of posts that include URLs is 323.\n- Posts Consisting of only URLs: Number of posts that consist solely of URLs is 35.\n\n| Average Post Length      | 121.5 | Average Tag Length            | 2.2 |\n|---|---|---|---|\n| Posts Consisting of URLs |323| Posts Consisting of only URLs |35|",
                    "score": 0.4887999342818075
                },
                {
                    "context": "This table presents the relationship between the length of posts and the corresponding length of tags in terms of the number of words.,\nwith the following columns:\n- Length of Posts: Distribution of post lengths.\n- Length of Tag: Number of words in tags corresponding to post lengths.\n\n| Length of Posts | Length of Tag   |\n|---|---|\n| x=1 (1%)        | Number of Words |\n| 1               | 1               |\n| 10              | 5               |\n| 100             | 10              |\n| x>1000 (1%)     | 20              |",
                    "score": 0.3262633623359546
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What was the size of the dataset analyzed in the article?",
                    "answer": "The size of the dataset analyzed in the article consisted of 2,456 English language posts."
                },
                {
                    "question": "[SQ] What criteria were used to select the posts included in the dataset?",
                    "answer": "The posts included in the dataset were selected based on their language, specifically focusing on English language posts. A total of 2,456 posts were chosen for annotation, which represented 83% of the extracted data. Non-English posts and those with insufficient content, identified as having 'unknown' language, were excluded. Additionally, posts were filtered to remove noisy text, such as special characters and emoticons, ensuring that only relevant content was analyzed. The dataset also focused on posts that were categorized as topic-related and had a clear intent, although the final selection was influenced by the need to maintain a balance in the classification of intent and topic relevance."
                },
                {
                    "question": "[SQ] What time period do the analyzed posts cover?",
                    "answer": "The time period covered by the analyzed posts is not specified in the provided information."
                },
                {
                    "question": "[SQ] Were there any specific themes or topics focused on within the dataset?",
                    "answer": "The dataset focused on specific themes related to religion and spirituality, society/unrest and war, society/racism, society/personal offense/hate crime, law and government/politics related to espionage and intelligence/terrorism, and legal issues/human rights."
                },
                {
                    "question": "[MQ] What was the size of the analyzed dataset, which consisted of 2,456 English language posts focused on themes such as religion, society, and politics?",
                    "answer": "The size of the analyzed dataset consisted of 2,456 English language posts."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 1.0,
                "semantic_similarity": 0.8199903686672796,
                "llm_context_precision_without_reference": 0.4401154401081049,
                "llm_context_precision_with_reference": 0.19999999999,
                "answer_relevancy": 0.8741693218537754,
                "answer_correctness": 0.2049975921668199
            },
            "deepeval": {
                "contextual_precision": 0.5,
                "contextual_recall": 0.0,
                "contextual_relevancy": 0.12048192771084337,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 10,
        "job_id": 1,
        "file_id": 2,
        "question_id": 5,
        "status": "done",
        "answer_text": "The study evaluated several performance metrics related to classification models, including:\n\n1. **True Positives (TP)**: 253\n2. **False Positives (FP)**: 93\n3. **False Negatives (FN)**: 39\n4. **True Negatives (TN)**: 2034\n\nAdditionally, the performance metrics for various classification algorithms across two test datasets included:\n\n- **Recall**:\n  - Decision Tree (DT): 0.79 (Test-Data1), 0.82 (Test-Data2)\n  - Random Forest (RF): 0.82 (Test-Data1), 0.84 (Test-Data2)\n  - Naive Bayes (NB): 0.79 (Test-Data1), 0.83 (Test-Data2)\n\n- **Precision**:\n  - Decision Tree (DT): 0.72 (Test-Data1), 0.75 (Test-Data2)\n  - Random Forest (RF): 0.78 (Test-Data1), 0.81 (Test-Data2)\n  - Naive Bayes (NB): 0.74 (Test-Data1), 0.78 (Test-Data2)\n\nCohen's Kappa coefficients for inter-rater agreement were reported as follows:\n- For topic annotations: 0.98\n- For intent annotations: 0.91",
        "answer_encoded": "[response not coded] The study reported performance metrics including True Positives (253), False Positives (93), False Negatives (39), True Negatives (2034), Recall values for Decision Tree (0.79-0.82), Random Forest (0.82-0.84), Naive Bayes (0.79-0.83), Precision values for Decision Tree (0.72-0.75), Random Forest (0.78-0.81), Naive Bayes (0.74-0.78), and Cohen's Kappa coefficients of 0.98 for topic annotations and 0.91 for intent annotations.",
        "answer_contexts": [
                {
                    "context": "This table presents the performance metrics (Recall and Precision) of various classification algorithms (Decision Tree, Random Forest, Naive Bayes) across two test datasets (Test-Data1 and Test-Data2).,\nwith the following columns:\n- Recall: Recall values for each algorithm across the two datasets.\n- Precision: Precision values for each algorithm across the two datasets.\n\n|   |           | Test-Data1 | Test-Data2 |      |      .1|      .2|      .3|\n|---|---|---|---|---|---|---|---|\n|   |           | DT         | RF         | NB   | DT   | RF   | NB   |\n|   | Recall    | 0.79       | 0.82       | 0.79 | 0.82 | 0.84 | 0.83 |\n|   | Precision | 0.72       | 0.78       | 0.74 | 0.75 | 0.81 | 0.78 |",
                    "score": 0.8418508648894797
                },
                {
                    "context": "This table presents the accuracy metrics, specifically precision and recall, for three different classifiers: Random Forest, Decision Tree, and Naive Bayes.,\nwith the following table title:\nAccuracy Metrics for Classifiers,\nwith the following columns:\n- Classifier: Different types of classifiers used in the analysis.\n- Metrics: Performance metrics including precision and recall for each classifier.\n\n| Table V: Accuracy Metrics for Classifiers |                               |\n|---|---|\n| Classifier                                | Metrics                       |\n| Random Forest (RF)                        | Precision: 0.78, Recall: 0.82 |\n| Decision Tree (DT)                        | Precision: 0.81, Recall: 0.84 |\n| Naive Bayes (NB)                          | Precision: 0.76, Recall: 0.80 |",
                    "score": 0.8336870021025126
                },
                {
                    "context": "This table presents a summary of predictive performance metrics, including true positives, false positives, false negatives, and true negatives, indicating the effectiveness of a classification model.,\nwith the following columns:\n- Topic: Describes the different metrics related to the classification model.\n- Predicted: Indicates the predicted outcomes based on the model.\n\n| Topic   | Predicted |\n|---|---|\n| TP=253  | Unknown   |\n| Actual  | Unknown   |\n| FP=93   | FN=39     |\n| TN=2034 |           |",
                    "score": 0.831508047766065
                },
                {
                    "context": "ROC Curve Analysis\n\nFig. 6. ROC Curve for Test-Data1 (Right) and Test-Data2 (Left). Source: Agarwal et al. [12]\n\nEach of our classifiers (RF, NB, and DT) using a 5 fold cross validation over the experimental dataset. Since, the accuracy measures are biased towards the majority class, we evaluate the performance of intent classifier using two standard information retrieval metrics i.e. precision and Area Under Operator Receiver Curve (AUC). Due to the misclassification in topic modeling, we evaluate the performance of intent classification in two steps. We first execute our model on all 346 posts (Test-Data1) classified as topic in previous stage. In second iteration, we evaluate the performance of intent classifier on 253 Tumblr posts (Test-Data2) correctly classified as topic.",
                    "score": 0.6568190401657333
                },
                {
                    "context": "This table presents the results of topic and intent annotation, including the number of annotations, observed agreement, random agreement probability, and Cohen's Kappa coefficients for both topic and intent classifications.,\nwith the following columns:\n- (a) Topic Annotation: Number of topic annotations.\n- (b) Intent Annotation: Number of intent annotations.\n- (c) Cohen’s Kappa Coefficient: Statistical measure of inter-rater agreement.\n\n|    | (a) Topic Annotation | (b) Intent Annotation |    .1|                        | (c) Cohen’s Kappa Coefficient |                       |      |      .1|\n|---|---|---|---|---|---|---|---|---|\n| A1 | Topic                | 292                   | A1 | Intent                 |103.0| Observed Agreement Po | 0.98 | 0.95 |\n| NA | 24                   | NA                    | 2  | Random Agreement Pr(e) |0.77| 0.51                  |      |      |\n| NA | 13                   | 2127                  | NA | 12                     |175.0| Kappa Coefficient κ   | 0.91 | 0.95 |",
                    "score": 0.4982812723749417
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific performance metrics were evaluated in the study, and what were their corresponding values?",
                    "answer": "The study evaluated several performance metrics related to classification models, including:\n\n1. **True Positives (TP)**: 253\n2. **False Positives (FP)**: 93\n3. **False Negatives (FN)**: 39\n4. **True Negatives (TN)**: 2034\n\nAdditionally, the performance metrics for various classification algorithms across two test datasets included:\n\n- **Recall**:\n  - Decision Tree (DT): 0.79 (Test-Data1), 0.82 (Test-Data2)\n  - Random Forest (RF): 0.82 (Test-Data1), 0.84 (Test-Data2)\n  - Naive Bayes (NB): 0.79 (Test-Data1), 0.83 (Test-Data2)\n\n- **Precision**:\n  - Decision Tree (DT): 0.72 (Test-Data1), 0.75 (Test-Data2)\n  - Random Forest (RF): 0.78 (Test-Data1), 0.81 (Test-Data2)\n  - Naive Bayes (NB): 0.74 (Test-Data1), 0.78 (Test-Data2)\n\nFor the classifiers, the accuracy metrics were:\n\n- Random Forest (RF): Precision: 0.78, Recall: 0.82\n- Decision Tree (DT): Precision: 0.81, Recall: 0.84\n- Naive Bayes (NB): Precision: 0.76, Recall: 0.80\n\nLastly, the study also reported Cohen's Kappa coefficients for inter-rater agreement, with values of 0.98 for topic annotations and 0.91 for intent annotations."
                },
                {
                    "question": "[SQ] What were the accuracy values for each classification algorithm evaluated in the study?",
                    "answer": "The accuracy values for each classification algorithm evaluated in the study are as follows:\n\n- Random Forest (RF): Precision: 0.78, Recall: 0.82\n- Decision Tree (DT): Precision: 0.81, Recall: 0.84\n- Naive Bayes (NB): Precision: 0.76, Recall: 0.80"
                },
                {
                    "question": "[SQ] How did the performance metrics vary between the two test datasets?",
                    "answer": "The performance metrics for the classification algorithms varied between the two test datasets. For Test-Data1, the Recall values were 0.79 for Decision Tree, 0.82 for Random Forest, and 0.79 for Naive Bayes. In contrast, for Test-Data2, the Recall values improved slightly, with Decision Tree at 0.82, Random Forest at 0.84, and Naive Bayes at 0.83. \n\nIn terms of Precision, Test-Data1 showed values of 0.72 for Decision Tree, 0.78 for Random Forest, and 0.74 for Naive Bayes. For Test-Data2, the Precision values were higher, with Decision Tree at 0.75, Random Forest at 0.81, and Naive Bayes at 0.78. \n\nOverall, both Recall and Precision metrics improved from Test-Data1 to Test-Data2 for all three classifiers."
                },
                {
                    "question": "[SQ] What were the specific values of Cohen's Kappa coefficients for the different classification tasks?",
                    "answer": "The specific values of Cohen's Kappa coefficients for the different classification tasks are as follows:\n\n- For topic classification: 0.91\n- For intent classification: 0.95"
                },
                {
                    "question": "[MQ] What performance metrics, including True Positives, False Positives, Recall, Precision, and Cohen's Kappa coefficients, were evaluated in the study, and what were their corresponding values for the classification algorithms across the test datasets?",
                    "answer": "The performance metrics evaluated in the study include True Positives (TP), False Positives (FP), Recall, Precision, and Cohen's Kappa coefficients. The corresponding values for the classification algorithms across the test datasets are as follows:\n\n- True Positives (TP): 253\n- False Positives (FP): 93\n- False Negatives (FN): 39\n- True Negatives (TN): 2034\n\nFor the classification algorithms across the test datasets:\n\n**Test-Data1:**\n- Decision Tree (DT): \n  - Recall: 0.79 \n  - Precision: 0.72\n- Random Forest (RF): \n  - Recall: 0.82 \n  - Precision: 0.78\n- Naive Bayes (NB): \n  - Recall: 0.79 \n  - Precision: 0.74\n\n**Test-Data2:**\n- Decision Tree (DT): \n  - Recall: 0.82 \n  - Precision: 0.75\n- Random Forest (RF): \n  - Recall: 0.84 \n  - Precision: 0.81\n- Naive Bayes (NB): \n  - Recall: 0.83 \n  - Precision: 0.78\n\nCohen's Kappa coefficients for the annotations were:\n- For topic annotations: 0.98\n- For intent annotations: 0.91"
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0.9523809523809523,
                "semantic_similarity": 0.7596778074471165,
                "llm_context_precision_without_reference": 0.3888888888759259,
                "llm_context_precision_with_reference": 0.11111111109999999,
                "answer_relevancy": 0.8383957941588017,
                "answer_correctness": 0.18991945186177914
            },
            "deepeval": {
                "contextual_precision": 0.8333333333333334,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.16822429906542055,
                "answer_relevancy": 0.9523809523809523,
                "faithfulness": 0.8
            }
        }
    },
        {
        "id": 11,
        "job_id": 1,
        "file_id": 3,
        "question_id": 1,
        "status": "done",
        "answer_text": "The study utilized several machine learning algorithms, including Char-LSTM and LabelSpreading with RBF kernel. Char-LSTM achieved a precision of 0.77 and a recall of 0.76, resulting in an F1-score of 0.76, indicating its effectiveness in minimizing false negatives. LabelSpreading with RBF kernel also achieved the same F1-score, demonstrating the robustness of the feature engineering scheme employed. These algorithms contributed to the findings by effectively classifying Twitter handles as extremist or non-extremist based on the engineered features, thereby aiding in the detection of violent extremists on social media.",
        "answer_encoded": "Char-LSTM, LabelSpreading (RBF)",
        "answer_contexts": [
                {
                    "context": "Among several approaches used in this work, char-LSTM and the semi-supervised approach LabelSpreading with RBF kernel achieve the equal and highest F1-score of 0.76. The fact that the LabelSpreading achieves comparable performance as char-LSTM, further demonstrates the effectiveness of the proposed feature engineering scheme, as LSTM has shown promising results in the literature while it does not use any hand-crafted features. Char-LSTM achieves a precision of 0.77 while maintaining a high recall of 0.76 on the positive class. This suggests that the memory module in LSTM can help in minimizing the number of false negatives.\n\n II. RELATED WORK\n\nThe explosive growth of the Web has raised numerous security and privacy issues. Mitigating these concerns has been studied from different aspects [6], [18], [23], [26]. For instance, several studies have focused on understanding extremism in social networks [4], [5], [8], [9], [11], [16], [17]. For instance, the work of [11], uses Twitter and proposes an approach to predict new extremists. They also determine if the newly created account belongs to a suspended extremist, and predict the ego-network of the suspended extremist upon creating her new account. Their approach integrates variants of the logistic regression with optimized search policies to detect the new accounts of returning suspended extremist users. They (1) use potential features of an account to predict if this account belongs to an extremist user, (2) determine if multiple accounts belong to the same extremist user, based on the fact that new account shall resemble the suspended account in different aspects, (3) predict whom the suspended extremist user is most likely to follow again, and finally (4) develop a network search policy to find the suspected users upon returning to a social network. Similar work of [8] uses tweets to build models to predict (1) if a pro-ISIS user’s account will be suspended due to the extremist content, (2) which users will adopt and retweet ISIS content, and (3) which users will have interactions with pro-ISIS users. To do so, the authors use logistic regression and random forest classifiers for different types of prediction tasks. They deploy variety of features across different dimensions, such as user meta-data, network statistics and temporal patterns of activity. Two scenarios are then designed for each prediction task: a time independent (static) one which does not take into account the temporal dependencies, and a simulated real-time one by considering the timeline of content availability. The difference between these two studies is, authors of [11] also study other aspects including identifying multiple accounts for an extremist user, re-following suspended accounts’ connections and searching for the suspended extremist users who might return to a social media.\n\nOther works also seek to identify the extremist content in radicalized groups beyond ISIS. The work of [16] uses data from Jihadist website Ansar AlJihad Network to develop supervised learning and NLP techniques to automatically detect cyber-recruitment of extremist groups. A comparison is done between classifiers naïve Bayes, logistic regression, classification trees, boosting and SVM, for labeling forum posts as either related or not related to the recruitment of extremist groups. They leverage the bag-of-words technique to convert the corpus into a term-document matrix, following the standard routine of the preprocessing techniques such as basic normalization and stemming. Similarly in [17], same Jihadist network along with their previously developed SVM classifier are used to automatically identify recruitment posts. Their previous work shall be served as pre-screening step to reduce the efforts made by human analysts to manually hand-label the documents. In their new study, the textual content of the dataset is analyzed with latent Dirichlet allocation (LDA) and fed into several time-series models to predict cyber-recruitment. This new research conducted by the same authors complemented their previous study, by applying current natural language processing and time series analysis techniques to forecast the recruitments.\n\nBeyond these works, the work of [9] takes a different approach to track individual’s behavioral indicators of home-grown extremism, using public and law enforcement data. The intuition is to use graph pattern matching to identify suspicious trajectories and potential radicalization over a dynamic heterogeneous graph associated with the fused data from public and law enforcement. The authors first develop a query pattern of radicalization and then run several graph pattern matching algorithms to detect and track the on-going radicalization. They develop the investigative simulation graph pattern matching technique, which is composed of required extension to the existing dual simulation graph pattern matching method to avoid over-matching. This approach provides analysts and law enforcement officials with the ability to find partial/full matches, given a query of radicalization, as well as the pace of the appearance of the radicalized extremists.",
                    "score": 0.8620329792191936
                },
                {
                    "context": "A. Approaches\n\n- Semi-Supervised: Laplacian support vector machines [2], graph inference-based label spreading approach [21] with radial basis function (RBF) and K-nearest neighbor (KNN) kernels, and co-training learner [7] with two SVMs.\n- Supervised: SVM, KNN, Gaussian naïve Bayes, logistic regression, adaboost, random forest, and Char-LSTM [24].\n\nWe note that supervised learners only use labeled instances for the training process, while semi-supervised algorithms use labeled and unlabeled instances [10]. For the sake of fair comparison, all algorithms were implemented and run in Python. Note for the methods that require special tuning of parameters, we performed grid search to choose the best set of parameters. Before going any further, we define the parameters used in each learner and then demonstrate their best picked values by our grid search.\n\n- SVM: Tolerance for stopping criteria was set to the default value of 0.001. Penalty parameter C was set to 1 and linear kernel was used.\n- Char-LSTM: This is similar to the character-aware models used for sequential word predictions. We adapt the neural network to a sequence classification problem where the inputs are the vector of one-hot encoding of each character of the handle and the output is the handle being classified as extremist or non-extremist. We set the maximum username length to 10, padding with zeros where necessary. We use an embedding layer after the input layer to convert each username dimension to 16. This is fed to a single layer LSTM module having 30 units.\n- LabelSpreading (RBF): RBF Kernel was used and γ was set to the default value of 20.\n- Laplacian SVM: We used linear kernel and set the parameters Cl = 0.6 and Cs = 0.6.\n- LabelSpreading (KNN): KNN kernel was used and the number of neighbors was set to 5.\n- Co-training (SVM): We followed the algorithm introduced in [7] and used two SVM as our classifiers. For both SVMs we set the tolerance for stopping criteria to 0.001 and the penalty parameter C = 1.\n- KNN: The number of neighbors was set to 5.\n- Gaussian NB: There were no specific parameter to tune.\n- Logistic regression: We used the l2 penalty. We also set the parameter C = 1 (the inverse of regularization strength) and tolerance for stopping criteria to 0.01.\n- Adaboost: The number of estimators was set to 200 and we also set the learning rate to 0.01.\n- Random forest: We used 200 estimators and the entropy criterion was used.\n\n B. Classification Results\n\nWe use tenfold cross-validation on the labeled data as follows. We first divided the set of labeled instances into 10 different sets of equal size. Each time, we held one set out for validation (we did this by removing their labels and adding them to the unlabeled instances). For the supervised learners, this set along with a set of the existing unlabeled samples are only used for the purpose of testing whereas for the semi-supervised setting, we use both sets in the training and testing phases. This procedure is performed for all approaches for the sake of fair comparison. Finally, we report the average of 10 different runs, using various evaluation metrics including precision, recall and F1-score in Table II.\n\n Observations.\n\n- SVM achieve the highest precision of 0.96 in identifying online violent extremists, which shows the significance of the proposed feature set.\n- The semi-supervised LabelSpreading (RBF) was able to perform as good as Char-LSTM and they both achieve the highest F1-score on identification of extremists. This along with the fact that Char-LSTM has shown promising results in the literature while it does not use any of our hand-crafted features, further demonstrates the effectiveness of the introduced feature engineering scheme.\n- For char-LSTM, we achieve a precision of 0.77 while maintaining a high recall of 0.76 on the positive class. This suggests that the memory module in LSTM can help in minimizing the number of false negatives.\n- Overall, the observations we make here suggest that the answer to the second question is positive– using an existing set of labeled examples could help inferring the labels of unseen usernames.",
                    "score": 0.7612819603529224
                },
                {
                    "context": "IV. METHODOLOGY\n\nHere, we first present the introduced feature groups used to filter out less likely extremists from the data. Next, we will pose our research questions and seek to answer them.\n\n A. Feature Engineering\n\nWe categorize the features used in this work into the following 3 major groups:\n\n1. Twitter handle’s related features: this group contains 3 features related to the given handle, namely, length of the handle, number of unique characters in the handle, and complexity of the handle. To compute the complexity, Kolmogorov complexity is used, which is defined as the length of the shortest program to reproduce the handle on a universal machine such as Turing machine [13]. Since Kolmogorov complexity is computationally intractable, we use the Entropy of the handle as a way to approximate its complexity.\n2. Profile related features: this group contains 7 features related to the profile of the user who posted the tweet, including the number of her followers, friends and tweets, the existence of profile’s description and location. Also, for the last two features in this group, we check if the account is verified and geo-enabled.\n3. Content related features: we have the following 3 features related to the content of the given tweet: the number of URLs, the number of hashtags and the sentiment of the content. For the sentiment, we check if the content has a higher negative score than its positive score.\n\nFor the sake of visualization, a 2-D projection of the sample of the filtered dataset (using t-SNE transformation [22]) is depicted in Fig. 1. As it is seen, basic clustering techniques such as K-means will have difficulty to correctly assign labels to the unlabeled instances using only few existing labeled samples.\n\n B. Research Questions\n\nHaving defined the feature engineering scheme in the previous section, here, we seek to answer the following research questions that will ultimately help identifying violent extremists in social media:\n\n- RQ1: Are extremists on Twitter inclined to adopt similar handles?\n\nFig. 1. 2-D projection of the sampled filtered data using t-SNE transformation. Clustering techniques such as K-means will have difficulty to correctly assign labels to the unlabeled instances using only few existing labeled samples.\n\n30\n\n20\n\n10\n\n-10\n\n20\n\n30\n\nPositive\n\n-40\n\nNegative\n\nUnlabeled\n\n20\n\n10\n\n10\n\n20\n\n- RQ2: Can we infer the labels (extremist vs. non-extremist) of unseen handles based on their proximity to the labeled instances?\n\nTo answer the first question, for each pair of extremist users (i, j) we compute the similarity between their corresponding handles 〈si, sj〉 as follows:\n\nSim(si, sj) = 1 - L(si, sj) / max(len(si), len(sj)) (1)\n\nwhere L(si, sj) is the well-known Lavenshtein ratio [12] which is used as a measure of distance between the two strings s1 and s2. We create a vector ve whose elements are similarity scores between each pair of extremists. We repeat the procedure for each pair of extremist i and a normal user k and create a vector ven. We conduct a two-sample t-test on ve and ven with the null and alternative hypotheses defined as H0: ve ≤ ven, H1: ve > ven. The null hypothesis is rejected at significance level α = 0.01 and p-value of p = 0.009, suggesting that extremists are biased towards adopting similar handles. Although this might seem a bit simplistic at the first sight, it has not been examined in the literature. Later, we will see how effective this simple idea could be in inferring the labels for unseen handles and help detecting the extremists by merely glancing at their handles.\n\nTo answer the second question, let us first obtain our feature spaces associated with the labeled and unlabeled instances, by converting each handle to a vector of 5 features. We use the following features: length of the handle, maximum number of occurrence of a character in the handle, number of unique characters in the handle, number of digits that the handle starts with, and complexity of the handle. Ultimately, these two feature spaces are fed as the inputs to the semi-supervised and supervised learners.\n\n V. EXPERIMENTS\n\nIn this section, we first describe the learners used in this work and provide details on the parameters they use. Then, classification results are presented and finally significance of the features is discussed.",
                    "score": 0.6473828846538342
                },
                {
                    "context": "This new research conducted by the same authors complemented their previous study, by applying current natural language processing and time series analysis techniques to forecast the recruitments.\n\nBeyond these works, the work of [9] takes a different approach to track individual’s behavioral indicators of home-grown extremism, using public and law enforcement data. The intuition is to use graph pattern matching to identify suspicious trajectories and potential radicalization over a dynamic heterogeneous graph associated with the fused data from public and law enforcement. The authors first develop a query pattern of radicalization and then run several graph pattern matching algorithms to detect and track the on-going radicalization. They develop the investigative simulation graph pattern matching technique, which is composed of required extension to the existing dual simulation graph pattern matching method to avoid over-matching. This approach provides analysts and law enforcement officials with the ability to find partial/full matches, given a query of radicalization, as well as the pace of the appearance of the radicalized extremists. As opposed to the above studies, in this paper, we make the first attempt on determining if a given Twitter handle belongs to an extremist user or not, using only little information gathered from the handle, profile and content.\n\n III. DATA PREPARATION\n\nThe dataset was collected from Twitter and consists of approximately 1.6M tweets that were posted using 25 extremism-related hashtags such as #AbuBakralBaghdadi, #ISIL, #ISIS, #Daesh, and #IslamicState. We construct our extremist labels (positive labels) by collecting a limited number of 150 suspended ISIS-related Twitter handles which were reported to the Twitter Safety account (@TwitterSafety) by normal users. To make a balanced labeled dataset, 150 random handles corresponding to normal users were also collected to serve as our negative labels. Inspired by the literature [8], [11], [19], we define 3 major groups of overall 13 features, which could be leveraged to filter out less likely extremists. This way, we obtain 300K highly extremism related tweets from which we randomly pick a smaller sample of 3K handles who posted the tweets. The description of the dataset is shown in Table I.",
                    "score": 0.37632678589705176
                },
                {
                    "context": "C. Significance of Features\n\nWe conduct significance analysis of the features using the labeled instances and feature selection measure χ2. The results in Table III suggest that the most significant feature is the number of the unique characters in the username while the least important one is the maximum number of occurrence of a character in the username. This observation further demonstrates that frequency and importance of the features in the labeled dataset are not necessarily in line with each other and in fact are inversely related in our case. In other words, although maximum number of occurrence of a character in the username is the most frequent feature in the labeled dataset, it is the least important feature in identification of online violent extremists according to the Fig. 2 where we depict the frequency of each feature for both labeled and unlabeled examples.\n\n VI. CONCLUSION AND FUTURE WORK\n\nIn this work, we presented a scheme that using as little as three groups of information related to the Twitter handle, profile and textual content of users, can determine if a given handle could belong to an extremist. The framework first uses highly indicative patterns related to extremism to filter out less likely extremists. Ultimately, high likely extremist are identified using only features related to their usernames.\n\nIn future, we would like to replicate the work by deploying more features and investigate if incorporating those features to the framework can lead to performance boost. We also plan to incorporate the feature space designed in this work into a semi-supervised learner as regularization terms in order to further increase the classification performance in detecting online violent extremists. Finally, since hand-labeling unlabeled examples is expensive, a valuable research direction would be to deploy active learning to enable iterative supervised learning to actively query for labels.\n\n VII. ACKNOWLEDGMENTS\n\nThis work was supported through DoD Minerva program.\n\n REFERENCES\n\n[1] Abutaleb, Y. \"Twitter suspended 360,000 accounts for 'promotion of terrorism'.\" http://www.reuters.com/article/us-twitter-terrorism-idUSKCN10T1ST, August 2016.\n\n[2] M. Belkin, P. Niyogi, and V. Sindhwani. \"Manifold regularization: A geometric framework for learning from labeled and unlabeled examples.\" JMLR, vol. 7, no. Nov, pp. 2399-2434, 2006.\n\n[3] Alvari, Hamidreza, Sattar Hashemi, and Ali Hamzeh. \"Detecting overlapping communities in social networks by game theory and structural equivalence concept.\" In International Conference on Artificial Intelligence and Computational Intelligence, pp. 620-630. Springer, Berlin, Heidelberg, 2011.\n\n[4] Benigni, Matthew C and Joseph, Kenneth and Carley, Kathleen M. \"Online extremism and the communities that sustain it: Detecting the ISIS supporting community on Twitter.\" PloS one, 2017.\n\n[5] Benigni, Matthew and Carley, Kathleen M. \"From Tweets to Intelligence: Understanding the Islamic Jihad Supporting Community on Twitter.\" 2016 International Conference on Social Computing, Behavioral-Cultural Modeling, & Prediction and Behavior Representation in Modeling and Simulation.\n\n[6] Beigi, Ghazaleh, and Huan Liu. \"Privacy in social media: Identification, mitigation and applications.\" arXiv preprint arXiv:1808.02191 (2018).\n\n[7] Blum, A., and Mitchell, T. \"Combining labeled and unlabeled data with co-training.\" COLT, 1998.\n\n[8] Ferrara, E., Wang, W., Varol, O, Flammini, A., and Galstyan, A. \"Predicting online extremism, content adopters, and interaction reciprocity.\" SocInfo, 2016.\n\n[9] Hung, B., Jayasumana, P., and Bandara, V. \"Detecting Radicalization Trajectories Using Graph Pattern Matching Algorithms.\" ISI, 2016.\n\n[10] Alvari, Hamidreza, Paulo Shakarian, and JE Kelly Snyder. \"Semi-supervised learning for detecting human trafficking.\" Security Informatics 6, no. 1 (2017): 1.\n\n[11] Klausen, J., Marks, C., and Zaman, T. \"Finding Online Extremists in Social Networks.\" INFORMS, 2016.\n\n[12] \"How python-Levenshtein.ratio is computed.\" URL http://stackoverflow.com/questions/14260126/\n\n[13] Li, Ming and Vitnyi, Paul M.B. \"An Introduction to Kolmogorov Complexity and Its Applications.\" Springer, 2008.",
                    "score": 0.2792047665215019
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific AI algorithm was utilized in the study, and how does it contribute to the overall findings presented in the article?",
                    "answer": "The study utilized several machine learning algorithms, including Char-LSTM and LabelSpreading with RBF kernel. Char-LSTM achieved a precision of 0.77 and a recall of 0.76, resulting in an F1-score of 0.76, which indicates its effectiveness in minimizing false negatives. LabelSpreading with RBF kernel also achieved the same F1-score, demonstrating the robustness of the feature engineering scheme employed. These algorithms contributed to the findings by effectively classifying Twitter handles as extremist or non-extremist based on the engineered features, thereby aiding in the detection of violent extremists on social media."
                },
                {
                    "question": "[SQ] What are the key features used in the Char-LSTM and LabelSpreading algorithms for classification?",
                    "answer": "The Char-LSTM algorithm utilizes features related to the usernames, specifically focusing on the one-hot encoding of each character in the handle. It processes these inputs through an embedding layer and a single layer LSTM module to classify the handles as extremist or non-extremist.\n\nFor the LabelSpreading algorithm, the key features include the radial basis function (RBF) kernel, which is employed to spread labels across the data points based on their similarities. The effectiveness of the feature engineering scheme is highlighted by the performance of LabelSpreading, which achieves comparable results to Char-LSTM without relying on hand-crafted features. Additionally, the analysis indicates that the number of unique characters in a handle is a significant feature for classification."
                },
                {
                    "question": "[SQ] How do the performance metrics of Char-LSTM compare to other algorithms used in similar studies?",
                    "answer": "Char-LSTM achieves a precision of 0.77 and a recall of 0.76, resulting in an F1-score of 0.76. This performance is comparable to the semi-supervised approach LabelSpreading with RBF kernel, which also has an F1-score of 0.76 but with a higher precision of 0.85 and a recall of 0.69. In comparison to other algorithms, Char-LSTM's precision is lower than that of SVM, which has the highest precision at 0.96, but its recall is higher than that of SVM, which has a recall of 0.5. Other algorithms, such as Laplacian SVM and KNN, have F1-scores of 0.7 and 0.74, respectively, indicating that Char-LSTM performs well relative to these methods as well. Overall, Char-LSTM demonstrates strong performance, particularly in recall, while maintaining competitive precision and F1-score among the various algorithms evaluated."
                },
                {
                    "question": "[SQ] What specific challenges were addressed by using the RBF kernel in the LabelSpreading algorithm?",
                    "answer": "The use of the RBF kernel in the LabelSpreading algorithm addresses challenges related to the effective handling of non-linear relationships in the data. It allows the algorithm to capture complex patterns and similarities between instances, which is particularly useful in scenarios where the data may not be linearly separable. This capability enhances the algorithm's performance in inferring labels for unseen instances by leveraging the structure of the data more effectively than linear kernels might. Additionally, the RBF kernel helps in managing the influence of distance between labeled and unlabeled instances, thereby improving the overall classification accuracy."
                },
                {
                    "question": "[MQ] What machine learning algorithms were employed in the study, specifically Char-LSTM and LabelSpreading with RBF kernel, and how did their performance contribute to classifying Twitter handles as extremist or non-extremist?",
                    "answer": "Char-LSTM and LabelSpreading with RBF kernel were two machine learning algorithms employed in the study. Both achieved the highest F1-score of 0.76, indicating their effectiveness in classifying Twitter handles as extremist or non-extremist. Char-LSTM demonstrated a precision of 0.77 and a recall of 0.76 on the positive class, suggesting that its memory module helped reduce false negatives. The comparable performance of LabelSpreading to Char-LSTM further validated the proposed feature engineering scheme, highlighting the significance of the features used in the classification process. This suggests that both algorithms effectively leveraged the features derived from Twitter handles, user profiles, and tweet content to identify extremist users."
                },
                {
                    "question": "[SQ] What specific features derived from Twitter handles were most influential in the performance of Char-LSTM and LabelSpreading?",
                    "answer": "The most influential features derived from Twitter handles that contributed to the performance of Char-LSTM and LabelSpreading include the length of the handle, the number of unique characters in the handle, and the complexity of the handle. Among these, the number of unique characters was identified as the most significant feature in the classification task. Additionally, the complexity of the handle was approximated using the Entropy of the handle, which also played a role in the feature set used for classification."
                },
                {
                    "question": "[SQ] How does the performance of Char-LSTM and LabelSpreading compare to other machine learning algorithms in terms of precision and recall?",
                    "answer": "Char-LSTM achieves a precision of 0.77 and a recall of 0.76, while LabelSpreading with RBF kernel has a precision of 0.85 and a recall of 0.69. Compared to other algorithms, SVM has the highest precision at 0.96 but a lower recall of 0.5. Laplacian SVM and Co-Training (SVM) also show competitive precision values of 0.89 and 0.9, respectively, but their recall scores are lower than that of Char-LSTM. Overall, Char-LSTM maintains a good balance between precision and recall, while LabelSpreading demonstrates strong precision but slightly lower recall."
                },
                {
                    "question": "[SQ] What role did the feature engineering scheme play in the effectiveness of Char-LSTM and LabelSpreading for classifying extremist Twitter handles?",
                    "answer": "The feature engineering scheme significantly contributed to the effectiveness of both Char-LSTM and LabelSpreading in classifying extremist Twitter handles. It provided a structured approach to filter out less likely extremists by utilizing three major groups of features: Twitter handle-related features, profile-related features, and content-related features. This comprehensive feature set allowed the models to leverage important patterns associated with extremism, enhancing their classification performance. The comparable results achieved by LabelSpreading, despite not using hand-crafted features, further underscore the effectiveness of the feature engineering scheme in improving the overall classification accuracy of extremist handles."
                },
                {
                    "question": "[MQ] What specific machine learning algorithms, including Char-LSTM and LabelSpreading with RBF kernel, were utilized in the study to classify Twitter handles as extremist or non-extremist, and how did their performance metrics, such as precision and recall, reflect their effectiveness?",
                    "answer": "The study utilized several machine learning algorithms to classify Twitter handles as extremist or non-extremist, including Char-LSTM, LabelSpreading with RBF kernel, SVM, KNN, Gaussian naïve Bayes, logistic regression, adaboost, and random forest. \n\nChar-LSTM achieved a precision of 0.77 and a recall of 0.76 on the positive class, indicating its effectiveness in minimizing false negatives. LabelSpreading with RBF kernel matched Char-LSTM's performance, both achieving the highest F1-score of 0.76, which highlights the effectiveness of the feature engineering scheme used in the study. Additionally, SVM demonstrated the highest precision of 0.96 in identifying online violent extremists, showcasing the significance of the proposed feature set. Overall, these performance metrics reflect the algorithms' capabilities in accurately classifying extremist handles based on the features derived from Twitter data."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0.8,
                "semantic_similarity": 0.9492991716059898,
                "llm_context_precision_without_reference": 0.7470238095051339,
                "llm_context_precision_with_reference": 0.7470238095051339,
                "answer_relevancy": 0.863320117187547,
                "answer_correctness": 0.7998247929014973
            },
            "deepeval": {
                "contextual_precision": 0.8055555555555555,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.515625,
                "answer_relevancy": 1.0,
                "faithfulness": 0.8
            }
        },
    },
    {
        "id": 12,
        "job_id": 1,
        "file_id": 3,
        "question_id": 2,
        "status": "done",
        "answer_text": "The analysis in the study focused on three major groups of features related to Twitter handles, user profiles, and tweet content.\n\n1. **Twitter Handle Features**: This group included the length of the handle, the number of unique characters in the handle, and the complexity of the handle, which was approximated using the Entropy of the handle. These features were justified as they help in identifying patterns that may indicate extremist behavior based on the similarity of handles among extremist users.\n\n2. **Profile Features**: This group encompassed the number of followers, friends, and tweets of the user, as well as the existence of a profile description and location. Additionally, it considered whether the account was verified and geo-enabled. These features were relevant for understanding the user's social network and credibility, which could correlate with extremist tendencies.\n\n3. **Content Features**: This group included the number of URLs, the number of hashtags, and the sentiment of the tweet content, specifically focusing on whether the content had a higher negative score than positive. These features were selected to analyze the nature of the tweets themselves, as extremist content may exhibit specific characteristics in terms of sentiment and engagement.\n\nThe justification for these features was based on their potential to filter out less likely extremists and to identify patterns that could assist in detecting violent extremists on social media platforms. The significance of these features was further supported by statistical analysis, highlighting their relevance in the context of the research objectives.",
        "answer_encoded": "[response not coded] The analysis selected features related to Twitter handles (length, unique characters, complexity), user profiles (followers, friends, tweets, profile description, location, verification, geo-enablement), and tweet content (URLs, hashtags, sentiment) to identify patterns indicative of extremist behavior.",
        "answer_contexts": [
                {
                    "context": "IV. METHODOLOGY\n\nHere, we first present the introduced feature groups used to filter out less likely extremists from the data. Next, we will pose our research questions and seek to answer them.\n\n A. Feature Engineering\n\nWe categorize the features used in this work into the following 3 major groups:\n\n1. Twitter handle’s related features: this group contains 3 features related to the given handle, namely, length of the handle, number of unique characters in the handle, and complexity of the handle. To compute the complexity, Kolmogorov complexity is used, which is defined as the length of the shortest program to reproduce the handle on a universal machine such as Turing machine [13]. Since Kolmogorov complexity is computationally intractable, we use the Entropy of the handle as a way to approximate its complexity.\n2. Profile related features: this group contains 7 features related to the profile of the user who posted the tweet, including the number of her followers, friends and tweets, the existence of profile’s description and location. Also, for the last two features in this group, we check if the account is verified and geo-enabled.\n3. Content related features: we have the following 3 features related to the content of the given tweet: the number of URLs, the number of hashtags and the sentiment of the content. For the sentiment, we check if the content has a higher negative score than its positive score.\n\nFor the sake of visualization, a 2-D projection of the sample of the filtered dataset (using t-SNE transformation [22]) is depicted in Fig. 1. As it is seen, basic clustering techniques such as K-means will have difficulty to correctly assign labels to the unlabeled instances using only few existing labeled samples.\n\n B. Research Questions\n\nHaving defined the feature engineering scheme in the previous section, here, we seek to answer the following research questions that will ultimately help identifying violent extremists in social media:\n\n- RQ1: Are extremists on Twitter inclined to adopt similar handles?\n\nFig. 1. 2-D projection of the sampled filtered data using t-SNE transformation. Clustering techniques such as K-means will have difficulty to correctly assign labels to the unlabeled instances using only few existing labeled samples.\n\n30\n\n20\n\n10\n\n-10\n\n20\n\n30\n\nPositive\n\n-40\n\nNegative\n\nUnlabeled\n\n20\n\n10\n\n10\n\n20\n\n- RQ2: Can we infer the labels (extremist vs. non-extremist) of unseen handles based on their proximity to the labeled instances?\n\nTo answer the first question, for each pair of extremist users (i, j) we compute the similarity between their corresponding handles 〈si, sj〉 as follows:\n\nSim(si, sj) = 1 - L(si, sj) / max(len(si), len(sj)) (1)\n\nwhere L(si, sj) is the well-known Lavenshtein ratio [12] which is used as a measure of distance between the two strings s1 and s2. We create a vector ve whose elements are similarity scores between each pair of extremists. We repeat the procedure for each pair of extremist i and a normal user k and create a vector ven. We conduct a two-sample t-test on ve and ven with the null and alternative hypotheses defined as H0: ve ≤ ven, H1: ve > ven. The null hypothesis is rejected at significance level α = 0.01 and p-value of p = 0.009, suggesting that extremists are biased towards adopting similar handles. Although this might seem a bit simplistic at the first sight, it has not been examined in the literature. Later, we will see how effective this simple idea could be in inferring the labels for unseen handles and help detecting the extremists by merely glancing at their handles.\n\nTo answer the second question, let us first obtain our feature spaces associated with the labeled and unlabeled instances, by converting each handle to a vector of 5 features. We use the following features: length of the handle, maximum number of occurrence of a character in the handle, number of unique characters in the handle, number of digits that the handle starts with, and complexity of the handle. Ultimately, these two feature spaces are fed as the inputs to the semi-supervised and supervised learners.\n\n V. EXPERIMENTS\n\nIn this section, we first describe the learners used in this work and provide details on the parameters they use. Then, classification results are presented and finally significance of the features is discussed.",
                    "score": 0.8467229661875052
                },
                {
                    "context": "C. Significance of Features\n\nWe conduct significance analysis of the features using the labeled instances and feature selection measure χ2. The results in Table III suggest that the most significant feature is the number of the unique characters in the username while the least important one is the maximum number of occurrence of a character in the username. This observation further demonstrates that frequency and importance of the features in the labeled dataset are not necessarily in line with each other and in fact are inversely related in our case. In other words, although maximum number of occurrence of a character in the username is the most frequent feature in the labeled dataset, it is the least important feature in identification of online violent extremists according to the Fig. 2 where we depict the frequency of each feature for both labeled and unlabeled examples.\n\n VI. CONCLUSION AND FUTURE WORK\n\nIn this work, we presented a scheme that using as little as three groups of information related to the Twitter handle, profile and textual content of users, can determine if a given handle could belong to an extremist. The framework first uses highly indicative patterns related to extremism to filter out less likely extremists. Ultimately, high likely extremist are identified using only features related to their usernames.\n\nIn future, we would like to replicate the work by deploying more features and investigate if incorporating those features to the framework can lead to performance boost. We also plan to incorporate the feature space designed in this work into a semi-supervised learner as regularization terms in order to further increase the classification performance in detecting online violent extremists. Finally, since hand-labeling unlabeled examples is expensive, a valuable research direction would be to deploy active learning to enable iterative supervised learning to actively query for labels.\n\n VII. ACKNOWLEDGMENTS\n\nThis work was supported through DoD Minerva program.\n\n REFERENCES\n\n[1] Abutaleb, Y. \"Twitter suspended 360,000 accounts for 'promotion of terrorism'.\" http://www.reuters.com/article/us-twitter-terrorism-idUSKCN10T1ST, August 2016.\n\n[2] M. Belkin, P. Niyogi, and V. Sindhwani. \"Manifold regularization: A geometric framework for learning from labeled and unlabeled examples.\" JMLR, vol. 7, no. Nov, pp. 2399-2434, 2006.\n\n[3] Alvari, Hamidreza, Sattar Hashemi, and Ali Hamzeh. \"Detecting overlapping communities in social networks by game theory and structural equivalence concept.\" In International Conference on Artificial Intelligence and Computational Intelligence, pp. 620-630. Springer, Berlin, Heidelberg, 2011.\n\n[4] Benigni, Matthew C and Joseph, Kenneth and Carley, Kathleen M. \"Online extremism and the communities that sustain it: Detecting the ISIS supporting community on Twitter.\" PloS one, 2017.\n\n[5] Benigni, Matthew and Carley, Kathleen M. \"From Tweets to Intelligence: Understanding the Islamic Jihad Supporting Community on Twitter.\" 2016 International Conference on Social Computing, Behavioral-Cultural Modeling, & Prediction and Behavior Representation in Modeling and Simulation.\n\n[6] Beigi, Ghazaleh, and Huan Liu. \"Privacy in social media: Identification, mitigation and applications.\" arXiv preprint arXiv:1808.02191 (2018).\n\n[7] Blum, A., and Mitchell, T. \"Combining labeled and unlabeled data with co-training.\" COLT, 1998.\n\n[8] Ferrara, E., Wang, W., Varol, O, Flammini, A., and Galstyan, A. \"Predicting online extremism, content adopters, and interaction reciprocity.\" SocInfo, 2016.\n\n[9] Hung, B., Jayasumana, P., and Bandara, V. \"Detecting Radicalization Trajectories Using Graph Pattern Matching Algorithms.\" ISI, 2016.\n\n[10] Alvari, Hamidreza, Paulo Shakarian, and JE Kelly Snyder. \"Semi-supervised learning for detecting human trafficking.\" Security Informatics 6, no. 1 (2017): 1.\n\n[11] Klausen, J., Marks, C., and Zaman, T. \"Finding Online Extremists in Social Networks.\" INFORMS, 2016.\n\n[12] \"How python-Levenshtein.ratio is computed.\" URL http://stackoverflow.com/questions/14260126/\n\n[13] Li, Ming and Vitnyi, Paul M.B. \"An Introduction to Kolmogorov Complexity and Its Applications.\" Springer, 2008.",
                    "score": 0.8275481003815147
                },
                {
                    "context": "This new research conducted by the same authors complemented their previous study, by applying current natural language processing and time series analysis techniques to forecast the recruitments.\n\nBeyond these works, the work of [9] takes a different approach to track individual’s behavioral indicators of home-grown extremism, using public and law enforcement data. The intuition is to use graph pattern matching to identify suspicious trajectories and potential radicalization over a dynamic heterogeneous graph associated with the fused data from public and law enforcement. The authors first develop a query pattern of radicalization and then run several graph pattern matching algorithms to detect and track the on-going radicalization. They develop the investigative simulation graph pattern matching technique, which is composed of required extension to the existing dual simulation graph pattern matching method to avoid over-matching. This approach provides analysts and law enforcement officials with the ability to find partial/full matches, given a query of radicalization, as well as the pace of the appearance of the radicalized extremists. As opposed to the above studies, in this paper, we make the first attempt on determining if a given Twitter handle belongs to an extremist user or not, using only little information gathered from the handle, profile and content.\n\n III. DATA PREPARATION\n\nThe dataset was collected from Twitter and consists of approximately 1.6M tweets that were posted using 25 extremism-related hashtags such as #AbuBakralBaghdadi, #ISIL, #ISIS, #Daesh, and #IslamicState. We construct our extremist labels (positive labels) by collecting a limited number of 150 suspended ISIS-related Twitter handles which were reported to the Twitter Safety account (@TwitterSafety) by normal users. To make a balanced labeled dataset, 150 random handles corresponding to normal users were also collected to serve as our negative labels. Inspired by the literature [8], [11], [19], we define 3 major groups of overall 13 features, which could be leveraged to filter out less likely extremists. This way, we obtain 300K highly extremism related tweets from which we randomly pick a smaller sample of 3K handles who posted the tweets. The description of the dataset is shown in Table I.",
                    "score": 0.5862353315766493
                },
                {
                    "context": "Detection of Violent Extremists in Social Media\n\nHamidreza Alvari, Soumajyoti Sarkar, Paulo Shakarian\n\nArizona State University\n\nTempe, USA\n\n{halvari, ssarka18, shak}@asu.edu\n\n Abstract\n\nThe ease of use of the Internet has enabled violent extremists such as the Islamic State of Iraq and Syria (ISIS) to easily reach large audience, build personal relationships and increase recruitment. Social media are primarily based on the reports they receive from their own users to mitigate the problem. Despite efforts of social media in suspending many accounts, this solution is not guaranteed to be effective, because not all extremists are caught this way, or they can simply return with another account or migrate to other social networks. Consequently, extra efforts need to be dedicated to proposing capabilities that could be deployed by authorities to combat radicalized extremists and mitigate their threats, regardless of the underlying social network platform.\n\n Present work\n\nIn this paper, we design a detection scheme that using as little as three groups of information (inspired from the literature [8], [11], [19]), can determine whether or not a given username1 belongs to an extremist user. Specifically, we use a dataset from Twitter [25] and first show that extremist users on Twitter tend to adopt handles that follow similar patterns, in contrast to the normal users. Then, a detection framework is proposed to identify if a given Twitter handle belongs to an extremist given its proximity to an existing set of extremist-related handles. We compare different supervised and semi-supervised approaches using the features from Twitter handle, profile information and content which are highly indicative of online extremism. To further show the significance of the features we conduct significance analysis of the features using the labeled instances and feature selection measure χ2 and compare our results against char-LSTM which automatically extracts features.\n\n Contributions\n\nOur main contributions are thus summarized in below:\n\n- We first demonstrate that extremists on Twitter are inclined towards adopting handles with similar patterns. To that end, we used the well-known Lavenshtein ratio as a measure of distance between two Twitter handles and performed two-sample t-test to demonstrate that compared to normal users, extremists tend to choose similar handles.\n- We propose three main groups of features, related to the Twitter handles, profile information and tweet-level content. Overall, our feature engineering scheme has 13 features which are then fed into different supervised and semi-supervised learners.\n- Results on a real-world ISIS-related dataset demonstrate that the introduced features are effective in detecting online violent extremists in social media.\n\n Observations\n\nWe make the following observations:\n\n- The highest precision of 0.96 in identification of the extremists belongs to SVM. This is in line with the previous research that SVM performs well on textual data.\n\n1In this work, we may use the terms usernames and handles interchangeably.",
                    "score": 0.5781169872200685
                },
                {
                    "context": "Among several approaches used in this work, char-LSTM and the semi-supervised approach LabelSpreading with RBF kernel achieve the equal and highest F1-score of 0.76. The fact that the LabelSpreading achieves comparable performance as char-LSTM, further demonstrates the effectiveness of the proposed feature engineering scheme, as LSTM has shown promising results in the literature while it does not use any hand-crafted features. Char-LSTM achieves a precision of 0.77 while maintaining a high recall of 0.76 on the positive class. This suggests that the memory module in LSTM can help in minimizing the number of false negatives.\n\n II. RELATED WORK\n\nThe explosive growth of the Web has raised numerous security and privacy issues. Mitigating these concerns has been studied from different aspects [6], [18], [23], [26]. For instance, several studies have focused on understanding extremism in social networks [4], [5], [8], [9], [11], [16], [17]. For instance, the work of [11], uses Twitter and proposes an approach to predict new extremists. They also determine if the newly created account belongs to a suspended extremist, and predict the ego-network of the suspended extremist upon creating her new account. Their approach integrates variants of the logistic regression with optimized search policies to detect the new accounts of returning suspended extremist users. They (1) use potential features of an account to predict if this account belongs to an extremist user, (2) determine if multiple accounts belong to the same extremist user, based on the fact that new account shall resemble the suspended account in different aspects, (3) predict whom the suspended extremist user is most likely to follow again, and finally (4) develop a network search policy to find the suspected users upon returning to a social network. Similar work of [8] uses tweets to build models to predict (1) if a pro-ISIS user’s account will be suspended due to the extremist content, (2) which users will adopt and retweet ISIS content, and (3) which users will have interactions with pro-ISIS users. To do so, the authors use logistic regression and random forest classifiers for different types of prediction tasks. They deploy variety of features across different dimensions, such as user meta-data, network statistics and temporal patterns of activity. Two scenarios are then designed for each prediction task: a time independent (static) one which does not take into account the temporal dependencies, and a simulated real-time one by considering the timeline of content availability. The difference between these two studies is, authors of [11] also study other aspects including identifying multiple accounts for an extremist user, re-following suspended accounts’ connections and searching for the suspended extremist users who might return to a social media.\n\nOther works also seek to identify the extremist content in radicalized groups beyond ISIS. The work of [16] uses data from Jihadist website Ansar AlJihad Network to develop supervised learning and NLP techniques to automatically detect cyber-recruitment of extremist groups. A comparison is done between classifiers naïve Bayes, logistic regression, classification trees, boosting and SVM, for labeling forum posts as either related or not related to the recruitment of extremist groups. They leverage the bag-of-words technique to convert the corpus into a term-document matrix, following the standard routine of the preprocessing techniques such as basic normalization and stemming. Similarly in [17], same Jihadist network along with their previously developed SVM classifier are used to automatically identify recruitment posts. Their previous work shall be served as pre-screening step to reduce the efforts made by human analysts to manually hand-label the documents. In their new study, the textual content of the dataset is analyzed with latent Dirichlet allocation (LDA) and fed into several time-series models to predict cyber-recruitment. This new research conducted by the same authors complemented their previous study, by applying current natural language processing and time series analysis techniques to forecast the recruitments.\n\nBeyond these works, the work of [9] takes a different approach to track individual’s behavioral indicators of home-grown extremism, using public and law enforcement data. The intuition is to use graph pattern matching to identify suspicious trajectories and potential radicalization over a dynamic heterogeneous graph associated with the fused data from public and law enforcement. The authors first develop a query pattern of radicalization and then run several graph pattern matching algorithms to detect and track the on-going radicalization. They develop the investigative simulation graph pattern matching technique, which is composed of required extension to the existing dual simulation graph pattern matching method to avoid over-matching. This approach provides analysts and law enforcement officials with the ability to find partial/full matches, given a query of radicalization, as well as the pace of the appearance of the radicalized extremists.",
                    "score": 0.3600442500649496
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific features or characteristics were selected for analysis in the study, and how were they justified in the context of the research objectives?",
                    "answer": "The analysis in the study focused on three major groups of features related to Twitter handles, user profiles, and tweet content. \n\n1. **Twitter Handle’s Related Features**: This group included the length of the handle, the number of unique characters in the handle, and the complexity of the handle, which was approximated using the Entropy of the handle. These features were justified as they help in identifying patterns that may indicate extremist behavior based on the similarity of handles among extremist users.\n\n2. **Profile Related Features**: This group encompassed the number of followers, friends, and tweets of the user, as well as the existence of a profile description and location. Additionally, it considered whether the account was verified and geo-enabled. These features were relevant for understanding the user's social network and credibility, which could correlate with extremist tendencies.\n\n3. **Content Related Features**: This group included the number of URLs, the number of hashtags, and the sentiment of the tweet content, specifically focusing on whether the content had a higher negative score than positive. These features were selected to analyze the nature of the tweets themselves, as extremist content may exhibit specific characteristics in terms of sentiment and engagement.\n\nThe justification for these features was based on their potential to filter out less likely extremists and to identify patterns that could assist in detecting violent extremists on social media platforms. The significance of these features was further supported by statistical analysis, highlighting their relevance in the context of the research objectives."
                },
                {
                    "question": "[SQ] What statistical methods were used to analyze the selected features in the study?",
                    "answer": "The study employed the chi-squared test (χ2) to analyze the significance of the selected features in relation to the characteristics of Twitter handles. Additionally, a two-sample t-test was conducted to compare similarity scores between extremist users and normal users, with specific null and alternative hypotheses defined for this analysis."
                },
                {
                    "question": "[SQ] How do the selected features compare to those used in similar studies on extremist behavior?",
                    "answer": "The selected features in this study are categorized into three major groups: Twitter handle-related features, profile-related features, and content-related features. This approach is distinct as it focuses on specific characteristics of Twitter handles, such as their length, complexity, and uniqueness, alongside user profile metrics like follower count and tweet volume, and tweet content aspects like sentiment and hashtag usage. \n\nIn contrast to similar studies, which may utilize broader or different feature sets, this research emphasizes a targeted feature engineering scheme that aims to filter out less likely extremists effectively. The significance analysis conducted reveals that certain features, such as the number of unique characters in usernames, play a crucial role in identifying extremists, while others, like the maximum occurrence of a character, are less important despite being frequent. This nuanced understanding of feature importance may differ from findings in other studies, highlighting the unique contributions of this research to the field of extremist behavior detection on social media."
                },
                {
                    "question": "[SQ] What limitations were identified regarding the selected features in the context of the research objectives?",
                    "answer": "One limitation identified regarding the selected features is the inverse relationship between the frequency and importance of certain features in the labeled dataset. Specifically, while the maximum number of occurrences of a character in a username was the most frequent feature, it was deemed the least important for identifying online violent extremists. This suggests that not all frequently occurring features contribute significantly to the research objectives, indicating a need for careful consideration in feature selection. Additionally, the complexity of the handle, while included, may not provide substantial insights due to its computational challenges and the reliance on an approximation method."
                },
                {
                    "question": "[MQ] What specific Twitter handle-related, profile-related, and content-related features were selected for analysis in the study, and what justifications were provided for their relevance to detecting extremist behavior on social media?",
                    "answer": "The analysis in the study focused on three major groups of features related to Twitter handles, user profiles, and tweet content, which were deemed relevant for detecting extremist behavior on social media.\n\n1. **Twitter Handle-Related Features**: \n   - Length of the handle\n   - Number of unique characters in the handle\n   - Complexity of the handle (approximated using the Entropy of the handle)\n\n   These features were selected because they can indicate patterns that extremists might follow when creating their handles, suggesting that extremists may adopt similar handle characteristics.\n\n2. **Profile-Related Features**: \n   - Number of followers\n   - Number of friends\n   - Number of tweets\n   - Existence of a profile description\n   - Existence of location information\n   - Verification status of the account\n   - Geo-enabled status\n\n   These features provide insights into the user's social network and engagement level, which can be indicative of their potential extremist affiliations or behaviors.\n\n3. **Content-Related Features**: \n   - Number of URLs in the tweet\n   - Number of hashtags used\n   - Sentiment of the content (assessed by comparing negative and positive scores)\n\n   The content-related features were included as they can reflect the nature of the user's interactions and the type of messages they are promoting, which are crucial for identifying extremist content.\n\nThe justification for these features lies in their ability to filter out less likely extremists and to highlight patterns that are characteristic of extremist behavior, thereby enhancing the detection framework's effectiveness."
                },
                {
                    "question": "[SQ] What specific patterns in Twitter handle characteristics were identified as indicative of extremist behavior?",
                    "answer": "Extremists on Twitter tend to adopt handles that exhibit specific patterns, including a similarity in handle length, the number of unique characters, and the overall complexity of the handle. The complexity is approximated using the entropy of the handle, which serves as a measure of its information content. These characteristics were found to be significantly different when compared to normal users, indicating a tendency among extremists to choose handles that follow similar patterns."
                },
                {
                    "question": "[SQ] How do the selected profile-related features correlate with user engagement and extremist tendencies?",
                    "answer": "The selected profile-related features, which include the number of followers, friends, and tweets, as well as the existence of a profile description and location, can provide insights into user engagement and extremist tendencies. A higher number of followers may indicate greater influence or reach within a community, potentially correlating with extremist tendencies if the user is part of a radicalized network. Similarly, the number of friends and tweets can reflect active engagement on the platform, which may also be associated with the dissemination of extremist content.\n\nThe existence of a profile description and location can further enhance understanding of user intent and identity. Verified accounts may lend credibility to the user, while geo-enabled features could indicate a specific regional focus that aligns with extremist activities. Overall, these profile-related features can serve as indicators of user engagement levels and may help in identifying patterns associated with extremist behavior."
                },
                {
                    "question": "[SQ] What specific characteristics of tweet content were found to be most predictive of extremist behavior?",
                    "answer": "The characteristics of tweet content that were found to be most predictive of extremist behavior include the number of URLs, the number of hashtags, and the sentiment of the content. Specifically, the sentiment analysis checks if the content has a higher negative score than its positive score, indicating a tendency towards negative or extremist sentiments."
                },
                {
                    "question": "[MQ] What specific features related to Twitter handles, user profiles, and tweet content were selected for analysis in the study, and how do these features contribute to identifying patterns indicative of extremist behavior on social media?",
                    "answer": "The analysis focused on three major groups of features related to Twitter handles, user profiles, and tweet content. \n\n1. **Twitter Handle Features**: This group includes:\n   - Length of the handle\n   - Number of unique characters in the handle\n   - Complexity of the handle, approximated using the Entropy of the handle\n\n2. **Profile Features**: This group consists of:\n   - Number of followers\n   - Number of friends\n   - Total number of tweets\n   - Existence of a profile description\n   - Existence of a location\n   - Verification status of the account\n   - Geo-enabled status of the account\n\n3. **Content Features**: This group includes:\n   - Number of URLs in the tweet\n   - Number of hashtags used\n   - Sentiment of the content, specifically checking if the negative score exceeds the positive score\n\nThese features contribute to identifying patterns indicative of extremist behavior by allowing the detection framework to filter out less likely extremists based on observable characteristics. For instance, the similarity in handle patterns among extremists can be analyzed, while profile features provide insights into user engagement and authenticity. Content features help assess the nature of the tweets, particularly in terms of sentiment and the use of extremist-related language or symbols. Together, these features enable a comprehensive approach to classify Twitter handles as potentially extremist or non-extremist."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0.42857142857142855,
                "semantic_similarity": 0.8749133508287055,
                "llm_context_precision_without_reference": 0.9999999999875,
                "llm_context_precision_with_reference": 0.698412698389418,
                "answer_relevancy": 0.832382095497067,
                "answer_correctness": 0.21872833770717637
            },
            "deepeval": {
                "contextual_precision": 0.5,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.1568627450980392,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 13,
        "job_id": 1,
        "file_id": 3,
        "question_id": 3,
        "status": "done",
        "answer_text": "The social network utilized for data collection in the analyzed article is Twitter.",
        "answer_encoded": "Twitter",
        "answer_contexts": [
                {
                    "context": "This new research conducted by the same authors complemented their previous study, by applying current natural language processing and time series analysis techniques to forecast the recruitments.\n\nBeyond these works, the work of [9] takes a different approach to track individual’s behavioral indicators of home-grown extremism, using public and law enforcement data. The intuition is to use graph pattern matching to identify suspicious trajectories and potential radicalization over a dynamic heterogeneous graph associated with the fused data from public and law enforcement. The authors first develop a query pattern of radicalization and then run several graph pattern matching algorithms to detect and track the on-going radicalization. They develop the investigative simulation graph pattern matching technique, which is composed of required extension to the existing dual simulation graph pattern matching method to avoid over-matching. This approach provides analysts and law enforcement officials with the ability to find partial/full matches, given a query of radicalization, as well as the pace of the appearance of the radicalized extremists. As opposed to the above studies, in this paper, we make the first attempt on determining if a given Twitter handle belongs to an extremist user or not, using only little information gathered from the handle, profile and content.\n\n III. DATA PREPARATION\n\nThe dataset was collected from Twitter and consists of approximately 1.6M tweets that were posted using 25 extremism-related hashtags such as #AbuBakralBaghdadi, #ISIL, #ISIS, #Daesh, and #IslamicState. We construct our extremist labels (positive labels) by collecting a limited number of 150 suspended ISIS-related Twitter handles which were reported to the Twitter Safety account (@TwitterSafety) by normal users. To make a balanced labeled dataset, 150 random handles corresponding to normal users were also collected to serve as our negative labels. Inspired by the literature [8], [11], [19], we define 3 major groups of overall 13 features, which could be leveraged to filter out less likely extremists. This way, we obtain 300K highly extremism related tweets from which we randomly pick a smaller sample of 3K handles who posted the tweets. The description of the dataset is shown in Table I.",
                    "score": 0.8443436943379433
                },
                {
                    "context": "IV. METHODOLOGY\n\nHere, we first present the introduced feature groups used to filter out less likely extremists from the data. Next, we will pose our research questions and seek to answer them.\n\n A. Feature Engineering\n\nWe categorize the features used in this work into the following 3 major groups:\n\n1. Twitter handle’s related features: this group contains 3 features related to the given handle, namely, length of the handle, number of unique characters in the handle, and complexity of the handle. To compute the complexity, Kolmogorov complexity is used, which is defined as the length of the shortest program to reproduce the handle on a universal machine such as Turing machine [13]. Since Kolmogorov complexity is computationally intractable, we use the Entropy of the handle as a way to approximate its complexity.\n2. Profile related features: this group contains 7 features related to the profile of the user who posted the tweet, including the number of her followers, friends and tweets, the existence of profile’s description and location. Also, for the last two features in this group, we check if the account is verified and geo-enabled.\n3. Content related features: we have the following 3 features related to the content of the given tweet: the number of URLs, the number of hashtags and the sentiment of the content. For the sentiment, we check if the content has a higher negative score than its positive score.\n\nFor the sake of visualization, a 2-D projection of the sample of the filtered dataset (using t-SNE transformation [22]) is depicted in Fig. 1. As it is seen, basic clustering techniques such as K-means will have difficulty to correctly assign labels to the unlabeled instances using only few existing labeled samples.\n\n B. Research Questions\n\nHaving defined the feature engineering scheme in the previous section, here, we seek to answer the following research questions that will ultimately help identifying violent extremists in social media:\n\n- RQ1: Are extremists on Twitter inclined to adopt similar handles?\n\nFig. 1. 2-D projection of the sampled filtered data using t-SNE transformation. Clustering techniques such as K-means will have difficulty to correctly assign labels to the unlabeled instances using only few existing labeled samples.\n\n30\n\n20\n\n10\n\n-10\n\n20\n\n30\n\nPositive\n\n-40\n\nNegative\n\nUnlabeled\n\n20\n\n10\n\n10\n\n20\n\n- RQ2: Can we infer the labels (extremist vs. non-extremist) of unseen handles based on their proximity to the labeled instances?\n\nTo answer the first question, for each pair of extremist users (i, j) we compute the similarity between their corresponding handles 〈si, sj〉 as follows:\n\nSim(si, sj) = 1 - L(si, sj) / max(len(si), len(sj)) (1)\n\nwhere L(si, sj) is the well-known Lavenshtein ratio [12] which is used as a measure of distance between the two strings s1 and s2. We create a vector ve whose elements are similarity scores between each pair of extremists. We repeat the procedure for each pair of extremist i and a normal user k and create a vector ven. We conduct a two-sample t-test on ve and ven with the null and alternative hypotheses defined as H0: ve ≤ ven, H1: ve > ven. The null hypothesis is rejected at significance level α = 0.01 and p-value of p = 0.009, suggesting that extremists are biased towards adopting similar handles. Although this might seem a bit simplistic at the first sight, it has not been examined in the literature. Later, we will see how effective this simple idea could be in inferring the labels for unseen handles and help detecting the extremists by merely glancing at their handles.\n\nTo answer the second question, let us first obtain our feature spaces associated with the labeled and unlabeled instances, by converting each handle to a vector of 5 features. We use the following features: length of the handle, maximum number of occurrence of a character in the handle, number of unique characters in the handle, number of digits that the handle starts with, and complexity of the handle. Ultimately, these two feature spaces are fed as the inputs to the semi-supervised and supervised learners.\n\n V. EXPERIMENTS\n\nIn this section, we first describe the learners used in this work and provide details on the parameters they use. Then, classification results are presented and finally significance of the features is discussed.",
                    "score": 0.8140016063103688
                },
                {
                    "context": "Detection of Violent Extremists in Social Media\n\nHamidreza Alvari, Soumajyoti Sarkar, Paulo Shakarian\n\nArizona State University\n\nTempe, USA\n\n{halvari, ssarka18, shak}@asu.edu\n\n Abstract\n\nThe ease of use of the Internet has enabled violent extremists such as the Islamic State of Iraq and Syria (ISIS) to easily reach large audience, build personal relationships and increase recruitment. Social media are primarily based on the reports they receive from their own users to mitigate the problem. Despite efforts of social media in suspending many accounts, this solution is not guaranteed to be effective, because not all extremists are caught this way, or they can simply return with another account or migrate to other social networks. Consequently, extra efforts need to be dedicated to proposing capabilities that could be deployed by authorities to combat radicalized extremists and mitigate their threats, regardless of the underlying social network platform.\n\n Present work\n\nIn this paper, we design a detection scheme that using as little as three groups of information (inspired from the literature [8], [11], [19]), can determine whether or not a given username1 belongs to an extremist user. Specifically, we use a dataset from Twitter [25] and first show that extremist users on Twitter tend to adopt handles that follow similar patterns, in contrast to the normal users. Then, a detection framework is proposed to identify if a given Twitter handle belongs to an extremist given its proximity to an existing set of extremist-related handles. We compare different supervised and semi-supervised approaches using the features from Twitter handle, profile information and content which are highly indicative of online extremism. To further show the significance of the features we conduct significance analysis of the features using the labeled instances and feature selection measure χ2 and compare our results against char-LSTM which automatically extracts features.\n\n Contributions\n\nOur main contributions are thus summarized in below:\n\n- We first demonstrate that extremists on Twitter are inclined towards adopting handles with similar patterns. To that end, we used the well-known Lavenshtein ratio as a measure of distance between two Twitter handles and performed two-sample t-test to demonstrate that compared to normal users, extremists tend to choose similar handles.\n- We propose three main groups of features, related to the Twitter handles, profile information and tweet-level content. Overall, our feature engineering scheme has 13 features which are then fed into different supervised and semi-supervised learners.\n- Results on a real-world ISIS-related dataset demonstrate that the introduced features are effective in detecting online violent extremists in social media.\n\n Observations\n\nWe make the following observations:\n\n- The highest precision of 0.96 in identification of the extremists belongs to SVM. This is in line with the previous research that SVM performs well on textual data.\n\n1In this work, we may use the terms usernames and handles interchangeably.",
                    "score": 0.7490780353737275
                },
                {
                    "context": "C. Significance of Features\n\nWe conduct significance analysis of the features using the labeled instances and feature selection measure χ2. The results in Table III suggest that the most significant feature is the number of the unique characters in the username while the least important one is the maximum number of occurrence of a character in the username. This observation further demonstrates that frequency and importance of the features in the labeled dataset are not necessarily in line with each other and in fact are inversely related in our case. In other words, although maximum number of occurrence of a character in the username is the most frequent feature in the labeled dataset, it is the least important feature in identification of online violent extremists according to the Fig. 2 where we depict the frequency of each feature for both labeled and unlabeled examples.\n\n VI. CONCLUSION AND FUTURE WORK\n\nIn this work, we presented a scheme that using as little as three groups of information related to the Twitter handle, profile and textual content of users, can determine if a given handle could belong to an extremist. The framework first uses highly indicative patterns related to extremism to filter out less likely extremists. Ultimately, high likely extremist are identified using only features related to their usernames.\n\nIn future, we would like to replicate the work by deploying more features and investigate if incorporating those features to the framework can lead to performance boost. We also plan to incorporate the feature space designed in this work into a semi-supervised learner as regularization terms in order to further increase the classification performance in detecting online violent extremists. Finally, since hand-labeling unlabeled examples is expensive, a valuable research direction would be to deploy active learning to enable iterative supervised learning to actively query for labels.\n\n VII. ACKNOWLEDGMENTS\n\nThis work was supported through DoD Minerva program.\n\n REFERENCES\n\n[1] Abutaleb, Y. \"Twitter suspended 360,000 accounts for 'promotion of terrorism'.\" http://www.reuters.com/article/us-twitter-terrorism-idUSKCN10T1ST, August 2016.\n\n[2] M. Belkin, P. Niyogi, and V. Sindhwani. \"Manifold regularization: A geometric framework for learning from labeled and unlabeled examples.\" JMLR, vol. 7, no. Nov, pp. 2399-2434, 2006.\n\n[3] Alvari, Hamidreza, Sattar Hashemi, and Ali Hamzeh. \"Detecting overlapping communities in social networks by game theory and structural equivalence concept.\" In International Conference on Artificial Intelligence and Computational Intelligence, pp. 620-630. Springer, Berlin, Heidelberg, 2011.\n\n[4] Benigni, Matthew C and Joseph, Kenneth and Carley, Kathleen M. \"Online extremism and the communities that sustain it: Detecting the ISIS supporting community on Twitter.\" PloS one, 2017.\n\n[5] Benigni, Matthew and Carley, Kathleen M. \"From Tweets to Intelligence: Understanding the Islamic Jihad Supporting Community on Twitter.\" 2016 International Conference on Social Computing, Behavioral-Cultural Modeling, & Prediction and Behavior Representation in Modeling and Simulation.\n\n[6] Beigi, Ghazaleh, and Huan Liu. \"Privacy in social media: Identification, mitigation and applications.\" arXiv preprint arXiv:1808.02191 (2018).\n\n[7] Blum, A., and Mitchell, T. \"Combining labeled and unlabeled data with co-training.\" COLT, 1998.\n\n[8] Ferrara, E., Wang, W., Varol, O, Flammini, A., and Galstyan, A. \"Predicting online extremism, content adopters, and interaction reciprocity.\" SocInfo, 2016.\n\n[9] Hung, B., Jayasumana, P., and Bandara, V. \"Detecting Radicalization Trajectories Using Graph Pattern Matching Algorithms.\" ISI, 2016.\n\n[10] Alvari, Hamidreza, Paulo Shakarian, and JE Kelly Snyder. \"Semi-supervised learning for detecting human trafficking.\" Security Informatics 6, no. 1 (2017): 1.\n\n[11] Klausen, J., Marks, C., and Zaman, T. \"Finding Online Extremists in Social Networks.\" INFORMS, 2016.\n\n[12] \"How python-Levenshtein.ratio is computed.\" URL http://stackoverflow.com/questions/14260126/\n\n[13] Li, Ming and Vitnyi, Paul M.B. \"An Introduction to Kolmogorov Complexity and Its Applications.\" Springer, 2008.",
                    "score": 0.6592578457139343
                },
                {
                    "context": "Among several approaches used in this work, char-LSTM and the semi-supervised approach LabelSpreading with RBF kernel achieve the equal and highest F1-score of 0.76. The fact that the LabelSpreading achieves comparable performance as char-LSTM, further demonstrates the effectiveness of the proposed feature engineering scheme, as LSTM has shown promising results in the literature while it does not use any hand-crafted features. Char-LSTM achieves a precision of 0.77 while maintaining a high recall of 0.76 on the positive class. This suggests that the memory module in LSTM can help in minimizing the number of false negatives.\n\n II. RELATED WORK\n\nThe explosive growth of the Web has raised numerous security and privacy issues. Mitigating these concerns has been studied from different aspects [6], [18], [23], [26]. For instance, several studies have focused on understanding extremism in social networks [4], [5], [8], [9], [11], [16], [17]. For instance, the work of [11], uses Twitter and proposes an approach to predict new extremists. They also determine if the newly created account belongs to a suspended extremist, and predict the ego-network of the suspended extremist upon creating her new account. Their approach integrates variants of the logistic regression with optimized search policies to detect the new accounts of returning suspended extremist users. They (1) use potential features of an account to predict if this account belongs to an extremist user, (2) determine if multiple accounts belong to the same extremist user, based on the fact that new account shall resemble the suspended account in different aspects, (3) predict whom the suspended extremist user is most likely to follow again, and finally (4) develop a network search policy to find the suspected users upon returning to a social network. Similar work of [8] uses tweets to build models to predict (1) if a pro-ISIS user’s account will be suspended due to the extremist content, (2) which users will adopt and retweet ISIS content, and (3) which users will have interactions with pro-ISIS users. To do so, the authors use logistic regression and random forest classifiers for different types of prediction tasks. They deploy variety of features across different dimensions, such as user meta-data, network statistics and temporal patterns of activity. Two scenarios are then designed for each prediction task: a time independent (static) one which does not take into account the temporal dependencies, and a simulated real-time one by considering the timeline of content availability. The difference between these two studies is, authors of [11] also study other aspects including identifying multiple accounts for an extremist user, re-following suspended accounts’ connections and searching for the suspended extremist users who might return to a social media.\n\nOther works also seek to identify the extremist content in radicalized groups beyond ISIS. The work of [16] uses data from Jihadist website Ansar AlJihad Network to develop supervised learning and NLP techniques to automatically detect cyber-recruitment of extremist groups. A comparison is done between classifiers naïve Bayes, logistic regression, classification trees, boosting and SVM, for labeling forum posts as either related or not related to the recruitment of extremist groups. They leverage the bag-of-words technique to convert the corpus into a term-document matrix, following the standard routine of the preprocessing techniques such as basic normalization and stemming. Similarly in [17], same Jihadist network along with their previously developed SVM classifier are used to automatically identify recruitment posts. Their previous work shall be served as pre-screening step to reduce the efforts made by human analysts to manually hand-label the documents. In their new study, the textual content of the dataset is analyzed with latent Dirichlet allocation (LDA) and fed into several time-series models to predict cyber-recruitment. This new research conducted by the same authors complemented their previous study, by applying current natural language processing and time series analysis techniques to forecast the recruitments.\n\nBeyond these works, the work of [9] takes a different approach to track individual’s behavioral indicators of home-grown extremism, using public and law enforcement data. The intuition is to use graph pattern matching to identify suspicious trajectories and potential radicalization over a dynamic heterogeneous graph associated with the fused data from public and law enforcement. The authors first develop a query pattern of radicalization and then run several graph pattern matching algorithms to detect and track the on-going radicalization. They develop the investigative simulation graph pattern matching technique, which is composed of required extension to the existing dual simulation graph pattern matching method to avoid over-matching. This approach provides analysts and law enforcement officials with the ability to find partial/full matches, given a query of radicalization, as well as the pace of the appearance of the radicalized extremists.",
                    "score": 0.25643946721325145
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] Which social network or platform was utilized for data collection in the analyzed article?",
                    "answer": "The data collection in the analyzed article was conducted using Twitter."
                },
                {
                    "question": "[SQ] What specific methods were used to collect data from Twitter in the analyzed article?",
                    "answer": "Data was collected from Twitter by gathering approximately 1.6 million tweets that included 25 extremism-related hashtags, such as #AbuBakralBaghdadi, #ISIL, #ISIS, #Daesh, and #IslamicState. Additionally, a limited number of 150 suspended ISIS-related Twitter handles were collected, which had been reported to the Twitter Safety account by normal users. To create a balanced dataset, 150 random handles corresponding to normal users were also collected. From this, 300,000 highly extremism-related tweets were identified, and a smaller sample of 3,000 handles that posted these tweets was randomly selected for analysis."
                },
                {
                    "question": "[SQ] How was the data from Twitter analyzed in the study?",
                    "answer": "The data from Twitter was analyzed by constructing a dataset consisting of approximately 1.6 million tweets that included 25 extremism-related hashtags. From this dataset, 300,000 highly extremism-related tweets were filtered, and a smaller sample of 3,000 handles was randomly selected for analysis. The researchers categorized features into three major groups: Twitter handle-related features, profile-related features, and content-related features. They employed various techniques, including similarity measures and statistical tests, to identify patterns among extremist users and to infer labels for unseen handles based on their proximity to labeled instances. Additionally, different supervised and semi-supervised learning approaches were utilized to classify the handles as extremist or non-extremist based on the engineered features."
                },
                {
                    "question": "[SQ] What was the sample size of the Twitter data collected in the analyzed article?",
                    "answer": "The sample size of the Twitter data collected in the analyzed article was approximately 1.6 million tweets."
                },
                {
                    "question": "[MQ] Which social network was used for data collection in the analyzed article, specifically involving approximately 1.6 million tweets from Twitter that included extremism-related hashtags?",
                    "answer": "The social network used for data collection in the analyzed article is Twitter."
                },
                {
                    "question": "[SQ] What were the specific extremism-related hashtags used in the data collection from Twitter?",
                    "answer": "The specific extremism-related hashtags used in the data collection from Twitter include #AbuBakralBaghdadi, #ISIL, #ISIS, #Daesh, and #IslamicState."
                },
                {
                    "question": "[SQ] How many extremism-related Twitter handles were included in the data collection process?",
                    "answer": "The data collection process included a total of 150 suspended ISIS-related Twitter handles."
                },
                {
                    "question": "[SQ] What criteria were used to select the random handles of normal users for the dataset?",
                    "answer": "The random handles of normal users were selected to serve as negative labels, ensuring a balanced labeled dataset. Specifically, 150 random handles corresponding to normal users were collected to match the 150 suspended ISIS-related Twitter handles that were identified as extremist."
                },
                {
                    "question": "[MQ] Which social network was utilized for data collection in the analyzed article, specifically involving approximately 1.6 million tweets that included 25 extremism-related hashtags such as #AbuBakralBaghdadi and #ISIS?",
                    "answer": "The social network utilized for data collection in the analyzed article is Twitter."
                },
                {
                    "question": "[SQ] What was the time frame during which the tweets were collected from Twitter?",
                    "answer": "The time frame during which the tweets were collected from Twitter is not specified in the provided information."
                },
                {
                    "question": "[SQ] How were the extremism-related hashtags selected for the data collection?",
                    "answer": "The extremism-related hashtags were selected based on their association with ISIS and related topics, specifically including hashtags such as #AbuBakralBaghdadi, #ISIL, #ISIS, #Daesh, and #IslamicState. These hashtags were used to collect tweets for the dataset."
                },
                {
                    "question": "[SQ] What were the main objectives of analyzing the collected tweets from Twitter?",
                    "answer": "The main objectives of analyzing the collected tweets from Twitter were to determine whether a given Twitter handle belongs to an extremist user and to identify patterns in the handles adopted by extremists compared to normal users. The analysis aimed to filter out less likely extremists using specific features related to the Twitter handles, user profiles, and tweet content. Additionally, the research sought to infer labels for unseen handles based on their proximity to existing extremist-related handles, ultimately contributing to the detection of violent extremists in social media."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 0.9999999999999996,
                "llm_context_precision_without_reference": 0.874999999978125,
                "llm_context_precision_with_reference": 0.874999999978125,
                "answer_relevancy": 0.8087136901956149,
                "answer_correctness": 0.9999999999999999
            },
            "deepeval": {
                "contextual_precision": 1.0,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.19047619047619047,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 14,
        "job_id": 1,
        "file_id": 3,
        "question_id": 4,
        "status": "done",
        "answer_text": "The size of the dataset analyzed in the article was approximately 1.6 million tweets.",
        "answer_encoded": "[response not coded] The analyzed dataset consisted of approximately 1.6 million tweets.",
        "answer_contexts": [
                {
                    "context": "This new research conducted by the same authors complemented their previous study, by applying current natural language processing and time series analysis techniques to forecast the recruitments.\n\nBeyond these works, the work of [9] takes a different approach to track individual’s behavioral indicators of home-grown extremism, using public and law enforcement data. The intuition is to use graph pattern matching to identify suspicious trajectories and potential radicalization over a dynamic heterogeneous graph associated with the fused data from public and law enforcement. The authors first develop a query pattern of radicalization and then run several graph pattern matching algorithms to detect and track the on-going radicalization. They develop the investigative simulation graph pattern matching technique, which is composed of required extension to the existing dual simulation graph pattern matching method to avoid over-matching. This approach provides analysts and law enforcement officials with the ability to find partial/full matches, given a query of radicalization, as well as the pace of the appearance of the radicalized extremists. As opposed to the above studies, in this paper, we make the first attempt on determining if a given Twitter handle belongs to an extremist user or not, using only little information gathered from the handle, profile and content.\n\n III. DATA PREPARATION\n\nThe dataset was collected from Twitter and consists of approximately 1.6M tweets that were posted using 25 extremism-related hashtags such as #AbuBakralBaghdadi, #ISIL, #ISIS, #Daesh, and #IslamicState. We construct our extremist labels (positive labels) by collecting a limited number of 150 suspended ISIS-related Twitter handles which were reported to the Twitter Safety account (@TwitterSafety) by normal users. To make a balanced labeled dataset, 150 random handles corresponding to normal users were also collected to serve as our negative labels. Inspired by the literature [8], [11], [19], we define 3 major groups of overall 13 features, which could be leveraged to filter out less likely extremists. This way, we obtain 300K highly extremism related tweets from which we randomly pick a smaller sample of 3K handles who posted the tweets. The description of the dataset is shown in Table I.",
                    "score": 0.8270144429945689
                },
                {
                    "context": "IV. METHODOLOGY\n\nHere, we first present the introduced feature groups used to filter out less likely extremists from the data. Next, we will pose our research questions and seek to answer them.\n\n A. Feature Engineering\n\nWe categorize the features used in this work into the following 3 major groups:\n\n1. Twitter handle’s related features: this group contains 3 features related to the given handle, namely, length of the handle, number of unique characters in the handle, and complexity of the handle. To compute the complexity, Kolmogorov complexity is used, which is defined as the length of the shortest program to reproduce the handle on a universal machine such as Turing machine [13]. Since Kolmogorov complexity is computationally intractable, we use the Entropy of the handle as a way to approximate its complexity.\n2. Profile related features: this group contains 7 features related to the profile of the user who posted the tweet, including the number of her followers, friends and tweets, the existence of profile’s description and location. Also, for the last two features in this group, we check if the account is verified and geo-enabled.\n3. Content related features: we have the following 3 features related to the content of the given tweet: the number of URLs, the number of hashtags and the sentiment of the content. For the sentiment, we check if the content has a higher negative score than its positive score.\n\nFor the sake of visualization, a 2-D projection of the sample of the filtered dataset (using t-SNE transformation [22]) is depicted in Fig. 1. As it is seen, basic clustering techniques such as K-means will have difficulty to correctly assign labels to the unlabeled instances using only few existing labeled samples.\n\n B. Research Questions\n\nHaving defined the feature engineering scheme in the previous section, here, we seek to answer the following research questions that will ultimately help identifying violent extremists in social media:\n\n- RQ1: Are extremists on Twitter inclined to adopt similar handles?\n\nFig. 1. 2-D projection of the sampled filtered data using t-SNE transformation. Clustering techniques such as K-means will have difficulty to correctly assign labels to the unlabeled instances using only few existing labeled samples.\n\n30\n\n20\n\n10\n\n-10\n\n20\n\n30\n\nPositive\n\n-40\n\nNegative\n\nUnlabeled\n\n20\n\n10\n\n10\n\n20\n\n- RQ2: Can we infer the labels (extremist vs. non-extremist) of unseen handles based on their proximity to the labeled instances?\n\nTo answer the first question, for each pair of extremist users (i, j) we compute the similarity between their corresponding handles 〈si, sj〉 as follows:\n\nSim(si, sj) = 1 - L(si, sj) / max(len(si), len(sj)) (1)\n\nwhere L(si, sj) is the well-known Lavenshtein ratio [12] which is used as a measure of distance between the two strings s1 and s2. We create a vector ve whose elements are similarity scores between each pair of extremists. We repeat the procedure for each pair of extremist i and a normal user k and create a vector ven. We conduct a two-sample t-test on ve and ven with the null and alternative hypotheses defined as H0: ve ≤ ven, H1: ve > ven. The null hypothesis is rejected at significance level α = 0.01 and p-value of p = 0.009, suggesting that extremists are biased towards adopting similar handles. Although this might seem a bit simplistic at the first sight, it has not been examined in the literature. Later, we will see how effective this simple idea could be in inferring the labels for unseen handles and help detecting the extremists by merely glancing at their handles.\n\nTo answer the second question, let us first obtain our feature spaces associated with the labeled and unlabeled instances, by converting each handle to a vector of 5 features. We use the following features: length of the handle, maximum number of occurrence of a character in the handle, number of unique characters in the handle, number of digits that the handle starts with, and complexity of the handle. Ultimately, these two feature spaces are fed as the inputs to the semi-supervised and supervised learners.\n\n V. EXPERIMENTS\n\nIn this section, we first describe the learners used in this work and provide details on the parameters they use. Then, classification results are presented and finally significance of the features is discussed.",
                    "score": 0.6477562282720892
                },
                {
                    "context": "TABLE I\n\n DESCRIPTION OF THE DATASET",
                    "score": 0.48360435769001286
                },
                {
                    "context": "Detection of Violent Extremists in Social Media\n\nHamidreza Alvari, Soumajyoti Sarkar, Paulo Shakarian\n\nArizona State University\n\nTempe, USA\n\n{halvari, ssarka18, shak}@asu.edu\n\n Abstract\n\nThe ease of use of the Internet has enabled violent extremists such as the Islamic State of Iraq and Syria (ISIS) to easily reach large audience, build personal relationships and increase recruitment. Social media are primarily based on the reports they receive from their own users to mitigate the problem. Despite efforts of social media in suspending many accounts, this solution is not guaranteed to be effective, because not all extremists are caught this way, or they can simply return with another account or migrate to other social networks. Consequently, extra efforts need to be dedicated to proposing capabilities that could be deployed by authorities to combat radicalized extremists and mitigate their threats, regardless of the underlying social network platform.\n\n Present work\n\nIn this paper, we design a detection scheme that using as little as three groups of information (inspired from the literature [8], [11], [19]), can determine whether or not a given username1 belongs to an extremist user. Specifically, we use a dataset from Twitter [25] and first show that extremist users on Twitter tend to adopt handles that follow similar patterns, in contrast to the normal users. Then, a detection framework is proposed to identify if a given Twitter handle belongs to an extremist given its proximity to an existing set of extremist-related handles. We compare different supervised and semi-supervised approaches using the features from Twitter handle, profile information and content which are highly indicative of online extremism. To further show the significance of the features we conduct significance analysis of the features using the labeled instances and feature selection measure χ2 and compare our results against char-LSTM which automatically extracts features.\n\n Contributions\n\nOur main contributions are thus summarized in below:\n\n- We first demonstrate that extremists on Twitter are inclined towards adopting handles with similar patterns. To that end, we used the well-known Lavenshtein ratio as a measure of distance between two Twitter handles and performed two-sample t-test to demonstrate that compared to normal users, extremists tend to choose similar handles.\n- We propose three main groups of features, related to the Twitter handles, profile information and tweet-level content. Overall, our feature engineering scheme has 13 features which are then fed into different supervised and semi-supervised learners.\n- Results on a real-world ISIS-related dataset demonstrate that the introduced features are effective in detecting online violent extremists in social media.\n\n Observations\n\nWe make the following observations:\n\n- The highest precision of 0.96 in identification of the extremists belongs to SVM. This is in line with the previous research that SVM performs well on textual data.\n\n1In this work, we may use the terms usernames and handles interchangeably.",
                    "score": 0.48176170510176625
                },
                {
                    "context": "This table summarizes data related to a classification task, showing the total number of raw and filtered samples, along with the counts of unlabeled and labeled samples categorized as positive and negative.,\nwith the following columns:\n- Name: Describes the type of data or category.\n- Value: Indicates the corresponding count or classification.\n\n| Name                | Value    |          |\n|---|---|---|\n| Raw                 | 1.6M     |          |\n| Filtered            | 300K     |          |\n| Unlabeled (sampled) | 3K       |          |\n| Labeled             | Positive | Negative |\n|                     | 150      | 150      |",
                    "score": 0.46814256621400113
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What was the size of the dataset analyzed in the article?",
                    "answer": "The dataset analyzed in the article consisted of approximately 1.6 million tweets."
                },
                {
                    "question": "[SQ] What criteria were used to select the tweets in the dataset?",
                    "answer": "The dataset was constructed from approximately 1.6 million tweets that were posted using 25 extremism-related hashtags, such as #AbuBakralBaghdadi, #ISIL, #ISIS, #Daesh, and #IslamicState. To create extremist labels, a limited number of 150 suspended ISIS-related Twitter handles were collected, which had been reported to the Twitter Safety account by normal users. Additionally, to balance the dataset, 150 random handles corresponding to normal users were also collected to serve as negative labels. Ultimately, 300,000 highly extremism-related tweets were obtained, from which a smaller sample of 3,000 handles that posted the tweets was randomly selected."
                },
                {
                    "question": "[SQ] What time period do the tweets in the dataset cover?",
                    "answer": "The time period covered by the tweets in the dataset is not specified in the provided information."
                },
                {
                    "question": "[SQ] Were there any specific topics or hashtags focused on within the dataset?",
                    "answer": "The dataset focused on extremism-related topics, specifically utilizing 25 hashtags such as #AbuBakralBaghdadi, #ISIL, #ISIS, #Daesh, and #IslamicState."
                },
                {
                    "question": "[MQ] What was the size of the analyzed dataset, which consisted of approximately 1.6 million tweets related to extremism using 25 specific hashtags?",
                    "answer": "The analyzed dataset consisted of approximately 1.6 million tweets."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0.6,
                "semantic_similarity": 0.8108974973141068,
                "llm_context_precision_without_reference": 0.49999999998333333,
                "llm_context_precision_with_reference": 0.499999999975,
                "answer_relevancy": 0.884597271741916,
                "answer_correctness": 0.2027243743285267
            },
            "deepeval": {
                "contextual_precision": 1.0,
                "contextual_recall": 0.9090909090909091,
                "contextual_relevancy": 0.16666666666666666,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 15,
        "job_id": 1,
        "file_id": 3,
        "question_id": 5,
        "status": "done",
        "answer_text": "The performance metrics evaluated in the study include Precision, Recall, and F1-score. The corresponding values for various machine learning models are as follows:\n\n- **SVM**: Precision 0.96, Recall 0.5, F1-score 0.65\n- **Char-LSTM**: Precision 0.77, Recall 0.76, F1-score 0.76\n- **LabelSpreading (RBF)**: Precision 0.85, Recall 0.69, F1-score 0.76\n- **Laplacian SVM**: Precision 0.89, Recall 0.6, F1-score 0.7\n- **LabelSpreading (KNN)**: Precision 0.83, Recall 0.67, F1-score 0.73\n- **Co-Training (SVM)**: Precision 0.9, Recall 0.53, F1-score 0.66\n- **KNN**: Precision 0.81, Recall 0.7, F1-score 0.74\n- **Gaussian NB**: Precision 0.89, Recall 0.56, F1-score 0.69\n- **Logistic Regression**: Precision 0.76, Recall 0.61, F1-score 0.67\n- **AdaBoost**: Precision 0.88, Recall 0.58, F1-score 0.69\n- **Random Forest**: Precision 0.79, Recall 0.71, F1-score 0.74",
        "answer_encoded": "[response not coded] The study evaluated performance metrics including Precision, Recall, and F1-score for various models, with values ranging from Precision 0.76 to 0.96, Recall 0.5 to 0.76, and F1-score 0.65 to 0.76.",
        "answer_contexts": [
                {
                    "context": "This table presents the performance metrics (Precision, Recall, and F1-score) of various machine learning models used for classification tasks.,\nwith the following table title:\nPerformance Metrics of Machine Learning Models,\nwith the following columns:\n- Learner: The name of the machine learning model.\n- Precision: The proportion of true positive results in the positive predictions.\n- Recall: The proportion of true positive results in the actual positives.\n- F1-score: The harmonic mean of precision and recall.\n\n| Learner              | Precision | Recall | F1-score |\n|---|---|---|---|\n| SVM                  |0.96|0.5|0.65|\n| Char-LSTM            |0.77|0.76|0.76|\n| LabelSpreading (RBF) |0.85|0.69|0.76|\n| Laplacian SVM        |0.89|0.6|0.7|\n| LabelSpreading (KNN) |0.83|0.67|0.73|\n| Co-Training (SVM)    |0.9|0.53|0.66|\n| KNN                  |0.81|0.7|0.74|\n| Gaussian NB          |0.89|0.56|0.69|\n| Logistic Regression  |0.76|0.61|0.67|\n| AdaBoost             |0.88|0.58|0.69|\n| Random Forest        |0.79|0.71|0.74|",
                    "score": 0.855799746509961
                },
                {
                    "context": "This table summarizes data related to a classification task, showing the total number of raw and filtered samples, along with the counts of unlabeled and labeled samples categorized as positive and negative.,\nwith the following columns:\n- Name: Describes the type of data or category.\n- Value: Indicates the corresponding count or classification.\n\n| Name                | Value    |          |\n|---|---|---|\n| Raw                 | 1.6M     |          |\n| Filtered            | 300K     |          |\n| Unlabeled (sampled) | 3K       |          |\n| Labeled             | Positive | Negative |\n|                     | 150      | 150      |",
                    "score": 0.7888188009100966
                },
                {
                    "context": "TABLE II\n\n COMPARISON OF THE METHODS ON THE LABELED DATA, FOR THE POSITIVE (EXTREMIST) CLASS.",
                    "score": 0.6250831075458597
                },
                {
                    "context": "Among several approaches used in this work, char-LSTM and the semi-supervised approach LabelSpreading with RBF kernel achieve the equal and highest F1-score of 0.76. The fact that the LabelSpreading achieves comparable performance as char-LSTM, further demonstrates the effectiveness of the proposed feature engineering scheme, as LSTM has shown promising results in the literature while it does not use any hand-crafted features. Char-LSTM achieves a precision of 0.77 while maintaining a high recall of 0.76 on the positive class. This suggests that the memory module in LSTM can help in minimizing the number of false negatives.\n\n II. RELATED WORK\n\nThe explosive growth of the Web has raised numerous security and privacy issues. Mitigating these concerns has been studied from different aspects [6], [18], [23], [26]. For instance, several studies have focused on understanding extremism in social networks [4], [5], [8], [9], [11], [16], [17]. For instance, the work of [11], uses Twitter and proposes an approach to predict new extremists. They also determine if the newly created account belongs to a suspended extremist, and predict the ego-network of the suspended extremist upon creating her new account. Their approach integrates variants of the logistic regression with optimized search policies to detect the new accounts of returning suspended extremist users. They (1) use potential features of an account to predict if this account belongs to an extremist user, (2) determine if multiple accounts belong to the same extremist user, based on the fact that new account shall resemble the suspended account in different aspects, (3) predict whom the suspended extremist user is most likely to follow again, and finally (4) develop a network search policy to find the suspected users upon returning to a social network. Similar work of [8] uses tweets to build models to predict (1) if a pro-ISIS user’s account will be suspended due to the extremist content, (2) which users will adopt and retweet ISIS content, and (3) which users will have interactions with pro-ISIS users. To do so, the authors use logistic regression and random forest classifiers for different types of prediction tasks. They deploy variety of features across different dimensions, such as user meta-data, network statistics and temporal patterns of activity. Two scenarios are then designed for each prediction task: a time independent (static) one which does not take into account the temporal dependencies, and a simulated real-time one by considering the timeline of content availability. The difference between these two studies is, authors of [11] also study other aspects including identifying multiple accounts for an extremist user, re-following suspended accounts’ connections and searching for the suspended extremist users who might return to a social media.\n\nOther works also seek to identify the extremist content in radicalized groups beyond ISIS. The work of [16] uses data from Jihadist website Ansar AlJihad Network to develop supervised learning and NLP techniques to automatically detect cyber-recruitment of extremist groups. A comparison is done between classifiers naïve Bayes, logistic regression, classification trees, boosting and SVM, for labeling forum posts as either related or not related to the recruitment of extremist groups. They leverage the bag-of-words technique to convert the corpus into a term-document matrix, following the standard routine of the preprocessing techniques such as basic normalization and stemming. Similarly in [17], same Jihadist network along with their previously developed SVM classifier are used to automatically identify recruitment posts. Their previous work shall be served as pre-screening step to reduce the efforts made by human analysts to manually hand-label the documents. In their new study, the textual content of the dataset is analyzed with latent Dirichlet allocation (LDA) and fed into several time-series models to predict cyber-recruitment. This new research conducted by the same authors complemented their previous study, by applying current natural language processing and time series analysis techniques to forecast the recruitments.\n\nBeyond these works, the work of [9] takes a different approach to track individual’s behavioral indicators of home-grown extremism, using public and law enforcement data. The intuition is to use graph pattern matching to identify suspicious trajectories and potential radicalization over a dynamic heterogeneous graph associated with the fused data from public and law enforcement. The authors first develop a query pattern of radicalization and then run several graph pattern matching algorithms to detect and track the on-going radicalization. They develop the investigative simulation graph pattern matching technique, which is composed of required extension to the existing dual simulation graph pattern matching method to avoid over-matching. This approach provides analysts and law enforcement officials with the ability to find partial/full matches, given a query of radicalization, as well as the pace of the appearance of the radicalized extremists.",
                    "score": 0.47170825610532036
                },
                {
                    "context": "A. Approaches\n\n- Semi-Supervised: Laplacian support vector machines [2], graph inference-based label spreading approach [21] with radial basis function (RBF) and K-nearest neighbor (KNN) kernels, and co-training learner [7] with two SVMs.\n- Supervised: SVM, KNN, Gaussian naïve Bayes, logistic regression, adaboost, random forest, and Char-LSTM [24].\n\nWe note that supervised learners only use labeled instances for the training process, while semi-supervised algorithms use labeled and unlabeled instances [10]. For the sake of fair comparison, all algorithms were implemented and run in Python. Note for the methods that require special tuning of parameters, we performed grid search to choose the best set of parameters. Before going any further, we define the parameters used in each learner and then demonstrate their best picked values by our grid search.\n\n- SVM: Tolerance for stopping criteria was set to the default value of 0.001. Penalty parameter C was set to 1 and linear kernel was used.\n- Char-LSTM: This is similar to the character-aware models used for sequential word predictions. We adapt the neural network to a sequence classification problem where the inputs are the vector of one-hot encoding of each character of the handle and the output is the handle being classified as extremist or non-extremist. We set the maximum username length to 10, padding with zeros where necessary. We use an embedding layer after the input layer to convert each username dimension to 16. This is fed to a single layer LSTM module having 30 units.\n- LabelSpreading (RBF): RBF Kernel was used and γ was set to the default value of 20.\n- Laplacian SVM: We used linear kernel and set the parameters Cl = 0.6 and Cs = 0.6.\n- LabelSpreading (KNN): KNN kernel was used and the number of neighbors was set to 5.\n- Co-training (SVM): We followed the algorithm introduced in [7] and used two SVM as our classifiers. For both SVMs we set the tolerance for stopping criteria to 0.001 and the penalty parameter C = 1.\n- KNN: The number of neighbors was set to 5.\n- Gaussian NB: There were no specific parameter to tune.\n- Logistic regression: We used the l2 penalty. We also set the parameter C = 1 (the inverse of regularization strength) and tolerance for stopping criteria to 0.01.\n- Adaboost: The number of estimators was set to 200 and we also set the learning rate to 0.01.\n- Random forest: We used 200 estimators and the entropy criterion was used.\n\n B. Classification Results\n\nWe use tenfold cross-validation on the labeled data as follows. We first divided the set of labeled instances into 10 different sets of equal size. Each time, we held one set out for validation (we did this by removing their labels and adding them to the unlabeled instances). For the supervised learners, this set along with a set of the existing unlabeled samples are only used for the purpose of testing whereas for the semi-supervised setting, we use both sets in the training and testing phases. This procedure is performed for all approaches for the sake of fair comparison. Finally, we report the average of 10 different runs, using various evaluation metrics including precision, recall and F1-score in Table II.\n\n Observations.\n\n- SVM achieve the highest precision of 0.96 in identifying online violent extremists, which shows the significance of the proposed feature set.\n- The semi-supervised LabelSpreading (RBF) was able to perform as good as Char-LSTM and they both achieve the highest F1-score on identification of extremists. This along with the fact that Char-LSTM has shown promising results in the literature while it does not use any of our hand-crafted features, further demonstrates the effectiveness of the introduced feature engineering scheme.\n- For char-LSTM, we achieve a precision of 0.77 while maintaining a high recall of 0.76 on the positive class. This suggests that the memory module in LSTM can help in minimizing the number of false negatives.\n- Overall, the observations we make here suggest that the answer to the second question is positive– using an existing set of labeled examples could help inferring the labels of unseen usernames.",
                    "score": 0.47051617671879126
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific performance metrics were evaluated in the study, and what were their corresponding values?",
                    "answer": "The performance metrics evaluated in the study include Precision, Recall, and F1-score. The corresponding values for various machine learning models are as follows:\n\n- **SVM**: Precision 0.96, Recall 0.5, F1-score 0.65\n- **Char-LSTM**: Precision 0.77, Recall 0.76, F1-score 0.76\n- **LabelSpreading (RBF)**: Precision 0.85, Recall 0.69, F1-score 0.76\n- **Laplacian SVM**: Precision 0.89, Recall 0.6, F1-score 0.7\n- **LabelSpreading (KNN)**: Precision 0.83, Recall 0.67, F1-score 0.73\n- **Co-Training (SVM)**: Precision 0.9, Recall 0.53, F1-score 0.66\n- **KNN**: Precision 0.81, Recall 0.7, F1-score 0.74\n- **Gaussian NB**: Precision 0.89, Recall 0.56, F1-score 0.69\n- **Logistic Regression**: Precision 0.76, Recall 0.61, F1-score 0.67\n- **AdaBoost**: Precision 0.88, Recall 0.58, F1-score 0.69\n- **Random Forest**: Precision 0.79, Recall 0.71, F1-score 0.74"
                },
                {
                    "question": "[SQ] What were the specific datasets used for evaluating the performance metrics in the study?",
                    "answer": "The evaluation of performance metrics in the study utilized a dataset collected from Twitter, consisting of approximately 1.6 million tweets associated with 25 extremism-related hashtags. From this dataset, a balanced labeled dataset was created by collecting 150 suspended ISIS-related Twitter handles as positive labels and 150 random handles of normal users as negative labels. Additionally, a filtered dataset of 300,000 highly extremism-related tweets was derived, from which a sample of 3,000 handles was randomly selected for further analysis."
                },
                {
                    "question": "[SQ] How do the performance metrics compare across different machine learning models in terms of their strengths and weaknesses?",
                    "answer": "The performance metrics of various machine learning models reveal distinct strengths and weaknesses among them. \n\nSVM stands out with the highest precision of 0.96, indicating its strong ability to correctly identify positive instances. However, its recall is relatively low at 0.5, suggesting it misses a significant number of actual positive cases. This indicates that while SVM is precise, it may not be the best choice when capturing all relevant instances is crucial.\n\nChar-LSTM and LabelSpreading (RBF) both achieve the highest F1-score of 0.76, demonstrating a balanced performance between precision and recall. Char-LSTM has a precision of 0.77 and a recall of 0.76, indicating it effectively minimizes false negatives while maintaining a good level of true positives. This model's architecture, which leverages memory through LSTM, contributes to its effectiveness.\n\nLabelSpreading (RBF) shows a precision of 0.85 and a recall of 0.69, indicating it performs well in identifying true positives but is slightly less effective than Char-LSTM in terms of recall. \n\nOther models like KNN and Gaussian Naïve Bayes show moderate performance, with KNN achieving a precision of 0.81 and recall of 0.7, while Gaussian Naïve Bayes has a precision of 0.89 but a lower recall of 0.56. This suggests that Gaussian Naïve Bayes is good at identifying positive cases but struggles with capturing all actual positives.\n\nModels like Logistic Regression and AdaBoost have lower overall performance, with F1-scores of 0.67 and 0.69, respectively, indicating they may not be as effective for this classification task.\n\nIn summary, SVM excels in precision, Char-LSTM and LabelSpreading (RBF) provide a balanced approach, while other models exhibit varying strengths and weaknesses in precision and recall, impacting their overall effectiveness in classification tasks."
                },
                {
                    "question": "[SQ] Were there any additional performance metrics evaluated in the study beyond Precision, Recall, and F1-score?",
                    "answer": "No, only Precision, Recall, and F1-score were evaluated as performance metrics in the study."
                },
                {
                    "question": "[MQ] What were the values of the Precision, Recall, and F1-score performance metrics for the various machine learning models evaluated in the study?",
                    "answer": "The performance metrics for the various machine learning models evaluated in the study are as follows:\n\n- **SVM**: Precision = 0.96, Recall = 0.5, F1-score = 0.65\n- **Char-LSTM**: Precision = 0.77, Recall = 0.76, F1-score = 0.76\n- **LabelSpreading (RBF)**: Precision = 0.85, Recall = 0.69, F1-score = 0.76\n- **Laplacian SVM**: Precision = 0.89, Recall = 0.6, F1-score = 0.7\n- **LabelSpreading (KNN)**: Precision = 0.83, Recall = 0.67, F1-score = 0.73\n- **Co-Training (SVM)**: Precision = 0.9, Recall = 0.53, F1-score = 0.66\n- **KNN**: Precision = 0.81, Recall = 0.7, F1-score = 0.74\n- **Gaussian NB**: Precision = 0.89, Recall = 0.56, F1-score = 0.69\n- **Logistic Regression**: Precision = 0.76, Recall = 0.61, F1-score = 0.67\n- **AdaBoost**: Precision = 0.88, Recall = 0.58, F1-score = 0.69\n- **Random Forest**: Precision = 0.79, Recall = 0.71, F1-score = 0.74"
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 0.6666666666666666,
                "faithfulness": 1.0,
                "semantic_similarity": 0.8879300428352728,
                "llm_context_precision_without_reference": 0.6716269841157904,
                "llm_context_precision_with_reference": 0.5262896825265253,
                "answer_relevancy": 0.8688403211180221,
                "answer_correctness": 0.5553158440421515
            },
            "deepeval": {
                "contextual_precision": 0.6428571428571428,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.5942028985507246,
                "answer_relevancy": 1.0,
                "faithfulness": 0.1875
            }
        }
    },
    {
        "id": 16,
        "job_id": 1,
        "file_id": 4,
        "question_id": 1,
        "status": "done",
        "answer_text": "The study utilized several AI algorithms, specifically SVM (Support Vector Machine), Naive Bayes, and AdaBoost. These algorithms were employed to classify tweets as either radical or non-radical based on features extracted from the data. The findings indicate that AdaBoost performed the best among the classifiers, achieving a 100% accuracy rate in classifying instances, while SVM and Naive Bayes also demonstrated high accuracy but with some misclassifications. This highlights the effectiveness of machine learning techniques in automatically identifying jihadist messages, which is crucial for law enforcement agencies in managing and responding to radical content online.",
        "answer_encoded": "SVM, AdaBoost, Naive Bayes",
        "answer_contexts": [
                {
                    "context": "TABLE VI: Results when using all features (S + T + SB) on the full dataset.\n\nTable VI shows the results for three different classifiers using all features on all the datasets TW-PRO, TW-RAND and TW-CON. As can be seen in the table AdaBoost performs slightly better than both Naive Bayes and SVM.\n\n V. CONCLUSIONS AND FUTURE WORK\n\nIn this work we have used machine learning to automatically identify jihadist messages. One of the major problems with classification is that in most cases the data is manually labeled by analysts as either jihadist or non-jihadist (we use the terms radical or non-radical). We avoided this and related issues such as analyst disagreement by working with data labeled from incorporated hashtags and using networks of known jihadists to assure radical content. One of the drawbacks with our method is that many of the features are dependent on the dataset. For future work it would be interesting to use both data dependent and data independent features and evaluate the results.\n\nDetecting radical content in order to react on it or to work with partners to remove it is an important task for law enforcement agencies. Due to the enormous amount of official high quality jihadist material issued by media operatives as well as user generated content available on social media there is a need for tools that can aid analysts in their work of detecting radical content online semi-automatically.\n\n REFERENCES\n\n1. A. Fisher, “Last gang in town: How jihadist networks maintain a persistent presence online,” in Perspectives on Terrorism (to appear), 2015.\n2. A. Fisher and N. Prucha, “Tweeting for the caliphate: Twitter as the new frontier for jihadist propaganda.” in CTC Sentinel 6.6 19-23, 2013.\n3. A. Fisher and N. Prucha, “The call-up: The roots of a resilient and persistent jihadist presence on twitter,” in CTX Vol.4 No.3, 2014.\n4. M. Lynch, F. Deen, and S. Aday, “Syrias socially mediated civil war.” in United States Institute Of Peace 91.1 1-35, 2014.\n5. N. Prucha, “Online territories of terror: how jihadist movements project influence on the internet and why it matters offline,” in Dissertation, University of Vienna, 2015.\n6. S. Wright, N. Dorman, and C. Cortbus, “Twitter shuts down isis supporters and jihadists as mi5 launch anti−terror social media crackdown,” in Mirror UK News, 2015.\n7. B. Pang, L. Lee, and S. Vaithyanathan, “Thumbs up?: Sentiment classification using machine learning techniques,” in ACL-02, 2002.\n8. A. Agarwal, B. Xie, I. Vovsha, O. Rambow, and R. Passonneau, “Sentiment analysis of twitter data,” in LSM 2011, 2011, pp. 30–38.\n9. L. Barbosa and J. Feng, “Robust sentiment detection on twitter from biased and noisy data,” in COLING 10, 2010, pp. 36–44.\n10. B. Sriram, D. Fuhry, E. Demir, H. Ferhatosmanoglu, and M. Demirbas, “Short text classification in twitter to improve information filtering,” in ACM SIGIR, ser. SIGIR ’10, 2010, pp. 841–842.\n11. K. Lee, D. Palsetia, R. Naraya0, #NaN M. M. A. Patwary, A. Agrawal, and A. Choudhary, “Twitter trending topic classification,” in ICDMW, 2011, pp. 251–258.\n12. R. Batool, A. M. Khattak, J. Maqbool, and S. Lee, “Precise tweet classification and sentiment analysis,” in ICIS. IEEE, 2013.\n13. A. Go, R. Bhayani, and L. Huang, “Twitter sentiment classification using distant supervision,” CS224N Project Report, Stanford, 2009.\n14. M. Yang, M. Kiang, Y. Ku, C. Chiu, and Y. Li, “Social media analytics for radical opinion mining in hate group web forums,” Journal of homeland security and emergency management, vol. 8, no. 1, 2011.\n15. W. I. Magdy Walid, “#failedrevolutions: Using twitter to study the antecedents of isis support,” arXiv preprint arXiv:1503.02401, 2005.\n16.",
                    "score": 0.8210990817512362
                },
                {
                    "context": "most common approach to classification is done using features such as keywords, entities, synonyms, and parts of speech [12], [13]. In [14] techniques based on machine learning and semantic-oriented approaches was used to identify radical opinions in hate group web forums. Four different types of text features: syntactic, stylistic, content-specific, and lexicon features where used and three classification techniques (SVM, Naive Bayes, and AdaBoost).\n\nAn approach using ISIS related tweets to predict future support or opposition for ISIS was done in [15] where the authors used twitter data to study the antecedents of ISIS support of users. Predictions about future support or opposition for ISIS could be done with 87% accuracy using a SVM classifier.\n\n III. CLASSIFICATION OF JIHADIST MESSAGES\n\nAutomatically analyzing messages on Twitter is an important task for law enforcement agencies. It is impossible for human analysts to manually read all information that is available. Not only is the available information made up of various forms of media such as texts, pictures and video content, the information is also made available by different extremists media groups in multiple languages - with Arabic dominating this field. With media groups operating alongside fighting elements, and with the influx of non-Arab foreign fighters, content is created across a range of languages appealing to different audiences while providing a consistent message and ideology. Using computers to classify content automatically as radical or not would significantly speed up the analysis so that radical content can be removed earlier. However, it is important to emphasize that computers should only be used to support analysts - in this case an automatic classification of tweets can be presented to the analysts that can make a decision whether the tweet is radical or not.\n\nWe use a machine learning approach as a first step towards determining if a tweet is supportive of Jihadist groups or not. To build a classifier that can do this we need to have a suitable dataset to select features from that are useful in determining if a tweet is supporting Jihadist groups or not. The most common approach is to use humans that manually classify tweets as either supporting or non-supporting but in this work we have used another approach. We have collected a set of tweets containing hashtags related to jihadists, and in particular ISIS, from the English language spectrum of pro-ISIS clusters on Twitter. All of the hashtags we used have a corresponding Arabic hashtag and are often used within Arabic and non-Arabic tweets to widen the availability of ISIS material in general. In this work we have focused on the English hashtags and the hashtags we have used to collect data are the following: #IS, #ISLAMICSTATE, #ILoveISIS, #AllEyesOnISIS, #CalamaityWillBeFallUS, #KhalifaRestored, #Islamicstate. The tweets where collected between 25th of June 2014 and 29th of August 2014. Some of the messages that were collected containing the hashtags mentioned above were not related to ISIS and they had no violent/radical message. For example, in some cases the #IS hashtag was not referring to the Islamic state but to the verb \"is\" (to be). In other cases, some of the hashtags were used since the tweets contained.\n\n A. Datasets\n\nAs mentioned in the previous section, we used three different datasets. We will label these datasets TW-PRO, TW-RAND and TW-CON (Table I).",
                    "score": 0.6594169316837059
                },
                {
                    "context": "12. R. Batool, A. M. Khattak, J. Maqbool, and S. Lee, “Precise tweet classification and sentiment analysis,” in ICIS. IEEE, 2013.\n13. A. Go, R. Bhayani, and L. Huang, “Twitter sentiment classification using distant supervision,” CS224N Project Report, Stanford, 2009.\n14. M. Yang, M. Kiang, Y. Ku, C. Chiu, and Y. Li, “Social media analytics for radical opinion mining in hate group web forums,” Journal of homeland security and emergency management, vol. 8, no. 1, 2011.\n15. W. I. Magdy Walid, “#failedrevolutions: Using twitter to study the antecedents of isis support,” arXiv preprint arXiv:1503.02401, 2005.\n16. N. Shuyo, “Language detection library for java,” http://code.google.com/p/language-detection/, 2010.\n17. C. D. Manning, M. Surdeanu, J. Bauer, J. Finkel, S. J. Bethard, and D. McClosky, “The Stanford CoreNLP natural language processing toolkit,” in Proc. of 52nd Annual Meeting of the Ass. for Comp. Ling.: System Demonstrations, 2014, pp. 55–60.\n18. A. Naraya0, #NaN H. Paskov, N. Gong, J. Bethencourt, E. Stefanov, E. Shin, and D. Song, “On the feasibility of internet-scale author identification,” in 2012 IEEE SP, 2012, pp. 300 –314.\n19. F. Johansson, L. Kaati, and A. Shrestha, “Time profiles for identifying users in online environments,” in IEEE JISIC, 2014, pp. 83–90.\n20. T. T. Thet, J.-C. Na, and C. S. Khoo, “Aspect-based sentiment analysis of movie reviews on discussion boards,” Jour. of Inf. Sci., 2010.\n21. C. Lee and G. G. Lee, “Information gain and divergence-based feature selection for machine learning-based text categorization,” Formal Methods for Information Retrieval, vol. 42, pp. 155–165, 2006.\n22. A. Fisher and N. Prucha, “Is this the most successful release of a jihadist video ever? part 2,” in Jihadica.com, 2014.",
                    "score": 0.4956785967962551
                },
                {
                    "context": "This table presents the performance of different classification algorithms, showing the number of instances classified as non-radical and radical, along with the accuracy of each algorithm.,\nwith the following table title:\nClassification Algorithm Performance,\nwith the following columns:\n- Non Radical: Number of instances classified as non-radical.\n- Radical: Number of instances classified as radical.\n- Correctly Classified Instances: Number of instances that were correctly classified.\n- : Accuracy percentage of the classification.\n\n| Non Radical | Radical | Correctly Classified Instances |        |\n|---|---|---|---|\n| SVM         |1974|24| 99.1 % |\n| Naive Bayes |1997|1| 99.9 % |\n| AdaBoost    |1998|0| 100 %  |",
                    "score": 0.49433196910215055
                },
                {
                    "context": "This table presents the performance metrics of different classification algorithms, including the number of instances classified as non-radical and radical, along with the percentage of correctly classified instances.,\nwith the following columns:\n- Algorithm: The classification algorithms evaluated.\n- Non Radical: Number of instances classified as non-radical.\n- Radical: Number of instances classified as radical.\n- Correctly Classified Instances: Percentage of instances correctly classified by the algorithm.\n\n|             | Non Radical | Radical | Correctly Classified Instances |   |\n|---|---|---|---|---|\n| SVM         |3099|92| 97.9 %                         |   |\n| Naive Bayes |2877|314| 89.0 %                         |   |\n| AdaBoost    |1600|0| 100 %                          |   |",
                    "score": 0.49392129561807446
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific AI algorithm was utilized in the study, and how does it contribute to the overall findings presented in the article?",
                    "answer": "The study utilized several AI algorithms, specifically SVM (Support Vector Machine), Naive Bayes, and AdaBoost. These algorithms were employed to classify tweets as either radical or non-radical based on features extracted from the data. The findings indicate that AdaBoost performed the best among the classifiers, achieving a 100% accuracy rate in classifying instances, while SVM and Naive Bayes also demonstrated high accuracy but with some misclassifications. This highlights the effectiveness of machine learning techniques in automatically identifying jihadist messages, which is crucial for law enforcement agencies in managing and responding to radical content online."
                },
                {
                    "question": "[SQ] What features were extracted from the tweets to train the AI algorithms?",
                    "answer": "The features extracted from the tweets to train the AI algorithms included three different classes: stylometric features, time-based features, and sentiment-based features. The stylometric features comprised a set of frequently used words, with 173 words identified, including terms related to ISIS and common verbs."
                },
                {
                    "question": "[SQ] How did the performance of AdaBoost compare to SVM and Naive Bayes in terms of precision and recall?",
                    "answer": "The performance of AdaBoost was superior to both SVM and Naive Bayes in terms of accuracy. AdaBoost achieved 100% accuracy in one dataset and 99.5% in another, while SVM and Naive Bayes had lower accuracy percentages, with SVM reaching a maximum of 99.1% and Naive Bayes achieving up to 99.9%. In terms of classification, AdaBoost classified all instances correctly as non-radical in one dataset, while SVM and Naive Bayes misclassified some radical instances. This indicates that AdaBoost not only had higher accuracy but also demonstrated better precision in identifying non-radical content compared to the other classifiers."
                },
                {
                    "question": "[SQ] What implications do the study's findings have for law enforcement agencies in combating online radicalization?",
                    "answer": "The study's findings suggest that an automated approach to detecting jihadist messages on social media can significantly aid law enforcement agencies in their efforts to combat online radicalization. By utilizing machine learning techniques to classify tweets as supportive or non-supportive of jihadist groups, agencies can process vast amounts of information more efficiently than manual analysis alone. This capability allows for quicker identification and removal of radical content, thereby potentially reducing the spread of extremist propaganda. However, it is emphasized that such automated tools should serve as support for human analysts rather than replace them, ensuring that nuanced decisions regarding content classification are made by trained professionals. Overall, the findings indicate a promising direction for enhancing the effectiveness of counter-radicalization strategies in the digital landscape."
                },
                {
                    "question": "[MQ] Which AI algorithms were employed in the study to classify tweets as radical or non-radical, and what were their respective performances in terms of accuracy?",
                    "answer": "The study employed three AI algorithms to classify tweets as radical or non-radical: SVM, Naive Bayes, and AdaBoost. Their respective performances in terms of accuracy were as follows:\n\n- SVM: 97.9% accuracy\n- Naive Bayes: 89.0% accuracy\n- AdaBoost: 100% accuracy\n\nIn another evaluation, the performances were:\n\n- SVM: 99.1% accuracy\n- Naive Bayes: 99.9% accuracy\n- AdaBoost: 100% accuracy"
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 0.9012657339771285,
                "llm_context_precision_without_reference": 0, #NaN
                "llm_context_precision_with_reference": 0.8333333333055556,
                "answer_relevancy": 0.757677075175033,
                "answer_correctness": 0.9753164334942821
            },
            "deepeval": {
                "contextual_precision": 0.6428571428571428,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.19047619047619047,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 17,
        "job_id": 1,
        "file_id": 4,
        "question_id": 2,
        "status": "done",
        "answer_text": "The study focused on three classes of features for analysis: stylometric features, time-based features, and sentiment-based features.\n\nStylometric features included frequently used words, punctuation, letter bigrams, word bigrams, and hashtags. These were justified as they help capture the linguistic style and content of tweets, which is crucial for distinguishing between supportive and non-supportive messages related to jihadist groups.\n\nTime-based features provided insights into when tweets were posted, such as the hour of the day, period of the day, day of the week, and type of day. These features were important for revealing patterns in tweet activity that might correlate with radical content.\n\nSentiment-based features assessed the emotional tone of the tweets, categorizing them into various sentiment levels. This analysis was justified as it aimed to understand the overall attitude expressed in the tweets, which is relevant for identifying radical sentiments.\n\nThe selection of these features aimed to build a robust classifier to automatically identify jihadist messages, thereby supporting analysts in detecting and responding to radical content online.",
        "answer_encoded": "[response not coded] The analysis selected stylometric features, time-based features, and sentiment-based features to build a classifier for identifying jihadist messages.",
        "answer_contexts": [
                {
                    "context": "most common approach to classification is done using features such as keywords, entities, synonyms, and parts of speech [12], [13]. In [14] techniques based on machine learning and semantic-oriented approaches was used to identify radical opinions in hate group web forums. Four different types of text features: syntactic, stylistic, content-specific, and lexicon features where used and three classification techniques (SVM, Naive Bayes, and AdaBoost).\n\nAn approach using ISIS related tweets to predict future support or opposition for ISIS was done in [15] where the authors used twitter data to study the antecedents of ISIS support of users. Predictions about future support or opposition for ISIS could be done with 87% accuracy using a SVM classifier.\n\n III. CLASSIFICATION OF JIHADIST MESSAGES\n\nAutomatically analyzing messages on Twitter is an important task for law enforcement agencies. It is impossible for human analysts to manually read all information that is available. Not only is the available information made up of various forms of media such as texts, pictures and video content, the information is also made available by different extremists media groups in multiple languages - with Arabic dominating this field. With media groups operating alongside fighting elements, and with the influx of non-Arab foreign fighters, content is created across a range of languages appealing to different audiences while providing a consistent message and ideology. Using computers to classify content automatically as radical or not would significantly speed up the analysis so that radical content can be removed earlier. However, it is important to emphasize that computers should only be used to support analysts - in this case an automatic classification of tweets can be presented to the analysts that can make a decision whether the tweet is radical or not.\n\nWe use a machine learning approach as a first step towards determining if a tweet is supportive of Jihadist groups or not. To build a classifier that can do this we need to have a suitable dataset to select features from that are useful in determining if a tweet is supporting Jihadist groups or not. The most common approach is to use humans that manually classify tweets as either supporting or non-supporting but in this work we have used another approach. We have collected a set of tweets containing hashtags related to jihadists, and in particular ISIS, from the English language spectrum of pro-ISIS clusters on Twitter. All of the hashtags we used have a corresponding Arabic hashtag and are often used within Arabic and non-Arabic tweets to widen the availability of ISIS material in general. In this work we have focused on the English hashtags and the hashtags we have used to collect data are the following: #IS, #ISLAMICSTATE, #ILoveISIS, #AllEyesOnISIS, #CalamaityWillBeFallUS, #KhalifaRestored, #Islamicstate. The tweets where collected between 25th of June 2014 and 29th of August 2014. Some of the messages that were collected containing the hashtags mentioned above were not related to ISIS and they had no violent/radical message. For example, in some cases the #IS hashtag was not referring to the Islamic state but to the verb \"is\" (to be). In other cases, some of the hashtags were used since the tweets contained.\n\n A. Datasets\n\nAs mentioned in the previous section, we used three different datasets. We will label these datasets TW-PRO, TW-RAND and TW-CON (Table I).",
                    "score": 0.8347606607421719
                },
                {
                    "context": "TABLE I: The datasets used for the experiments\n\nThe data was preprocessed and re-tweets, annotations and urls were removed. The data was tokenized and lemmatized to obtain the base form of the words. In the process of lemmatizing the toolkit [17] was used.\n\n B. Features\n\nIn our experiments we have used three different classes of features:\n\n- stylometric features (S)\n- time based features (T)\n- sentiment based features (SB)\n\nThe stylometric features that we have used in this work are shown in Table II. The stylometric features also contain a set of the words that are the most frequent in the dataset. We have used 173 frequently used words where the 10 most frequently used words in the dataset are: state, islamic, not, do, kill, support, abu, allah, people, and al. Among the most common words we can notice words that are related to ISIS (state and islamic), verbs like kill and support as well as the word abu. The word abu refers to individuals who usually assume a nom de guerre starting with abu (father of) [name] by which various foreign fighters, martyrdom operatives, ideologues etc are introduced and made popular within the respective clusters; allah simply refers to \"God\" and the Arabic appellation is preferred by pro-ISIS clusters who generally adhere to Arabic dominated language sets; \"al\" is the Arabic article \"al\" (\"the\").",
                    "score": 0.8322464723179912
                },
                {
                    "context": "TABLE VI: Results when using all features (S + T + SB) on the full dataset.\n\nTable VI shows the results for three different classifiers using all features on all the datasets TW-PRO, TW-RAND and TW-CON. As can be seen in the table AdaBoost performs slightly better than both Naive Bayes and SVM.\n\n V. CONCLUSIONS AND FUTURE WORK\n\nIn this work we have used machine learning to automatically identify jihadist messages. One of the major problems with classification is that in most cases the data is manually labeled by analysts as either jihadist or non-jihadist (we use the terms radical or non-radical). We avoided this and related issues such as analyst disagreement by working with data labeled from incorporated hashtags and using networks of known jihadists to assure radical content. One of the drawbacks with our method is that many of the features are dependent on the dataset. For future work it would be interesting to use both data dependent and data independent features and evaluate the results.\n\nDetecting radical content in order to react on it or to work with partners to remove it is an important task for law enforcement agencies. Due to the enormous amount of official high quality jihadist material issued by media operatives as well as user generated content available on social media there is a need for tools that can aid analysts in their work of detecting radical content online semi-automatically.\n\n REFERENCES\n\n1. A. Fisher, “Last gang in town: How jihadist networks maintain a persistent presence online,” in Perspectives on Terrorism (to appear), 2015.\n2. A. Fisher and N. Prucha, “Tweeting for the caliphate: Twitter as the new frontier for jihadist propaganda.” in CTC Sentinel 6.6 19-23, 2013.\n3. A. Fisher and N. Prucha, “The call-up: The roots of a resilient and persistent jihadist presence on twitter,” in CTX Vol.4 No.3, 2014.\n4. M. Lynch, F. Deen, and S. Aday, “Syrias socially mediated civil war.” in United States Institute Of Peace 91.1 1-35, 2014.\n5. N. Prucha, “Online territories of terror: how jihadist movements project influence on the internet and why it matters offline,” in Dissertation, University of Vienna, 2015.\n6. S. Wright, N. Dorman, and C. Cortbus, “Twitter shuts down isis supporters and jihadists as mi5 launch anti−terror social media crackdown,” in Mirror UK News, 2015.\n7. B. Pang, L. Lee, and S. Vaithyanathan, “Thumbs up?: Sentiment classification using machine learning techniques,” in ACL-02, 2002.\n8. A. Agarwal, B. Xie, I. Vovsha, O. Rambow, and R. Passonneau, “Sentiment analysis of twitter data,” in LSM 2011, 2011, pp. 30–38.\n9. L. Barbosa and J. Feng, “Robust sentiment detection on twitter from biased and noisy data,” in COLING 10, 2010, pp. 36–44.\n10. B. Sriram, D. Fuhry, E. Demir, H. Ferhatosmanoglu, and M. Demirbas, “Short text classification in twitter to improve information filtering,” in ACM SIGIR, ser. SIGIR ’10, 2010, pp. 841–842.\n11. K. Lee, D. Palsetia, R. Naraya0, #NaN M. M. A. Patwary, A. Agrawal, and A. Choudhary, “Twitter trending topic classification,” in ICDMW, 2011, pp. 251–258.\n12. R. Batool, A. M. Khattak, J. Maqbool, and S. Lee, “Precise tweet classification and sentiment analysis,” in ICIS. IEEE, 2013.\n13. A. Go, R. Bhayani, and L. Huang, “Twitter sentiment classification using distant supervision,” CS224N Project Report, Stanford, 2009.\n14. M. Yang, M. Kiang, Y. Ku, C. Chiu, and Y. Li, “Social media analytics for radical opinion mining in hate group web forums,” Journal of homeland security and emergency management, vol. 8, no. 1, 2011.\n15. W. I. Magdy Walid, “#failedrevolutions: Using twitter to study the antecedents of isis support,” arXiv preprint arXiv:1503.02401, 2005.\n16.",
                    "score": 0.8202416300902208
                },
                {
                    "context": "TABLE IV: Results when using features (S + T + SB) on the datasets TW-RAND and TW-PRO.\n\nWhile TW-CON are tweets that are against ISIS. The tweets that are against ISIS contain similar hashtags and topics as the TW-PRO dataset and is therefore harder to separate than the randomly collected tweets.",
                    "score": 0.8134977391041659
                },
                {
                    "context": "2015 European Intelligence and Security Informatics Conference\n\n Detecting Jihadist Messages on Twitter\n\nMichael Ashcroft\n\nUppsala University, Dept. of Inf. tech.\n\nUppsala, Sweden\n\nmichael.ashcroft@it.uu.se\n\nAli Fisher\n\nVORTEX, University of Vienna\n\nVienna, Austria\n\nali@humanshuddle.com\n\nLisa Kaati\n\nFOI/Uppsala University\n\nStockholm, Sweden\n\nlisa.kaati@foi.se\n\nEnghin Omer\n\nUppsala University, Dept. of Inf. tech.\n\nUppsala, Sweden\n\nomer.enghin@yahoo.com\n\nNico Prucha\n\nICSR, King’s College\n\nLondon, UK\n\nnico.prucha@univie.ac.at\n\nAbstract— Jihadist groups such as ISIS are spreading online propaganda using various forms of social media such as Twitter and YouTube. One of the most common approaches to stop these groups is to suspend accounts that spread propaganda when they are discovered. This approach requires that human analysts manually read and analyze an enormous amount of information on social media. In this work we make a first attempt to automatically detect messages released by jihadist groups on Twitter. We use a machine learning approach that classifies a tweet as containing material that is supporting jihadist groups or not. Even though our results are preliminary and more tests need to be carried out we believe that results indicate that an automated approach to aid analysts in their work with detecting radical content on social media is a promising way forward. It should be noted that an automatic approach to detect radical content should only be used as a support tool for human analysts in their work.\n\n I. INTRODUCTION\n\nJihadist groups, and specifically ISIS, have been able to maintain a persistent online presence by sharing content through a broad network of “media mujahedeen” in one of the clearest incarnations of netwar since it was first envisaged. ISIS uses dispersed forms of network organization and strategy to disseminate rich audiovisual content from the battlefield in near-real time. Its interconnected network constantly refigures itself, much like the way a swarm of bees or flock of birds constantly reorganizes in mid-flight. It marks a shift from the broadcast models of communication during conflict to a new dispersed and resilient form, the user curated swarmcast. This makes ISIS a challenge for traditionally hierarchical organizations to counter.\n\nThe internet has been identified by senior Sunni extremists as a “battlefield for jihad, a place for missionary work, a field of confronting the enemies of God.” This was further encouraged by a “Twitter Guide” (dalil Twitter) posted on the Shumukh al-Islam forum which outlined reasons for using Twitter as an important arena of the electronic front (ribat). Since 2011 the Syrian conflict, recognized as the most “socially mediated” in history, has developed into the new focal point for jihadi media culture. Within this online battlefield Twitter has become the Beacon for Jihadist Activity Online. In particular the self-proclaimed “Islamic State” that is in the process of consolidating territory in Syria and Iraq has effectively built up and maintains a persistent presence online. One may argue, this online presence reflects the real-world consolidation of territory and one may be inclined to term this ideologically coherent and technically resilient presence as online territories of terror.\n\n II. RADICAL CONTENT ON SOCIAL MEDIA\n\nJihadist supporters, in particular ISIS supporters, use Twitter to distribute radical content through a dispersed network of Twitter accounts. The structure of the network gives ISIS a stable and persistent online presence even if key players are detected and suspended.\n\n A. Related work\n\nMachine learning is the most common approach to sentiment classification. Previous work in this area includes various studies. In one study, tweets are classified into five topic categories and in another, trending topics on Twitter are classified into 18 general categories using bag-of-words and network-based classification. Results show that accuracy is up to 65% and 70% for the different classification methods respectively.\n\nDOI 10.1109/EISIC.2015.27",
                    "score": 0.3418676025967865
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific features or characteristics were selected for analysis in the study, and how were they justified in the context of the research objectives?",
                    "answer": "The analysis in the study focused on three classes of features: stylometric features, time-based features, and sentiment-based features. \n\nStylometric features included the frequency of function words, frequent words, punctuation, hashtags, letter bigrams, and word bigrams. These features were justified as they help capture the linguistic style and content of the tweets, which is crucial for distinguishing between supportive and non-supportive messages related to jihadist groups.\n\nTime-based features provided information about when tweets were posted, including the hour of the day, period of the day, day of the week, and type of day. These features were important as they could reveal patterns in tweet activity that might correlate with radical content.\n\nSentiment-based features assessed the emotional tone of the tweets, categorizing them into various sentiment levels. This analysis was justified as it aimed to understand the overall attitude expressed in the tweets, which is relevant for identifying radical sentiments.\n\nThe selection of these features was aimed at building a robust classifier to automatically identify jihadist messages, thereby supporting analysts in their efforts to detect and respond to radical content online."
                },
                {
                    "question": "[SQ] What criteria were used to select the specific stylometric features for analysis in the study?",
                    "answer": "The selection of stylometric features for analysis was based on their frequency and relevance within the dataset. Specifically, the study utilized a set of frequently used words, punctuation, letter bigrams, word bigrams, and hashtags. The most common words and hashtags were identified, with a focus on those that were particularly associated with the themes of the tweets, such as those related to ISIS. The inclusion of these features aimed to capture the linguistic patterns and stylistic elements present in the tweets, which could contribute to the classification of the content as radical or non-radical."
                },
                {
                    "question": "[SQ] How did the researchers determine the relevance of time-based features in relation to jihadist content?",
                    "answer": "The researchers included time-based features as part of their classification approach to analyze jihadist content on Twitter. These features likely relate to the timing of tweets, such as the frequency of posts during specific events or periods of heightened activity related to jihadist groups. By examining how the timing of tweets correlates with the dissemination of radical content, the researchers aimed to enhance the classification process. However, specific methodologies or findings regarding the effectiveness of these time-based features were not detailed in the provided information."
                },
                {
                    "question": "[SQ] What methods were employed to assess the sentiment-based features and their impact on identifying radical sentiments?",
                    "answer": "Sentiment-based features were assessed as part of a broader machine learning approach to classify tweets related to jihadist groups. The experiments utilized a combination of stylometric, time-based, and sentiment-based features to evaluate their effectiveness in identifying radical sentiments. The results indicated that these features contributed to the overall classification performance, with specific attention given to the sentiment expressed in the tweets. The classifiers employed, including AdaBoost, Naive Bayes, and SVM, were tested on various datasets to determine the impact of sentiment-based features alongside other feature types."
                },
                {
                    "question": "[MQ] What stylometric, time-based, and sentiment-based features were selected for analysis in the study, and how were their roles justified in identifying radical content in tweets related to jihadist groups?",
                    "answer": "The analysis in the study utilized three classes of features: stylometric features, time-based features, and sentiment-based features. \n\nStylometric features included a set of frequently used words within the dataset, with 173 words identified, among which the ten most common were: state, islamic, not, do, kill, support, abu, allah, people, and al. These words were significant as they were directly related to the themes and ideologies associated with jihadist content, helping to distinguish radical messages from non-radical ones.\n\nTime-based features likely pertained to the timing of tweets, which could provide context regarding the relevance or urgency of the content being shared, although specific details on these features were not provided.\n\nSentiment-based features were designed to analyze the emotional tone of the tweets, which could indicate support or opposition to jihadist ideologies. By assessing the sentiment expressed in the tweets, the study aimed to enhance the classification of messages as supportive or non-supportive of jihadist groups.\n\nTogether, these features were justified as essential tools for identifying radical content, as they provided a multifaceted approach to understanding the language, timing, and emotional context of tweets related to jihadist groups."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 0.891719467448018,
                "llm_context_precision_without_reference": 0, #NaN
                "llm_context_precision_with_reference": 0, #NaN
                "answer_relevancy": 0.9465326272264871,
                "answer_correctness": 0, #NaN
            },
            "deepeval": {
                "contextual_precision": 0.9166666666666666,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.1111111111111111,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 18,
        "job_id": 1,
        "file_id": 4,
        "question_id": 3,
        "status": "done",
        "answer_text": "The social network utilized for data collection in the analyzed article is Twitter.",
        "answer_encoded": "Twitter",
        "answer_contexts": [
                {
                    "context": "TABLE IV: Results when using features (S + T + SB) on the datasets TW-RAND and TW-PRO.\n\nWhile TW-CON are tweets that are against ISIS. The tweets that are against ISIS contain similar hashtags and topics as the TW-PRO dataset and is therefore harder to separate than the randomly collected tweets.",
                    "score": 0.8279165271989435
                },
                {
                    "context": "12. R. Batool, A. M. Khattak, J. Maqbool, and S. Lee, “Precise tweet classification and sentiment analysis,” in ICIS. IEEE, 2013.\n13. A. Go, R. Bhayani, and L. Huang, “Twitter sentiment classification using distant supervision,” CS224N Project Report, Stanford, 2009.\n14. M. Yang, M. Kiang, Y. Ku, C. Chiu, and Y. Li, “Social media analytics for radical opinion mining in hate group web forums,” Journal of homeland security and emergency management, vol. 8, no. 1, 2011.\n15. W. I. Magdy Walid, “#failedrevolutions: Using twitter to study the antecedents of isis support,” arXiv preprint arXiv:1503.02401, 2005.\n16. N. Shuyo, “Language detection library for java,” http://code.google.com/p/language-detection/, 2010.\n17. C. D. Manning, M. Surdeanu, J. Bauer, J. Finkel, S. J. Bethard, and D. McClosky, “The Stanford CoreNLP natural language processing toolkit,” in Proc. of 52nd Annual Meeting of the Ass. for Comp. Ling.: System Demonstrations, 2014, pp. 55–60.\n18. A. Naraya0, #NaN H. Paskov, N. Gong, J. Bethencourt, E. Stefanov, E. Shin, and D. Song, “On the feasibility of internet-scale author identification,” in 2012 IEEE SP, 2012, pp. 300 –314.\n19. F. Johansson, L. Kaati, and A. Shrestha, “Time profiles for identifying users in online environments,” in IEEE JISIC, 2014, pp. 83–90.\n20. T. T. Thet, J.-C. Na, and C. S. Khoo, “Aspect-based sentiment analysis of movie reviews on discussion boards,” Jour. of Inf. Sci., 2010.\n21. C. Lee and G. G. Lee, “Information gain and divergence-based feature selection for machine learning-based text categorization,” Formal Methods for Information Retrieval, vol. 42, pp. 155–165, 2006.\n22. A. Fisher and N. Prucha, “Is this the most successful release of a jihadist video ever? part 2,” in Jihadica.com, 2014.",
                    "score": 0.8260289616508928
                },
                {
                    "context": "This table categorizes different datasets of tweets based on their stance towards ISIS, including pro-ISIS tweets, random tweets on various topics, and anti-ISIS tweets.,\nwith the following table title:\nDataset,\nwith the following columns:\n- Dataset: Names of the tweet datasets.\n- Description: Descriptions of the tweet datasets.\n\n| Dataset | Description                                          |\n|---|---|\n| TW-PRO  | Tweets that are pro ISIS,                            |\n| TW-RAND | Randomly collected tweets discussing various topics. |\n| TW-CON  | Tweets from accounts that are against ISIS.          |",
                    "score": 0.8237400601710639
                },
                {
                    "context": "2015 European Intelligence and Security Informatics Conference\n\n Detecting Jihadist Messages on Twitter\n\nMichael Ashcroft\n\nUppsala University, Dept. of Inf. tech.\n\nUppsala, Sweden\n\nmichael.ashcroft@it.uu.se\n\nAli Fisher\n\nVORTEX, University of Vienna\n\nVienna, Austria\n\nali@humanshuddle.com\n\nLisa Kaati\n\nFOI/Uppsala University\n\nStockholm, Sweden\n\nlisa.kaati@foi.se\n\nEnghin Omer\n\nUppsala University, Dept. of Inf. tech.\n\nUppsala, Sweden\n\nomer.enghin@yahoo.com\n\nNico Prucha\n\nICSR, King’s College\n\nLondon, UK\n\nnico.prucha@univie.ac.at\n\nAbstract— Jihadist groups such as ISIS are spreading online propaganda using various forms of social media such as Twitter and YouTube. One of the most common approaches to stop these groups is to suspend accounts that spread propaganda when they are discovered. This approach requires that human analysts manually read and analyze an enormous amount of information on social media. In this work we make a first attempt to automatically detect messages released by jihadist groups on Twitter. We use a machine learning approach that classifies a tweet as containing material that is supporting jihadist groups or not. Even though our results are preliminary and more tests need to be carried out we believe that results indicate that an automated approach to aid analysts in their work with detecting radical content on social media is a promising way forward. It should be noted that an automatic approach to detect radical content should only be used as a support tool for human analysts in their work.\n\n I. INTRODUCTION\n\nJihadist groups, and specifically ISIS, have been able to maintain a persistent online presence by sharing content through a broad network of “media mujahedeen” in one of the clearest incarnations of netwar since it was first envisaged. ISIS uses dispersed forms of network organization and strategy to disseminate rich audiovisual content from the battlefield in near-real time. Its interconnected network constantly refigures itself, much like the way a swarm of bees or flock of birds constantly reorganizes in mid-flight. It marks a shift from the broadcast models of communication during conflict to a new dispersed and resilient form, the user curated swarmcast. This makes ISIS a challenge for traditionally hierarchical organizations to counter.\n\nThe internet has been identified by senior Sunni extremists as a “battlefield for jihad, a place for missionary work, a field of confronting the enemies of God.” This was further encouraged by a “Twitter Guide” (dalil Twitter) posted on the Shumukh al-Islam forum which outlined reasons for using Twitter as an important arena of the electronic front (ribat). Since 2011 the Syrian conflict, recognized as the most “socially mediated” in history, has developed into the new focal point for jihadi media culture. Within this online battlefield Twitter has become the Beacon for Jihadist Activity Online. In particular the self-proclaimed “Islamic State” that is in the process of consolidating territory in Syria and Iraq has effectively built up and maintains a persistent presence online. One may argue, this online presence reflects the real-world consolidation of territory and one may be inclined to term this ideologically coherent and technically resilient presence as online territories of terror.\n\n II. RADICAL CONTENT ON SOCIAL MEDIA\n\nJihadist supporters, in particular ISIS supporters, use Twitter to distribute radical content through a dispersed network of Twitter accounts. The structure of the network gives ISIS a stable and persistent online presence even if key players are detected and suspended.\n\n A. Related work\n\nMachine learning is the most common approach to sentiment classification. Previous work in this area includes various studies. In one study, tweets are classified into five topic categories and in another, trending topics on Twitter are classified into 18 general categories using bag-of-words and network-based classification. Results show that accuracy is up to 65% and 70% for the different classification methods respectively.\n\nDOI 10.1109/EISIC.2015.27",
                    "score": 0.6597112338858985
                },
                {
                    "context": "TABLE I: The datasets used for the experiments\n\nThe data was preprocessed and re-tweets, annotations and urls were removed. The data was tokenized and lemmatized to obtain the base form of the words. In the process of lemmatizing the toolkit [17] was used.\n\n B. Features\n\nIn our experiments we have used three different classes of features:\n\n- stylometric features (S)\n- time based features (T)\n- sentiment based features (SB)\n\nThe stylometric features that we have used in this work are shown in Table II. The stylometric features also contain a set of the words that are the most frequent in the dataset. We have used 173 frequently used words where the 10 most frequently used words in the dataset are: state, islamic, not, do, kill, support, abu, allah, people, and al. Among the most common words we can notice words that are related to ISIS (state and islamic), verbs like kill and support as well as the word abu. The word abu refers to individuals who usually assume a nom de guerre starting with abu (father of) [name] by which various foreign fighters, martyrdom operatives, ideologues etc are introduced and made popular within the respective clusters; allah simply refers to \"God\" and the Arabic appellation is preferred by pro-ISIS clusters who generally adhere to Arabic dominated language sets; \"al\" is the Arabic article \"al\" (\"the\").",
                    "score": 0.4836837728806196
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] Which social network or platform was utilized for data collection in the analyzed article?",
                    "answer": "The social network utilized for data collection in the analyzed article is Twitter."
                },
                {
                    "question": "[SQ] What specific data collection methods were employed on Twitter in the analyzed article?",
                    "answer": "The data collection methods involved gathering tweets containing specific hashtags related to jihadists, particularly ISIS. The hashtags used for collecting data included #IS, #ISLAMICSTATE, #ILoveISIS, #AllEyesOnISIS, #CalamaityWillBeFallUS, #KhalifaRestored, and #Islamicstate. The tweets were collected from the English language spectrum of pro-ISIS clusters on Twitter between June 25, 2014, and August 29, 2014. The collected data underwent preprocessing, which included the removal of retweets, annotations, and URLs, followed by tokenization and lemmatization to obtain the base form of the words."
                },
                {
                    "question": "[SQ] How was the data from Twitter analyzed in the context of the study?",
                    "answer": "The data from Twitter was analyzed using a machine learning approach that involved classifying tweets based on their content related to jihadist groups, specifically ISIS. The analysis included preprocessing steps such as removing retweets, annotations, and URLs, followed by tokenization and lemmatization to obtain the base forms of words. Three classes of features were utilized in the experiments: stylometric features, time-based features, and sentiment-based features. Stylometric features included a set of frequently used words, particularly those associated with ISIS, which helped in distinguishing between different types of tweets. The results indicated that this automated approach could assist human analysts in detecting radical content on social media."
                },
                {
                    "question": "[SQ] What were the main findings derived from the Twitter data in the analyzed article?",
                    "answer": "The main findings indicate that machine learning can be effectively utilized to automatically identify jihadist messages on Twitter. The study highlights the challenges of classifying tweets, particularly due to the overlap in hashtags and topics between pro-ISIS and anti-ISIS tweets. Preliminary results suggest that an automated approach could assist human analysts in detecting radical content, although it should serve as a support tool rather than a replacement for human judgment. Additionally, the performance of different classifiers was evaluated, with AdaBoost showing slightly better results compared to Naive Bayes and SVM. Future work is suggested to explore both data-dependent and data-independent features for improved classification."
                },
                {
                    "question": "[MQ] Which social network was used for data collection in the analyzed article, specifically focusing on tweets related to jihadist groups like ISIS?",
                    "answer": "The social network used for data collection in the analyzed article, specifically focusing on tweets related to jihadist groups like ISIS, is Twitter."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 0.9999999999999996,
                "llm_context_precision_without_reference": 0, #NaN
                "llm_context_precision_with_reference": 0, #NaN
                "answer_relevancy": 0, #NaN
                "answer_correctness": 0.9999999999999999
            },
            "deepeval": {
                "contextual_precision": 1.0,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.07936507936507936,
                "answer_relevancy": 1.0,
                "faithfulness": 0.5
            }
        },
    },
    {
        "id": 19,
        "job_id": 1,
        "file_id": 4,
        "question_id": 4,
        "status": "done",
        "answer_text": "The size of the dataset analyzed in the article is not specified in the provided information.",
        "answer_encoded": "[response not coded] The size of the analyzed dataset is unspecified.",
        "answer_contexts": [
                {
                    "context": "This table categorizes different datasets of tweets based on their stance towards ISIS, including pro-ISIS tweets, random tweets on various topics, and anti-ISIS tweets.,\nwith the following table title:\nDataset,\nwith the following columns:\n- Dataset: Names of the tweet datasets.\n- Description: Descriptions of the tweet datasets.\n\n| Dataset | Description                                          |\n|---|---|\n| TW-PRO  | Tweets that are pro ISIS,                            |\n| TW-RAND | Randomly collected tweets discussing various topics. |\n| TW-CON  | Tweets from accounts that are against ISIS.          |",
                    "score": 0.8529448975548082
                },
                {
                    "context": "TABLE IV: Results when using features (S + T + SB) on the datasets TW-RAND and TW-PRO.\n\nWhile TW-CON are tweets that are against ISIS. The tweets that are against ISIS contain similar hashtags and topics as the TW-PRO dataset and is therefore harder to separate than the randomly collected tweets.",
                    "score": 0.8316695182067402
                },
                {
                    "context": "12. R. Batool, A. M. Khattak, J. Maqbool, and S. Lee, “Precise tweet classification and sentiment analysis,” in ICIS. IEEE, 2013.\n13. A. Go, R. Bhayani, and L. Huang, “Twitter sentiment classification using distant supervision,” CS224N Project Report, Stanford, 2009.\n14. M. Yang, M. Kiang, Y. Ku, C. Chiu, and Y. Li, “Social media analytics for radical opinion mining in hate group web forums,” Journal of homeland security and emergency management, vol. 8, no. 1, 2011.\n15. W. I. Magdy Walid, “#failedrevolutions: Using twitter to study the antecedents of isis support,” arXiv preprint arXiv:1503.02401, 2005.\n16. N. Shuyo, “Language detection library for java,” http://code.google.com/p/language-detection/, 2010.\n17. C. D. Manning, M. Surdeanu, J. Bauer, J. Finkel, S. J. Bethard, and D. McClosky, “The Stanford CoreNLP natural language processing toolkit,” in Proc. of 52nd Annual Meeting of the Ass. for Comp. Ling.: System Demonstrations, 2014, pp. 55–60.\n18. A. Naraya0, #NaN H. Paskov, N. Gong, J. Bethencourt, E. Stefanov, E. Shin, and D. Song, “On the feasibility of internet-scale author identification,” in 2012 IEEE SP, 2012, pp. 300 –314.\n19. F. Johansson, L. Kaati, and A. Shrestha, “Time profiles for identifying users in online environments,” in IEEE JISIC, 2014, pp. 83–90.\n20. T. T. Thet, J.-C. Na, and C. S. Khoo, “Aspect-based sentiment analysis of movie reviews on discussion boards,” Jour. of Inf. Sci., 2010.\n21. C. Lee and G. G. Lee, “Information gain and divergence-based feature selection for machine learning-based text categorization,” Formal Methods for Information Retrieval, vol. 42, pp. 155–165, 2006.\n22. A. Fisher and N. Prucha, “Is this the most successful release of a jihadist video ever? part 2,” in Jihadica.com, 2014.",
                    "score": 0.6344500742473
                },
                {
                    "context": "most common approach to classification is done using features such as keywords, entities, synonyms, and parts of speech [12], [13]. In [14] techniques based on machine learning and semantic-oriented approaches was used to identify radical opinions in hate group web forums. Four different types of text features: syntactic, stylistic, content-specific, and lexicon features where used and three classification techniques (SVM, Naive Bayes, and AdaBoost).\n\nAn approach using ISIS related tweets to predict future support or opposition for ISIS was done in [15] where the authors used twitter data to study the antecedents of ISIS support of users. Predictions about future support or opposition for ISIS could be done with 87% accuracy using a SVM classifier.\n\n III. CLASSIFICATION OF JIHADIST MESSAGES\n\nAutomatically analyzing messages on Twitter is an important task for law enforcement agencies. It is impossible for human analysts to manually read all information that is available. Not only is the available information made up of various forms of media such as texts, pictures and video content, the information is also made available by different extremists media groups in multiple languages - with Arabic dominating this field. With media groups operating alongside fighting elements, and with the influx of non-Arab foreign fighters, content is created across a range of languages appealing to different audiences while providing a consistent message and ideology. Using computers to classify content automatically as radical or not would significantly speed up the analysis so that radical content can be removed earlier. However, it is important to emphasize that computers should only be used to support analysts - in this case an automatic classification of tweets can be presented to the analysts that can make a decision whether the tweet is radical or not.\n\nWe use a machine learning approach as a first step towards determining if a tweet is supportive of Jihadist groups or not. To build a classifier that can do this we need to have a suitable dataset to select features from that are useful in determining if a tweet is supporting Jihadist groups or not. The most common approach is to use humans that manually classify tweets as either supporting or non-supporting but in this work we have used another approach. We have collected a set of tweets containing hashtags related to jihadists, and in particular ISIS, from the English language spectrum of pro-ISIS clusters on Twitter. All of the hashtags we used have a corresponding Arabic hashtag and are often used within Arabic and non-Arabic tweets to widen the availability of ISIS material in general. In this work we have focused on the English hashtags and the hashtags we have used to collect data are the following: #IS, #ISLAMICSTATE, #ILoveISIS, #AllEyesOnISIS, #CalamaityWillBeFallUS, #KhalifaRestored, #Islamicstate. The tweets where collected between 25th of June 2014 and 29th of August 2014. Some of the messages that were collected containing the hashtags mentioned above were not related to ISIS and they had no violent/radical message. For example, in some cases the #IS hashtag was not referring to the Islamic state but to the verb \"is\" (to be). In other cases, some of the hashtags were used since the tweets contained.\n\n A. Datasets\n\nAs mentioned in the previous section, we used three different datasets. We will label these datasets TW-PRO, TW-RAND and TW-CON (Table I).",
                    "score": 0.5506727345332291
                },
                {
                    "context": "TABLE I: The datasets used for the experiments\n\nThe data was preprocessed and re-tweets, annotations and urls were removed. The data was tokenized and lemmatized to obtain the base form of the words. In the process of lemmatizing the toolkit [17] was used.\n\n B. Features\n\nIn our experiments we have used three different classes of features:\n\n- stylometric features (S)\n- time based features (T)\n- sentiment based features (SB)\n\nThe stylometric features that we have used in this work are shown in Table II. The stylometric features also contain a set of the words that are the most frequent in the dataset. We have used 173 frequently used words where the 10 most frequently used words in the dataset are: state, islamic, not, do, kill, support, abu, allah, people, and al. Among the most common words we can notice words that are related to ISIS (state and islamic), verbs like kill and support as well as the word abu. The word abu refers to individuals who usually assume a nom de guerre starting with abu (father of) [name] by which various foreign fighters, martyrdom operatives, ideologues etc are introduced and made popular within the respective clusters; allah simply refers to \"God\" and the Arabic appellation is preferred by pro-ISIS clusters who generally adhere to Arabic dominated language sets; \"al\" is the Arabic article \"al\" (\"the\").",
                    "score": 0.34908615069198323
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What was the size of the dataset analyzed in the article?",
                    "answer": "The size of the dataset analyzed in the article is not specified in the provided information."
                },
                {
                    "question": "[SQ] What type of data was included in the dataset analyzed in the article?",
                    "answer": "The dataset analyzed in the article included tweets categorized into three types: pro-ISIS tweets, randomly collected tweets discussing various topics, and anti-ISIS tweets."
                },
                {
                    "question": "[SQ] How was the dataset collected or sourced for the analysis in the article?",
                    "answer": "The dataset was collected by gathering tweets containing hashtags related to jihadists, specifically focusing on ISIS. The collection targeted the English language spectrum of pro-ISIS clusters on Twitter, utilizing hashtags that also have corresponding Arabic versions. The tweets were collected between June 25, 2014, and August 29, 2014. However, it was noted that some tweets included in the dataset did not relate to ISIS or contained non-violent messages, as certain hashtags could refer to different contexts."
                },
                {
                    "question": "[SQ] What is the time frame of the data included in the dataset analyzed in the article?",
                    "answer": "The time frame of the data included in the dataset analyzed in the article is not specified in the provided information."
                },
                {
                    "question": "[MQ] What is the size of the dataset analyzed in the article, which includes tweets categorized as pro-ISIS, anti-ISIS, and randomly collected tweets discussing various topics?",
                    "answer": "The size of the dataset analyzed in the article is not specified in the provided information."
                },
                {
                    "question": "[SQ] What is the total number of tweets categorized as pro-ISIS in the dataset?",
                    "answer": "The total number of tweets categorized as pro-ISIS in the dataset is not specified in the provided information."
                },
                {
                    "question": "[SQ] How many tweets were categorized as anti-ISIS in the dataset?",
                    "answer": "The dataset includes a category labeled TW-CON, which consists of tweets from accounts that are against ISIS. However, the specific number of tweets categorized as anti-ISIS is not provided in the information available."
                },
                {
                    "question": "[SQ] What is the number of randomly collected tweets discussing various topics in the dataset?",
                    "answer": "The dataset contains randomly collected tweets discussing various topics under the name TW-RAND. However, the specific number of tweets in this dataset is not provided in the information."
                },
                {
                    "question": "[MQ] What is the size of the analyzed dataset that includes tweets categorized as pro-ISIS, anti-ISIS, and randomly collected tweets, given that specific numbers for each category are not provided?",
                    "answer": "The size of the analyzed dataset that includes tweets categorized as pro-ISIS, anti-ISIS, and randomly collected tweets is not specified in the provided information."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 0.892900793953267,
                "llm_context_precision_without_reference": 0, #NaN
                "llm_context_precision_with_reference": 0, #NaN
                "answer_relevancy": 0, #NaN
                "answer_correctness": 0, #NaN
            },
            "deepeval": {
                "contextual_precision": 1.0,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.029411764705882353,
                "answer_relevancy": 1.0,
                "faithfulness": 0.8333333333333334
            }
        },
    },
    {
        "id": 20,
        "job_id": 1,
        "file_id": 4,
        "question_id": 5,
        "status": "done",
        "answer_text": "The performance metrics evaluated in the study included the number of non-radical instances classified, the number of radical instances classified, the count of correctly classified instances, and the accuracy percentage of the classification. The corresponding values for each algorithm are as follows:\n\n1. **SVM**:\n   - Non Radical: 1155 (first table), 3099 (second table), 1974 (third table)\n   - Radical: 38 (first table), 92 (second table), 24 (third table)\n   - Correctly Classified Instances: 98.5% (first table), 97.9% (second table), 99.1% (third table)\n\n2. **Naive Bayes**:\n   - Non Radical: 1178 (first table), 2877 (second table), 1997 (third table)\n   - Radical: 15 (first table), 314 (second table), 1 (third table)\n   - Correctly Classified Instances: 96.8% (first table), 89.0% (second table), 99.9% (third table)\n\n3. **AdaBoost**:\n   - Non Radical: 1182 (first table), 1600 (second table), 1998 (third table)\n   - Radical: 11 (first table), 0 (second table), 0 (third table)\n   - Correctly Classified Instances: 99.5% (first table), 100% (second table), 100% (third table)",
        "answer_encoded": "[response not coded] The study evaluated performance metrics including the classification of non-radical and radical instances, with SVM achieving up to 99.1% accuracy, Naive Bayes up to 99.9%, and AdaBoost consistently at 100%.",
        "answer_contexts": [
                {
                    "context": "This table presents the performance metrics of different classification algorithms, including the number of non-radical and radical instances, the count of correctly classified instances, and their respective accuracy percentages.,\nwith the following table title:\nClassification Algorithm Performance Metrics,\nwith the following columns:\n- Non Radical: Number of non-radical instances classified.\n- Radical: Number of radical instances classified.\n- Correctly Classified Instances: Count of instances that were correctly classified.\n- : Accuracy percentage of the classification.\n- : Empty column.\n\n| Non Radical | Radical | Correctly Classified Instances |        |   |\n|---|---|---|---|---|\n| SVM         |1155|38| 98.5 % |   |\n| Naive Bayes |1178|15| 96.8 % |   |\n| AdaBoost    |1182|11| 99.5 % |   |",
                    "score": 0.817386533401221
                },
                {
                    "context": "This table presents the performance metrics of different classification algorithms, including the number of instances classified as non-radical and radical, along with the percentage of correctly classified instances.,\nwith the following columns:\n- Algorithm: The classification algorithms evaluated.\n- Non Radical: Number of instances classified as non-radical.\n- Radical: Number of instances classified as radical.\n- Correctly Classified Instances: Percentage of instances correctly classified by the algorithm.\n\n|             | Non Radical | Radical | Correctly Classified Instances |   |\n|---|---|---|---|---|\n| SVM         |3099|92| 97.9 %                         |   |\n| Naive Bayes |2877|314| 89.0 %                         |   |\n| AdaBoost    |1600|0| 100 %                          |   |",
                    "score": 0.8062709634254299
                },
                {
                    "context": "This table presents the performance of different classification algorithms, showing the number of instances classified as non-radical and radical, along with the accuracy of each algorithm.,\nwith the following table title:\nClassification Algorithm Performance,\nwith the following columns:\n- Non Radical: Number of instances classified as non-radical.\n- Radical: Number of instances classified as radical.\n- Correctly Classified Instances: Number of instances that were correctly classified.\n- : Accuracy percentage of the classification.\n\n| Non Radical | Radical | Correctly Classified Instances |        |\n|---|---|---|---|\n| SVM         |1974|24| 99.1 % |\n| Naive Bayes |1997|1| 99.9 % |\n| AdaBoost    |1998|0| 100 %  |",
                    "score": 0.7968177513469317
                },
                {
                    "context": "The results differed depending on what datasets we used. Using TW-PRO and TW-RAND led to better results than if TW-PRO and TW-CON were used. The results for TW-PRO and TW-RAND and the features (S + T + SB) are shown in Table IV. As can be noted AdaBoost performs very well with 100% accuracy on the test set.\n\n TABLE IV:\n\nResults for using the datasets TW-PRO and TW-CON are shown in Table V, the accuracy when using the AdaBoost classifier is still high (99.5%). Since the datasets that are used for the experiments in Table IV and Table V differ the results are expected. TW-RAND contain randomly selected tweets.",
                    "score": 0.7889493292804208
                },
                {
                    "context": "TABLE V: Results when using all features (S + T + SB) on TW-CON and TW-PRO.",
                    "score": 0.7854479398188398
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific performance metrics were evaluated in the study, and what were their corresponding values?",
                    "answer": "The performance metrics evaluated in the study included the number of non-radical instances classified, the number of radical instances classified, the count of correctly classified instances, and the accuracy percentage of the classification. The corresponding values for each algorithm are as follows:\n\n1. **SVM**:\n   - Non Radical: 1155 (first table), 3099 (second table), 1974 (third table)\n   - Radical: 38 (first table), 92 (second table), 24 (third table)\n   - Correctly Classified Instances: 98.5% (first table), 97.9% (second table), 99.1% (third table)\n\n2. **Naive Bayes**:\n   - Non Radical: 1178 (first table), 2877 (second table), 1997 (third table)\n   - Radical: 15 (first table), 314 (second table), 1 (third table)\n   - Correctly Classified Instances: 96.8% (first table), 89.0% (second table), 99.9% (third table)\n\n3. **AdaBoost**:\n   - Non Radical: 1182 (first table), 1600 (second table), 1998 (third table)\n   - Radical: 11 (first table), 0 (second table), 0 (third table)\n   - Correctly Classified Instances: 99.5% (first table), 100% (second table), 100% (third table)"
                },
                {
                    "question": "[SQ] What were the specific values for the accuracy percentage of each algorithm in the study?",
                    "answer": "The accuracy percentages for each algorithm in the study are as follows:\n\n- SVM: 98.5%, 97.9%, 99.1%\n- Naive Bayes: 96.8%, 89.0%, 99.9%\n- AdaBoost: 99.5%, 100%, 100%"
                },
                {
                    "question": "[SQ] How did the performance metrics differ between the first, second, and third tables for each algorithm?",
                    "answer": "The performance metrics for each algorithm varied across the three tables in terms of the number of non-radical and radical instances classified, as well as the accuracy percentages.\n\n1. **SVM**:\n   - First Table: 1155 non-radical, 38 radical, 98.5% accuracy.\n   - Second Table: 3099 non-radical, 92 radical, 97.9% accuracy.\n   - Third Table: 1974 non-radical, 24 radical, 99.1% accuracy.\n\n2. **Naive Bayes**:\n   - First Table: 1178 non-radical, 15 radical, 96.8% accuracy.\n   - Second Table: 2877 non-radical, 314 radical, 89.0% accuracy.\n   - Third Table: 1997 non-radical, 1 radical, 99.9% accuracy.\n\n3. **AdaBoost**:\n   - First Table: 1182 non-radical, 11 radical, 99.5% accuracy.\n   - Second Table: 1600 non-radical, 0 radical, 100% accuracy.\n   - Third Table: 1998 non-radical, 0 radical, 100% accuracy.\n\nOverall, the accuracy percentages varied, with AdaBoost consistently achieving high accuracy across all tables, while Naive Bayes showed a significant drop in the second table. SVM's performance fluctuated, with the highest accuracy in the third table. The number of instances classified also differed significantly among the tables."
                },
                {
                    "question": "[SQ] What additional performance metrics, if any, were considered in the study beyond those already mentioned?",
                    "answer": "No additional performance metrics beyond those already mentioned were considered in the study. The focus was solely on the number of non-radical and radical instances, the count of correctly classified instances, and the accuracy percentages of the classification algorithms."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 0, #NaN
                "faithfulness": 0, #NaN
                "semantic_similarity": 0.8672424059602921,
                "llm_context_precision_without_reference": 0.8333333332916666,
                "llm_context_precision_with_reference": 0.7555555555303703,
                "answer_relevancy": 0.8874879465651438,
                "answer_correctness": 0.21682838591533193
            },
            "deepeval": {
                "contextual_precision": 1.0,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.20408163265306123,
                "answer_relevancy": 0.8823529411764706,
                "faithfulness": 0.8125
            }
        }
    },
        {
        "id": 21,
        "job_id": 1,
        "file_id": 5,
        "question_id": 1,
        "status": "done",
        "answer_text": "The study utilized a best-first search algorithm as the specific AI approach. This algorithm contributes to the overall findings by enabling the focused crawler to efficiently explore and identify relevant YouTube user profiles that promote hate and extremism. By prioritizing nodes based on their similarity scores with training profiles, the algorithm allows for a systematic traversal of the user network, ensuring that the most promising candidates are examined first. This method enhances the accuracy of identifying malicious content and users, ultimately demonstrating the effectiveness of the proposed approach in combating online radicalization.",
        "answer_encoded": "Best-first Search",
        "answer_contexts": [
                {
                    "context": "3. PERFORMANCE EVALUATION\n\nThe crawler requires exemplary documents or training examples to learn the specific characteristics and properties of documents in the training dataset. A statistical model (text classifier) needs to be built from a collection of documents pertaining to a predefined topic. We create a list of 35 user-ids used as training profiles. The 35 user ids consists of 612 videos and hence the training is performed on 612 videos. We obtain the training dataset by manually searching (keyword based) for anti-India hate and extremism promoting channels using YouTube search and traversing related video links (using the heuristic that videos on similar topic will be connected as relevant on YouTube). We select 10 random positive class (hate and extremist) channels for creating test dataset. Each user works as a seed input to the focused crawler. To evaluate the effectiveness of our solution approach we execute our focused crawler several times for various configurations and seed. Table 1 shows the confusion matrix for binary classification performed during Best-First Search approach. Given the input of 10 seed users and 6 modes (pair of threshold and n-gram values) we get different number of connected users in each iteration. To measure the accuracy of our proposed approach we collect results of all 60 iterations and classify 1046 (921 + 125) users as relevant and 381 (314 + 67) as irrelevant users. There is a misclassification of 25.42% and 65.10% in predicting the relevant and irrelevant users respectively.",
                    "score": 0.8087065253641741
                },
                {
                    "context": "A Focused Crawler for Mining Hate and Extremism\n\n Promoting Videos on YouTube\n\n Swati Agarwal, Ashish Sureka\n\n Indraprastha Institute of Information Technology, Delhi (IIIT-D)\n\n New Delhi, India\n\n swatia@iiitd.ac.in, ashish@iiitd.ac.in\n\n ABSTRACT\n\nOnline video sharing platforms such as YouTube contains several videos and users promoting hate and extremism. Due to low barrier to publication and anonymity, YouTube is misused as a platform by some users and communities to post negative videos disseminating hatred against a particular religion, country or person. We formulate the problem of identification of such malicious videos as a search problem and present a focused-crawler based approach consisting of various components performing several tasks: search strategy or algorithm, node similarity computation metric, learning from exemplary profiles serving as training data, stopping criterion, node classifier and queue manager. We implement a best-first search algorithm and conduct experiments to measure the accuracy of the proposed approach. Experimental results demonstrate that the proposed approach is effective.\n\n Categories and Subject Descriptors\n\nH.5.4 [Hypertext/Hypermedia]: Navigation; K.4.2 [Social Issues]: Abuse and crime involving computers; D.2.8 [Metrics]: Performance measures; H.3.1 [Content Analysis and Indexing]: Linguistic processing\n\n Keywords\n\nSocial Media Analytics; Focused Crawler; Hate and Extremism Detection; Video Sharing Website; Online Radicalization.\n\n 1. RESEARCH MOTIVATION AND AIM\n\nResearch shows that YouTube has become a convenient platform for many hate and extremist groups to share information and promote their ideologies. The reason is because video is the most usable medium to share views with others [1]. Previous studies show that extremist groups put forth hateful speech, offensive comments and messages focusing their mission [3]. Social networking allows these users to facilitate recruitment, gradually reaching world wide viewers, connecting to other hate promoting groups, spreading extremist content and forming their communities sharing a common agenda [2] [6]. The presence of such extremist content in large amount is a major concern for YouTube moderators (to uphold the reputation of the website), government and law enforcement agencies (identifying extremist content and user communities to stop such promotion in country). However, despite several community guidelines and administrative efforts made by YouTube, it has become a repository of large amounts of malicious and offensive videos [5]. Detecting such hate promoting videos and users is a significant and technically challenging problem. 100 hours of videos are uploaded every minute, that makes YouTube a very dynamic website. Hence, locating such users by keyword based search is overwhelmingly impractical. The work presented in this paper is motivated by the need of a solution to combat and counter online radicalization. We frame our problem as: identifying such videos promoting hate and extremism on YouTube. The research aim of the work presented in this paper is to investigate the application of a focused crawler (best-first search) based approach for retrieving YouTube user-profiles promoting hate and extremism. To investigate the effectiveness of contextual features such as the title of the videos uploaded, commented, shared, and favourited for computing the similarity between nodes in the focused crawler traversal and to examine the effectiveness of subscribers, featured channels and public contacts as links between nodes.\n\n 2. BEST-FIRST SEARCH CRAWLER\n\nThe proposed method is a multi-step process primarily consists of three phases, Training Profile Collection, Statistical Model Building and Focused Crawler. We perform a manual analysis and a visual inspection of activity feeds and contextual metadata of various YouTube channels. We collect 35 positive class channels (promoting hate and extremism) used as training profiles. We build our training dataset by extracting the discriminatory features (user activity feeds such as titles of videos uploaded, shared, favourited & commented by the user and profile information) of these 35 channels using YouTube API¹. We build a statistical model from these training profiles by applying character n-gram based language modeling approach. We build a focused crawler (best-first search) which is a recursive process.\n\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage, and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). Copyright is held by the author/owner(s).\n\nHT’14, September 1–4, 2014, Santiago, Chile.\n\nACM 978-1-4503-2954-5/14/09.\n\nhttp://dx.doi.org/10.1145/2631775.2631776.",
                    "score": 0.7917669221964375
                },
                {
                    "context": "Algorithm 1: Focused Crawler- Best First Search\n\nData: Seed User U, Width of Graph w, Size of Graph s, Threshold th, N-gram N g, Positive ResultClass Channels Up\n\n1. forall : A connected directed cyclic graph, Nodes=User u\n- u ∈ Up do\n2. end D.add(ExtractFeatures(u))\n3. Algorithm BFS(U)\n4. while graphsize < s do\n- userfeeds Uf ← ExtractFeatures(U)\n- scorescore ← LanguageModeling(D, Uf, Ng)\n- if (score < th) then\n- U.class ← Irrelevant\n- else U.class ← Relevant\n- end Hashmap Usorted.InsertionSort(U, score)\n- for i ← 1 to w do\n- end Hashmap Ugraph.add(Usorted(i))\n- for all Ug ∈ Ugraph do\n- f r = Extract F rontiers(Ug)\n- end Hashmap Ucrawler.add(f r)\n- forall Uf r ∈ Ucrawler do\n- end end BFS(Uf r)\n\n Algorithm 2: Frontier Extraction for a YouTube User\n\nData: User u\n\nResult: Frontiers of a channel\n\n1. Algorithm Extract_F rontiers(U)\n2. usubs ← u.getSubscribers()\n3. uf c ← u.getFeaturedChannels()\n4. ucon ← u.getFriends()\n\nIt takes one YouTube channel as a seed (a positive class channel) and extract its contextual metadata (user activity feeds and profile information) using YouTube API. We find the extent of textual similarity between these metadata and training data by using statistical model (build in phase 2) and LingPipe API. We implement a binary classifier to classify a user channel as relevant or irrelevant. A user channel is said to be relevant (hate and extremism promoting channel) if the computation score is above a predefined threshold. If a channel is relevant, then we further extend its frontiers (links to other YouTube channels) i.e. the subscribers of the channel, featured channels suggested by the user and its contacts available publicly. We extract these frontiers by parsing users’ YouTube homepage using jsoup HTML parser library. We execute focused crawler phase for each frontier recursively which results a connected graph, where nodes represent the user channels and edges represent the links between two users.\n\nInputs to the algorithm is a seed (a positive class user), width of graph w i.e. maximum number of children of a node, size of graph s i.e. maximum number of nodes in graph, threshold th for classification, n-gram value N g for similarity computation (language modeling), and a lexicon of 35 positive class channels Uₚ. We compare each training profile with all profiles and compute their similarity score for each mode. We take an average of these 35 scores and compute the threshold values. The proposed method (Algorithm 1) follows the standard best-first traversing to explore relevant user to seed input. Best-First Search examines a node in the graph and finds the most promising node among its children to be traversed next. This priority of nodes (users) is decided based upon the extent of similarity with the training profiles. A user with the similarity score above a specified threshold is said to be relevant and allowed to be extended further. If a node is relevant and has the highest priority (similarity score) among all relevant nodes then we extend it first and explore its links and discard irrelevant nodes. We process each node only once and if a node appears again then we only include the connecting edge in the graph. Steps 1 and 2 extract all contextual features for 35 training profiles using a feature extraction algorithm and build a training data set. Steps 4 and 5 extract all features for seed user U and compute its similarity score with training profiles using character n-gram and language modeling. Steps 6 to 8 represent the classification procedure and labeling of users as relevant or irrelevant depending upon the threshold measures.\n\nBFS method has non-binary priority values assigned to each node. The priority values are the similarity score, which is computed by comparing the users’ contextual metadata (user activity feeds and profile information) with training profiles. Steps 9 and 10 make a list of top w (maximum number of children, a node can have) users among relevant users based upon their similarity score, sorted in a decreasing order. Steps 11 − 13 extracts frontiers of a user channel using Algorithm 2. Steps 14 and 15 repeat Steps 3 − 13 for each frontier extracted. We execute this function till we get a graph with desired number of nodes or there is no more node is left to extend.\n\n Table 1: Best-First Search Confusion Matrix",
                    "score": 0.7835627031301315
                },
                {
                    "context": "REFERENCES\n\n[1] Hsinchun Chen, Dorothy Denning, Nancy Roberts, Catherine A. Larson, Ximing Yu, and Chunneng Huang. The dark web forum portal: From multi-lingual to video. In ISI, pages 7–14. IEEE, 2011.\n\n[2] Maura Conway and Lisa McInerney. Jihadi video and auto-radicalisation: Evidence from an exploratory youtube study. In Daniel Ortiz-Arroyo, Henrik Legind Larsen, Daniel Dajun Zeng, David Hicks, and Gerhard Wagner, editors, Intelligence and Security Informatics, volume 5376 of Lecture Notes in Computer Science, pages 108–118. Springer Berlin Heidelberg, 2008.\n\n[3] Lacy G McNamee, Brittany L Peterson, and Jorge Pe˜na. A call to educate, participate, invoke and indict: Understanding the communication of online hate groups. Communication Monographs, 77(2):257–280, 2010.\n\n[4] S. Rawat and D.R. Patil. Efficient focused crawling based on best first search. In Advance Computing Conference (IACC), 2013 IEEE 3rd International, pages 908–911, Feb 2013.\n\n[5] Ashish Sureka, Ponnurangam Kumaraguru, Atul Goyal, and Sidharth Chhabra. Mining youtube to discover extremist videos, users and hidden communities. In Pu-Jen Cheng, Min-Yen Kan, Wai Lam, and Preslav Nakov, editors, Information Retrieval Technology, volume 6458 of Lecture Notes in Computer Science, pages 13–24. Springer Berlin Heidelberg, 2010.\n\n[6] Yilu Zhou, Edna Reid, Jialun Qin, Hsinchun Chen, and Guanpi Lai. Us domestic extremist groups on the web: link and content analysis. Intelligent Systems, IEEE, 20(5):44–51, 2005.",
                    "score": 0.7659809964545277
                },
                {
                    "context": "This table presents the counts of predicted relevant and irrelevant items, along with their actual classifications.,\nwith the following columns:\n- Predicted: Counts of items predicted as relevant or irrelevant.\n- Actual: Counts of items that are actually relevant or irrelevant.\n\n|            | Predicted |     |\n|---|---|---|\n| Relevant   |921|314|\n| Irrelevant |125|67|",
                    "score": 0.760450129102513
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific AI algorithm was utilized in the study, and how does it contribute to the overall findings presented in the article?",
                    "answer": "The study utilized a best-first search algorithm as the specific AI approach. This algorithm contributes to the overall findings by enabling the focused crawler to efficiently explore and identify relevant YouTube user profiles that promote hate and extremism. By prioritizing nodes based on their similarity scores with training profiles, the algorithm allows for a systematic traversal of the user network, ensuring that the most promising candidates are examined first. This method enhances the accuracy of identifying malicious content and users, ultimately demonstrating the effectiveness of the proposed approach in combating online radicalization."
                },
                {
                    "question": "[SQ] What are the key features of the best-first search algorithm used in the study?",
                    "answer": "The best-first search algorithm in the study incorporates several key features:\n\n1. **Node Similarity Computation**: It utilizes a similarity score based on the comparison of users' contextual metadata with training profiles, which helps in determining the relevance of nodes.\n\n2. **Priority Values**: Each node is assigned a non-binary priority value, which is the similarity score. This score dictates the order in which nodes are explored, with higher scores indicating more promising nodes.\n\n3. **Graph Traversal**: The algorithm follows a recursive process to explore user channels, allowing for the extension of frontiers based on relevant nodes identified during traversal.\n\n4. **Classification**: Nodes are classified as relevant or irrelevant based on a predefined threshold, allowing the algorithm to focus on those that meet the criteria for further exploration.\n\n5. **Controlled Expansion**: The algorithm limits the number of children (width of the graph) and the total number of nodes (size of the graph) to manage the exploration effectively.\n\n6. **Single Processing of Nodes**: Each node is processed only once to avoid redundancy, and if a node reappears, only the connecting edge is included in the graph.\n\n7. **Frontier Extraction**: It extracts frontiers from relevant nodes, which include subscribers, featured channels, and public contacts, facilitating further exploration of related user channels.\n\nThese features collectively enhance the algorithm's ability to efficiently identify and explore user channels promoting hate and extremism on platforms like YouTube."
                },
                {
                    "question": "[SQ] How does the algorithm's prioritization of nodes impact the efficiency of the crawler?",
                    "answer": "The algorithm's prioritization of nodes significantly enhances the efficiency of the crawler by ensuring that it explores the most promising user channels first. By assigning non-binary priority values based on the similarity scores calculated from the contextual metadata of users, the crawler can focus on those nodes that are more likely to be relevant to the predefined topic of hate and extremism. This targeted approach minimizes unnecessary exploration of irrelevant nodes, allowing the crawler to build a connected graph more quickly and effectively. As a result, the algorithm can achieve a higher accuracy in identifying relevant users while reducing the overall time and resources spent on the crawling process."
                },
                {
                    "question": "[SQ] What metrics were used to evaluate the effectiveness of the AI algorithm in identifying hate and extremism?",
                    "answer": "The effectiveness of the AI algorithm in identifying hate and extremism was evaluated using a confusion matrix for binary classification, which included metrics such as the number of relevant and irrelevant users predicted by the model. Specifically, the results indicated a misclassification rate of 25.42% for predicting relevant users and 65.10% for predicting irrelevant users. Additionally, the total counts of classified users were 1046 as relevant and 381 as irrelevant, which contributed to measuring the accuracy of the proposed approach."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 1.0,
                "llm_context_precision_without_reference": 0.999999999975,
                "llm_context_precision_with_reference": 0.999999999975,
                "answer_relevancy": 0.855069074118429,
                "answer_correctness": 1.0
            },
            "deepeval": {
                "contextual_precision": 1.0,
                "contextual_recall": 0.8,
                "contextual_relevancy": 0.2857142857142857,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 22,
        "job_id": 1,
        "file_id": 5,
        "question_id": 2,
        "status": "done",
        "answer_text": "The analysis in the study focused on various contextual features derived from user activity feeds and profile information on YouTube. Specifically, the features included the titles of videos uploaded, shared, favorited, and commented on by users, as well as the profile information of the channels. These features were justified as they are critical for computing the similarity between nodes during the focused crawler's traversal. The aim was to identify channels promoting hate and extremism, and these features were essential for building a statistical model that could effectively classify users as relevant or irrelevant based on their activity and content.",
        "answer_encoded": "[response not coded] The selected features for the analysis included video titles uploaded, shared, favorited, and commented on by users, along with channel profile information, to compute node similarity and classify users related to hate and extremism.",
        "answer_contexts": [
                {
                    "context": "3. PERFORMANCE EVALUATION\n\nThe crawler requires exemplary documents or training examples to learn the specific characteristics and properties of documents in the training dataset. A statistical model (text classifier) needs to be built from a collection of documents pertaining to a predefined topic. We create a list of 35 user-ids used as training profiles. The 35 user ids consists of 612 videos and hence the training is performed on 612 videos. We obtain the training dataset by manually searching (keyword based) for anti-India hate and extremism promoting channels using YouTube search and traversing related video links (using the heuristic that videos on similar topic will be connected as relevant on YouTube). We select 10 random positive class (hate and extremist) channels for creating test dataset. Each user works as a seed input to the focused crawler. To evaluate the effectiveness of our solution approach we execute our focused crawler several times for various configurations and seed. Table 1 shows the confusion matrix for binary classification performed during Best-First Search approach. Given the input of 10 seed users and 6 modes (pair of threshold and n-gram values) we get different number of connected users in each iteration. To measure the accuracy of our proposed approach we collect results of all 60 iterations and classify 1046 (921 + 125) users as relevant and 381 (314 + 67) as irrelevant users. There is a misclassification of 25.42% and 65.10% in predicting the relevant and irrelevant users respectively.",
                    "score": 0.7910436882268022
                },
                {
                    "context": "This table presents the counts of predicted relevant and irrelevant items, along with their actual classifications.,\nwith the following columns:\n- Predicted: Counts of items predicted as relevant or irrelevant.\n- Actual: Counts of items that are actually relevant or irrelevant.\n\n|            | Predicted |     |\n|---|---|---|\n| Relevant   |921|314|\n| Irrelevant |125|67|",
                    "score": 0.7768830232721609
                },
                {
                    "context": "Algorithm 1: Focused Crawler- Best First Search\n\nData: Seed User U, Width of Graph w, Size of Graph s, Threshold th, N-gram N g, Positive ResultClass Channels Up\n\n1. forall : A connected directed cyclic graph, Nodes=User u\n- u ∈ Up do\n2. end D.add(ExtractFeatures(u))\n3. Algorithm BFS(U)\n4. while graphsize < s do\n- userfeeds Uf ← ExtractFeatures(U)\n- scorescore ← LanguageModeling(D, Uf, Ng)\n- if (score < th) then\n- U.class ← Irrelevant\n- else U.class ← Relevant\n- end Hashmap Usorted.InsertionSort(U, score)\n- for i ← 1 to w do\n- end Hashmap Ugraph.add(Usorted(i))\n- for all Ug ∈ Ugraph do\n- f r = Extract F rontiers(Ug)\n- end Hashmap Ucrawler.add(f r)\n- forall Uf r ∈ Ucrawler do\n- end end BFS(Uf r)\n\n Algorithm 2: Frontier Extraction for a YouTube User\n\nData: User u\n\nResult: Frontiers of a channel\n\n1. Algorithm Extract_F rontiers(U)\n2. usubs ← u.getSubscribers()\n3. uf c ← u.getFeaturedChannels()\n4. ucon ← u.getFriends()\n\nIt takes one YouTube channel as a seed (a positive class channel) and extract its contextual metadata (user activity feeds and profile information) using YouTube API. We find the extent of textual similarity between these metadata and training data by using statistical model (build in phase 2) and LingPipe API. We implement a binary classifier to classify a user channel as relevant or irrelevant. A user channel is said to be relevant (hate and extremism promoting channel) if the computation score is above a predefined threshold. If a channel is relevant, then we further extend its frontiers (links to other YouTube channels) i.e. the subscribers of the channel, featured channels suggested by the user and its contacts available publicly. We extract these frontiers by parsing users’ YouTube homepage using jsoup HTML parser library. We execute focused crawler phase for each frontier recursively which results a connected graph, where nodes represent the user channels and edges represent the links between two users.\n\nInputs to the algorithm is a seed (a positive class user), width of graph w i.e. maximum number of children of a node, size of graph s i.e. maximum number of nodes in graph, threshold th for classification, n-gram value N g for similarity computation (language modeling), and a lexicon of 35 positive class channels Uₚ. We compare each training profile with all profiles and compute their similarity score for each mode. We take an average of these 35 scores and compute the threshold values. The proposed method (Algorithm 1) follows the standard best-first traversing to explore relevant user to seed input. Best-First Search examines a node in the graph and finds the most promising node among its children to be traversed next. This priority of nodes (users) is decided based upon the extent of similarity with the training profiles. A user with the similarity score above a specified threshold is said to be relevant and allowed to be extended further. If a node is relevant and has the highest priority (similarity score) among all relevant nodes then we extend it first and explore its links and discard irrelevant nodes. We process each node only once and if a node appears again then we only include the connecting edge in the graph. Steps 1 and 2 extract all contextual features for 35 training profiles using a feature extraction algorithm and build a training data set. Steps 4 and 5 extract all features for seed user U and compute its similarity score with training profiles using character n-gram and language modeling. Steps 6 to 8 represent the classification procedure and labeling of users as relevant or irrelevant depending upon the threshold measures.\n\nBFS method has non-binary priority values assigned to each node. The priority values are the similarity score, which is computed by comparing the users’ contextual metadata (user activity feeds and profile information) with training profiles. Steps 9 and 10 make a list of top w (maximum number of children, a node can have) users among relevant users based upon their similarity score, sorted in a decreasing order. Steps 11 − 13 extracts frontiers of a user channel using Algorithm 2. Steps 14 and 15 repeat Steps 3 − 13 for each frontier extracted. We execute this function till we get a graph with desired number of nodes or there is no more node is left to extend.\n\n Table 1: Best-First Search Confusion Matrix",
                    "score": 0.7551080337254028
                },
                {
                    "context": "A Focused Crawler for Mining Hate and Extremism\n\n Promoting Videos on YouTube\n\n Swati Agarwal, Ashish Sureka\n\n Indraprastha Institute of Information Technology, Delhi (IIIT-D)\n\n New Delhi, India\n\n swatia@iiitd.ac.in, ashish@iiitd.ac.in\n\n ABSTRACT\n\nOnline video sharing platforms such as YouTube contains several videos and users promoting hate and extremism. Due to low barrier to publication and anonymity, YouTube is misused as a platform by some users and communities to post negative videos disseminating hatred against a particular religion, country or person. We formulate the problem of identification of such malicious videos as a search problem and present a focused-crawler based approach consisting of various components performing several tasks: search strategy or algorithm, node similarity computation metric, learning from exemplary profiles serving as training data, stopping criterion, node classifier and queue manager. We implement a best-first search algorithm and conduct experiments to measure the accuracy of the proposed approach. Experimental results demonstrate that the proposed approach is effective.\n\n Categories and Subject Descriptors\n\nH.5.4 [Hypertext/Hypermedia]: Navigation; K.4.2 [Social Issues]: Abuse and crime involving computers; D.2.8 [Metrics]: Performance measures; H.3.1 [Content Analysis and Indexing]: Linguistic processing\n\n Keywords\n\nSocial Media Analytics; Focused Crawler; Hate and Extremism Detection; Video Sharing Website; Online Radicalization.\n\n 1. RESEARCH MOTIVATION AND AIM\n\nResearch shows that YouTube has become a convenient platform for many hate and extremist groups to share information and promote their ideologies. The reason is because video is the most usable medium to share views with others [1]. Previous studies show that extremist groups put forth hateful speech, offensive comments and messages focusing their mission [3]. Social networking allows these users to facilitate recruitment, gradually reaching world wide viewers, connecting to other hate promoting groups, spreading extremist content and forming their communities sharing a common agenda [2] [6]. The presence of such extremist content in large amount is a major concern for YouTube moderators (to uphold the reputation of the website), government and law enforcement agencies (identifying extremist content and user communities to stop such promotion in country). However, despite several community guidelines and administrative efforts made by YouTube, it has become a repository of large amounts of malicious and offensive videos [5]. Detecting such hate promoting videos and users is a significant and technically challenging problem. 100 hours of videos are uploaded every minute, that makes YouTube a very dynamic website. Hence, locating such users by keyword based search is overwhelmingly impractical. The work presented in this paper is motivated by the need of a solution to combat and counter online radicalization. We frame our problem as: identifying such videos promoting hate and extremism on YouTube. The research aim of the work presented in this paper is to investigate the application of a focused crawler (best-first search) based approach for retrieving YouTube user-profiles promoting hate and extremism. To investigate the effectiveness of contextual features such as the title of the videos uploaded, commented, shared, and favourited for computing the similarity between nodes in the focused crawler traversal and to examine the effectiveness of subscribers, featured channels and public contacts as links between nodes.\n\n 2. BEST-FIRST SEARCH CRAWLER\n\nThe proposed method is a multi-step process primarily consists of three phases, Training Profile Collection, Statistical Model Building and Focused Crawler. We perform a manual analysis and a visual inspection of activity feeds and contextual metadata of various YouTube channels. We collect 35 positive class channels (promoting hate and extremism) used as training profiles. We build our training dataset by extracting the discriminatory features (user activity feeds such as titles of videos uploaded, shared, favourited & commented by the user and profile information) of these 35 channels using YouTube API¹. We build a statistical model from these training profiles by applying character n-gram based language modeling approach. We build a focused crawler (best-first search) which is a recursive process.\n\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage, and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). Copyright is held by the author/owner(s).\n\nHT’14, September 1–4, 2014, Santiago, Chile.\n\nACM 978-1-4503-2954-5/14/09.\n\nhttp://dx.doi.org/10.1145/2631775.2631776.",
                    "score": 0.7474141063755256
                },
                {
                    "context": "REFERENCES\n\n[1] Hsinchun Chen, Dorothy Denning, Nancy Roberts, Catherine A. Larson, Ximing Yu, and Chunneng Huang. The dark web forum portal: From multi-lingual to video. In ISI, pages 7–14. IEEE, 2011.\n\n[2] Maura Conway and Lisa McInerney. Jihadi video and auto-radicalisation: Evidence from an exploratory youtube study. In Daniel Ortiz-Arroyo, Henrik Legind Larsen, Daniel Dajun Zeng, David Hicks, and Gerhard Wagner, editors, Intelligence and Security Informatics, volume 5376 of Lecture Notes in Computer Science, pages 108–118. Springer Berlin Heidelberg, 2008.\n\n[3] Lacy G McNamee, Brittany L Peterson, and Jorge Pe˜na. A call to educate, participate, invoke and indict: Understanding the communication of online hate groups. Communication Monographs, 77(2):257–280, 2010.\n\n[4] S. Rawat and D.R. Patil. Efficient focused crawling based on best first search. In Advance Computing Conference (IACC), 2013 IEEE 3rd International, pages 908–911, Feb 2013.\n\n[5] Ashish Sureka, Ponnurangam Kumaraguru, Atul Goyal, and Sidharth Chhabra. Mining youtube to discover extremist videos, users and hidden communities. In Pu-Jen Cheng, Min-Yen Kan, Wai Lam, and Preslav Nakov, editors, Information Retrieval Technology, volume 6458 of Lecture Notes in Computer Science, pages 13–24. Springer Berlin Heidelberg, 2010.\n\n[6] Yilu Zhou, Edna Reid, Jialun Qin, Hsinchun Chen, and Guanpi Lai. Us domestic extremist groups on the web: link and content analysis. Intelligent Systems, IEEE, 20(5):44–51, 2005.",
                    "score": 0.741532893843841
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific features or characteristics were selected for analysis in the study, and how were they justified in the context of the research objectives?",
                    "answer": "The analysis in the study focused on various contextual features derived from user activity feeds and profile information on YouTube. Specifically, the features included the titles of videos uploaded, shared, favorited, and commented on by users, as well as the profile information of the channels. These features were justified in the context of the research objectives as they are critical for computing the similarity between nodes during the focused crawler's traversal. The aim was to identify channels promoting hate and extremism, and these features were essential for building a statistical model that could effectively classify users as relevant or irrelevant based on their activity and content."
                },
                {
                    "question": "[SQ] What criteria were used to select the specific features for analysis in the study?",
                    "answer": "The specific features for analysis in the study were selected based on a manual analysis and visual inspection of activity feeds and contextual metadata from various YouTube channels. The features included user activity feeds such as the titles of videos uploaded, shared, favorited, and commented on by the user, as well as profile information. These features were extracted from 35 positive class channels that promote hate and extremism, which served as training profiles for building the statistical model."
                },
                {
                    "question": "[SQ] How do the selected features contribute to the effectiveness of the statistical model in classifying users?",
                    "answer": "The selected features, which include user activity feeds such as titles of videos uploaded, shared, favorited, and commented on, along with profile information, play a crucial role in the effectiveness of the statistical model for classifying users. By extracting these contextual metadata elements, the model can compute similarity scores between user profiles and the training dataset. This allows for a more nuanced understanding of user behavior and content preferences, which is essential for accurately identifying relevant (hate and extremism promoting) and irrelevant users.\n\nThe use of character n-gram based language modeling further enhances the model's ability to capture linguistic patterns and characteristics specific to the targeted content. This statistical approach enables the model to differentiate between users based on their engagement with hate-promoting material, thereby improving classification accuracy. The combination of these features ensures that the model is well-equipped to recognize and classify users effectively, leading to a more reliable identification of extremist content on the platform."
                },
                {
                    "question": "[SQ] Were there any alternative features considered for analysis, and if so, why were they not included?",
                    "answer": "The analysis focused on extracting specific contextual features such as user activity feeds, including titles of videos uploaded, shared, favorited, and commented by users, as well as profile information. While other features may have been considered, the emphasis was placed on these particular features due to their relevance in distinguishing hate and extremism promoting channels. The decision to exclude alternative features likely stemmed from the need to streamline the model and enhance its effectiveness in identifying the targeted content."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 1.0,
                "semantic_similarity": 0.8335598537932186,
                "llm_context_precision_without_reference": 0.8041666666465626,
                "llm_context_precision_with_reference": 0.4777777777618519,
                "answer_relevancy": 0.8432068327107612,
                "answer_correctness": 0.291723296781638
            },
            "deepeval": {
                "contextual_precision": 1.0,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.024390243902439025,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 23,
        "job_id": 1,
        "file_id": 5,
        "question_id": 3,
        "status": "done",
        "answer_text": "The platform utilized for data collection in the analyzed article is YouTube.",
        "answer_encoded": "YouTube",
        "answer_contexts": [
                {
                    "context": "REFERENCES\n\n[1] Hsinchun Chen, Dorothy Denning, Nancy Roberts, Catherine A. Larson, Ximing Yu, and Chunneng Huang. The dark web forum portal: From multi-lingual to video. In ISI, pages 7–14. IEEE, 2011.\n\n[2] Maura Conway and Lisa McInerney. Jihadi video and auto-radicalisation: Evidence from an exploratory youtube study. In Daniel Ortiz-Arroyo, Henrik Legind Larsen, Daniel Dajun Zeng, David Hicks, and Gerhard Wagner, editors, Intelligence and Security Informatics, volume 5376 of Lecture Notes in Computer Science, pages 108–118. Springer Berlin Heidelberg, 2008.\n\n[3] Lacy G McNamee, Brittany L Peterson, and Jorge Pe˜na. A call to educate, participate, invoke and indict: Understanding the communication of online hate groups. Communication Monographs, 77(2):257–280, 2010.\n\n[4] S. Rawat and D.R. Patil. Efficient focused crawling based on best first search. In Advance Computing Conference (IACC), 2013 IEEE 3rd International, pages 908–911, Feb 2013.\n\n[5] Ashish Sureka, Ponnurangam Kumaraguru, Atul Goyal, and Sidharth Chhabra. Mining youtube to discover extremist videos, users and hidden communities. In Pu-Jen Cheng, Min-Yen Kan, Wai Lam, and Preslav Nakov, editors, Information Retrieval Technology, volume 6458 of Lecture Notes in Computer Science, pages 13–24. Springer Berlin Heidelberg, 2010.\n\n[6] Yilu Zhou, Edna Reid, Jialun Qin, Hsinchun Chen, and Guanpi Lai. Us domestic extremist groups on the web: link and content analysis. Intelligent Systems, IEEE, 20(5):44–51, 2005.",
                    "score": 0.8171214025207045
                },
                {
                    "context": "3. PERFORMANCE EVALUATION\n\nThe crawler requires exemplary documents or training examples to learn the specific characteristics and properties of documents in the training dataset. A statistical model (text classifier) needs to be built from a collection of documents pertaining to a predefined topic. We create a list of 35 user-ids used as training profiles. The 35 user ids consists of 612 videos and hence the training is performed on 612 videos. We obtain the training dataset by manually searching (keyword based) for anti-India hate and extremism promoting channels using YouTube search and traversing related video links (using the heuristic that videos on similar topic will be connected as relevant on YouTube). We select 10 random positive class (hate and extremist) channels for creating test dataset. Each user works as a seed input to the focused crawler. To evaluate the effectiveness of our solution approach we execute our focused crawler several times for various configurations and seed. Table 1 shows the confusion matrix for binary classification performed during Best-First Search approach. Given the input of 10 seed users and 6 modes (pair of threshold and n-gram values) we get different number of connected users in each iteration. To measure the accuracy of our proposed approach we collect results of all 60 iterations and classify 1046 (921 + 125) users as relevant and 381 (314 + 67) as irrelevant users. There is a misclassification of 25.42% and 65.10% in predicting the relevant and irrelevant users respectively.",
                    "score": 0.8151086735884526
                },
                {
                    "context": "A Focused Crawler for Mining Hate and Extremism\n\n Promoting Videos on YouTube\n\n Swati Agarwal, Ashish Sureka\n\n Indraprastha Institute of Information Technology, Delhi (IIIT-D)\n\n New Delhi, India\n\n swatia@iiitd.ac.in, ashish@iiitd.ac.in\n\n ABSTRACT\n\nOnline video sharing platforms such as YouTube contains several videos and users promoting hate and extremism. Due to low barrier to publication and anonymity, YouTube is misused as a platform by some users and communities to post negative videos disseminating hatred against a particular religion, country or person. We formulate the problem of identification of such malicious videos as a search problem and present a focused-crawler based approach consisting of various components performing several tasks: search strategy or algorithm, node similarity computation metric, learning from exemplary profiles serving as training data, stopping criterion, node classifier and queue manager. We implement a best-first search algorithm and conduct experiments to measure the accuracy of the proposed approach. Experimental results demonstrate that the proposed approach is effective.\n\n Categories and Subject Descriptors\n\nH.5.4 [Hypertext/Hypermedia]: Navigation; K.4.2 [Social Issues]: Abuse and crime involving computers; D.2.8 [Metrics]: Performance measures; H.3.1 [Content Analysis and Indexing]: Linguistic processing\n\n Keywords\n\nSocial Media Analytics; Focused Crawler; Hate and Extremism Detection; Video Sharing Website; Online Radicalization.\n\n 1. RESEARCH MOTIVATION AND AIM\n\nResearch shows that YouTube has become a convenient platform for many hate and extremist groups to share information and promote their ideologies. The reason is because video is the most usable medium to share views with others [1]. Previous studies show that extremist groups put forth hateful speech, offensive comments and messages focusing their mission [3]. Social networking allows these users to facilitate recruitment, gradually reaching world wide viewers, connecting to other hate promoting groups, spreading extremist content and forming their communities sharing a common agenda [2] [6]. The presence of such extremist content in large amount is a major concern for YouTube moderators (to uphold the reputation of the website), government and law enforcement agencies (identifying extremist content and user communities to stop such promotion in country). However, despite several community guidelines and administrative efforts made by YouTube, it has become a repository of large amounts of malicious and offensive videos [5]. Detecting such hate promoting videos and users is a significant and technically challenging problem. 100 hours of videos are uploaded every minute, that makes YouTube a very dynamic website. Hence, locating such users by keyword based search is overwhelmingly impractical. The work presented in this paper is motivated by the need of a solution to combat and counter online radicalization. We frame our problem as: identifying such videos promoting hate and extremism on YouTube. The research aim of the work presented in this paper is to investigate the application of a focused crawler (best-first search) based approach for retrieving YouTube user-profiles promoting hate and extremism. To investigate the effectiveness of contextual features such as the title of the videos uploaded, commented, shared, and favourited for computing the similarity between nodes in the focused crawler traversal and to examine the effectiveness of subscribers, featured channels and public contacts as links between nodes.\n\n 2. BEST-FIRST SEARCH CRAWLER\n\nThe proposed method is a multi-step process primarily consists of three phases, Training Profile Collection, Statistical Model Building and Focused Crawler. We perform a manual analysis and a visual inspection of activity feeds and contextual metadata of various YouTube channels. We collect 35 positive class channels (promoting hate and extremism) used as training profiles. We build our training dataset by extracting the discriminatory features (user activity feeds such as titles of videos uploaded, shared, favourited & commented by the user and profile information) of these 35 channels using YouTube API¹. We build a statistical model from these training profiles by applying character n-gram based language modeling approach. We build a focused crawler (best-first search) which is a recursive process.\n\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage, and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). Copyright is held by the author/owner(s).\n\nHT’14, September 1–4, 2014, Santiago, Chile.\n\nACM 978-1-4503-2954-5/14/09.\n\nhttp://dx.doi.org/10.1145/2631775.2631776.",
                    "score": 0.8122518802469016
                },
                {
                    "context": "Algorithm 1: Focused Crawler- Best First Search\n\nData: Seed User U, Width of Graph w, Size of Graph s, Threshold th, N-gram N g, Positive ResultClass Channels Up\n\n1. forall : A connected directed cyclic graph, Nodes=User u\n- u ∈ Up do\n2. end D.add(ExtractFeatures(u))\n3. Algorithm BFS(U)\n4. while graphsize < s do\n- userfeeds Uf ← ExtractFeatures(U)\n- scorescore ← LanguageModeling(D, Uf, Ng)\n- if (score < th) then\n- U.class ← Irrelevant\n- else U.class ← Relevant\n- end Hashmap Usorted.InsertionSort(U, score)\n- for i ← 1 to w do\n- end Hashmap Ugraph.add(Usorted(i))\n- for all Ug ∈ Ugraph do\n- f r = Extract F rontiers(Ug)\n- end Hashmap Ucrawler.add(f r)\n- forall Uf r ∈ Ucrawler do\n- end end BFS(Uf r)\n\n Algorithm 2: Frontier Extraction for a YouTube User\n\nData: User u\n\nResult: Frontiers of a channel\n\n1. Algorithm Extract_F rontiers(U)\n2. usubs ← u.getSubscribers()\n3. uf c ← u.getFeaturedChannels()\n4. ucon ← u.getFriends()\n\nIt takes one YouTube channel as a seed (a positive class channel) and extract its contextual metadata (user activity feeds and profile information) using YouTube API. We find the extent of textual similarity between these metadata and training data by using statistical model (build in phase 2) and LingPipe API. We implement a binary classifier to classify a user channel as relevant or irrelevant. A user channel is said to be relevant (hate and extremism promoting channel) if the computation score is above a predefined threshold. If a channel is relevant, then we further extend its frontiers (links to other YouTube channels) i.e. the subscribers of the channel, featured channels suggested by the user and its contacts available publicly. We extract these frontiers by parsing users’ YouTube homepage using jsoup HTML parser library. We execute focused crawler phase for each frontier recursively which results a connected graph, where nodes represent the user channels and edges represent the links between two users.\n\nInputs to the algorithm is a seed (a positive class user), width of graph w i.e. maximum number of children of a node, size of graph s i.e. maximum number of nodes in graph, threshold th for classification, n-gram value N g for similarity computation (language modeling), and a lexicon of 35 positive class channels Uₚ. We compare each training profile with all profiles and compute their similarity score for each mode. We take an average of these 35 scores and compute the threshold values. The proposed method (Algorithm 1) follows the standard best-first traversing to explore relevant user to seed input. Best-First Search examines a node in the graph and finds the most promising node among its children to be traversed next. This priority of nodes (users) is decided based upon the extent of similarity with the training profiles. A user with the similarity score above a specified threshold is said to be relevant and allowed to be extended further. If a node is relevant and has the highest priority (similarity score) among all relevant nodes then we extend it first and explore its links and discard irrelevant nodes. We process each node only once and if a node appears again then we only include the connecting edge in the graph. Steps 1 and 2 extract all contextual features for 35 training profiles using a feature extraction algorithm and build a training data set. Steps 4 and 5 extract all features for seed user U and compute its similarity score with training profiles using character n-gram and language modeling. Steps 6 to 8 represent the classification procedure and labeling of users as relevant or irrelevant depending upon the threshold measures.\n\nBFS method has non-binary priority values assigned to each node. The priority values are the similarity score, which is computed by comparing the users’ contextual metadata (user activity feeds and profile information) with training profiles. Steps 9 and 10 make a list of top w (maximum number of children, a node can have) users among relevant users based upon their similarity score, sorted in a decreasing order. Steps 11 − 13 extracts frontiers of a user channel using Algorithm 2. Steps 14 and 15 repeat Steps 3 − 13 for each frontier extracted. We execute this function till we get a graph with desired number of nodes or there is no more node is left to extend.\n\n Table 1: Best-First Search Confusion Matrix",
                    "score": 0.7644141878627817
                },
                {
                    "context": "This table presents the counts of predicted relevant and irrelevant items, along with their actual classifications.,\nwith the following columns:\n- Predicted: Counts of items predicted as relevant or irrelevant.\n- Actual: Counts of items that are actually relevant or irrelevant.\n\n|            | Predicted |     |\n|---|---|---|\n| Relevant   |921|314|\n| Irrelevant |125|67|",
                    "score": 0.7548633250884724
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] Which social network or platform was utilized for data collection in the analyzed article?",
                    "answer": "The platform utilized for data collection in the analyzed article is YouTube."
                },
                {
                    "question": "[SQ] What specific data collection methods were employed on YouTube in the analyzed article?",
                    "answer": "The data collection methods employed involved manually searching for anti-India hate and extremism promoting channels using keyword-based searches on YouTube. This included traversing related video links based on the heuristic that videos on similar topics would be connected as relevant. Additionally, a training dataset was created by extracting user activity feeds and contextual metadata from selected YouTube channels using the YouTube API. The channels were categorized into positive class channels promoting hate and extremism, which served as training profiles for the focused crawler."
                },
                {
                    "question": "[SQ] How was the data from YouTube analyzed in the context of the study?",
                    "answer": "Data from YouTube was analyzed through a multi-step process that involved manual analysis and visual inspection of activity feeds and contextual metadata from various YouTube channels. A collection of 35 positive class channels, which promote hate and extremism, was used as training profiles. The analysis included extracting discriminatory features such as titles of videos uploaded, shared, favorited, and commented on by users, as well as profile information. This data was then utilized to build a statistical model using a character n-gram based language modeling approach. The focused crawler employed a best-first search algorithm to traverse the network of user profiles, classifying them as relevant or irrelevant based on their similarity to the training profiles."
                },
                {
                    "question": "[SQ] What were the main findings derived from the data collected on YouTube?",
                    "answer": "The main findings derived from the data collected on YouTube indicate that the platform is extensively used by hate and extremist groups to disseminate harmful content. A focused crawler approach was implemented to identify and classify user profiles promoting hate and extremism. The analysis involved extracting contextual features from user activity feeds and profile information, which were then compared against a training dataset of known extremist channels. \n\nThe results showed that the proposed method effectively identified relevant users, with a total of 1,046 users classified as relevant and 381 as irrelevant. However, there was a notable misclassification rate, with 25.42% of relevant users and 65.10% of irrelevant users misclassified. This highlights the challenges in accurately detecting extremist content amidst the vast amount of videos uploaded to the platform. The findings underscore the need for improved methods to combat online radicalization and the dissemination of hate speech on social media platforms."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 1.0000000000000004,
                "llm_context_precision_without_reference": 0.999999999975,
                "llm_context_precision_with_reference": 0.999999999975,
                "answer_relevancy": 0.807821103562388,
                "answer_correctness": 1.0
            },
            "deepeval": {
                "contextual_precision": 1.0,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.18181818181818182,
                "answer_relevancy": 1.0,
                "faithfulness": 0.8571428571428571
            }
        },
    },
    {
        "id": 24,
        "job_id": 1,
        "file_id": 5,
        "question_id": 4,
        "status": "done",
        "answer_text": "The dataset analyzed consisted of 612 videos used for training, along with a test dataset created from 10 random positive class channels.",
        "answer_encoded": "[response not coded] The analyzed dataset consisted of 612 training videos and a test dataset from 10 random positive class channels.",
        "answer_contexts": [
                {
                    "context": "3. PERFORMANCE EVALUATION\n\nThe crawler requires exemplary documents or training examples to learn the specific characteristics and properties of documents in the training dataset. A statistical model (text classifier) needs to be built from a collection of documents pertaining to a predefined topic. We create a list of 35 user-ids used as training profiles. The 35 user ids consists of 612 videos and hence the training is performed on 612 videos. We obtain the training dataset by manually searching (keyword based) for anti-India hate and extremism promoting channels using YouTube search and traversing related video links (using the heuristic that videos on similar topic will be connected as relevant on YouTube). We select 10 random positive class (hate and extremist) channels for creating test dataset. Each user works as a seed input to the focused crawler. To evaluate the effectiveness of our solution approach we execute our focused crawler several times for various configurations and seed. Table 1 shows the confusion matrix for binary classification performed during Best-First Search approach. Given the input of 10 seed users and 6 modes (pair of threshold and n-gram values) we get different number of connected users in each iteration. To measure the accuracy of our proposed approach we collect results of all 60 iterations and classify 1046 (921 + 125) users as relevant and 381 (314 + 67) as irrelevant users. There is a misclassification of 25.42% and 65.10% in predicting the relevant and irrelevant users respectively.",
                    "score": 0.8042295511001092
                },
                {
                    "context": "This table presents the counts of predicted relevant and irrelevant items, along with their actual classifications.,\nwith the following columns:\n- Predicted: Counts of items predicted as relevant or irrelevant.\n- Actual: Counts of items that are actually relevant or irrelevant.\n\n|            | Predicted |     |\n|---|---|---|\n| Relevant   |921|314|\n| Irrelevant |125|67|",
                    "score": 0.7748428662961547
                },
                {
                    "context": "REFERENCES\n\n[1] Hsinchun Chen, Dorothy Denning, Nancy Roberts, Catherine A. Larson, Ximing Yu, and Chunneng Huang. The dark web forum portal: From multi-lingual to video. In ISI, pages 7–14. IEEE, 2011.\n\n[2] Maura Conway and Lisa McInerney. Jihadi video and auto-radicalisation: Evidence from an exploratory youtube study. In Daniel Ortiz-Arroyo, Henrik Legind Larsen, Daniel Dajun Zeng, David Hicks, and Gerhard Wagner, editors, Intelligence and Security Informatics, volume 5376 of Lecture Notes in Computer Science, pages 108–118. Springer Berlin Heidelberg, 2008.\n\n[3] Lacy G McNamee, Brittany L Peterson, and Jorge Pe˜na. A call to educate, participate, invoke and indict: Understanding the communication of online hate groups. Communication Monographs, 77(2):257–280, 2010.\n\n[4] S. Rawat and D.R. Patil. Efficient focused crawling based on best first search. In Advance Computing Conference (IACC), 2013 IEEE 3rd International, pages 908–911, Feb 2013.\n\n[5] Ashish Sureka, Ponnurangam Kumaraguru, Atul Goyal, and Sidharth Chhabra. Mining youtube to discover extremist videos, users and hidden communities. In Pu-Jen Cheng, Min-Yen Kan, Wai Lam, and Preslav Nakov, editors, Information Retrieval Technology, volume 6458 of Lecture Notes in Computer Science, pages 13–24. Springer Berlin Heidelberg, 2010.\n\n[6] Yilu Zhou, Edna Reid, Jialun Qin, Hsinchun Chen, and Guanpi Lai. Us domestic extremist groups on the web: link and content analysis. Intelligent Systems, IEEE, 20(5):44–51, 2005.",
                    "score": 0.7513857190129347
                },
                {
                    "context": "A Focused Crawler for Mining Hate and Extremism\n\n Promoting Videos on YouTube\n\n Swati Agarwal, Ashish Sureka\n\n Indraprastha Institute of Information Technology, Delhi (IIIT-D)\n\n New Delhi, India\n\n swatia@iiitd.ac.in, ashish@iiitd.ac.in\n\n ABSTRACT\n\nOnline video sharing platforms such as YouTube contains several videos and users promoting hate and extremism. Due to low barrier to publication and anonymity, YouTube is misused as a platform by some users and communities to post negative videos disseminating hatred against a particular religion, country or person. We formulate the problem of identification of such malicious videos as a search problem and present a focused-crawler based approach consisting of various components performing several tasks: search strategy or algorithm, node similarity computation metric, learning from exemplary profiles serving as training data, stopping criterion, node classifier and queue manager. We implement a best-first search algorithm and conduct experiments to measure the accuracy of the proposed approach. Experimental results demonstrate that the proposed approach is effective.\n\n Categories and Subject Descriptors\n\nH.5.4 [Hypertext/Hypermedia]: Navigation; K.4.2 [Social Issues]: Abuse and crime involving computers; D.2.8 [Metrics]: Performance measures; H.3.1 [Content Analysis and Indexing]: Linguistic processing\n\n Keywords\n\nSocial Media Analytics; Focused Crawler; Hate and Extremism Detection; Video Sharing Website; Online Radicalization.\n\n 1. RESEARCH MOTIVATION AND AIM\n\nResearch shows that YouTube has become a convenient platform for many hate and extremist groups to share information and promote their ideologies. The reason is because video is the most usable medium to share views with others [1]. Previous studies show that extremist groups put forth hateful speech, offensive comments and messages focusing their mission [3]. Social networking allows these users to facilitate recruitment, gradually reaching world wide viewers, connecting to other hate promoting groups, spreading extremist content and forming their communities sharing a common agenda [2] [6]. The presence of such extremist content in large amount is a major concern for YouTube moderators (to uphold the reputation of the website), government and law enforcement agencies (identifying extremist content and user communities to stop such promotion in country). However, despite several community guidelines and administrative efforts made by YouTube, it has become a repository of large amounts of malicious and offensive videos [5]. Detecting such hate promoting videos and users is a significant and technically challenging problem. 100 hours of videos are uploaded every minute, that makes YouTube a very dynamic website. Hence, locating such users by keyword based search is overwhelmingly impractical. The work presented in this paper is motivated by the need of a solution to combat and counter online radicalization. We frame our problem as: identifying such videos promoting hate and extremism on YouTube. The research aim of the work presented in this paper is to investigate the application of a focused crawler (best-first search) based approach for retrieving YouTube user-profiles promoting hate and extremism. To investigate the effectiveness of contextual features such as the title of the videos uploaded, commented, shared, and favourited for computing the similarity between nodes in the focused crawler traversal and to examine the effectiveness of subscribers, featured channels and public contacts as links between nodes.\n\n 2. BEST-FIRST SEARCH CRAWLER\n\nThe proposed method is a multi-step process primarily consists of three phases, Training Profile Collection, Statistical Model Building and Focused Crawler. We perform a manual analysis and a visual inspection of activity feeds and contextual metadata of various YouTube channels. We collect 35 positive class channels (promoting hate and extremism) used as training profiles. We build our training dataset by extracting the discriminatory features (user activity feeds such as titles of videos uploaded, shared, favourited & commented by the user and profile information) of these 35 channels using YouTube API¹. We build a statistical model from these training profiles by applying character n-gram based language modeling approach. We build a focused crawler (best-first search) which is a recursive process.\n\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage, and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). Copyright is held by the author/owner(s).\n\nHT’14, September 1–4, 2014, Santiago, Chile.\n\nACM 978-1-4503-2954-5/14/09.\n\nhttp://dx.doi.org/10.1145/2631775.2631776.",
                    "score": 0.7505034287791875
                },
                {
                    "context": "Algorithm 1: Focused Crawler- Best First Search\n\nData: Seed User U, Width of Graph w, Size of Graph s, Threshold th, N-gram N g, Positive ResultClass Channels Up\n\n1. forall : A connected directed cyclic graph, Nodes=User u\n- u ∈ Up do\n2. end D.add(ExtractFeatures(u))\n3. Algorithm BFS(U)\n4. while graphsize < s do\n- userfeeds Uf ← ExtractFeatures(U)\n- scorescore ← LanguageModeling(D, Uf, Ng)\n- if (score < th) then\n- U.class ← Irrelevant\n- else U.class ← Relevant\n- end Hashmap Usorted.InsertionSort(U, score)\n- for i ← 1 to w do\n- end Hashmap Ugraph.add(Usorted(i))\n- for all Ug ∈ Ugraph do\n- f r = Extract F rontiers(Ug)\n- end Hashmap Ucrawler.add(f r)\n- forall Uf r ∈ Ucrawler do\n- end end BFS(Uf r)\n\n Algorithm 2: Frontier Extraction for a YouTube User\n\nData: User u\n\nResult: Frontiers of a channel\n\n1. Algorithm Extract_F rontiers(U)\n2. usubs ← u.getSubscribers()\n3. uf c ← u.getFeaturedChannels()\n4. ucon ← u.getFriends()\n\nIt takes one YouTube channel as a seed (a positive class channel) and extract its contextual metadata (user activity feeds and profile information) using YouTube API. We find the extent of textual similarity between these metadata and training data by using statistical model (build in phase 2) and LingPipe API. We implement a binary classifier to classify a user channel as relevant or irrelevant. A user channel is said to be relevant (hate and extremism promoting channel) if the computation score is above a predefined threshold. If a channel is relevant, then we further extend its frontiers (links to other YouTube channels) i.e. the subscribers of the channel, featured channels suggested by the user and its contacts available publicly. We extract these frontiers by parsing users’ YouTube homepage using jsoup HTML parser library. We execute focused crawler phase for each frontier recursively which results a connected graph, where nodes represent the user channels and edges represent the links between two users.\n\nInputs to the algorithm is a seed (a positive class user), width of graph w i.e. maximum number of children of a node, size of graph s i.e. maximum number of nodes in graph, threshold th for classification, n-gram value N g for similarity computation (language modeling), and a lexicon of 35 positive class channels Uₚ. We compare each training profile with all profiles and compute their similarity score for each mode. We take an average of these 35 scores and compute the threshold values. The proposed method (Algorithm 1) follows the standard best-first traversing to explore relevant user to seed input. Best-First Search examines a node in the graph and finds the most promising node among its children to be traversed next. This priority of nodes (users) is decided based upon the extent of similarity with the training profiles. A user with the similarity score above a specified threshold is said to be relevant and allowed to be extended further. If a node is relevant and has the highest priority (similarity score) among all relevant nodes then we extend it first and explore its links and discard irrelevant nodes. We process each node only once and if a node appears again then we only include the connecting edge in the graph. Steps 1 and 2 extract all contextual features for 35 training profiles using a feature extraction algorithm and build a training data set. Steps 4 and 5 extract all features for seed user U and compute its similarity score with training profiles using character n-gram and language modeling. Steps 6 to 8 represent the classification procedure and labeling of users as relevant or irrelevant depending upon the threshold measures.\n\nBFS method has non-binary priority values assigned to each node. The priority values are the similarity score, which is computed by comparing the users’ contextual metadata (user activity feeds and profile information) with training profiles. Steps 9 and 10 make a list of top w (maximum number of children, a node can have) users among relevant users based upon their similarity score, sorted in a decreasing order. Steps 11 − 13 extracts frontiers of a user channel using Algorithm 2. Steps 14 and 15 repeat Steps 3 − 13 for each frontier extracted. We execute this function till we get a graph with desired number of nodes or there is no more node is left to extend.\n\n Table 1: Best-First Search Confusion Matrix",
                    "score": 0.7304196748557473
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What was the size of the dataset analyzed in the article?",
                    "answer": "The dataset analyzed in the article consisted of 612 videos used for training, along with a test dataset created from 10 random positive class channels."
                },
                {
                    "question": "[SQ] What criteria were used to select the 612 videos for training?",
                    "answer": "The 612 videos for training were selected by manually searching for anti-India hate and extremism promoting channels using YouTube search, along with traversing related video links. This approach was based on the heuristic that videos on similar topics would be connected as relevant on YouTube."
                },
                {
                    "question": "[SQ] How many videos were included in the test dataset?",
                    "answer": "The test dataset included 10 random positive class channels, but the specific number of videos included in the test dataset is not provided."
                },
                {
                    "question": "[SQ] What is the distribution of classes within the training and test datasets?",
                    "answer": "The training dataset consists of 612 videos, which are classified based on their relevance to the topic of anti-India hate and extremism. For the test dataset, 10 random positive class channels (hate and extremist) are selected. The overall classification results indicate that there are 1046 users classified as relevant (921 predicted relevant + 125 predicted irrelevant) and 381 users classified as irrelevant (314 predicted relevant + 67 predicted irrelevant)."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 1.0,
                "semantic_similarity": 0.785999976705105,
                "llm_context_precision_without_reference": 0.8333333332916666,
                "llm_context_precision_with_reference": 0.9999999999,
                "answer_relevancy": 0.8738032502423841,
                "answer_correctness": 0.19649999417627625
            },
            "deepeval": {
                "contextual_precision": 1.0,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.10256410256410256,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 25,
        "job_id": 1,
        "file_id": 5,
        "question_id": 5,
        "status": "done",
        "answer_text": "The study evaluated the misclassification rates for predicting relevant and irrelevant users. The misclassification rate for predicting relevant users was 25.42%, while for irrelevant users, it was 65.10%.",
        "answer_encoded": "[response not coded] The study reported misclassification rates of 25.42% for relevant users and 65.10% for irrelevant users.",
        "answer_contexts": [
                {
                    "context": "This table presents the counts of predicted relevant and irrelevant items, along with their actual classifications.,\nwith the following columns:\n- Predicted: Counts of items predicted as relevant or irrelevant.\n- Actual: Counts of items that are actually relevant or irrelevant.\n\n|            | Predicted |     |\n|---|---|---|\n| Relevant   |921|314|\n| Irrelevant |125|67|",
                    "score": 0.8028720641366155
                },
                {
                    "context": "3. PERFORMANCE EVALUATION\n\nThe crawler requires exemplary documents or training examples to learn the specific characteristics and properties of documents in the training dataset. A statistical model (text classifier) needs to be built from a collection of documents pertaining to a predefined topic. We create a list of 35 user-ids used as training profiles. The 35 user ids consists of 612 videos and hence the training is performed on 612 videos. We obtain the training dataset by manually searching (keyword based) for anti-India hate and extremism promoting channels using YouTube search and traversing related video links (using the heuristic that videos on similar topic will be connected as relevant on YouTube). We select 10 random positive class (hate and extremist) channels for creating test dataset. Each user works as a seed input to the focused crawler. To evaluate the effectiveness of our solution approach we execute our focused crawler several times for various configurations and seed. Table 1 shows the confusion matrix for binary classification performed during Best-First Search approach. Given the input of 10 seed users and 6 modes (pair of threshold and n-gram values) we get different number of connected users in each iteration. To measure the accuracy of our proposed approach we collect results of all 60 iterations and classify 1046 (921 + 125) users as relevant and 381 (314 + 67) as irrelevant users. There is a misclassification of 25.42% and 65.10% in predicting the relevant and irrelevant users respectively.",
                    "score": 0.790927169518432
                },
                {
                    "context": "REFERENCES\n\n[1] Hsinchun Chen, Dorothy Denning, Nancy Roberts, Catherine A. Larson, Ximing Yu, and Chunneng Huang. The dark web forum portal: From multi-lingual to video. In ISI, pages 7–14. IEEE, 2011.\n\n[2] Maura Conway and Lisa McInerney. Jihadi video and auto-radicalisation: Evidence from an exploratory youtube study. In Daniel Ortiz-Arroyo, Henrik Legind Larsen, Daniel Dajun Zeng, David Hicks, and Gerhard Wagner, editors, Intelligence and Security Informatics, volume 5376 of Lecture Notes in Computer Science, pages 108–118. Springer Berlin Heidelberg, 2008.\n\n[3] Lacy G McNamee, Brittany L Peterson, and Jorge Pe˜na. A call to educate, participate, invoke and indict: Understanding the communication of online hate groups. Communication Monographs, 77(2):257–280, 2010.\n\n[4] S. Rawat and D.R. Patil. Efficient focused crawling based on best first search. In Advance Computing Conference (IACC), 2013 IEEE 3rd International, pages 908–911, Feb 2013.\n\n[5] Ashish Sureka, Ponnurangam Kumaraguru, Atul Goyal, and Sidharth Chhabra. Mining youtube to discover extremist videos, users and hidden communities. In Pu-Jen Cheng, Min-Yen Kan, Wai Lam, and Preslav Nakov, editors, Information Retrieval Technology, volume 6458 of Lecture Notes in Computer Science, pages 13–24. Springer Berlin Heidelberg, 2010.\n\n[6] Yilu Zhou, Edna Reid, Jialun Qin, Hsinchun Chen, and Guanpi Lai. Us domestic extremist groups on the web: link and content analysis. Intelligent Systems, IEEE, 20(5):44–51, 2005.",
                    "score": 0.7273850710810119
                },
                {
                    "context": "A Focused Crawler for Mining Hate and Extremism\n\n Promoting Videos on YouTube\n\n Swati Agarwal, Ashish Sureka\n\n Indraprastha Institute of Information Technology, Delhi (IIIT-D)\n\n New Delhi, India\n\n swatia@iiitd.ac.in, ashish@iiitd.ac.in\n\n ABSTRACT\n\nOnline video sharing platforms such as YouTube contains several videos and users promoting hate and extremism. Due to low barrier to publication and anonymity, YouTube is misused as a platform by some users and communities to post negative videos disseminating hatred against a particular religion, country or person. We formulate the problem of identification of such malicious videos as a search problem and present a focused-crawler based approach consisting of various components performing several tasks: search strategy or algorithm, node similarity computation metric, learning from exemplary profiles serving as training data, stopping criterion, node classifier and queue manager. We implement a best-first search algorithm and conduct experiments to measure the accuracy of the proposed approach. Experimental results demonstrate that the proposed approach is effective.\n\n Categories and Subject Descriptors\n\nH.5.4 [Hypertext/Hypermedia]: Navigation; K.4.2 [Social Issues]: Abuse and crime involving computers; D.2.8 [Metrics]: Performance measures; H.3.1 [Content Analysis and Indexing]: Linguistic processing\n\n Keywords\n\nSocial Media Analytics; Focused Crawler; Hate and Extremism Detection; Video Sharing Website; Online Radicalization.\n\n 1. RESEARCH MOTIVATION AND AIM\n\nResearch shows that YouTube has become a convenient platform for many hate and extremist groups to share information and promote their ideologies. The reason is because video is the most usable medium to share views with others [1]. Previous studies show that extremist groups put forth hateful speech, offensive comments and messages focusing their mission [3]. Social networking allows these users to facilitate recruitment, gradually reaching world wide viewers, connecting to other hate promoting groups, spreading extremist content and forming their communities sharing a common agenda [2] [6]. The presence of such extremist content in large amount is a major concern for YouTube moderators (to uphold the reputation of the website), government and law enforcement agencies (identifying extremist content and user communities to stop such promotion in country). However, despite several community guidelines and administrative efforts made by YouTube, it has become a repository of large amounts of malicious and offensive videos [5]. Detecting such hate promoting videos and users is a significant and technically challenging problem. 100 hours of videos are uploaded every minute, that makes YouTube a very dynamic website. Hence, locating such users by keyword based search is overwhelmingly impractical. The work presented in this paper is motivated by the need of a solution to combat and counter online radicalization. We frame our problem as: identifying such videos promoting hate and extremism on YouTube. The research aim of the work presented in this paper is to investigate the application of a focused crawler (best-first search) based approach for retrieving YouTube user-profiles promoting hate and extremism. To investigate the effectiveness of contextual features such as the title of the videos uploaded, commented, shared, and favourited for computing the similarity between nodes in the focused crawler traversal and to examine the effectiveness of subscribers, featured channels and public contacts as links between nodes.\n\n 2. BEST-FIRST SEARCH CRAWLER\n\nThe proposed method is a multi-step process primarily consists of three phases, Training Profile Collection, Statistical Model Building and Focused Crawler. We perform a manual analysis and a visual inspection of activity feeds and contextual metadata of various YouTube channels. We collect 35 positive class channels (promoting hate and extremism) used as training profiles. We build our training dataset by extracting the discriminatory features (user activity feeds such as titles of videos uploaded, shared, favourited & commented by the user and profile information) of these 35 channels using YouTube API¹. We build a statistical model from these training profiles by applying character n-gram based language modeling approach. We build a focused crawler (best-first search) which is a recursive process.\n\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage, and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). Copyright is held by the author/owner(s).\n\nHT’14, September 1–4, 2014, Santiago, Chile.\n\nACM 978-1-4503-2954-5/14/09.\n\nhttp://dx.doi.org/10.1145/2631775.2631776.",
                    "score": 0.7267805940056108
                },
                {
                    "context": "Algorithm 1: Focused Crawler- Best First Search\n\nData: Seed User U, Width of Graph w, Size of Graph s, Threshold th, N-gram N g, Positive ResultClass Channels Up\n\n1. forall : A connected directed cyclic graph, Nodes=User u\n- u ∈ Up do\n2. end D.add(ExtractFeatures(u))\n3. Algorithm BFS(U)\n4. while graphsize < s do\n- userfeeds Uf ← ExtractFeatures(U)\n- scorescore ← LanguageModeling(D, Uf, Ng)\n- if (score < th) then\n- U.class ← Irrelevant\n- else U.class ← Relevant\n- end Hashmap Usorted.InsertionSort(U, score)\n- for i ← 1 to w do\n- end Hashmap Ugraph.add(Usorted(i))\n- for all Ug ∈ Ugraph do\n- f r = Extract F rontiers(Ug)\n- end Hashmap Ucrawler.add(f r)\n- forall Uf r ∈ Ucrawler do\n- end end BFS(Uf r)\n\n Algorithm 2: Frontier Extraction for a YouTube User\n\nData: User u\n\nResult: Frontiers of a channel\n\n1. Algorithm Extract_F rontiers(U)\n2. usubs ← u.getSubscribers()\n3. uf c ← u.getFeaturedChannels()\n4. ucon ← u.getFriends()\n\nIt takes one YouTube channel as a seed (a positive class channel) and extract its contextual metadata (user activity feeds and profile information) using YouTube API. We find the extent of textual similarity between these metadata and training data by using statistical model (build in phase 2) and LingPipe API. We implement a binary classifier to classify a user channel as relevant or irrelevant. A user channel is said to be relevant (hate and extremism promoting channel) if the computation score is above a predefined threshold. If a channel is relevant, then we further extend its frontiers (links to other YouTube channels) i.e. the subscribers of the channel, featured channels suggested by the user and its contacts available publicly. We extract these frontiers by parsing users’ YouTube homepage using jsoup HTML parser library. We execute focused crawler phase for each frontier recursively which results a connected graph, where nodes represent the user channels and edges represent the links between two users.\n\nInputs to the algorithm is a seed (a positive class user), width of graph w i.e. maximum number of children of a node, size of graph s i.e. maximum number of nodes in graph, threshold th for classification, n-gram value N g for similarity computation (language modeling), and a lexicon of 35 positive class channels Uₚ. We compare each training profile with all profiles and compute their similarity score for each mode. We take an average of these 35 scores and compute the threshold values. The proposed method (Algorithm 1) follows the standard best-first traversing to explore relevant user to seed input. Best-First Search examines a node in the graph and finds the most promising node among its children to be traversed next. This priority of nodes (users) is decided based upon the extent of similarity with the training profiles. A user with the similarity score above a specified threshold is said to be relevant and allowed to be extended further. If a node is relevant and has the highest priority (similarity score) among all relevant nodes then we extend it first and explore its links and discard irrelevant nodes. We process each node only once and if a node appears again then we only include the connecting edge in the graph. Steps 1 and 2 extract all contextual features for 35 training profiles using a feature extraction algorithm and build a training data set. Steps 4 and 5 extract all features for seed user U and compute its similarity score with training profiles using character n-gram and language modeling. Steps 6 to 8 represent the classification procedure and labeling of users as relevant or irrelevant depending upon the threshold measures.\n\nBFS method has non-binary priority values assigned to each node. The priority values are the similarity score, which is computed by comparing the users’ contextual metadata (user activity feeds and profile information) with training profiles. Steps 9 and 10 make a list of top w (maximum number of children, a node can have) users among relevant users based upon their similarity score, sorted in a decreasing order. Steps 11 − 13 extracts frontiers of a user channel using Algorithm 2. Steps 14 and 15 repeat Steps 3 − 13 for each frontier extracted. We execute this function till we get a graph with desired number of nodes or there is no more node is left to extend.\n\n Table 1: Best-First Search Confusion Matrix",
                    "score": 0.7242172918161287
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific performance metrics were evaluated in the study, and what were their corresponding values?",
                    "answer": "The study evaluated the misclassification rates for predicting relevant and irrelevant users. The misclassification rate for predicting relevant users was 25.42%, while for irrelevant users, it was 65.10%."
                },
                {
                    "question": "[SQ] What methods were used to calculate the misclassification rates in the study?",
                    "answer": "The misclassification rates in the study were calculated by comparing the predicted classifications of users (relevant or irrelevant) against their actual classifications. Specifically, the counts of predicted relevant and irrelevant users were summed to determine the total number of users classified, and the misclassification percentages were derived from the counts of misclassified users in each category. The rates were expressed as a percentage of the total users classified in each category."
                },
                {
                    "question": "[SQ] Were there any other performance metrics evaluated besides misclassification rates?",
                    "answer": "The provided information does not mention any performance metrics evaluated besides misclassification rates. It primarily focuses on the misclassification percentages for predicting relevant and irrelevant users."
                },
                {
                    "question": "[SQ] How do the misclassification rates compare to those from previous studies or benchmarks?",
                    "answer": "The misclassification rates reported indicate a misclassification of 25.42% for predicting relevant users and 65.10% for predicting irrelevant users. Without specific benchmarks or previous studies provided in the context, a direct comparison cannot be made. However, these rates highlight significant challenges in accurately classifying users in the context of hate and extremism detection on platforms like YouTube."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 0.0,
                "faithfulness": 1.0,
                "semantic_similarity": 0.7916812752043788,
                "llm_context_precision_without_reference": 0.99999999995,
                "llm_context_precision_with_reference": 0.0,
                "answer_relevancy": 0.8349260562208226,
                "answer_correctness": 0.1979203188010947
            },
            "deepeval": {
                "contextual_precision": 0.25,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.2,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        }
    },
    {
        "id": 26,
        "job_id": 1,
        "file_id": 6,
        "question_id": 1,
        "status": "done",
        "answer_text": "The study utilized various machine learning algorithms, including Support Vector Machine (SVM), Naive Bayes, Decision Tree, Random Forest, K-Nearest Neighbors (KNN), and ensemble methods such as boosting and bagging. SVM achieved a predictive accuracy of 84% when using TF-IDF features extracted from bi-gram features of tweets. This highlights the effectiveness of machine learning approaches in identifying extreme content on social media, particularly in the context of the Afghanistan war zone, and underscores the need for improved labeling procedures and the potential for enhanced predictive capabilities through the inclusion of semantic knowledge in future research.",
        "answer_encoded": "SVM, Naive Bayes, Decision Trees, RF",
        "answer_contexts": [
                {
                    "context": "Figure 7. Impact of Sample size on classification model accuracy.\n\n 5. Conclusions and Future Work\n\nThe wide-spread use of social media has heavily impacted the lives of people in communities. Nowadays, extremist organizations often use social media to disseminate their viewpoints to a larger community; either to generate sympathy for their cause or to recruit people. In this work, our objective is to use social media website Twitter-based tweets data in combination with machine learning approaches to automatically identify user tweets having extreme contents. Many such approaches have been proposed in the literature and they often were able to achieve predictive accuracy of around 80% [10,14–18]. Most of the earlier reported work is related to ISIS and to our knowledge, this is the novel reported research work in the context of the Afghanistan war zone to predict tweets having extreme and neutral contents. The analysis involves processing tweets data to generate TF-IDF features extracted from 1-g, 2-g, 3-g, etc., and PCA-based reduced features. A two-step analysis was performed: Exploratory Data Analysis (EDA) and Classification Modelling. In terms of EDA, we highlighted the importance of an exploratory data analysis in defining a hypothesis that can be useful in getting better predictive ability of the underlying predictive classification problem. We also demonstrate that simplest extracted features from natural language processing domain can help to identify between extreme and neutral tweet content but are not good enough to differentiate between sub-classes of extreme (i.e., pro-Afghan government or pro-Taliban). In a classification modelling process, various classification models were applied and SVM classification model has shown a predictive accuracy 84% using TF-IDF features extracted from bi-gram features of tweets.\n\nThe analysis suggests that in order to get better predictive ability in terms of extreme sub-groups, the tweets content semantic knowledge is required in the analysis. We plan to include semantic knowledge in our future work for this purpose. This is important because many tweets contain.",
                    "score": 0.6828919853769959
                },
                {
                    "context": "The second approach in our analysis was to evaluate our hypothesis of identifying tweets having extreme or neutral views. For this purpose, we opted to apply various classifiers like naïve Bayes, SVM, decision tree, random forest, KNN and ensemble classification models (see Section 4.3). The classification performance is presented in the form of evaluation measures like predictive accuracy, precision, recall, F-score. Classification models often face complexity in terms of training process when working with high-dimensional data. Therefore, we apply PCA to reduce the dimensions considering the assumption that the reduced set of features preserves maximum structure (in terms of variance preservation) of the data and this reduced set of features will be used by the classification models. The classification results, in term of evaluation measures, with various set of features (i.e., unigram, bigram, PCA-based reduced feature set) are presented in Table 5. The results illustrate that the proposed framework has encouraging outcomes for radical/extreme content identification and aspect-based sentiment analysis of tweets.\n\n Table 5. Average score on unigram, bigram feature set and Principal Component Analysis (PCA)-based reduced feature set.",
                    "score": 0.5135470439715131
                },
                {
                    "context": "4.3. Classification Model Building\n\nWe opted to apply various prominent classification algorithms for training purposes that best suit text classification. The dataset consists of TF-IDF based features computed from n-gram terms in the tweets and all the tweets have pre-assigned class labels. Seven different classifiers are considered; SVM, naïve Bayes’, decision tree, random forest, KNN, and ensemble methods (with bagging and boosting). Each classification model is trained in a supervised fashion using tweets that are labeled either extreme or neutral.\n\nThe ensemble classification techniques (with bagging and boosting) are applied to build a strong model by combining a set of weak learners to achieve better performance. Where, individual learners are trained on the same dataset and the prediction task is performed using a combination approach. In order to get better predictive ability, individual members of the classifiers should be accurate and diverse. We, therefore, used different learning algorithms in our ensemble model that were SVM, decision tree, and naïve Bayes’, etc. All experiments were performed using complete set of features extracted from our Twitter dataset that consists of TF-IDF feature set and PCA-based transformed reduced features obtained through the original TF-IDF features in order to find the most effective algorithms in terms of classification accuracy.\n\nFor the evaluation of the classification model, the data is usually split into training and test set. The training data is used to train model and the test set is used to evaluate the performance of the model. This approach of using one part of data as a training set and the other part of data as a test set does not give reliable accuracy as the accuracy with another test set may vary. We, therefore adopted, to use a K-fold cross-validation method [52,53] where we split data into K parts. In each fold, K-1 parts are used for training and the remaining one part is used for testing purpose and this process is repeated K times with varying training and test sets. This helps in getting generalization performance of the classification model for the dataset and more reliable results on an unseen test set. All the classification results presented in this paper are based on 10-fold (K = 10) cross-validation though experiments with K = 5 were also performed, however, predictive accuracy was not much different.\n\n 4.4. Results\n\nIn this work, our objective was to classify tweets having extreme or non-extreme (neutral) views. We adopted to apply machine learning approaches to demonstrate the efficacy of classifying tweets having extreme views or not. Firstly, it is important to mention that an automated labelling procedure of text data require improvement in order to get more accurate predictive ability using machine learning methods. This was the reason for us to use human assigned class labels, particularly in the context-based sentiment analysis, as a better viable solution (see Section 4.1).\n\nIn terms of analysis, we present results in a two-step approach. The first approach in our analysis is applying PCA, as an EDA tool, which is a key to better understand data and in making/refining hypotheses (see Section 4.2). Applying classification models straightaway without understanding natural patterns in the data seems not to be a sensible way of analyzing data. Though we observed that PCA faced a challenge in terms of capturing variance in the first few dimensions for a very high-dimensional dataset. We believe that this has given us better clue of the hidden patterns in the data. The visualization through PCA for our dataset has demonstrated a better separation between clusters of neutral and extreme class. But cluster separation between sub-classes of extremes, as pro-Afghan government and pro-Taliban, were not obvious. These visualization results helped us in making hypothesis that using simplest features like TF-IDF and n-gram for tweets dataset can only help to differentiate between tweets either neutral or extreme. Whereas, discrimination between sub-classes of extreme may require some semantic knowledge in order to get discrimination between them.",
                    "score": 0.5104051751711378
                },
                {
                    "context": "This table presents the performance metrics of various machine learning algorithms (SVM, Naive Bayes, Decision Tree, KNN, Random Forest, and Boosting) across different sample sizes (400, 600, 1000) and techniques (Bagging).,\nwith the following columns:\n- Sample Size: Different sample sizes used for evaluating the algorithms.\n- SVM: Performance metric for Support Vector Machine.\n- Naive Bayes: Performance metric for Naive Bayes classifier.\n- Decision Tree: Performance metric for Decision Tree algorithm.\n- KNN: Performance metric for K-Nearest Neighbors.\n- Random Forest: Performance metric for Random Forest algorithm.\n- Boosting: Performance metric for Boosting techniques.\n\n|         | SVM | Naive Bayes | Decision Tree | KNN | Random Forest | Boosting |\n|---|---|---|---|---|---|---|\n| 400     | 90  | 60          | 0             | 70  |               |          |\n| 600     | 50  | 40          | 30            | 20  | 10            |          |\n| 1000    |     |             |               |     |               |          |\n| Bagging |     |             |               |     |               |          |",
                    "score": 0.5039629049135239
                },
                {
                    "context": "Appl. Sci.2019, 9, 3723\n\nUnlike dictionary-based approaches, machine learning can also be used to predict social media extreme content. As a common practice, this problem is handled in machine learning using supervised approaches that require pre-defined labels for training a classification model. This limitation is often resolved using sentiment-based dictionaries in order to label each sample. We observed that quite often such dictionary-based approaches to label the training data give false labels due to the limitation of dictionaries to sense the context of sentences. We applied dictionary-based approaches to label tweets, either extreme or neutral, for our Twitter dataset. After carefully observing each tweet and its label, we observed that around 70% of dictionary-based assigned labels, for a sub sample data of 1000 tweets, were incorrect. This has raised some serious questions on earlier work that was often based on a dataset with labels assigned using dictionary-based approaches before applying any machine learning-based classifier [10,14,15]. Therefore, for generating training data, we used a dataset where we carefully read each tweet and then assigned a suitable label to it. The need to improve the automatic labelling procedure requires more attention of researchers than ever before.\n\nOver the last few decades, machine learning has been widely used for various problems like movie and product review systems, authorship attribution, proteomic and genomic studies, sentiment analysis, etc. However, analysis of the extreme or radicalized social media content studies are very few. The earlier published work of identifying extremism on social media platforms is mostly related to a terrorist group called the Islamic State of Iraq and Syria (ISIS). Very little work has been done in the context of Taliban using social media analysis to identify radicalized content (see Table 1). This study involves analysis of the microblogging site Twitter data (crawled using a set of keywords) using machine learning approach to understand that if a tweet or set of tweets have extreme/radicalized content. This study takes Afghanistan as a region of interest for the purpose of analysis.\n\n Table 1. Previous work on radicalization detection.",
                    "score": 0.49915972638073197
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific AI algorithm was utilized in the study, and how does it contribute to the overall findings presented in the article?",
                    "answer": "The study utilized various machine learning algorithms, including Support Vector Machine (SVM), Naive Bayes, Decision Tree, Random Forest, K-Nearest Neighbors (KNN), and ensemble methods such as boosting and bagging. These algorithms were applied to classify tweets as either extreme or neutral. The findings indicate that SVM achieved a predictive accuracy of 84% when using TF-IDF features extracted from bi-gram features of tweets. This demonstrates the effectiveness of machine learning approaches in identifying extreme content on social media, particularly in the context of the Afghanistan war zone, highlighting the need for improved labeling procedures and the potential for better predictive capabilities through the inclusion of semantic knowledge in future work."
                },
                {
                    "question": "[SQ] What were the specific features used in the machine learning algorithms for classifying tweets?",
                    "answer": "The specific features used in the machine learning algorithms for classifying tweets included TF-IDF based features computed from n-gram terms in the tweets. The analysis involved extracting features from unigrams, bigrams, and trigrams, as well as PCA-based transformed reduced features obtained from the original TF-IDF features."
                },
                {
                    "question": "[SQ] How did the performance of the SVM algorithm compare to other algorithms used in the study?",
                    "answer": "The SVM algorithm demonstrated strong performance in the study, particularly with unigram and bigram feature extraction methods. It achieved an accuracy of 90% with 1-gram features, which was among the highest in that category. When using bigram features, SVM improved its accuracy to 84.71%, outperforming other algorithms like Naive Bayes and Decision Tree in that specific comparison. \n\nIn terms of ensemble techniques, SVM showed stability and accuracy, indicating it was competitive with methods like boosting and bagging. Overall, SVM was one of the more effective algorithms for identifying extremism in the dataset, especially when compared to individual models like Decision Tree and KNN, which maintained lower accuracy levels."
                },
                {
                    "question": "[SQ] What implications do the study's findings have for future research on social media content classification?",
                    "answer": "The study's findings highlight the necessity of incorporating semantic knowledge into the analysis of social media content to improve the predictive accuracy of classification models, particularly for distinguishing between sub-groups of extreme content. Future research should focus on developing automated systems that can better understand the context and nuances of language used in tweets, as traditional dictionary-based approaches have proven inadequate. Additionally, there is a need for more reliable labeling methods for training data, as the study revealed a significant percentage of incorrect labels when using dictionary-based techniques. This suggests that future efforts should prioritize the creation of robust labeling processes and explore advanced machine learning techniques that can capture the semantic orientations of language to enhance the identification of extremist views on social media platforms."
                },
                {
                    "question": "[MQ] Which machine learning algorithms were employed in the study for classifying tweets, and how did the Support Vector Machine (SVM) perform compared to other algorithms in terms of accuracy and feature extraction methods?",
                    "answer": "The study employed several machine learning algorithms for classifying tweets, including Support Vector Machine (SVM), naïve Bayes, decision tree, random forest, K-Nearest Neighbors (KNN), and ensemble methods with bagging and boosting.\n\nIn terms of performance, the Support Vector Machine (SVM) achieved a predictive accuracy of 84% using TF-IDF features extracted from bi-gram features of tweets. The performance metrics for SVM at different sample sizes indicated varying results, with the highest accuracy of 90% at a sample size of 400. Comparatively, other algorithms such as naïve Bayes and decision tree showed lower accuracy rates, with naïve Bayes reaching a maximum of 60% and decision tree recording 0% accuracy at the same sample size. Overall, SVM demonstrated superior performance in accuracy compared to the other algorithms tested in the study."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0.75,
                "semantic_similarity": 0.8611352449792844,
                "llm_context_precision_without_reference": 0.9326515151421886,
                "llm_context_precision_with_reference": 0.9536042240501004,
                "answer_relevancy": 0.8493295405721236,
                "answer_correctness": 0.2152838112448211
            },
            "deepeval": {
                "contextual_precision": 0.5657142857142856,
                "contextual_recall": 0.8,
                "contextual_relevancy": 0.29591836734693877,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 27,
        "job_id": 1,
        "file_id": 6,
        "question_id": 2,
        "status": "done",
        "answer_text": "The analysis focused on features extracted from tweets using TF-IDF, specifically employing unigram and bigram feature sets, along with a reduced feature set obtained through Principal Component Analysis (PCA). These features were justified based on their ability to capture the underlying structure of the data while addressing the challenges posed by high-dimensional datasets. The use of PCA aimed to preserve maximum variance, which is crucial for effective classification. The study emphasized that while simpler features could differentiate between extreme and neutral tweet content, they were insufficient for distinguishing between sub-classes of extreme content, indicating a need for more semantic knowledge in future analyses.",
        "answer_encoded": "[response not coded] The analysis selected unigram and bigram features from tweets using TF-IDF, along with a reduced feature set from PCA, to effectively capture data structure and variance for classification.",
        "answer_contexts": [
                {
                    "context": "The second approach in our analysis was to evaluate our hypothesis of identifying tweets having extreme or neutral views. For this purpose, we opted to apply various classifiers like naïve Bayes, SVM, decision tree, random forest, KNN and ensemble classification models (see Section 4.3). The classification performance is presented in the form of evaluation measures like predictive accuracy, precision, recall, F-score. Classification models often face complexity in terms of training process when working with high-dimensional data. Therefore, we apply PCA to reduce the dimensions considering the assumption that the reduced set of features preserves maximum structure (in terms of variance preservation) of the data and this reduced set of features will be used by the classification models. The classification results, in term of evaluation measures, with various set of features (i.e., unigram, bigram, PCA-based reduced feature set) are presented in Table 5. The results illustrate that the proposed framework has encouraging outcomes for radical/extreme content identification and aspect-based sentiment analysis of tweets.\n\n Table 5. Average score on unigram, bigram feature set and Principal Component Analysis (PCA)-based reduced feature set.",
                    "score": 0.8444147513616334
                },
                {
                    "context": "This table compares the performance of various classification algorithms using different feature extraction methods: Unigram, Bigram, and a Reduced Feature Set through PCA. Metrics such as Accuracy, Precision, Recall, and F-Score are provided for each algorithm.,\nwith the following table title:\nClassification Algorithms Performance Comparison,\nwith the following columns:\n- Classification Algorithms: Different algorithms used for classification.\n- Unigram: Performance metrics for classification using Unigram feature extraction.\n- Bigram: Performance metrics for classification using Bigram feature extraction.\n- Reduced Feature Set (Using PCA): Performance metrics for classification using a reduced feature set through PCA.\n\n| Classification Algorithms | Unigram                                                       | Bigram                                                        | Reduced Feature Set (Using PCA)                               |\n|---|---|---|---|\n| Naïve Bayes’              | Accuracy: 83.16 Precision: 82.81 Recall: 80.2 F-Score: 81.48  | Accuracy: 81.05 Precision: 79.73 Recall: 80.84 F-Score: 80.28 | Accuracy: 68.06 Precision: 67.87 Recall: 67.70 F-Score: 67.78 |\n| SVM                       | Accuracy: 80.73 Precision: 80.65 Recall: 77.21 F-Score: 78.89 | Accuracy: 84.71 Precision: 85.18 Recall: 83.15 F-Score: 84.15 | Accuracy: 74.10 Precision: 75.00 Recall: 73.21 F-Score: 74.09 |\n| Decision Tree             | Accuracy: 76.06 Precision: 79.56 Recall: 69.28 F-Score: 74.06 | Accuracy: 77.43 Precision: 80.22 Recall: 71.34 F-Score: 75.52 | Accuracy: 70.70 Precision: 76.17 Recall: 68.77 F-Score: 72.28 |\n| Random Forest             | Accuracy: 70.7 Precision: 74.04 Recall: 70.04 F-Score: 71.98  | Accuracy: 69.56 Precision: 84.70 Recall: 50.87 F-Score: 63.56 | Accuracy: 76.00 Precision: 78.77 Recall: 74.69 F-Score: 76.68 |\n| KNN                       | Accuracy: 74.78 Precision: 73.05 Recall: 72.82 F-Score: 72.93 | Accuracy: 73.87 Precision: 70.34 Recall: 66.29 F-Score: 68.25 | Accuracy: 72.55 Precision: 73.85 Recall: 73.33 F-Score: 73.59 |\n| Bagging                   | Accuracy: 83.12 Precision: 82.21 Recall: 81.01 F-Score: 81.61 | Accuracy: 83.66 Precision: 81.89 Recall: 80.01 F-Score: 80.94 | Accuracy: 70.17 Precision: 73.91 Recall: 68.44 F-Score: 71.07 |\n| Boosting                  | Accuracy: 81.81 Precision: 80.30 Recall: 78.56 F-Score: 79.42 | Accuracy: 84.43 Precision: 86.29 Recall: 82.76 F-Score: 84.49 | Accuracy: 72.52 Precision: 73.39 Recall: 71.43 F-Score: 72.40 |",
                    "score": 0.555561030385936
                },
                {
                    "context": "Figure 7. Impact of Sample size on classification model accuracy.\n\n 5. Conclusions and Future Work\n\nThe wide-spread use of social media has heavily impacted the lives of people in communities. Nowadays, extremist organizations often use social media to disseminate their viewpoints to a larger community; either to generate sympathy for their cause or to recruit people. In this work, our objective is to use social media website Twitter-based tweets data in combination with machine learning approaches to automatically identify user tweets having extreme contents. Many such approaches have been proposed in the literature and they often were able to achieve predictive accuracy of around 80% [10,14–18]. Most of the earlier reported work is related to ISIS and to our knowledge, this is the novel reported research work in the context of the Afghanistan war zone to predict tweets having extreme and neutral contents. The analysis involves processing tweets data to generate TF-IDF features extracted from 1-g, 2-g, 3-g, etc., and PCA-based reduced features. A two-step analysis was performed: Exploratory Data Analysis (EDA) and Classification Modelling. In terms of EDA, we highlighted the importance of an exploratory data analysis in defining a hypothesis that can be useful in getting better predictive ability of the underlying predictive classification problem. We also demonstrate that simplest extracted features from natural language processing domain can help to identify between extreme and neutral tweet content but are not good enough to differentiate between sub-classes of extreme (i.e., pro-Afghan government or pro-Taliban). In a classification modelling process, various classification models were applied and SVM classification model has shown a predictive accuracy 84% using TF-IDF features extracted from bi-gram features of tweets.\n\nThe analysis suggests that in order to get better predictive ability in terms of extreme sub-groups, the tweets content semantic knowledge is required in the analysis. We plan to include semantic knowledge in our future work for this purpose. This is important because many tweets contain.",
                    "score": 0.5555037901193056
                },
                {
                    "context": "It can be observed from the results that naïve Bayes’ has shown a better result with 83.16% accuracy on unigram features. The SVM has demonstrated an improvement in the predictive accuracy (with 84.71% accuracy) with bigram features in comparison with unigram features. The ensemble techniques (i.e., boosting and bagging) are also comparable due to the high and stable accuracy over n-grams features. All other individual models (decision tree, KNN, random forest) have maintained less than 80% accuracy. Similarly, all the classifiers are also tested on a reduced feature set obtained through PCA. We present here the results obtained using a reduced feature set preserving 95% variance in the dataset. The experiments were also performed with a reduced feature set ensuring 90% variance in the dataset, but the classification predictive accuracy was not much different. PCA helped to reduce the high dimension features into low dimensions to minimize the overall analysis time required by the classification model training process. The outcome of classifiers on these reduced features is also depicted in Table 5 reporting the random forest by achieving highest accuracy (76%). The results indicate that PCA-based reduced feature set has shown compromised performance of classifiers compared with complete feature set.\n\nOverall, the results of our experiments demonstrate that SVM and ensemble techniques are more stable and accurate to identify extremism from the content of the Twitter dataset. From a feature sets like TF-IDF from uni-gram and bi-gram features and PCA based reduced feature set, the TF-IDF computed from bi-gram features was observed to be more effective with an average accuracy of 84%.\n\n 4.4.1. n-Gram Comparison\n\nIt is evident from Figure 6 that bigram provides a good stable performance compared with a unigram and trigram regarding the ability to capture the sentiment expressed. On the other hand, the bigram signifies an optimal result to carry out the sentiment analysis of tweets concerning extreme/radical identification. It is obvious from Figure 6 that naïve Bayes’ and decision tree vary with the value of ‘n’ as compared to SVM, bagging, boosting and KNN, etc.",
                    "score": 0.4745463378955562
                },
                {
                    "context": "4.3. Classification Model Building\n\nWe opted to apply various prominent classification algorithms for training purposes that best suit text classification. The dataset consists of TF-IDF based features computed from n-gram terms in the tweets and all the tweets have pre-assigned class labels. Seven different classifiers are considered; SVM, naïve Bayes’, decision tree, random forest, KNN, and ensemble methods (with bagging and boosting). Each classification model is trained in a supervised fashion using tweets that are labeled either extreme or neutral.\n\nThe ensemble classification techniques (with bagging and boosting) are applied to build a strong model by combining a set of weak learners to achieve better performance. Where, individual learners are trained on the same dataset and the prediction task is performed using a combination approach. In order to get better predictive ability, individual members of the classifiers should be accurate and diverse. We, therefore, used different learning algorithms in our ensemble model that were SVM, decision tree, and naïve Bayes’, etc. All experiments were performed using complete set of features extracted from our Twitter dataset that consists of TF-IDF feature set and PCA-based transformed reduced features obtained through the original TF-IDF features in order to find the most effective algorithms in terms of classification accuracy.\n\nFor the evaluation of the classification model, the data is usually split into training and test set. The training data is used to train model and the test set is used to evaluate the performance of the model. This approach of using one part of data as a training set and the other part of data as a test set does not give reliable accuracy as the accuracy with another test set may vary. We, therefore adopted, to use a K-fold cross-validation method [52,53] where we split data into K parts. In each fold, K-1 parts are used for training and the remaining one part is used for testing purpose and this process is repeated K times with varying training and test sets. This helps in getting generalization performance of the classification model for the dataset and more reliable results on an unseen test set. All the classification results presented in this paper are based on 10-fold (K = 10) cross-validation though experiments with K = 5 were also performed, however, predictive accuracy was not much different.\n\n 4.4. Results\n\nIn this work, our objective was to classify tweets having extreme or non-extreme (neutral) views. We adopted to apply machine learning approaches to demonstrate the efficacy of classifying tweets having extreme views or not. Firstly, it is important to mention that an automated labelling procedure of text data require improvement in order to get more accurate predictive ability using machine learning methods. This was the reason for us to use human assigned class labels, particularly in the context-based sentiment analysis, as a better viable solution (see Section 4.1).\n\nIn terms of analysis, we present results in a two-step approach. The first approach in our analysis is applying PCA, as an EDA tool, which is a key to better understand data and in making/refining hypotheses (see Section 4.2). Applying classification models straightaway without understanding natural patterns in the data seems not to be a sensible way of analyzing data. Though we observed that PCA faced a challenge in terms of capturing variance in the first few dimensions for a very high-dimensional dataset. We believe that this has given us better clue of the hidden patterns in the data. The visualization through PCA for our dataset has demonstrated a better separation between clusters of neutral and extreme class. But cluster separation between sub-classes of extremes, as pro-Afghan government and pro-Taliban, were not obvious. These visualization results helped us in making hypothesis that using simplest features like TF-IDF and n-gram for tweets dataset can only help to differentiate between tweets either neutral or extreme. Whereas, discrimination between sub-classes of extreme may require some semantic knowledge in order to get discrimination between them.",
                    "score": 0.45357432821689336
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific features or characteristics were selected for analysis in the study, and how were they justified in the context of the research objectives?",
                    "answer": "The analysis focused on features extracted from tweets using TF-IDF, specifically employing unigram and bigram feature sets, as well as a reduced feature set obtained through Principal Component Analysis (PCA). These features were justified based on their ability to capture the underlying structure of the data while addressing the challenges posed by high-dimensional datasets. The use of PCA aimed to preserve maximum variance, which is crucial for effective classification. The study highlighted that while simpler features could differentiate between extreme and neutral tweet content, they were insufficient for distinguishing between sub-classes of extreme content, indicating a need for more semantic knowledge in future analyses."
                },
                {
                    "question": "[SQ] What criteria were used to select the specific features for analysis in the study?",
                    "answer": "The specific features for analysis in the study were selected based on their ability to preserve maximum structure of the data, particularly in terms of variance preservation. The study utilized TF-IDF features extracted from n-grams (unigram, bigram, etc.) and applied Principal Component Analysis (PCA) to reduce the dimensionality of the dataset. This approach aimed to enhance the classification models' performance by ensuring that the reduced feature set maintained the essential characteristics of the original data."
                },
                {
                    "question": "[SQ] How did the use of PCA influence the interpretation of the results?",
                    "answer": "The application of PCA facilitated a clearer understanding of the data by reducing its dimensionality, which allowed for better visualization of the clusters representing different classes of tweets. It highlighted the separation between neutral and extreme views, indicating that tweets with radical/extreme perspectives share similar characteristics in both high-dimensional and low-dimensional spaces. However, PCA also revealed challenges in distinguishing between subclasses of extreme views, such as pro-Taliban and pro-Afghan government tweets. This insight suggested that while PCA was effective for identifying general categories, further semantic analysis might be necessary for more nuanced differentiation within extreme views. Overall, PCA served as a valuable exploratory tool that informed the hypothesis and guided the classification approach."
                },
                {
                    "question": "[SQ] What limitations were identified regarding the selected features in distinguishing between different types of tweet content?",
                    "answer": "The analysis indicated that while the simplest extracted features from the natural language processing domain could help identify extreme and neutral tweet content, they were insufficient for differentiating between sub-classes of extreme content, such as pro-Afghan government or pro-Taliban tweets. This limitation suggests that a deeper understanding of the semantic knowledge within the tweets is necessary for more accurate classification of these sub-groups."
                },
                {
                    "question": "[MQ] What features were selected for analysis in the study, specifically regarding TF-IDF n-grams and PCA, and how were these choices justified in terms of preserving data structure and enhancing classification performance?",
                    "answer": "The analysis focused on three feature extraction methods: unigram, bigram, and a reduced feature set obtained through Principal Component Analysis (PCA). Unigram features consist of single words, while bigram features capture pairs of consecutive words, allowing for a richer representation of the text. The choice of these n-grams was justified by their ability to effectively capture sentiment expressed in tweets, with bigram features demonstrating superior performance in classification tasks.\n\nPCA was applied to reduce the dimensionality of the dataset while preserving maximum variance, which helps maintain the underlying structure of the data. This reduction aimed to minimize the complexity faced by classification models when dealing with high-dimensional data. Although the PCA-based reduced feature set showed compromised performance compared to the complete feature sets, it still facilitated a more efficient analysis process. The results indicated that the combination of TF-IDF features from both unigram and bigram representations, along with PCA, contributed to improved classification performance, particularly in identifying extreme content in tweets."
                },
                {
                    "question": "[SQ] What specific advantages do unigram and bigram features provide in the context of sentiment analysis for tweets?",
                    "answer": "Unigram features provide a baseline for sentiment analysis, allowing for the identification of individual words and their associated sentiments. However, bigram features offer a more stable performance and are particularly effective in capturing the sentiment expressed in tweets. They enhance the ability to identify context and relationships between words, which is crucial for analyzing extreme or radical sentiments. Overall, bigram features demonstrate improved predictive accuracy compared to unigrams, making them more suitable for sentiment analysis in this context."
                },
                {
                    "question": "[SQ] How did the dimensionality reduction through PCA impact the overall classification accuracy compared to using only TF-IDF features?",
                    "answer": "Dimensionality reduction through PCA resulted in a compromised performance of classifiers compared to using the complete set of TF-IDF features. While PCA helped reduce the complexity of the classification models and minimized analysis time, the accuracy of classifiers on the PCA-based reduced feature set was generally lower. For instance, the highest accuracy achieved with the PCA-reduced feature set was 76% for the random forest, which is significantly less than the accuracies obtained using the full feature sets, such as 84% for SVM with bi-gram features. This indicates that while PCA can simplify the model training process, it may also lead to a loss of important information that affects classification accuracy."
                },
                {
                    "question": "[SQ] What additional semantic features could be considered in future analyses to improve the differentiation between subclasses of extreme tweet content?",
                    "answer": "To improve the differentiation between subclasses of extreme tweet content, future analyses could consider incorporating semantic features such as sentiment intensity, contextual embeddings (e.g., using models like BERT or Word2Vec), and aspect-based sentiment indicators. Additionally, analyzing the relationships between words and phrases within the tweets, as well as employing techniques to capture nuances in meaning and sentiment, could enhance the understanding of the content. This would help in distinguishing between pro-Afghan government and pro-Taliban sentiments more effectively."
                },
                {
                    "question": "[MQ] What specific features, including unigram and bigram TF-IDF n-grams and a reduced set from PCA, were selected for analysis in the study, and how were these choices justified in terms of preserving data structure and enhancing classification performance?",
                    "answer": "The analysis in the study utilized specific features derived from TF-IDF computed from unigram and bigram n-grams, as well as a reduced feature set obtained through Principal Component Analysis (PCA). The choice of these features was justified by their ability to preserve the structure of the data while enhancing classification performance. \n\nUnigram and bigram features were selected for their effectiveness in capturing sentiment and providing stable performance in classification tasks. The bigram features, in particular, were noted for their optimal results in sentiment analysis related to extreme or radical identification. \n\nPCA was employed to reduce the dimensionality of the feature set while preserving a significant amount of variance in the dataset (95% variance was targeted). This approach aimed to minimize the complexity associated with high-dimensional data, thereby improving the efficiency of the classification model training process. The results indicated that while PCA-based reduced feature sets compromised some classifier performance compared to complete feature sets, they still provided valuable insights into the data structure and facilitated better model training."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0.8461538461538461,
                "semantic_similarity": 0.8355718100568559,
                "llm_context_precision_without_reference": 0.999999999990909,
                "llm_context_precision_with_reference": 0.46388888887961116,
                "answer_relevancy": 0.8089887458183305,
                "answer_correctness": 0.43966218328344475
            },
            "deepeval": {
                "contextual_precision": 0.6428571428571428,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.044444444444444446,
                "answer_relevancy": 1.0,
                "faithfulness": 0.8571428571428571
            }
        },
    },
    {
        "id": 28,
        "job_id": 1,
        "file_id": 6,
        "question_id": 3,
        "status": "done",
        "answer_text": "The social network utilized for data collection in the analyzed article is Twitter.",
        "answer_encoded": "Twitter",
        "answer_contexts": [
                {
                    "context": "3.1. Data Collection and Preparation\n\nMany Twitter-based datasets are available over the internet either freely or commercially for understanding public sentiment on social or political issues [39,40]. However, there is no dataset available in the context of Afghanistan war zone for assessing public sentiment on the war situation in Afghanistan. Therefore, we collected new and relevant data from Twitter associated with our problem. Twitter provides APIs that allow researchers to extract real-time tweets using different parameter settings for text analytics. These APIs extract tweets either based on given query terms or tweets from a profile of a specified user or based on given geo-location or language constraints or combination of any of these. The request to API not only returns tweet text but it also other information that includes username, user location, tweet text, user mentions in tweets, etc. The API supports the JavaScript Object Notation (JSON), Extensible Markup Language (XML) and Really Simply Syndication (RSS) formats.\n\nData [ ] = Search(term, username, longitude, latitude, lang)\n\n𝐷𝑎𝑡𝑎 ሾ ሿ = 𝑆𝑒𝑎𝑟𝑐ℎ(𝑡𝑒𝑟𝑚, 𝑢𝑠𝑒𝑟𝑛𝑎𝑚𝑒, 𝑙𝑜𝑛𝑔𝑖𝑡𝑢𝑑𝑒, 𝑙𝑎𝑡𝑖𝑡𝑢𝑑𝑒, 𝑙𝑎𝑛𝑔)\n\nIt is important to mention that Twitter generates more than 500 million tweets per day on different topics and events [41,42]. To fetch the only relevant tweets from all the available data, a query was carefully prepared. Afghanistan was chosen as a targeted geo-location with the conjunction of a query for data extraction. The reason for selecting Afghanistan as our key focus was because of an extreme level of conflict between the public of Afghanistan on the matter of Taliban and Afghan government. Many Afghani support Taliban groups and they express openly about it on social media. Similarly, there are also those people in Afghanistan who support Afghan government and express their opinion against the Taliban on the social media platforms very openly. There is also a big community in Afghanistan who discuss issues and have their opinions—and their opinions are quite fair and neutral with a focus on bringing peace in the community. Considering this situation, we formulated a problem definition stating that studying Afghanistan is the most suitable case scenario to identify extreme and neutral content in tweets using the machine learning techniques. We believe that the same can be replicated to other geo-locations in future studies.\n\nFor relevant data extraction, we used several Twitter trends that are related to Taliban matters; while from all of them the #kunduz event was the hottest trending topic. The Kunduz trend was the result of an airstrike conducted by Afghan forces on a religious school in the strong hold area of Taliban on 2 April 2018. Afghan government was of the view that Taliban leaders’ presence at the Madrassa was the reason of this attack by the Afghan forces.\n\nIn order to collect data from Twitter to understand the sentiment of Afghan people after Kunduz Madrassa attack in Afghanistan, the list of query words was prepared based on the trending topics.",
                    "score": 0.7594704574326197
                },
                {
                    "context": "4.1. Data Collection and Preprocessing\n\nA Twitter Streaming API was used to collect tweets from the geo-location of Afghanistan from 2nd April 2018 to 8th April 2018 after Kunduz Madrassa attack by Afghan forces. A list of 60 specific query terms, like Taliban, airstrike, peace, Afghan, etc. were used to extract tweets from the profile of users (see Section 3.1.1 for query words details). A total of 7500 tweets were downloaded. Many tweets were repeated in the corpus because of retweet feature of Twitter, and we only considered unique tweets in our dataset. We also filtered out tweets that are not relevant to the context of our problem and they appear in a dataset because of some query words in them but their text is not related to our problem. Finally, the resulting dataset has 3380 tweets for the analysis.\n\nFor the classification task, the labels were required to be given using most appropriate and accurate approach. As mentioned earlier in Section 3.1.1., automated data annotation is often observed to be not reliable with around 70% error rate when compared with humanly assigned classes for our dataset (see Table 3 for sample labels of tweets using WordNet, SentiWordNet and manual labelling by humans). The dictionaries assign labels in numerical form where range of scores is between {-ve, 0, +ve}. The -ve and +ve score represent the negative and positive sentiment correspondingly and zero denote to a neutral sentiment. Based on these scores it is insufficient to distinguish between anti or pro entities because both writers use similar words.\n\nTherefore, we adopted an approach where five different persons from various walks of life (i.e., a journalist, an academic at the Islamia University of Bahawalpur (IUB) from political science department, an academic from computer science department of the IUB and first two authors of this paper) were asked to label tweets. More than 95% of the tweets were given class labels based on the consensus of all five persons. For the remaining 5% of the tweets, the three or more persons agreed to assign a one class label whereas the remaining one or two persons had different views of class label assignments, so in such cases the class label was assigned based on the majority. The main disadvantage of the involvement of humans to label each tweet is a time taking process for preparing a training set for machine learning models. To fully automate the process of detecting extreme contents, the research community needs to focus on developing methods to automatically label each tweet that not only involves the occurrence of the words in a tweet content but also needs to consider the semantics in naturally written text.\n\n Table 3. Example of data labelling comparison.",
                    "score": 0.7563473656594137
                },
                {
                    "context": "20,000 suspected Twitter accounts and claims that 93% of all examining accounts are supporting ISIS. Furthermore, a minimum threshold of 46,000 and max bound of 90,000 was estimated for existing ISIS-supporting accounts from October to November 2014. Where each account had an average of 1000 followers, considerably higher than any ordinary Twitter user.\n\nA hybrid approach of sentiment analysis was proposed in [10] to predict ISIS supporter accounts on Twitter. Herein, real-time tweets are collected using specific query words (i.e., ISIS, bomb, terrorist) with Twitter Streaming API. After collecting data, a lexicon-based approach was used for labelling purpose, where SentiWordNet dictionary was used to calculate the score of each tweet. For classification task, naïve Bayes’ algorithm was used. In this work a two-fold approach was applied where, after classifying every user, more tweets were collected from the same user account and verification of assigned sentiment score was performed using tweet history.\n\nAnother approach was presented in [24] where tweets were grouped into various radical groups based on the presence of special keywords such as “Al-Qaida”, “Jihad”, “Terrorist Operations” and “Extremism” through a lexical-based approach. A dictionary of semantically related terms (categories) was created by observing hashtags in tweets. For classification task, tweets were vectored based on dictionary related words, such as if any tweets contain dictionary related words, the score of tweets will be 1 otherwise 0. A set of rules was defined for each category and a vector representing each tweet was then compared with all rules to assign the most appropriate category to a tweet having radical content.\n\nMost of the work in the literature regarding extremism detection through social media content analysis using machine learning techniques was done related to ISIS. In the context of Afghanistan, much of the region has been in wars in the last fifty years and hence the literacy rate is not much high and a small community use Twitter as a medium of communication. Our research focuses on analyzing Twitter-based data, generated by the people of Afghanistan, in order to identify users having extreme views or neutral views that highly affects the mode of society. The purpose of this analysis is to help organizations to better understand the extremism in the society and to define strategies to reduce hate views in order to build a better peaceful society.\n\n 3. Materials and Methods\n\nThis study aims to build a state-of-the-art framework to assess the efficacy of technological advancement in the context of text-based content analysis. In this study we collected data from Twitter using Twitter Streaming API and apply standard preprocessing techniques of NLP that ranges from tokenization, stemming, lemmatization, computing TF-IDF features, etc., to generate a dataset. The main objective of this study is to develop a model that can predict a class of a given tweet either as neutral or extreme.\n\nWe proposed a framework that involves a two-step process of using machine learning methods in order to get better understanding of the data and predictive ability. The first step is to perform an Exploratory Data Analysis (EDA) [37,38], where the objective is to have a better understanding of underlying hidden patterns in the data. As part of an EDA, we use to apply Principal Component Analysis (PCA) to reduce dimensions of our dataset in order to visually observe hidden patterns in the data. As the second step of our analysis, we apply various machine learning classification models such as SVM, naïve Bayes’, decision tree, KNN and ensemble classification methods with boosting and bagging approaches. The evaluation of classification models is a key step. We compute evaluation measures such as accuracy, precision, recall and F-score in order to evaluate predictive performance of the algorithms applied. In our experiments, we also demonstrate the impact of data size on the performance of classification models.\n\nIn subsequent sub-sections, the key stages of our analysis are explained. These stages are data collection, data pruning, preprocessing, feature extraction, and exploratory data analysis, predictive model building and its evaluation. Figure 2 represents the schematic representation of the proposed framework of classifying tweets either as extreme or as neutral.",
                    "score": 0.5585220819090062
                },
                {
                    "context": "Among all social media platforms, Twitter is chosen since it is widely used by all communities ranging from common man to celebrities with the short form of text content in every tweet. The maximum size of an earlier tweet message was 140 characters per tweet which had been extended to 250 characters since November 2017. The short length of tweets, however, makes the problem more challenging because users often tweet on a topic giving very limited contextual information making it hard to perform sentiment analysis when compared with other social media platform contents [25].\n\nThe main contribution of the proposed methodology are as follows:\n\n- Importance of Data Labeling: To build a sentiment classification model, a labelled data set is needed to train and test the machine learning model. Commonly, as mentioned earlier, researchers use a dictionary-based method (i.e., SentiWordNet, SentiStrength) for this purpose. We reported that in aspect-based sentiment analysis the current labeling method has a lack of correctness and reliability.",
                    "score": 0.4621725499192638
                },
                {
                    "context": "Figure 7. Impact of Sample size on classification model accuracy.\n\n 5. Conclusions and Future Work\n\nThe wide-spread use of social media has heavily impacted the lives of people in communities. Nowadays, extremist organizations often use social media to disseminate their viewpoints to a larger community; either to generate sympathy for their cause or to recruit people. In this work, our objective is to use social media website Twitter-based tweets data in combination with machine learning approaches to automatically identify user tweets having extreme contents. Many such approaches have been proposed in the literature and they often were able to achieve predictive accuracy of around 80% [10,14–18]. Most of the earlier reported work is related to ISIS and to our knowledge, this is the novel reported research work in the context of the Afghanistan war zone to predict tweets having extreme and neutral contents. The analysis involves processing tweets data to generate TF-IDF features extracted from 1-g, 2-g, 3-g, etc., and PCA-based reduced features. A two-step analysis was performed: Exploratory Data Analysis (EDA) and Classification Modelling. In terms of EDA, we highlighted the importance of an exploratory data analysis in defining a hypothesis that can be useful in getting better predictive ability of the underlying predictive classification problem. We also demonstrate that simplest extracted features from natural language processing domain can help to identify between extreme and neutral tweet content but are not good enough to differentiate between sub-classes of extreme (i.e., pro-Afghan government or pro-Taliban). In a classification modelling process, various classification models were applied and SVM classification model has shown a predictive accuracy 84% using TF-IDF features extracted from bi-gram features of tweets.\n\nThe analysis suggests that in order to get better predictive ability in terms of extreme sub-groups, the tweets content semantic knowledge is required in the analysis. We plan to include semantic knowledge in our future work for this purpose. This is important because many tweets contain.",
                    "score": 0.46138557153260135
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] Which social network or platform was utilized for data collection in the analyzed article?",
                    "answer": "The social network utilized for data collection in the analyzed article is Twitter."
                },
                {
                    "question": "[SQ] What specific data collection methods were used on Twitter in the analyzed article?",
                    "answer": "The data collection methods used involved utilizing the Twitter Streaming API to gather tweets from the geo-location of Afghanistan, specifically from April 2 to April 8, 2018, following the Kunduz Madrassa attack. A list of 60 specific query terms related to the Taliban and the conflict was employed to extract relevant tweets. The process included filtering out duplicate tweets, non-English tweets, and those that did not pertain to the context of the study, resulting in a final dataset of 3,380 unique tweets for analysis."
                },
                {
                    "question": "[SQ] How was the data from Twitter analyzed in the study?",
                    "answer": "The data from Twitter was analyzed through a structured framework that involved several key stages. Initially, tweets were collected using the Twitter Streaming API, focusing on specific query terms related to the context of the Afghanistan war. After gathering the data, preprocessing techniques such as tokenization, stemming, and lemmatization were applied to prepare the dataset for analysis.\n\nThe analysis included a two-step process: first, an Exploratory Data Analysis (EDA) was conducted to uncover hidden patterns within the data, utilizing techniques like Principal Component Analysis (PCA) for dimensionality reduction. Following this, various machine learning classification models, including SVM, naïve Bayes, decision trees, KNN, and ensemble methods, were employed to classify the tweets as either extreme or neutral.\n\nThe performance of these classification models was evaluated using metrics such as accuracy, precision, recall, and F-score. The study also examined the impact of data size on the classification model's accuracy, highlighting the importance of effective data labeling and the need for semantic knowledge to improve predictive capabilities regarding extreme sub-groups."
                },
                {
                    "question": "[SQ] What were the main findings derived from the Twitter data in the analyzed article?",
                    "answer": "The main findings from the Twitter data analysis indicate that a significant portion of tweets contained extreme or neutral content related to the Afghanistan war zone. The study achieved a predictive accuracy of 84% using a Support Vector Machine (SVM) classification model with TF-IDF features extracted from bi-grams. It was noted that while simpler features from natural language processing could help identify extreme versus neutral tweets, they were insufficient for distinguishing between sub-classes of extreme content, such as pro-Afghan government or pro-Taliban sentiments. The analysis emphasized the necessity of incorporating semantic knowledge to enhance predictive ability regarding extreme sub-groups. Additionally, the research highlighted the challenges posed by the short length of tweets, which often limits contextual information, complicating sentiment analysis. The importance of accurate data labeling was also underscored, revealing that automated labeling methods currently exhibit a high error rate compared to human labeling. Overall, the findings aim to assist organizations in understanding extremism within Afghan society and developing strategies to mitigate hate views."
                },
                {
                    "question": "[MQ] Which social network was utilized for data collection in the analysis of tweets related to the Afghanistan war, specifically using the Twitter Streaming API?",
                    "answer": "The social network utilized for data collection in the analysis of tweets related to the Afghanistan war was Twitter, specifically using the Twitter Streaming API."
                },
                {
                    "question": "[SQ] What time frame was covered for tweet collection related to the Afghanistan war using the Twitter Streaming API?",
                    "answer": "The time frame covered for tweet collection related to the Afghanistan war using the Twitter Streaming API was from 2nd April 2018 to 8th April 2018."
                },
                {
                    "question": "[SQ] What specific query terms were used to filter tweets during the data collection process?",
                    "answer": "The specific query terms used to filter tweets during the data collection process included terms like Taliban, airstrike, peace, Afghan, among others. A total of 60 specific query terms were utilized for this purpose."
                },
                {
                    "question": "[SQ] How many unique tweets were ultimately included in the analysis after filtering?",
                    "answer": "The analysis ultimately included 3,380 unique tweets after filtering."
                },
                {
                    "question": "[MQ] Which social network was used for data collection in the analysis of tweets related to the Afghanistan war, specifically through the Twitter Streaming API from April 2 to April 8, 2018?",
                    "answer": "The social network used for data collection in the analysis of tweets related to the Afghanistan war was Twitter."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 0.9999999999999996,
                "llm_context_precision_without_reference": 0.9708624708536447,
                "llm_context_precision_with_reference": 0.9708624708536447,
                "answer_relevancy": 0.8087136901956149,
                "answer_correctness": 0.9999999999999999
            },
            "deepeval": {
                "contextual_precision": 0.8993055555555556,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.2391304347826087,
                "answer_relevancy": 0.5454545454545454,
                "faithfulness": 0.7272727272727273
            }
        },
    },
    {
        "id": 29,
        "job_id": 1,
        "file_id": 6,
        "question_id": 4,
        "status": "done",
        "answer_text": "The dataset analyzed in the article consisted of three subsets with sizes of 400, 600, and 1000 tweet samples each, totaling 3,380 unique tweets after filtering for relevance.",
        "answer_encoded": "[response not coded] The analyzed dataset comprised three subsets totaling 3,380 unique tweets.",
        "answer_contexts": [
                {
                    "context": "4.1. Data Collection and Preprocessing\n\nA Twitter Streaming API was used to collect tweets from the geo-location of Afghanistan from 2nd April 2018 to 8th April 2018 after Kunduz Madrassa attack by Afghan forces. A list of 60 specific query terms, like Taliban, airstrike, peace, Afghan, etc. were used to extract tweets from the profile of users (see Section 3.1.1 for query words details). A total of 7500 tweets were downloaded. Many tweets were repeated in the corpus because of retweet feature of Twitter, and we only considered unique tweets in our dataset. We also filtered out tweets that are not relevant to the context of our problem and they appear in a dataset because of some query words in them but their text is not related to our problem. Finally, the resulting dataset has 3380 tweets for the analysis.\n\nFor the classification task, the labels were required to be given using most appropriate and accurate approach. As mentioned earlier in Section 3.1.1., automated data annotation is often observed to be not reliable with around 70% error rate when compared with humanly assigned classes for our dataset (see Table 3 for sample labels of tweets using WordNet, SentiWordNet and manual labelling by humans). The dictionaries assign labels in numerical form where range of scores is between {-ve, 0, +ve}. The -ve and +ve score represent the negative and positive sentiment correspondingly and zero denote to a neutral sentiment. Based on these scores it is insufficient to distinguish between anti or pro entities because both writers use similar words.\n\nTherefore, we adopted an approach where five different persons from various walks of life (i.e., a journalist, an academic at the Islamia University of Bahawalpur (IUB) from political science department, an academic from computer science department of the IUB and first two authors of this paper) were asked to label tweets. More than 95% of the tweets were given class labels based on the consensus of all five persons. For the remaining 5% of the tweets, the three or more persons agreed to assign a one class label whereas the remaining one or two persons had different views of class label assignments, so in such cases the class label was assigned based on the majority. The main disadvantage of the involvement of humans to label each tweet is a time taking process for preparing a training set for machine learning models. To fully automate the process of detecting extreme contents, the research community needs to focus on developing methods to automatically label each tweet that not only involves the occurrence of the words in a tweet content but also needs to consider the semantics in naturally written text.\n\n Table 3. Example of data labelling comparison.",
                    "score": 0.7799571104533443
                },
                {
                    "context": "After the labeling process, our dataset was divided into four categories (i.e., pro-Afghan, pro-Taliban, Neutral, Irrelevant) based on the sentiment that it contains. The irrelevant class consists of a few random tweets, which are not related to our specified topic. They are in the corpus due to some query-words, but their tweet text is immaterial with respect to the context. The irrelevant tweets are filtered out from the corpus in further experiments. The description of each class and sub-class in a dataset is presented in Table 4.",
                    "score": 0.7056085060251416
                },
                {
                    "context": "Figure 7. Impact of Sample size on classification model accuracy.\n\n 5. Conclusions and Future Work\n\nThe wide-spread use of social media has heavily impacted the lives of people in communities. Nowadays, extremist organizations often use social media to disseminate their viewpoints to a larger community; either to generate sympathy for their cause or to recruit people. In this work, our objective is to use social media website Twitter-based tweets data in combination with machine learning approaches to automatically identify user tweets having extreme contents. Many such approaches have been proposed in the literature and they often were able to achieve predictive accuracy of around 80% [10,14–18]. Most of the earlier reported work is related to ISIS and to our knowledge, this is the novel reported research work in the context of the Afghanistan war zone to predict tweets having extreme and neutral contents. The analysis involves processing tweets data to generate TF-IDF features extracted from 1-g, 2-g, 3-g, etc., and PCA-based reduced features. A two-step analysis was performed: Exploratory Data Analysis (EDA) and Classification Modelling. In terms of EDA, we highlighted the importance of an exploratory data analysis in defining a hypothesis that can be useful in getting better predictive ability of the underlying predictive classification problem. We also demonstrate that simplest extracted features from natural language processing domain can help to identify between extreme and neutral tweet content but are not good enough to differentiate between sub-classes of extreme (i.e., pro-Afghan government or pro-Taliban). In a classification modelling process, various classification models were applied and SVM classification model has shown a predictive accuracy 84% using TF-IDF features extracted from bi-gram features of tweets.\n\nThe analysis suggests that in order to get better predictive ability in terms of extreme sub-groups, the tweets content semantic knowledge is required in the analysis. We plan to include semantic knowledge in our future work for this purpose. This is important because many tweets contain.",
                    "score": 0.5742575154486068
                },
                {
                    "context": "After the labeling process, our dataset was divided into four categories (i.e., pro-Afghan, pro-Taliban, Neutral, Irrelevant) based on the sentiment that it contains. The irrelevant class consists of a few random tweets, which are not related to our specified topic. They are in the corpus due to some query-words, but their tweet text is immaterial with respect to the context. The irrelevant tweets are filtered out from the corpus in further experiments. The description of each class and sub-class in a dataset is presented in Table 4.\n\n Table 4. Description of assigned classes.",
                    "score": 0.5125650220180241
                },
                {
                    "context": "3.1. Data Collection and Preparation\n\nMany Twitter-based datasets are available over the internet either freely or commercially for understanding public sentiment on social or political issues [39,40]. However, there is no dataset available in the context of Afghanistan war zone for assessing public sentiment on the war situation in Afghanistan. Therefore, we collected new and relevant data from Twitter associated with our problem. Twitter provides APIs that allow researchers to extract real-time tweets using different parameter settings for text analytics. These APIs extract tweets either based on given query terms or tweets from a profile of a specified user or based on given geo-location or language constraints or combination of any of these. The request to API not only returns tweet text but it also other information that includes username, user location, tweet text, user mentions in tweets, etc. The API supports the JavaScript Object Notation (JSON), Extensible Markup Language (XML) and Really Simply Syndication (RSS) formats.\n\nData [ ] = Search(term, username, longitude, latitude, lang)\n\n𝐷𝑎𝑡𝑎 ሾ ሿ = 𝑆𝑒𝑎𝑟𝑐ℎ(𝑡𝑒𝑟𝑚, 𝑢𝑠𝑒𝑟𝑛𝑎𝑚𝑒, 𝑙𝑜𝑛𝑔𝑖𝑡𝑢𝑑𝑒, 𝑙𝑎𝑡𝑖𝑡𝑢𝑑𝑒, 𝑙𝑎𝑛𝑔)\n\nIt is important to mention that Twitter generates more than 500 million tweets per day on different topics and events [41,42]. To fetch the only relevant tweets from all the available data, a query was carefully prepared. Afghanistan was chosen as a targeted geo-location with the conjunction of a query for data extraction. The reason for selecting Afghanistan as our key focus was because of an extreme level of conflict between the public of Afghanistan on the matter of Taliban and Afghan government. Many Afghani support Taliban groups and they express openly about it on social media. Similarly, there are also those people in Afghanistan who support Afghan government and express their opinion against the Taliban on the social media platforms very openly. There is also a big community in Afghanistan who discuss issues and have their opinions—and their opinions are quite fair and neutral with a focus on bringing peace in the community. Considering this situation, we formulated a problem definition stating that studying Afghanistan is the most suitable case scenario to identify extreme and neutral content in tweets using the machine learning techniques. We believe that the same can be replicated to other geo-locations in future studies.\n\nFor relevant data extraction, we used several Twitter trends that are related to Taliban matters; while from all of them the #kunduz event was the hottest trending topic. The Kunduz trend was the result of an airstrike conducted by Afghan forces on a religious school in the strong hold area of Taliban on 2 April 2018. Afghan government was of the view that Taliban leaders’ presence at the Madrassa was the reason of this attack by the Afghan forces.\n\nIn order to collect data from Twitter to understand the sentiment of Afghan people after Kunduz Madrassa attack in Afghanistan, the list of query words was prepared based on the trending topics.",
                    "score": 0.3992758505810163
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What was the size of the dataset analyzed in the article?",
                    "answer": "The dataset analyzed in the article consisted of three subsets with sizes of 400, 600, and 1000 tweet samples each."
                },
                {
                    "question": "[SQ] What criteria were used to select the tweet samples for each subset?",
                    "answer": "The tweet samples were selected based on their relevance to specific query terms related to the context of the Afghanistan war zone, such as \"Taliban,\" \"airstrike,\" and \"peace.\" After collecting tweets using the Twitter Streaming API, the dataset was filtered to include only unique tweets, removing duplicates caused by retweets. Additionally, tweets that were not relevant to the specified topic, despite containing query words, were also filtered out. The final dataset consisted of tweets categorized into four classes: pro-Afghan, pro-Taliban, Neutral, and Irrelevant, with the irrelevant class being composed of tweets that did not pertain to the main topic of interest."
                },
                {
                    "question": "[SQ] Were there any specific topics or themes covered in the tweet samples?",
                    "answer": "The tweet samples covered themes related to the Taliban's responses to Afghan airstrikes, human rights investigations into airstrikes, civilian casualties, and the dynamics of anti-Taliban movements in border areas. Additionally, there was a tweet that was unrelated to the main topics, focusing instead on trophy hunting."
                },
                {
                    "question": "[SQ] How was the quality of the tweet samples ensured in the dataset?",
                    "answer": "The quality of the tweet samples in the dataset was ensured through several steps. Initially, tweets were collected using specific query terms, and duplicates were removed to maintain uniqueness. Tweets that were not relevant to the context were filtered out, ensuring that only pertinent content remained. Additionally, a rigorous labeling process was employed, where five individuals from diverse backgrounds labeled the tweets, achieving over 95% consensus on the classifications. For the remaining tweets, the majority opinion was used to assign labels. This careful curation and labeling process helped to enhance the dataset's quality for analysis."
                },
                {
                    "question": "[MQ] What was the total size of the analyzed dataset, which included three subsets of 400, 600, and 1000 tweet samples each, filtered for relevance to the Afghanistan war context?",
                    "answer": "The total size of the analyzed dataset was 3380 tweets, which were filtered for relevance to the Afghanistan war context."
                },
                {
                    "question": "[SQ] What was the method used to filter the tweets for relevance to the Afghanistan war context?",
                    "answer": "The method involved collecting tweets using a Twitter Streaming API with a specific list of 60 query terms related to the Afghanistan war, such as Taliban and airstrike. After downloading a total of 7500 tweets, duplicates were removed to retain only unique tweets. Additionally, tweets that were not relevant to the context of the Afghanistan war, despite containing some of the query words, were filtered out. This process resulted in a final dataset of 3380 tweets that were deemed relevant for analysis."
                },
                {
                    "question": "[SQ] How were the tweet samples categorized within the dataset?",
                    "answer": "The tweet samples within the dataset were categorized into four distinct classes based on the sentiment they expressed: pro-Afghan, pro-Taliban, Neutral, and Irrelevant. The irrelevant class included tweets that were not related to the specified topic, despite containing certain query words. The categorization was primarily based on a consensus approach involving multiple individuals who labeled the tweets, ensuring that over 95% of the tweets received class labels agreed upon by the group. For the remaining tweets, the majority opinion among the labelers determined the final classification."
                },
                {
                    "question": "[SQ] What was the total number of unique tweets after filtering for relevance?",
                    "answer": "The total number of unique tweets after filtering for relevance was 3,380."
                },
                {
                    "question": "[MQ] What was the total size of the analyzed dataset after filtering for relevance to the Afghanistan war, which ultimately consisted of 3,380 unique tweets?",
                    "answer": "The total size of the analyzed dataset after filtering for relevance to the Afghanistan war was 3,380 unique tweets."
                },
                {
                    "question": "[SQ] What was the total number of tweets collected before filtering for relevance?",
                    "answer": "The total number of tweets collected before filtering for relevance was 7500."
                },
                {
                    "question": "[SQ] What specific query terms were used to filter the tweets related to the Afghanistan war?",
                    "answer": "A list of 60 specific query terms was used to filter the tweets related to the Afghanistan war. Some of the notable terms included \"Taliban,\" \"airstrike,\" \"peace,\" and \"Afghan.\" These terms were selected to extract relevant tweets from the geo-location of Afghanistan during the specified time frame after the Kunduz Madrassa attack."
                },
                {
                    "question": "[SQ] How were duplicates handled during the tweet collection process?",
                    "answer": "Duplicates were handled by removing tweets that occurred multiple times in the dataset due to the retweet feature of Twitter. This was achieved by using the unique tweet ID assigned to each newly generated tweet, ensuring that only unique tweets were considered in the final dataset."
                },
                {
                    "question": "[MQ] What was the size of the analyzed dataset after filtering for relevance to the Afghanistan war, which consisted of 3,380 unique tweets derived from an initial collection of 7,500 tweets using specific query terms?",
                    "answer": "The size of the analyzed dataset after filtering for relevance to the Afghanistan war was 3,380 unique tweets."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0.9230769230769231,
                "semantic_similarity": 0.8283858458580701,
                "llm_context_precision_without_reference": 0.62499999996875,
                "llm_context_precision_with_reference": 0.1249999999875,
                "answer_relevancy": 0.8339020558211664,
                "answer_correctness": 0.20709646146451752
            },
            "deepeval": {
                "contextual_precision": 0.9519230769230769,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.3246753246753247,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 30,
        "job_id": 1,
        "file_id": 6,
        "question_id": 5,
        "status": "done",
        "answer_text": "The study evaluated several performance metrics, including Accuracy, Precision, Recall, and F-Score for various classification algorithms. Here are the corresponding values for each algorithm using different feature extraction methods:\n\n1. **Naïve Bayes**:\n   - Unigram: Accuracy: 83.16, Precision: 82.81, Recall: 80.2, F-Score: 81.48\n   - Bigram: Accuracy: 81.05, Precision: 79.73, Recall: 80.84, F-Score: 80.28\n   - Reduced Feature Set (Using PCA): Accuracy: 68.06, Precision: 67.87, Recall: 67.70, F-Score: 67.78\n\n2. **SVM**:\n   - Unigram: Accuracy: 80.73, Precision: 80.65, Recall: 77.21, F-Score: 78.89\n   - Bigram: Accuracy: 84.71, Precision: 85.18, Recall: 83.15, F-Score: 84.15\n   - Reduced Feature Set (Using PCA): Accuracy: 74.10, Precision: 75.00, Recall: 73.21, F-Score: 74.09\n\n3. **Decision Tree**:\n   - Unigram: Accuracy: 76.06, Precision: 79.56, Recall: 69.28, F-Score: 74.06\n   - Bigram: Accuracy: 77.43, Precision: 80.22, Recall: 71.34, F-Score: 75.52\n   - Reduced Feature Set (Using PCA): Accuracy: 70.70, Precision: 76.17, Recall: 68.77, F-Score: 72.28\n\n4. **Random Forest**:\n   - Unigram: Accuracy: 70.7, Precision: 74.04, Recall: 70.04, F-Score: 71.98\n   - Bigram: Accuracy: 69.56, Precision: 84.70, Recall: 50.87, F-Score: 63.56\n   - Reduced Feature Set (Using PCA): Accuracy: 76.00, Precision: 78.77, Recall: 74.69, F-Score: 76.68\n\n5. **KNN**:\n   - Unigram: Accuracy: 74.78, Precision: 73.05, Recall: 72.82, F-Score: 72.93\n   - Bigram: Accuracy: 73.87, Precision: 70.34, Recall: 66.29, F-Score: 68.25\n   - Reduced Feature Set (Using PCA): Accuracy: 72.55, Precision: 73.85, Recall: 73.33, F-Score: 73.59\n\n6. **Bagging**:\n   - Unigram: Accuracy: 83.12, Precision: 82.21, Recall: 81.01, F-Score: 81.61\n   - Bigram: Accuracy: 83.66, Precision: 81.89, Recall: 80.01, F-Score: 80.94\n   - Reduced Feature Set (Using PCA): Accuracy: 70.17, Precision: 73.91, Recall: 68.44, F-Score: 71.07\n\n7. **Boosting**:\n   - Unigram: Accuracy: 81.81, Precision: 80.30, Recall: 78.56, F-Score: 79.42\n   - Bigram: Accuracy: 84.43, Precision: 86.29, Recall: 82.76, F-Score: 84.49\n   - Reduced Feature Set (Using PCA): Accuracy: 72.52, Precision: 73.39, Recall: 71.43, F-Score: 72.40",
        "answer_encoded": "[response not coded] The study evaluated performance metrics (Accuracy, Precision, Recall, F-Score) for various classification algorithms, with values varying across methods: Naïve Bayes (Unigram: Acc 83.16, Prec 82.81, Rec 80.2, F-Score 81.48), SVM (Bigram: Acc 84.71, Prec 85.18, Rec 83.15, F-Score 84.15), Decision Tree (Bigram: Acc 77.43, Prec 80.22, Rec 71.34, F-Score 75.52), Random Forest (Reduced Feature Set: Acc 76.00, Prec 78.77, Rec 74.69, F-Score 76.68), KNN (Unigram: Acc 74.78, Prec 73.05, Rec 72.82, F-Score 72.93), Bagging (Bigram: Acc 83.66, Prec 81.89, Rec 80.01, F-Score 80.94), and Boosting (Bigram: Acc 84.43, Prec 86.29, Rec 82.76, F-Score 84.49).",
        "answer_contexts": [
                {
                    "context": "This table compares the performance of various classification algorithms using different feature extraction methods: Unigram, Bigram, and a Reduced Feature Set through PCA. Metrics such as Accuracy, Precision, Recall, and F-Score are provided for each algorithm.,\nwith the following table title:\nClassification Algorithms Performance Comparison,\nwith the following columns:\n- Classification Algorithms: Different algorithms used for classification.\n- Unigram: Performance metrics for classification using Unigram feature extraction.\n- Bigram: Performance metrics for classification using Bigram feature extraction.\n- Reduced Feature Set (Using PCA): Performance metrics for classification using a reduced feature set through PCA.\n\n| Classification Algorithms | Unigram                                                       | Bigram                                                        | Reduced Feature Set (Using PCA)                               |\n|---|---|---|---|\n| Naïve Bayes’              | Accuracy: 83.16 Precision: 82.81 Recall: 80.2 F-Score: 81.48  | Accuracy: 81.05 Precision: 79.73 Recall: 80.84 F-Score: 80.28 | Accuracy: 68.06 Precision: 67.87 Recall: 67.70 F-Score: 67.78 |\n| SVM                       | Accuracy: 80.73 Precision: 80.65 Recall: 77.21 F-Score: 78.89 | Accuracy: 84.71 Precision: 85.18 Recall: 83.15 F-Score: 84.15 | Accuracy: 74.10 Precision: 75.00 Recall: 73.21 F-Score: 74.09 |\n| Decision Tree             | Accuracy: 76.06 Precision: 79.56 Recall: 69.28 F-Score: 74.06 | Accuracy: 77.43 Precision: 80.22 Recall: 71.34 F-Score: 75.52 | Accuracy: 70.70 Precision: 76.17 Recall: 68.77 F-Score: 72.28 |\n| Random Forest             | Accuracy: 70.7 Precision: 74.04 Recall: 70.04 F-Score: 71.98  | Accuracy: 69.56 Precision: 84.70 Recall: 50.87 F-Score: 63.56 | Accuracy: 76.00 Precision: 78.77 Recall: 74.69 F-Score: 76.68 |\n| KNN                       | Accuracy: 74.78 Precision: 73.05 Recall: 72.82 F-Score: 72.93 | Accuracy: 73.87 Precision: 70.34 Recall: 66.29 F-Score: 68.25 | Accuracy: 72.55 Precision: 73.85 Recall: 73.33 F-Score: 73.59 |\n| Bagging                   | Accuracy: 83.12 Precision: 82.21 Recall: 81.01 F-Score: 81.61 | Accuracy: 83.66 Precision: 81.89 Recall: 80.01 F-Score: 80.94 | Accuracy: 70.17 Precision: 73.91 Recall: 68.44 F-Score: 71.07 |\n| Boosting                  | Accuracy: 81.81 Precision: 80.30 Recall: 78.56 F-Score: 79.42 | Accuracy: 84.43 Precision: 86.29 Recall: 82.76 F-Score: 84.49 | Accuracy: 72.52 Precision: 73.39 Recall: 71.43 F-Score: 72.40 |",
                    "score": 0.8663882131335315
                },
                {
                    "context": "This table presents the performance metrics of various machine learning algorithms (SVM, Naive Bayes, Decision Tree, KNN, Random Forest, and Boosting) across different sample sizes (400, 600, 1000) and techniques (Bagging).,\nwith the following columns:\n- Sample Size: Different sample sizes used for evaluating the algorithms.\n- SVM: Performance metric for Support Vector Machine.\n- Naive Bayes: Performance metric for Naive Bayes classifier.\n- Decision Tree: Performance metric for Decision Tree algorithm.\n- KNN: Performance metric for K-Nearest Neighbors.\n- Random Forest: Performance metric for Random Forest algorithm.\n- Boosting: Performance metric for Boosting techniques.\n\n|         | SVM | Naive Bayes | Decision Tree | KNN | Random Forest | Boosting |\n|---|---|---|---|---|---|---|\n| 400     | 90  | 60          | 0             | 70  |               |          |\n| 600     | 50  | 40          | 30            | 20  | 10            |          |\n| 1000    |     |             |               |     |               |          |\n| Bagging |     |             |               |     |               |          |",
                    "score": 0.8447892713032484
                },
                {
                    "context": "The second approach in our analysis was to evaluate our hypothesis of identifying tweets having extreme or neutral views. For this purpose, we opted to apply various classifiers like naïve Bayes, SVM, decision tree, random forest, KNN and ensemble classification models (see Section 4.3). The classification performance is presented in the form of evaluation measures like predictive accuracy, precision, recall, F-score. Classification models often face complexity in terms of training process when working with high-dimensional data. Therefore, we apply PCA to reduce the dimensions considering the assumption that the reduced set of features preserves maximum structure (in terms of variance preservation) of the data and this reduced set of features will be used by the classification models. The classification results, in term of evaluation measures, with various set of features (i.e., unigram, bigram, PCA-based reduced feature set) are presented in Table 5. The results illustrate that the proposed framework has encouraging outcomes for radical/extreme content identification and aspect-based sentiment analysis of tweets.\n\n Table 5. Average score on unigram, bigram feature set and Principal Component Analysis (PCA)-based reduced feature set.",
                    "score": 0.6662415000579744
                },
                {
                    "context": "This table presents the performance metrics of various machine learning algorithms (SVM, Naive Bayes, Decision Tree, KNN, Random Forest, Boosting) across different n-gram models (1-gram, 2-gram) in a classification task. The values indicate accuracy percentages for each algorithm and n-gram combination.,\nwith the following columns:\n- n-gram: Different n-gram models used for classification.\n- SVM: Accuracy percentage of the SVM algorithm.\n- Naive Bayes: Accuracy percentage of the Naive Bayes algorithm.\n- Decision Tree: Accuracy percentage of the Decision Tree algorithm.\n- KNN: Accuracy percentage of the KNN algorithm.\n- Random Forest: Accuracy percentage of the Random Forest algorithm.\n- Boosting: Accuracy percentage of the Boosting algorithm.\n\n|         | SVM | Naive Bayes | Decision Tree | KNN | Random Forest | Boosting |\n|---|---|---|---|---|---|---|\n| 1-gram  | 90  | 68          | 80            | 0   | 70            |          |\n| 2-gram  | 60  | 50          | 40            | 30  | 20            | 10       |\n| 3-gram  |     |             |               |     |               |          |\n| 4-gram  |     |             |               |     |               |          |\n| Bagging |     |             |               |     |               |          |",
                    "score": 0.503072541557097
                },
                {
                    "context": "It can be observed from the results that naïve Bayes’ has shown a better result with 83.16% accuracy on unigram features. The SVM has demonstrated an improvement in the predictive accuracy (with 84.71% accuracy) with bigram features in comparison with unigram features. The ensemble techniques (i.e., boosting and bagging) are also comparable due to the high and stable accuracy over n-grams features. All other individual models (decision tree, KNN, random forest) have maintained less than 80% accuracy. Similarly, all the classifiers are also tested on a reduced feature set obtained through PCA. We present here the results obtained using a reduced feature set preserving 95% variance in the dataset. The experiments were also performed with a reduced feature set ensuring 90% variance in the dataset, but the classification predictive accuracy was not much different. PCA helped to reduce the high dimension features into low dimensions to minimize the overall analysis time required by the classification model training process. The outcome of classifiers on these reduced features is also depicted in Table 5 reporting the random forest by achieving highest accuracy (76%). The results indicate that PCA-based reduced feature set has shown compromised performance of classifiers compared with complete feature set.\n\nOverall, the results of our experiments demonstrate that SVM and ensemble techniques are more stable and accurate to identify extremism from the content of the Twitter dataset. From a feature sets like TF-IDF from uni-gram and bi-gram features and PCA based reduced feature set, the TF-IDF computed from bi-gram features was observed to be more effective with an average accuracy of 84%.\n\n 4.4.1. n-Gram Comparison\n\nIt is evident from Figure 6 that bigram provides a good stable performance compared with a unigram and trigram regarding the ability to capture the sentiment expressed. On the other hand, the bigram signifies an optimal result to carry out the sentiment analysis of tweets concerning extreme/radical identification. It is obvious from Figure 6 that naïve Bayes’ and decision tree vary with the value of ‘n’ as compared to SVM, bagging, boosting and KNN, etc.",
                    "score": 0.3422329032941709
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific performance metrics were evaluated in the study, and what were their corresponding values?",
                    "answer": "The study evaluated several performance metrics, including Accuracy, Precision, Recall, and F-Score for various classification algorithms. Here are the corresponding values for each algorithm using different feature extraction methods:\n\n1. **Naïve Bayes**:\n   - Unigram: Accuracy: 83.16, Precision: 82.81, Recall: 80.2, F-Score: 81.48\n   - Bigram: Accuracy: 81.05, Precision: 79.73, Recall: 80.84, F-Score: 80.28\n   - Reduced Feature Set (Using PCA): Accuracy: 68.06, Precision: 67.87, Recall: 67.70, F-Score: 67.78\n\n2. **SVM**:\n   - Unigram: Accuracy: 80.73, Precision: 80.65, Recall: 77.21, F-Score: 78.89\n   - Bigram: Accuracy: 84.71, Precision: 85.18, Recall: 83.15, F-Score: 84.15\n   - Reduced Feature Set (Using PCA): Accuracy: 74.10, Precision: 75.00, Recall: 73.21, F-Score: 74.09\n\n3. **Decision Tree**:\n   - Unigram: Accuracy: 76.06, Precision: 79.56, Recall: 69.28, F-Score: 74.06\n   - Bigram: Accuracy: 77.43, Precision: 80.22, Recall: 71.34, F-Score: 75.52\n   - Reduced Feature Set (Using PCA): Accuracy: 70.70, Precision: 76.17, Recall: 68.77, F-Score: 72.28\n\n4. **Random Forest**:\n   - Unigram: Accuracy: 70.7, Precision: 74.04, Recall: 70.04, F-Score: 71.98\n   - Bigram: Accuracy: 69.56, Precision: 84.70, Recall: 50.87, F-Score: 63.56\n   - Reduced Feature Set (Using PCA): Accuracy: 76.00, Precision: 78.77, Recall: 74.69, F-Score: 76.68\n\n5. **KNN**:\n   - Unigram: Accuracy: 74.78, Precision: 73.05, Recall: 72.82, F-Score: 72.93\n   - Bigram: Accuracy: 73.87, Precision: 70.34, Recall: 66.29, F-Score: 68.25\n   - Reduced Feature Set (Using PCA): Accuracy: 72.55, Precision: 73.85, Recall: 73.33, F-Score: 73.59\n\n6. **Bagging**:\n   - Unigram: Accuracy: 83.12, Precision: 82.21, Recall: 81.01, F-Score: 81.61\n   - Bigram: Accuracy: 83.66, Precision: 81.89, Recall: 80.01, F-Score: 80.94\n   - Reduced Feature Set (Using PCA): Accuracy: 70.17, Precision: 73.91, Recall: 68.44, F-Score: 71.07\n\n7. **Boosting**:\n   - Unigram: Accuracy: 81.81, Precision: 80.30, Recall: 78.56, F-Score: 79.42\n   - Bigram: Accuracy: 84.43, Precision: 86.29, Recall: 82.76, F-Score: 84.49\n   - Reduced Feature Set (Using PCA): Accuracy: 72.52, Precision: 73.39, Recall: 71.43, F-Score: 72.40"
                },
                {
                    "question": "[SQ] What were the feature extraction methods used in the study for each classification algorithm?",
                    "answer": "The feature extraction methods used in the study for each classification algorithm were Unigram, Bigram, and a Reduced Feature Set through PCA."
                },
                {
                    "question": "[SQ] How did the performance metrics vary across different classification algorithms?",
                    "answer": "The performance metrics varied significantly across different classification algorithms. For instance, in the evaluation using Unigram feature extraction, Naïve Bayes achieved an accuracy of 83.16, while Random Forest had a lower accuracy of 70.7. SVM performed well with an accuracy of 80.73, and Decision Tree showed an accuracy of 76.06. When using Bigram feature extraction, SVM's accuracy increased to 84.71, while Naïve Bayes dropped to 81.05. \n\nIn terms of the Reduced Feature Set using PCA, Naïve Bayes had the lowest accuracy at 68.06, whereas Random Forest improved to 76.00. The ensemble methods, Bagging and Boosting, also demonstrated competitive performance, with Bagging achieving an accuracy of 83.12 using Unigram and Boosting reaching 84.43 with Bigram.\n\nOverall, the results indicate that different algorithms respond differently to feature extraction methods, with some algorithms consistently outperforming others across various metrics."
                },
                {
                    "question": "[SQ] Were there any notable trends or patterns observed in the performance metrics based on the feature extraction methods?",
                    "answer": "Notable trends observed in the performance metrics indicate that the use of bigram feature extraction generally resulted in improved accuracy compared to unigram features for several classification algorithms, particularly for SVM and ensemble techniques like boosting. Additionally, while the reduced feature set obtained through PCA showed a decrease in performance across most algorithms, random forest achieved the highest accuracy among the classifiers tested with this method. Overall, bigram features appeared to provide a more stable and effective approach for sentiment analysis, especially in identifying extreme content in tweets."
                },
                {
                    "question": "[MQ] What performance metrics, including Accuracy, Precision, Recall, and F-Score, were evaluated in the study for various classification algorithms using Unigram, Bigram, and Reduced Feature Set (PCA), and what were their corresponding values?",
                    "answer": "The performance metrics evaluated for various classification algorithms using Unigram, Bigram, and Reduced Feature Set (PCA) include Accuracy, Precision, Recall, and F-Score. The corresponding values for each algorithm are as follows:\n\n**Naïve Bayes:**\n- Unigram: Accuracy: 83.16, Precision: 82.81, Recall: 80.2, F-Score: 81.48\n- Bigram: Accuracy: 81.05, Precision: 79.73, Recall: 80.84, F-Score: 80.28\n- Reduced Feature Set (PCA): Accuracy: 68.06, Precision: 67.87, Recall: 67.70, F-Score: 67.78\n\n**SVM:**\n- Unigram: Accuracy: 80.73, Precision: 80.65, Recall: 77.21, F-Score: 78.89\n- Bigram: Accuracy: 84.71, Precision: 85.18, Recall: 83.15, F-Score: 84.15\n- Reduced Feature Set (PCA): Accuracy: 74.10, Precision: 75.00, Recall: 73.21, F-Score: 74.09\n\n**Decision Tree:**\n- Unigram: Accuracy: 76.06, Precision: 79.56, Recall: 69.28, F-Score: 74.06\n- Bigram: Accuracy: 77.43, Precision: 80.22, Recall: 71.34, F-Score: 75.52\n- Reduced Feature Set (PCA): Accuracy: 70.70, Precision: 76.17, Recall: 68.77, F-Score: 72.28\n\n**Random Forest:**\n- Unigram: Accuracy: 70.7, Precision: 74.04, Recall: 70.04, F-Score: 71.98\n- Bigram: Accuracy: 69.56, Precision: 84.70, Recall: 50.87, F-Score: 63.56\n- Reduced Feature Set (PCA): Accuracy: 76.00, Precision: 78.77, Recall: 74.69, F-Score: 76.68\n\n**KNN:**\n- Unigram: Accuracy: 74.78, Precision: 73.05, Recall: 72.82, F-Score: 72.93\n- Bigram: Accuracy: 73.87, Precision: 70.34, Recall: 66.29, F-Score: 68.25\n- Reduced Feature Set (PCA): Accuracy: 72.55, Precision: 73.85, Recall: 73.33, F-Score: 73.59\n\n**Bagging:**\n- Unigram: Accuracy: 83.12, Precision: 82.21, Recall: 81.01, F-Score: 81.61\n- Bigram: Accuracy: 83.66, Precision: 81.89, Recall: 80.01, F-Score: 80.94\n- Reduced Feature Set (PCA): Accuracy: 70.17, Precision: 73.91, Recall: 68.44, F-Score: 71.07\n\n**Boosting:**\n- Unigram: Accuracy: 81.81, Precision: 80.30, Recall: 78.56, F-Score: 79.42\n- Bigram: Accuracy: 84.43, Precision: 86.29, Recall: 82.76, F-Score: 84.49\n- Reduced Feature Set (PCA): Accuracy: 72.52, Precision: 73.39, Recall: 71.43, F-Score: 72.40"
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 0.0,
                "faithfulness": 1.0,
                "semantic_similarity": 0.7602532702269482,
                "llm_context_precision_without_reference": 0.9999999999875,
                "llm_context_precision_with_reference": 0.16666666665,
                "answer_relevancy": 0.8628691298047952,
                "answer_correctness": 0.19006331755673705
            },
            "deepeval": {
                "contextual_precision": 0.6666666666666666,
                "contextual_recall": 0.0,
                "contextual_relevancy": 0.5660377358490566,
                "answer_relevancy": 1.0,
                "faithfulness": 0.036585365853658534
            }
        }
    },
        {
        "id": 31,
        "job_id": 1,
        "file_id": 7,
        "question_id": 1,
        "status": "done",
        "answer_text": "The study employed KNN (K-Nearest Neighbors) and LibSVM (Support Vector Machine) as the AI algorithms for detecting online radicalization on Twitter. These algorithms contribute to the overall findings by enabling the classification and identification of patterns associated with radicalization, enhancing the understanding of how such content can be detected and filtered on social media platforms.",
        "answer_encoded": "SVM",
        "answer_contexts": [
                {
                    "context": "Using KNN and SVM Based One-Class Classifier for Detecting Online Radicalization on Twitter\n\nConference Paper in Lecture Notes in Computer Science · February 2015\n\nDOI: 10.1007/978-3-319-14977-6_47",
                    "score": 0.6809830801887677
                },
                {
                    "context": "Using KNN and SVM Based One-Class Classifier for Detecting Online Radicalization on Twitter\n\n Swati Agarwal and Ashish Sureka\n\n Indraprastha Institute of Information Technology, Delhi (IIIT-D)\n\n New Delhi, India\n\n Email: swatia@iiitd.ac.in, ashish@iiitd.ac.in\n\n Abstract\n\nTwitter is the largest and most popular micro-blogging website on the Internet. Due to low publication barrier, anonymity, and wide penetration, Twitter has become an easy target or platform for extremists to disseminate their ideologies and opinions by posting hate and extremism promoting tweets. Millions of tweets are posted on Twitter every day and it is practically impossible for Twitter moderators or an intelligence and security analyst to manually identify such tweets, users, and communities. However, automatic classification of tweets into predefined categories is a non-trivial problem due to the short text of the tweet (the maximum length of a tweet can be 140 characters) and noisy content (incorrect grammar, spelling mistakes, presence of standard and non-standard abbreviations and slang). We frame the problem of hate and extremism promoting tweet detection as a one-class or unary-class categorization problem by learning a statistical model from a training set containing only the objects of one class. We propose several linguistic features such as presence of war, religious, negative emotions, and offensive terms to discriminate hate and extremism promoting tweets from other tweets. We employ a single-class SVM and KNN algorithm for one-class classification task. We conduct a case-study on Jihad, perform a characterization study of the tweets and measure the precision and recall of the machine-learning based classifier. Experimental results on large and real-world dataset demonstrate that the proposed approach is effective with F-score of 0.60 and 0.83 for the KNN and SVM classifier respectively.\n\n Keywords\n\nMining User Generated Content, One-Class Classifier, Online Radicalization, Short-Text Classification, Social media analytics, Twitter.\n\n 1 Research Motivation and Aim\n\nTwitter1 is a popular social networking website and the largest micro-blogging platform on the Internet. Twitter allows users to share ideas and information instantly by posting short messages of 140 characters called as Tweets.\n\n1 https://twitter.com/\n\nR. Natarajan et al. (Eds.): ICDCIT 2015, LNCS 8956, pp. 431–442, 2015.\n\n© Springer International Publishing Switzerland 2015",
                    "score": 0.5942879014276637
                },
                {
                    "context": "Using KNN and SVM Based One-Class Classifier for Detecting Online\n\n Fig. 3. Impact of Individual Feature on Overall Accuracy of A Classifier.\n\nRE= Religious, WR= War Related, BW= Bad Words, NE= Negative Emotions, EC= Emoticons, IS= Internet Slangs.\n\nVariance in overall accuracy of one class classifiers (KNN and LibSVM) after removing one feature vector at a time. Figure 3(a) reveals that if we remove religious or war related terms then the accuracy of KNN classifier decreases by 20 to 25%. Removing bad words or negative emoticons from feature vectors, accuracy falls down by 11 to 13%. Figure 3(a) reveals that internet slangs, emoticons and punctuations (! and ? marks) are less important features and doesn’t affect the accuracy by a major difference but we cannot neglect them completely because they affect the overall accuracy by 2 to 3%. Figure 3(b) reveals that in one class LibSVM classifier, presence of religious, war related terms, bad words and negative emotions plays an important role. And by removing any of these features, overall accuracy of classifier decreases by 20 to 45%. Ignoring presence of internet slangs and exclamation marks doesn’t affect accuracy. Unlike KNN classifier, removing emoticons and question marks decreases the performance by a reasonable rate. The reason of this misclassification is the presence of noisy content and sparsity in datasets. Feature space of testing dataset is a matrix of size 1M*8, where 70% of entries are 0.\n\n 6 Conclusion\n\nHate and extremism promoting users and Tweets are prevalent on Twitter. We observe presence of tweets containing hashtags indicating hate and extremism and also tweets which do not contain such hashtags but are hate and extremism promoting. We conduct a manual analysis of tweets and identify linguistic features which can be used as discriminators for the task of identifying hate and extremism promoting tweets. We demonstrate a correlation between such tweets and features like presence of war, religious, negative emotions and offensive terms. We train a one-class SVM and KNN on 10,486 positive class tweets.",
                    "score": 0.5820629849737693
                },
                {
                    "context": "Using KNN and SVM Based One-Class Classifier for Detecting Online\n\n Table 1. Summary of Literature Survey of 9 Papers on Detecting Various Forms of Radicalization on Twitter",
                    "score": 0.5768526918056012
                },
                {
                    "context": "S. Agarwal and A. Sureka shows that Twitter has become a platform for online radicalization and posting hate and extremism promoting content due to low publication barrier, lack of stringent moderation, anonymity and wide penetration [2][4][9].\n\nAutomatic identification of hate and extremism promoting tweets is useful to intelligence and security informatics agents as well as Twitter moderators. Manual identification of such tweets and filtering information from raw data is practically impossible due to the large volumes of tweets (500 million) posted every day. Tweets consist of short text (maximum of 140 characters) and noise (incorrect grammar, spelling mistakes, slang and abbreviations) as a result of which automatic classification of tweets is a technically challenging problem.\n\nThe motivation of the work presented in this paper is to investigate solutions to address the problems encountered by intelligence and security informatics agents and Twitter moderators for countering online radicalization on the largest micro-blogging platform on Internet. The research aim of the work presented in this paper is the following:\n\n1. To investigate techniques to automatically identify hate and extremism promoting tweets. To identify linguistic and stylistic features and characteristics of hate and extremism promoting tweets.\n2. To conduct empirical analysis on a large real-world dataset and demonstrate the effectiveness of the proposed Machine Learning based text classification approach. To examine the relative influence of each proposed feature for the task of identifying hate and extremism promoting tweets. To compare and contrast the performance of various Machine Learning algorithms (KNN and LibSVM) for the purpose of recognizing hate and extremism promoting tweets.\n\n 2 Related Work and Research Contributions\n\nWe conduct a literature survey in the area of online radicalization detection on Web 2.0 (refer to Table 1) and textual classification of microblogs (refer to Table 2). Online radicalization, hate and extremism has been studied on multiple topics and domains: terrorism, anti-black communities, nationalism, politics, jihad and anti-Islam. Table 1 and 2 also mentions the experimental dataset size used in each study. We characterize papers based on the linguistic features used for the classification task and highlight the tweet classification goals: humor [10], irony [10], sarcasm [7], spam [8], vulgarity [12] and sentiments. There are many categories in tweet classification but due to page limitation we discuss a few of them here. Table 3(a) and 3(b) shows the dimensions for reviewing these categories and features respectively. We conclude from the related work that there is a research gap in the area of hate and extremism promoting tweet classification (intersection of online radicalization on Web 2.0 and short text or micro-blog classification). In context to existing work, the study presented in this paper makes the following unique contributions extending our previous work ([1]).",
                    "score": 0.39161136736373847
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific AI algorithm was utilized in the study, and how does it contribute to the overall findings presented in the article?",
                    "answer": "The study employed KNN (K-Nearest Neighbors) and SVM (Support Vector Machine) as the AI algorithms for detecting online radicalization on Twitter. These algorithms contribute to the overall findings by enabling the classification and identification of patterns associated with radicalization, thus enhancing the understanding of how such content can be detected and filtered on social media platforms."
                },
                {
                    "question": "[SQ] What are the key features used by the KNN and SVM algorithms in the study?",
                    "answer": "The key features used by the KNN and SVM algorithms in the study include religious terms, war-related terms, bad words, negative emotions, emoticons, and internet slangs. These features serve as discriminators for identifying hate and extremism promoting tweets."
                },
                {
                    "question": "[SQ] How do the results from KNN compare to those from SVM in terms of accuracy and effectiveness?",
                    "answer": "The results indicate that the LibSVM classifier outperforms the KNN classifier in terms of accuracy and effectiveness. Specifically, the accuracy of the LibSVM classifier is 97%, while the KNN classifier achieves an accuracy of 90%. Additionally, the precision, F-score, and recall metrics are significantly higher for the LibSVM classifier compared to the KNN classifier, demonstrating that LibSVM is more effective in correctly identifying hate and extremism promoting tweets."
                },
                {
                    "question": "[SQ] What specific patterns of online radicalization were identified through the application of these algorithms?",
                    "answer": "The algorithms identified specific linguistic features and characteristics associated with hate and extremism promoting tweets. These features included the presence of terms related to war, religion, negative emotions, and offensive language. By analyzing these patterns, the algorithms aimed to effectively discriminate between hate and extremism promoting tweets and other types of tweets. The empirical analysis conducted on a large dataset demonstrated the effectiveness of the proposed machine learning approaches in recognizing these patterns."
                },
                {
                    "question": "[MQ] What AI algorithms were used in the study for detecting online radicalization on Twitter, and how do KNN and LibSVM contribute to identifying patterns associated with hate and extremism in tweets?",
                    "answer": "The study utilized KNN (K-Nearest Neighbors) and LibSVM (Support Vector Machine) as the AI algorithms for detecting online radicalization on Twitter. These algorithms contribute to identifying patterns associated with hate and extremism in tweets by employing a one-class classification approach. This method allows the algorithms to learn from a training set that contains only examples of hate and extremism promoting tweets, enabling them to recognize and classify similar tweets based on linguistic features such as the presence of war-related terms, religious references, negative emotions, and offensive language. The effectiveness of these algorithms was demonstrated through empirical analysis on a large dataset, showcasing their ability to accurately classify tweets and measure performance metrics like precision and recall."
                },
                {
                    "question": "[SQ] What role do linguistic features play in the effectiveness of KNN and LibSVM for detecting online radicalization?",
                    "answer": "Linguistic features play a crucial role in the effectiveness of KNN and LibSVM classifiers for detecting online radicalization. The presence of specific features such as religious terms, war-related terms, offensive words, and negative emotions significantly influences the accuracy of these classifiers. For the KNN classifier, removing religious or war-related terms can lead to a decrease in accuracy by 20 to 25%, while the removal of bad words or negative emoticons results in an accuracy drop of 11 to 13%. In contrast, the LibSVM classifier shows an even greater sensitivity, with accuracy decreasing by 20 to 45% when any of the key features are removed. Although some features like internet slangs and punctuation marks have a lesser impact, they still contribute to the overall accuracy. Thus, the careful selection and inclusion of these linguistic features are essential for enhancing the performance of the classifiers in identifying hate and extremism promoting tweets."
                },
                {
                    "question": "[SQ] How does the one-class classification approach enhance the performance of KNN and LibSVM in identifying hate and extremism in tweets?",
                    "answer": "The one-class classification approach enhances the performance of KNN and LibSVM in identifying hate and extremism in tweets by focusing on learning a statistical model from a training set that contains only examples of the target class, which in this case are hate and extremism promoting tweets. This method allows the classifiers to effectively distinguish between the target class and outliers without requiring a balanced dataset of both positive and negative examples.\n\nBy utilizing specific linguistic features such as the presence of war-related terms, religious references, negative emotions, and offensive language, the classifiers can better discriminate between hate-promoting content and benign tweets. The empirical analysis demonstrates that the removal of critical features significantly impacts the accuracy of the classifiers, indicating that the one-class approach is sensitive to these discriminative features.\n\nFurthermore, the experimental results show that the one-class LibSVM classifier outperforms the KNN classifier in terms of precision, recall, and overall accuracy, highlighting the effectiveness of this approach in handling the challenges posed by the noisy and sparse nature of tweet data. This targeted classification strategy allows for a more robust identification of harmful content, ultimately improving the detection of online radicalization on platforms like Twitter."
                },
                {
                    "question": "[SQ] What are the limitations of using KNN and LibSVM in the context of detecting online radicalization on Twitter?",
                    "answer": "The limitations of using KNN and LibSVM for detecting online radicalization on Twitter include challenges related to the noisy content and sparsity of the dataset. The presence of incorrect grammar, spelling mistakes, and the use of slang and abbreviations in tweets complicates the automatic classification process. Additionally, the feature space can be sparse, with a significant portion of entries being zero, which may affect the classifiers' performance. The reliance on specific linguistic features, such as the presence of religious or war-related terms, is crucial; removing these features can lead to a substantial decrease in accuracy. Furthermore, while some features like internet slangs and emoticons have a minor impact on accuracy, others are critical, and their removal can significantly hinder the classifiers' effectiveness."
                },
                {
                    "question": "[MQ] What AI algorithms, specifically KNN and LibSVM, were utilized in the study for detecting online radicalization on Twitter, and how do they leverage linguistic features to effectively identify patterns of hate and extremism in tweets?",
                    "answer": "The study utilized K-Nearest Neighbors (KNN) and Support Vector Machine (SVM) as one-class classifiers to detect online radicalization on Twitter. These algorithms were employed to frame the problem of identifying hate and extremism promoting tweets as a one-class categorization task, where the model is trained solely on examples from the target class.\n\nTo effectively identify patterns of hate and extremism in tweets, the study leveraged various linguistic features. These features included the presence of terms related to war, religious references, negative emotions, and offensive language. By analyzing these features, the classifiers could discriminate between hate and extremism promoting tweets and other types of tweets. The effectiveness of the classifiers was demonstrated through empirical analysis on a large dataset, achieving notable precision and recall metrics, indicating their capability to recognize harmful content amidst the noisy and short-text nature of tweets."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 0.9999999999999999,
                "llm_context_precision_without_reference": 0.7415305653874605,
                "llm_context_precision_with_reference": 0.7415305653874605,
                "answer_relevancy": 0.757677075175033,
                "answer_correctness": 0.9999995368498091
            },
            "deepeval": {
                "contextual_precision": 0.7654761904761903,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.36538461538461536,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 32,
        "job_id": 1,
        "file_id": 7,
        "question_id": 2,
        "status": "done",
        "answer_text": "The analysis in the study focused on specific linguistic features indicative of hate and extremism promoting content. Key features included the presence of religious and war-related terms, offensive language, and expressions of negative emotions. These features were justified due to their strong correlation with the identification of hate-promoting tweets, as demonstrated by empirical analysis that highlighted their significant impact on classification accuracy. The research objectives aimed to effectively filter and classify tweets, making these features essential for achieving the desired outcomes.",
        "answer_encoded": "[response not coded] The selected features for the analysis included religious and war-related terms, offensive language, and expressions of negative emotions, due to their strong correlation with hate-promoting content.",
        "answer_contexts": [
                {
                    "context": "Table 2. Summary of Literature Survey of 11 Papers on Classifying Tweets",
                    "score": 0.8161139740619137
                },
                {
                    "context": "This table presents various research studies focused on analyzing and filtering content on Twitter, highlighting their objectives, features, and the amount of data used in each study.,\nwith the following columns:\n- Reƒ: Reference identifier for each study.\n- Year: Year of publication for each research study.\n- Research Study: Indicates whether the study is a research study.\n- Objective: The main goal or aim of the research study.\n- Features: Key features or methodologies used in the study.\n- Data: Volume of data utilized in the research.\n\n| Reƒ   | Year | Research Study | Objective                                                        | Features    | Data  |\n|---|---|---|---|---|---|\n| \\[7]  |2013| ✓              | A linguistic analysis based approach to filter sarcastic tweets. | ✓ ✓ ✓ ✓     | 3.38M |\n| \\[10] |2012| ✓ ✓ ✓          | Identifying irony and humorous message on Twitter.               | ✓ ✓ ✓ ✓ ✓   | 50K   |\n| \\[12] |2012| ✓              | Identification of inappropriate and vulgar language in tweets.   | ✓ ✓         | 696M  |\n| \\[8]  |2012| ✓              | Language model to filter spam tweets in most trending topics.    | ✓ ✓ ✓ ✓ ✓ ✓ | 20M   |\n| \\[13] |2012| ✓              | Discovering valuable tweets with of interest to its audience.    | ✓ ✓ ✓ ✓ ✓   | 64M   |",
                    "score": 0.6652797837709665
                },
                {
                    "context": "1. A one-class classifier for identifying hate and extremism promoting tweets. While there has been work done in the area of humor, sarcasm, irony, sentiment, vulgar and spam tweets, to the best of our knowledge, our study is the first work on hate and extremism promoting tweet identification using a one-class classifier framework.\n\n2. An empirical analysis on real-world Twitter dataset investigating the influence of various linguistic features (discriminatory features) for the task of recognizing hate and extremism promoting tweets. We conduct a series of",
                    "score": 0.5028584386355849
                },
                {
                    "context": "This table outlines various aspects of a dataset related to tweets, including identifiers, performance metrics, classification methods, and data features.,\nwith the following table title:\nTweets Performance,\nwith the following columns:\n- Tweets: Identifies the dataset.\n- Java Language: Specifies the programming language used.\n- English: Indicates the language of the tweets.\n- Manual Annotation: Details the type of data used for classification.\n\n| Tweets             | Java Language      | English              | Manual Annotation |\n|---|---|---|---|\n| Dataset Identifier | Tweets Performance | One Class Classifier | Target Class Data |\n| Target Class       | K-NN               | Stopwords            | URL               |\n| Unknown            | LibSVM             | @Username            | Hashtags          |",
                    "score": 0.48105379893963435
                },
                {
                    "context": "S. Agarwal and A. Sureka shows that Twitter has become a platform for online radicalization and posting hate and extremism promoting content due to low publication barrier, lack of stringent moderation, anonymity and wide penetration [2][4][9].\n\nAutomatic identification of hate and extremism promoting tweets is useful to intelligence and security informatics agents as well as Twitter moderators. Manual identification of such tweets and filtering information from raw data is practically impossible due to the large volumes of tweets (500 million) posted every day. Tweets consist of short text (maximum of 140 characters) and noise (incorrect grammar, spelling mistakes, slang and abbreviations) as a result of which automatic classification of tweets is a technically challenging problem.\n\nThe motivation of the work presented in this paper is to investigate solutions to address the problems encountered by intelligence and security informatics agents and Twitter moderators for countering online radicalization on the largest micro-blogging platform on Internet. The research aim of the work presented in this paper is the following:\n\n1. To investigate techniques to automatically identify hate and extremism promoting tweets. To identify linguistic and stylistic features and characteristics of hate and extremism promoting tweets.\n2. To conduct empirical analysis on a large real-world dataset and demonstrate the effectiveness of the proposed Machine Learning based text classification approach. To examine the relative influence of each proposed feature for the task of identifying hate and extremism promoting tweets. To compare and contrast the performance of various Machine Learning algorithms (KNN and LibSVM) for the purpose of recognizing hate and extremism promoting tweets.\n\n 2 Related Work and Research Contributions\n\nWe conduct a literature survey in the area of online radicalization detection on Web 2.0 (refer to Table 1) and textual classification of microblogs (refer to Table 2). Online radicalization, hate and extremism has been studied on multiple topics and domains: terrorism, anti-black communities, nationalism, politics, jihad and anti-Islam. Table 1 and 2 also mentions the experimental dataset size used in each study. We characterize papers based on the linguistic features used for the classification task and highlight the tweet classification goals: humor [10], irony [10], sarcasm [7], spam [8], vulgarity [12] and sentiments. There are many categories in tweet classification but due to page limitation we discuss a few of them here. Table 3(a) and 3(b) shows the dimensions for reviewing these categories and features respectively. We conclude from the related work that there is a research gap in the area of hate and extremism promoting tweet classification (intersection of online radicalization on Web 2.0 and short text or micro-blog classification). In context to existing work, the study presented in this paper makes the following unique contributions extending our previous work ([1]).",
                    "score": 0.33717637277107404
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific features or characteristics were selected for analysis in the study, and how were they justified in the context of the research objectives?",
                    "answer": "The analysis in the study involved several key features or characteristics, including linguistic elements, language models, and methodologies for identifying specific types of content such as sarcasm, irony, inappropriate language, spam, and valuable tweets. These features were justified based on the research objectives, which aimed to filter and classify tweets effectively. For instance, the use of linguistic analysis was essential for understanding sarcasm, while language models were crucial for filtering spam in trending topics. The methodologies employed, such as one-class SVM and KNN classifiers, were selected to enhance the accuracy of classification tasks, ensuring that the studies could effectively address their respective goals."
                },
                {
                    "question": "[SQ] What methodologies were used to analyze the selected features, and why were they chosen?",
                    "answer": "The methodologies employed for analyzing the selected features include one-class SVM (Support Vector Machine) and KNN (K-Nearest Neighbors) classifiers. These methods were chosen for their effectiveness in classification tasks, particularly in identifying specific types of tweets, such as those promoting hate and extremism. The one-class classification approach is particularly suitable for scenarios where the focus is on detecting a target class amidst a larger dataset, which aligns with the objective of filtering and analyzing tweets based on their content."
                },
                {
                    "question": "[SQ] How did the researchers determine the relevance of linguistic elements in the context of sarcasm detection?",
                    "answer": "The researchers conducted an empirical analysis on a real-world Twitter dataset to investigate the influence of various linguistic features on the task of recognizing hate and extremism promoting tweets. They examined the impact of individual features on the overall accuracy of classifiers, specifically focusing on the presence of certain terms and expressions. By implementing a leave-one-out strategy, they assessed how the removal of specific features, such as religious or war-related terms, affected classifier performance. This approach allowed them to identify which linguistic elements were significant indicators in the classification process, although the context does not provide specific details on sarcasm detection."
                },
                {
                    "question": "[SQ] What criteria were used to classify tweets as spam or valuable, and how were these criteria validated?",
                    "answer": "The classification of tweets as spam or valuable involved the use of various linguistic features and methodologies. For spam detection, a language model was employed to filter tweets based on their relevance to trending topics, utilizing features such as keywords, patterns, and possibly user engagement metrics. The validation of these criteria was likely conducted through empirical analysis on large datasets, allowing researchers to assess the effectiveness of the classification methods. In the case of identifying valuable tweets, features that indicate user interest and engagement were analyzed, although specific validation methods for this classification were not detailed."
                },
                {
                    "question": "[MQ] What key linguistic features and methodologies were selected for the analysis of tweets in the study, and how were they justified in relation to the objectives of identifying sarcasm, spam, and hate speech?",
                    "answer": "The analysis of tweets in the study focused on various linguistic features that are indicative of hate and extremism promoting content. Key features included the presence of religious and war-related terms, offensive language, and expressions of negative emotions. These features were justified based on their strong correlation with the identification of hate-promoting tweets, as evidenced by empirical analysis showing their significant influence on classification accuracy.\n\nMethodologies employed in the study included a one-class classifier framework, which is particularly suited for the task of identifying hate and extremism due to the challenges posed by the vast volume of tweets and the complexity of their content. The study also compared different machine learning algorithms, specifically KNN and LibSVM, to evaluate their effectiveness in recognizing hate and extremism promoting tweets. The choice of these methodologies was driven by the need to develop an automated solution that could efficiently handle the large-scale data and the nuanced linguistic characteristics of tweets, which often include slang, abbreviations, and grammatical errors."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0.5,
                "semantic_similarity": 0.7917472358078306,
                "llm_context_precision_without_reference": 0.26666666665333333,
                "llm_context_precision_with_reference": 0.27146464645785984,
                "answer_relevancy": 0.8832279961399175,
                "answer_correctness": 0.19793680895195764
            },
            "deepeval": {
                "contextual_precision": 0.0,
                "contextual_recall": 0.0,
                "contextual_relevancy": 0.2545454545454545,
                "answer_relevancy": 0.5,
                "faithfulness": 0.75
            }
        },
    },
    {
        "id": 33,
        "job_id": 1,
        "file_id": 7,
        "question_id": 3,
        "status": "done",
        "answer_text": "The social network utilized for data collection in the analyzed article is Twitter.",
        "answer_encoded": "Twitter",
        "answer_contexts": [
                {
                    "context": "Table 2. Summary of Literature Survey of 11 Papers on Classifying Tweets",
                    "score": 0.6580188683857736
                },
                {
                    "context": "S. Agarwal and A. Sureka shows that Twitter has become a platform for online radicalization and posting hate and extremism promoting content due to low publication barrier, lack of stringent moderation, anonymity and wide penetration [2][4][9].\n\nAutomatic identification of hate and extremism promoting tweets is useful to intelligence and security informatics agents as well as Twitter moderators. Manual identification of such tweets and filtering information from raw data is practically impossible due to the large volumes of tweets (500 million) posted every day. Tweets consist of short text (maximum of 140 characters) and noise (incorrect grammar, spelling mistakes, slang and abbreviations) as a result of which automatic classification of tweets is a technically challenging problem.\n\nThe motivation of the work presented in this paper is to investigate solutions to address the problems encountered by intelligence and security informatics agents and Twitter moderators for countering online radicalization on the largest micro-blogging platform on Internet. The research aim of the work presented in this paper is the following:\n\n1. To investigate techniques to automatically identify hate and extremism promoting tweets. To identify linguistic and stylistic features and characteristics of hate and extremism promoting tweets.\n2. To conduct empirical analysis on a large real-world dataset and demonstrate the effectiveness of the proposed Machine Learning based text classification approach. To examine the relative influence of each proposed feature for the task of identifying hate and extremism promoting tweets. To compare and contrast the performance of various Machine Learning algorithms (KNN and LibSVM) for the purpose of recognizing hate and extremism promoting tweets.\n\n 2 Related Work and Research Contributions\n\nWe conduct a literature survey in the area of online radicalization detection on Web 2.0 (refer to Table 1) and textual classification of microblogs (refer to Table 2). Online radicalization, hate and extremism has been studied on multiple topics and domains: terrorism, anti-black communities, nationalism, politics, jihad and anti-Islam. Table 1 and 2 also mentions the experimental dataset size used in each study. We characterize papers based on the linguistic features used for the classification task and highlight the tweet classification goals: humor [10], irony [10], sarcasm [7], spam [8], vulgarity [12] and sentiments. There are many categories in tweet classification but due to page limitation we discuss a few of them here. Table 3(a) and 3(b) shows the dimensions for reviewing these categories and features respectively. We conclude from the related work that there is a research gap in the area of hate and extremism promoting tweet classification (intersection of online radicalization on Web 2.0 and short text or micro-blog classification). In context to existing work, the study presented in this paper makes the following unique contributions extending our previous work ([1]).",
                    "score": 0.6554379178181738
                },
                {
                    "context": "This table outlines various aspects of a dataset related to tweets, including identifiers, performance metrics, classification methods, and data features.,\nwith the following table title:\nTweets Performance,\nwith the following columns:\n- Tweets: Identifies the dataset.\n- Java Language: Specifies the programming language used.\n- English: Indicates the language of the tweets.\n- Manual Annotation: Details the type of data used for classification.\n\n| Tweets             | Java Language      | English              | Manual Annotation |\n|---|---|---|---|\n| Dataset Identifier | Tweets Performance | One Class Classifier | Target Class Data |\n| Target Class       | K-NN               | Stopwords            | URL               |\n| Unknown            | LibSVM             | @Username            | Hashtags          |",
                    "score": 0.5527832328340003
                },
                {
                    "context": "1. A one-class classifier for identifying hate and extremism promoting tweets. While there has been work done in the area of humor, sarcasm, irony, sentiment, vulgar and spam tweets, to the best of our knowledge, our study is the first work on hate and extremism promoting tweet identification using a one-class classifier framework.\n\n2. An empirical analysis on real-world Twitter dataset investigating the influence of various linguistic features (discriminatory features) for the task of recognizing hate and extremism promoting tweets. We conduct a series of",
                    "score": 0.3832895423777207
                },
                {
                    "context": "436 S. Agarwal and A. Sureka\n\nA semi-supervised learning3 approach to create our training dataset. Annotating Tweets is a time-consuming and tedious task (practically challenging to annotate a large dataset). Hence, we use semi-supervised learning making use of a small amount of labeled data and a large amount of unlabeled data.\n\nHashtags are strong indicators of the topic of the tweet. We create a list of seed hashtags such as #Terrorism, #Islamophobia and #Extremist and identify tweets containing these hashtags. We manually analyze tweets containing such hashtags and identify hate and extremism promoting tweets. We extend the list of hashtags by extracting new hashtags (not already in the list) present in the positive class tweets. Table 4 illustrates a sample of some seed hashtags and their respective tweets leading us to new hashtags. We then identify tweets containing the new hashtags and manually analyze the tweets to identify hate promoting tweets. As a result of this, we extend the list of hashtags and our training dataset of size S. We repeat this process several times to collect training dataset. This dataset and list of hashtags is publicly available at https://sites.google.com/a/iiitd.ac.in/agrswati/datasets.\n\nWe make our experimental dataset publicly available so that our experiments can be replicated and used for benchmark purposes by other researchers. We perform a random sampling on English tweets and use a sample as our testing (or validation) dataset. We remove the term ’RT’ (Re-Tweet), @username (username of the direct mention of a user in the tweet), URL (short URL) and hashtags. After removing these terms our problem becomes more challenging due to short text classification. In phase 4, we perform characterization and identification of various discriminatory features and compute the frequency (TF) of various terms. For example, religious, offensive, slang, negative emotions, punctuations and war related terms. Table 5 shows a sample of these terms present in hate and extremism promoting tweets. Figure 2(a) and 2(b) shows the frequency of these terms present in the training and testing dataset. While Figure 2(c) shows statistics of only positive class tweets present in testing dataset. Figure 2 also illustrates the frequency of terms that have been preprocessed in phase 3. All statistics are computed in logarithmic scale. These graphs shows that the frequency of religious and war related terms is very high in hate promoting tweets. We convert our datasets (training and testing) into a matrix of feature space; where each entity represents a TF of respective column feature in a given tweet.\n\nIn phase 5, we implement two independent one-class classifiers (KNN and LibSVM) to classify a tweet as hate promoting or unknown. We use LibSVM as it is a popular open-source machine-learning library implementing the SMO (Sequential Minimal Optimization) for SVMs supporting classification and regression. Algorithm 1 & 2 describes the procedure of KNN and LibSVM classifiers respectively. In last phase, we evaluate the performance of the two classifiers using standard confusion matrix.\n\n3 Semi-Supervised Learning: learning the classifier from a combination of both labeled and unlabeled data.",
                    "score": 0.37435074119495637
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] Which social network or platform was utilized for data collection in the analyzed article?",
                    "answer": "The social network utilized for data collection in the analyzed article is Twitter."
                },
                {
                    "question": "[SQ] What specific data collection methods were used on Twitter in the analyzed article?",
                    "answer": "The analyzed article does not specify particular data collection methods used on Twitter. However, it discusses the challenges of manually identifying and filtering tweets due to the large volume of content generated daily. The focus is on automatic identification techniques for hate and extremism promoting tweets, utilizing machine learning approaches for classification."
                },
                {
                    "question": "[SQ] How was the data from Twitter analyzed in the study?",
                    "answer": "The data from Twitter was analyzed using a semi-supervised learning approach, which involved creating a training dataset by combining a small amount of labeled data with a large amount of unlabeled data. The analysis included identifying tweets containing specific hashtags related to hate and extremism, manually analyzing these tweets to classify them, and extending the list of hashtags based on findings from the positive class tweets. The tweets were preprocessed to remove elements like retweets, usernames, URLs, and hashtags, making the classification task more challenging. Various linguistic and stylistic features were characterized, and the frequency of terms associated with hate and extremism was computed. Two machine learning classifiers, KNN and LibSVM, were implemented to classify tweets as hate promoting or unknown, with performance evaluated using a confusion matrix."
                },
                {
                    "question": "[SQ] What was the sample size of Twitter users involved in the data collection?",
                    "answer": "The information provided does not specify the sample size of Twitter users involved in the data collection for the studies mentioned. It only includes the volume of data utilized in each research study."
                },
                {
                    "question": "[MQ] Which social network was used for data collection in the analyzed article, and what methods were employed to identify and classify tweets related to hate and extremism?",
                    "answer": "The social network used for data collection in the analyzed article is Twitter. The methods employed to identify and classify tweets related to hate and extremism include a one-class classification framework utilizing machine learning algorithms, specifically K-Nearest Neighbors (KNN) and Support Vector Machine (SVM). The approach involves learning a statistical model from a training set containing only hate and extremism promoting tweets, and it incorporates various linguistic features to discriminate these tweets from others."
                },
                {
                    "question": "[SQ] What specific machine learning techniques were used to classify tweets in the study?",
                    "answer": "The study utilized two independent one-class classifiers: K-Nearest Neighbors (KNN) and Support Vector Machines (SVM) implemented through the LibSVM library."
                },
                {
                    "question": "[SQ] How were the linguistic and stylistic features selected for the classification of tweets?",
                    "answer": "The selection of linguistic and stylistic features for the classification of tweets involved conducting an empirical analysis on a large real-world dataset. This analysis aimed to identify the characteristics of hate and extremism promoting tweets. The study examined the relative influence of each proposed feature to determine their effectiveness in recognizing such tweets. Various linguistic features, referred to as discriminatory features, were investigated to enhance the classification process."
                },
                {
                    "question": "[SQ] What challenges were encountered in the data collection and classification process on Twitter?",
                    "answer": "The data collection and classification process on Twitter faced several challenges, including the sheer volume of tweets, with approximately 500 million posted daily, making manual identification and filtering of hate and extremism promoting content practically impossible. Additionally, tweets are often short, with a maximum of 140 characters, and can contain noise such as incorrect grammar, spelling mistakes, slang, and abbreviations, complicating automatic classification. Annotating a large dataset is also time-consuming and tedious, necessitating the use of semi-supervised learning to combine a small amount of labeled data with a larger amount of unlabeled data. Furthermore, the removal of certain terms like 'RT', @username, URLs, and hashtags during preprocessing adds to the complexity of the classification task."
                },
                {
                    "question": "[MQ] Which social network was utilized for data collection in the analyzed article, and what machine learning methods were employed to automatically identify and classify tweets related to hate and extremism?",
                    "answer": "The social network utilized for data collection in the analyzed article is Twitter. The machine learning methods employed to automatically identify and classify tweets related to hate and extremism are K-Nearest Neighbors (KNN) and Support Vector Machines (SVM), specifically using a one-class classification approach."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 0.9999999999999996,
                "llm_context_precision_without_reference": 0.762025012016545,
                "llm_context_precision_with_reference": 0.762025012016545,
                "answer_relevancy": 0.8087136901956149,
                "answer_correctness": 0.9999999999999999
            },
            "deepeval": {
                "contextual_precision": 0.26666666666666666,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.5308641975308642,
                "answer_relevancy": 1.0,
                "faithfulness": 0.8333333333333334
            }
        },
    },
    {
        "id": 34,
        "job_id": 1,
        "file_id": 7,
        "question_id": 4,
        "status": "done",
        "answer_text": "The size of the dataset analyzed in the article varies by study, with specific examples including 342K for the Nationalism study, 24.5K for the Anti-Black study, and 696 million for the inappropriate language study.",
        "answer_encoded": "[response not coded] The analyzed dataset sizes include 342K for the Nationalism study, 24.5K for the Anti-Black study, and 696 million for the inappropriate language study.",
        "answer_contexts": [
                {
                    "context": "This table presents various research studies focused on analyzing and filtering content on Twitter, highlighting their objectives, features, and the amount of data used in each study.,\nwith the following columns:\n- Reƒ: Reference identifier for each study.\n- Year: Year of publication for each research study.\n- Research Study: Indicates whether the study is a research study.\n- Objective: The main goal or aim of the research study.\n- Features: Key features or methodologies used in the study.\n- Data: Volume of data utilized in the research.\n\n| Reƒ   | Year | Research Study | Objective                                                        | Features    | Data  |\n|---|---|---|---|---|---|\n| \\[7]  |2013| ✓              | A linguistic analysis based approach to filter sarcastic tweets. | ✓ ✓ ✓ ✓     | 3.38M |\n| \\[10] |2012| ✓ ✓ ✓          | Identifying irony and humorous message on Twitter.               | ✓ ✓ ✓ ✓ ✓   | 50K   |\n| \\[12] |2012| ✓              | Identification of inappropriate and vulgar language in tweets.   | ✓ ✓         | 696M  |\n| \\[8]  |2012| ✓              | Language model to filter spam tweets in most trending topics.    | ✓ ✓ ✓ ✓ ✓ ✓ | 20M   |\n| \\[13] |2012| ✓              | Discovering valuable tweets with of interest to its audience.    | ✓ ✓ ✓ ✓ ✓   | 64M   |",
                    "score": 0.8128210753122254
                },
                {
                    "context": "Table 2. Summary of Literature Survey of 11 Papers on Classifying Tweets",
                    "score": 0.7226107510510615
                },
                {
                    "context": "This table outlines various aspects of a dataset related to tweets, including identifiers, performance metrics, classification methods, and data features.,\nwith the following table title:\nTweets Performance,\nwith the following columns:\n- Tweets: Identifies the dataset.\n- Java Language: Specifies the programming language used.\n- English: Indicates the language of the tweets.\n- Manual Annotation: Details the type of data used for classification.\n\n| Tweets             | Java Language      | English              | Manual Annotation |\n|---|---|---|---|\n| Dataset Identifier | Tweets Performance | One Class Classifier | Target Class Data |\n| Target Class       | K-NN               | Stopwords            | URL               |\n| Unknown            | LibSVM             | @Username            | Hashtags          |",
                    "score": 0.7195771305380906
                },
                {
                    "context": "This table presents studies conducted in 2013 that focus on various forms of online hate and extremism, detailing their objectives and datasets used.,\nwith the following table title:\nStudies on Online Hate and Extremism (2013),\nwith the following columns:\n- Reƒ: None\n- Year: None\n- Study: None\n- Objective: None\n- Dataset: None\n\n| Reƒ   | Year | Study       | Objective                                                                                         | Dataset   |\n|---|---|---|---|---|\n| \\[2]  |2013| Nationalism | Identification of most influential, active and engaged hate Tweets promoting accounts on Twitter. | 342K 3.5K |\n| \\[4]  |2013| Anti-Black  | Classification of racist and non-racist conflicts in tweets by applying statistical measures.     | 24.5K -   |\n| \\[9]  |2013| Nationalism | Identification and analysis of extreme right communities on various social networking websites.   | - 1697    |\n| \\[11] |2013| Terrorism   | Content analysis of tweets in order to identify hidden groups related to a specific topic.        | - -       |",
                    "score": 0.7184089162336255
                },
                {
                    "context": "S. Agarwal and A. Sureka\n\nand observe an F-Score of 0.83 and 0.60 respectively. We implement a leave one out strategy and examine the influence of each discriminatory feature on overall accuracy of classifiers. Based upon the accuracy results, we conclude that presence of religious, war related terms, offensive words and negative emotions are strong indicators of a tweet to be hate promoting. Unlike KNN classifier, presence of internet slangs and question mark plays an important role in LibSVM classifier.\n\n References\n\n1. Agrawal, S., Sureka, A. Learning to classify hate and extremism promoting tweets. JISIC (2014)\n2. Berger, J., Strathearn, B. Who matters online: Measuring influence, evaluating content and countering violent extremism in online social networks. The international centre for the study of radicalization and political violence (2013)\n3. Chang, C.C., Lin, C.J. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology 2, 2711–27127 (2011)\n4. Kwok, I., Wang, Y. Locate the hate: Detecting tweets against blacks. In: Twenty-Seventh AAAI Conference on Artificial Intelligence (2013)\n5. Li, R., Wang, S., Chang, K.C.C. Towards social data platform: automatic topic-focused monitor for twitter stream. Proceedings of the VLDB Endowment 6(14), 1966–1977 (2013)\n6. Li, R., Wang, S., Deng, H., Wang, R., Chang, K.C.C. Towards social user profiling: unified and discriminative influence model for inferring home locations. In: Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1023–1031. ACM (2012)\n7. Liebrecht, C., Kunneman, F., van den Bosch, A. The perfect solution for detecting sarcasm in tweets: not. Computational Approaches to Subjectivity, Sentiment and Social Media Analysis (2013)\n8. Martinez-Romo, J., Araujo, L. Detecting malicious tweets in trending topics using a statistical analysis of language. Expert Systems with Applications 40(8), 2992–3000 (2013)\n9. O’Callaghan, D., Greene, D., Conway, M., Carthy, J., Cunningham, P. Uncovering the wider structure of extreme right communities spanning popular online networks. In: Web Science Conference, pp. 276–285 (2013)\n10. Reyes, A., Rosso, P., Buscaldi, D. From humor recognition to irony detection: The figurative language of social media. Data & Knowledge Engineering 74, 1–12 (2012)\n11. Wadhwa, P., Bhatia, M.P.S. Tracking online radicalization using investigative data mining. In: NCC, pp. 1–5 (2013)\n12. Xiang, G., Fan, B., Wang, L., Hong, J., Rose, C. Detecting offensive tweets via topical feature discovery over a large scale twitter corpus. In: Proceedings of the 21st ACM International Conference on Information and Knowledge Management, pp. 1980–1984. ACM (2012)\n13. Yang, M.C., Lee, J.T., Lee, S.W., Rim, H.C. Finding interesting posts in twitter based on retweet graph analysis. In: SIGIR, pp. 1073–1074 (2012)",
                    "score": 0.18035443605339957
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What was the size of the dataset analyzed in the article?",
                    "answer": "The size of the dataset analyzed in the article varies by study, with specific examples including 342K for the Nationalism study, 24.5K for the Anti-Black study, and 3.38M for the linguistic analysis study."
                },
                {
                    "question": "[SQ] What specific methodologies were used to analyze the datasets in the article?",
                    "answer": "The methodologies used to analyze the datasets include linguistic analysis for filtering sarcastic tweets, language models for filtering spam tweets, and statistical measures for classifying racist and non-racist conflicts. Additionally, one-class classification methods such as SVM and K-NN classifiers were employed to identify hate and extremism promoting tweets. The research framework also involved phases like dataset collection, data pre-processing, feature extraction, and performance evaluation."
                },
                {
                    "question": "[SQ] How do the sizes of the datasets compare across different studies mentioned in the article?",
                    "answer": "The sizes of the datasets used in the studies vary significantly. The largest dataset is from a study focused on identifying inappropriate and vulgar language in tweets, which utilized 696 million data points. In contrast, the smallest dataset is from a study aimed at identifying irony and humorous messages, which used 50,000 data points. Other studies fall in between, with dataset sizes such as 3.38 million for a linguistic analysis of sarcastic tweets, 20 million for filtering spam tweets, and 64 million for discovering valuable tweets. The studies on online hate and extremism from 2013 also show a range, with datasets of 342,000 and 24,500 for different objectives. Overall, there is a broad spectrum of dataset sizes across the various studies."
                },
                {
                    "question": "[SQ] What criteria were used to select the datasets analyzed in the article?",
                    "answer": "The datasets analyzed in the studies were selected based on specific objectives related to content analysis on Twitter, such as identifying sarcasm, irony, inappropriate language, spam, and valuable tweets. Additionally, the volume of data varied significantly, with some studies utilizing millions of tweets to ensure a comprehensive analysis. The datasets also included various features and methodologies tailored to the specific aims of each research study."
                },
                {
                    "question": "[MQ] What were the sizes of the datasets analyzed in the studies, including specific examples such as 342K for the Nationalism study and 696 million for the inappropriate language study?",
                    "answer": "The sizes of the datasets analyzed in the studies include the following examples:\n\n- The Nationalism study utilized a dataset of 342K tweets.\n- The Anti-Black study involved a dataset of 24.5K tweets.\n- The study on extreme right communities had a dataset of 1697 entries.\n- The study on terrorism did not specify a dataset size.\n- In another study focused on identifying inappropriate and vulgar language, the dataset was significantly larger at 696 million tweets. \n\nThese examples illustrate the varying sizes of datasets used across different studies."
                },
                {
                    "question": "[SQ] What were the specific objectives of the studies that utilized the datasets mentioned?",
                    "answer": "The studies that utilized the datasets had the following specific objectives:\n\n1. **Nationalism Study**: Identification of the most influential, active, and engaged hate tweets promoting accounts on Twitter.\n2. **Anti-Black Study**: Classification of racist and non-racist conflicts in tweets by applying statistical measures.\n3. **Nationalism Study**: Identification and analysis of extreme right communities on various social networking websites.\n4. **Terrorism Study**: Content analysis of tweets in order to identify hidden groups related to a specific topic."
                },
                {
                    "question": "[SQ] How were the datasets collected and pre-processed for analysis in the studies?",
                    "answer": "Datasets were collected through a multi-step process that involved downloading publicly available datasets and combining them to create a larger and more diverse experimental dataset. This approach aimed to enhance the generalizability of the results. The collected datasets included tweets in multiple languages, but a language detection library was used to filter out non-English tweets, focusing the analysis on English language tweets, which constituted 85% of the total. This pre-processing step ensured that the training dataset was suitable for the one-class classification task aimed at identifying tweets promoting hate and extremism."
                },
                {
                    "question": "[SQ] What were the findings or conclusions drawn from the analysis of the largest dataset of 696 million tweets?",
                    "answer": "The analysis of the dataset consisting of 696 million tweets focused on the identification of inappropriate and vulgar language. The findings highlighted the challenges associated with classifying such content due to the vast volume of data and the complexities of short text, which often includes noise like incorrect grammar, spelling mistakes, slang, and abbreviations. The study aimed to demonstrate the effectiveness of machine learning approaches in automatically identifying inappropriate content, contributing to the broader understanding of tweet classification in the context of online radicalization and hate speech."
                },
                {
                    "question": "[MQ] What were the sizes of the datasets analyzed in the studies, including examples such as 342K for the Nationalism study, 24.5K for the Anti-Black study, and 696 million for the inappropriate language study?",
                    "answer": "The sizes of the datasets analyzed in the studies include the following examples: 342K for the Nationalism study, 24.5K for the Anti-Black study, and 696M for the study on inappropriate and vulgar language in tweets. Other dataset sizes mentioned are 3.5K for the Nationalism study, and 1697 for the analysis of extreme right communities."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 0.0,
                "faithfulness": 0.75,
                "semantic_similarity": 0.8179135015067208,
                "llm_context_precision_without_reference": 0.19999999998,
                "llm_context_precision_with_reference": 0.0,
                "answer_relevancy": 0.8658479421738372,
                "answer_correctness": 0.2044783753766802
            },
            "deepeval": {
                "contextual_precision": 0.5353535353535354,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.40540540540540543,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 35,
        "job_id": 1,
        "file_id": 7,
        "question_id": 5,
        "status": "done",
        "answer_text": "The specific performance metrics evaluated in the study and their corresponding values are as follows:\n\n**KNN:**\n- Precision: 0.48\n- Recall: 0.81\n- True Negative Rate (TNR): 0.92\n- Negative Predictive Value (NPV): 0.98\n- F-Score: 0.6\n- Accuracy: 0.9\n\n**LibSVM:**\n- Precision: 0.78\n- Recall: 0.88\n- True Negative Rate (TNR): 0.98\n- Negative Predictive Value (NPV): 0.99\n- F-Score: 0.83\n- Accuracy: 0.97",
        "answer_encoded": "[response not coded] The performance metrics in the study were: KNN - Precision: 0.48, Recall: 0.81, TNR: 0.92, NPV: 0.98, F-Score: 0.6, Accuracy: 0.9; LibSVM - Precision: 0.78, Recall: 0.88, TNR: 0.98, NPV: 0.99, F-Score: 0.83, Accuracy: 0.97.",
        "answer_contexts": [
                {
                    "context": "This table compares the performance metrics of two classifiers, KNN and LibSVM, including precision, recall, true negative rate (TNR), negative predictive value (NPV), F-score, and accuracy.,\nwith the following columns:\n- Classifier: The name of the classifier being evaluated.\n- Precision: The ratio of true positive predictions to the total predicted positives.\n- Recall: The ratio of true positive predictions to the total actual positives.\n- TNR: The true negative rate, indicating the proportion of actual negatives correctly identified.\n- NPV: The negative predictive value, representing the proportion of true negatives among all predicted negatives.\n- F-Score: The harmonic mean of precision and recall, providing a balance between the two.\n- Accuracy: The overall correctness of the classifier, calculated as the ratio of correct predictions to total predictions.\n\n| Classifier | Precision | Recall | TNR  | NPV  | F-Score | Accuracy |\n|---|---|---|---|---|---|---|\n| KNN        |0.48|0.81|0.92|0.98|0.6|0.9|\n| LibSVM     |0.78|0.88|0.98|0.99|0.83|0.97|",
                    "score": 0.8483542431337814
                },
                {
                    "context": "This table outlines various aspects of a dataset related to tweets, including identifiers, performance metrics, classification methods, and data features.,\nwith the following table title:\nTweets Performance,\nwith the following columns:\n- Tweets: Identifies the dataset.\n- Java Language: Specifies the programming language used.\n- English: Indicates the language of the tweets.\n- Manual Annotation: Details the type of data used for classification.\n\n| Tweets             | Java Language      | English              | Manual Annotation |\n|---|---|---|---|\n| Dataset Identifier | Tweets Performance | One Class Classifier | Target Class Data |\n| Target Class       | K-NN               | Stopwords            | URL               |\n| Unknown            | LibSVM             | @Username            | Hashtags          |",
                    "score": 0.6535597402049694
                },
                {
                    "context": "5.2 Experimental Results\n\nTo evaluate the performance of our proposed solution approach, we use basic measures of relevance used in information retrieval and machine learning. We asked 4 graduate students to manually annotate each tweet in the dataset and based upon their decisions we validate our results (we gave them simple instructions to annotate a tweet as positive if they find it hate and extremism promoting). We compute accuracy of our classifier in terms of precision, recall and f-score. Table 6(a) and 6(b) shows the standard confusion matrix for KNN and LibSVM classifiers. We execute our classifiers on a testing dataset of size 1 million records containing tweets from both target class (positive) and outliers. One class KNN algorithm classifies 142,766 (67,798 + 74,968) tweets as positive and 857,054 (15,522 + 841,712) tweets as unknown. Table 6(a) reveals that there is a misclassification of 18.6% and 8.2% in predicting target (positive) class and outlier (unknown) instances. Similarly, given an input of 1 million tweets, one class LibSVM algorithm predicts 103,975 (73,555 + 20,420) tweets as positive and 906,025 (9,765 + 896,260) tweets as unknown.\n\nTable 6(b) shows that 11.7% and 2.2% of tweets are wrongly classified as positive and unknown respectively. Table 6(c) shows accuracy results (precision, recall, f-score) for both KNN and LibSVM classifiers. Table 6(c) reveals that overall LibSVM classifier (accuracy of 97%) outperforms KNN classifier (accuracy of 90%). Results show that precision, f-score and accuracy of LibSVM classifier are much higher in comparison to KNN classifier and similarly recall is reasonably high for LibSVM classifier.\n\nWe apply leave-p-out strategy for both KNN and LibSVM classifiers (p = 1) and compute their accuracy. As discussed in Section 3, we use 8 discriminatory features to classify a tweet as hate promoting or unknown. Figure 3 shows",
                    "score": 0.3491459962647968
                },
                {
                    "context": "Using KNN and SVM Based One-Class Classifier for Detecting Online\n\n Fig. 3. Impact of Individual Feature on Overall Accuracy of A Classifier.\n\nRE= Religious, WR= War Related, BW= Bad Words, NE= Negative Emotions, EC= Emoticons, IS= Internet Slangs.\n\nVariance in overall accuracy of one class classifiers (KNN and LibSVM) after removing one feature vector at a time. Figure 3(a) reveals that if we remove religious or war related terms then the accuracy of KNN classifier decreases by 20 to 25%. Removing bad words or negative emoticons from feature vectors, accuracy falls down by 11 to 13%. Figure 3(a) reveals that internet slangs, emoticons and punctuations (! and ? marks) are less important features and doesn’t affect the accuracy by a major difference but we cannot neglect them completely because they affect the overall accuracy by 2 to 3%. Figure 3(b) reveals that in one class LibSVM classifier, presence of religious, war related terms, bad words and negative emotions plays an important role. And by removing any of these features, overall accuracy of classifier decreases by 20 to 45%. Ignoring presence of internet slangs and exclamation marks doesn’t affect accuracy. Unlike KNN classifier, removing emoticons and question marks decreases the performance by a reasonable rate. The reason of this misclassification is the presence of noisy content and sparsity in datasets. Feature space of testing dataset is a matrix of size 1M*8, where 70% of entries are 0.\n\n 6 Conclusion\n\nHate and extremism promoting users and Tweets are prevalent on Twitter. We observe presence of tweets containing hashtags indicating hate and extremism and also tweets which do not contain such hashtags but are hate and extremism promoting. We conduct a manual analysis of tweets and identify linguistic features which can be used as discriminators for the task of identifying hate and extremism promoting tweets. We demonstrate a correlation between such tweets and features like presence of war, religious, negative emotions and offensive terms. We train a one-class SVM and KNN on 10,486 positive class tweets.",
                    "score": 0.3279824646380975
                },
                {
                    "context": "(c) Accuracy Results of Classifiers",
                    "score": 0.3226528770373124
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific performance metrics were evaluated in the study, and what were their corresponding values?",
                    "answer": "The performance metrics evaluated in the study include:\n\n- Precision: KNN - 0.48, LibSVM - 0.78\n- Recall: KNN - 0.81, LibSVM - 0.88\n- True Negative Rate (TNR): KNN - 0.92, LibSVM - 0.98\n- Negative Predictive Value (NPV): KNN - 0.98, LibSVM - 0.99\n- F-Score: KNN - 0.6, LibSVM - 0.83\n- Accuracy: KNN - 0.9, LibSVM - 0.97"
                },
                {
                    "question": "[SQ] What were the specific datasets used for evaluating the performance metrics?",
                    "answer": "The specific datasets used for evaluating the performance metrics were two publicly available datasets that were downloaded and combined to form a single experimental dataset. This dataset consisted of tweets belonging to multiple languages, but experiments were conducted only on English language tweets."
                },
                {
                    "question": "[SQ] How were the performance metrics calculated for each model?",
                    "answer": "The performance metrics for each model were calculated using the following definitions:\n\n- **Precision** is determined by the ratio of true positive predictions to the total predicted positives.\n- **Recall** is calculated as the ratio of true positive predictions to the total actual positives.\n- **True Negative Rate (TNR)** indicates the proportion of actual negatives that were correctly identified.\n- **Negative Predictive Value (NPV)** represents the proportion of true negatives among all predicted negatives.\n- **F-Score** is the harmonic mean of precision and recall, providing a balance between the two metrics.\n- **Accuracy** is computed as the ratio of correct predictions to the total predictions made by the classifier. \n\nThese metrics provide a comprehensive evaluation of the classifiers' performance in distinguishing between the classes in the dataset."
                },
                {
                    "question": "[SQ] Were there any significant differences in performance metrics between KNN and LibSVM?",
                    "answer": "Yes, there were significant differences in performance metrics between KNN and LibSVM. The LibSVM classifier outperformed KNN in several key areas, including precision, recall, F-score, and accuracy. Specifically, LibSVM achieved a precision of 0.78, recall of 0.88, F-score of 0.83, and an accuracy of 97%, while KNN had a precision of 0.48, recall of 0.81, F-score of 0.60, and an accuracy of 90%. These results indicate that LibSVM provided a more effective classification performance compared to KNN."
                },
                {
                    "question": "[MQ] What were the evaluated performance metrics and their corresponding values for KNN and LibSVM in the study, specifically regarding precision, recall, true negative rate, negative predictive value, F-score, and accuracy?",
                    "answer": "The evaluated performance metrics for KNN and LibSVM in the study are as follows:\n\n**KNN:**\n- Precision: 0.48\n- Recall: 0.81\n- True Negative Rate (TNR): 0.92\n- Negative Predictive Value (NPV): 0.98\n- F-Score: 0.6\n- Accuracy: 0.9\n\n**LibSVM:**\n- Precision: 0.78\n- Recall: 0.88\n- True Negative Rate (TNR): 0.98\n- Negative Predictive Value (NPV): 0.99\n- F-Score: 0.83\n- Accuracy: 0.97"
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 1.0,
                "semantic_similarity": 0.8232769732021157,
                "llm_context_precision_without_reference": 0.642857142825,
                "llm_context_precision_with_reference": 0.642857142825,
                "answer_relevancy": 0.8478298312493928,
                "answer_correctness": 0.5808192433005289
            },
            "deepeval": {
                "contextual_precision": 0.5944444444444444,
                "contextual_recall": 0.6875,
                "contextual_relevancy": 0.3787878787878788,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        }
    },
    {
        "id": 36,
        "job_id": 1,
        "file_id": 8,
        "question_id": 1,
        "status": "done",
        "answer_text": "The study utilized several AI algorithms, including Naive Bayes, Support Vector Machines (SVM), AdaBoost, and Random Forest. These algorithms contribute to the overall findings by enabling the classification of social media posts as radical or non-radical based on linguistic structure and stylometric features. By employing these supervised machine learning techniques, the research aims to automate the detection of radical content in social media, addressing the challenges of manual identification and enhancing the efficiency of monitoring radicalization activities online.",
        "answer_encoded": "SVM, AdaBoost, Naive Bayes",
        "answer_contexts": [
                {
                    "context": "Identifying Radical Social Media Posts using Machine Learning\n\n Prabhakar Gupta¹, Pulkit Varshney¹, M. P. S. Bhatia²\n\n¹ Division of Information Technology, Netaji Subhas Institute of Technology, Delhi, India\n\nprabhakar.gupta@nsitonline.in, pulkitvarshney186@gmail.com\n\n² Division of Computer Engineering, Netaji Subhas Institute of Technology, Delhi, India\n\nbhatia.mps@gmail.com\n\n Abstract\n\nRadicalization (like cyberterrorism) is one of the major concerns to all governments and law enforcement agencies to provide safety and security to their citizens. A lot of radical groups, extremists and insurgent organizations use social media platforms such as Facebook, Twitter, Reddit, YouTube etc. to post their ideology and propagate their message to their followers. Manual detection of these posts is nearly an impossible task. We propose an automated system for extracting data from Twitter employing investigative data mining technique using the hashtags used in the posts. The system preprocesses the data to clean it by tokenizing, stemming and lemmatization. Data is classified as radical or nonradical using supervised machine learning classification techniques (Naive Bayes, SVM, AdaBoost and Random Forest) with varying parameters. The idea is to classify posts by identifying the linguistic structure, their stylometry and detecting a time based pattern.\n\n Keywords\n\nRadicalization; Cyberterrorism; Machine Learning; Data Mining; Shorttext classification\n\n I. INTRODUCTION\n\nSince the late 1980s, the World Wide Web has become a highly powerful means of communication worldwide, reaching an ever growing audience. According to the FBI, international radicalization has following characteristics: (1) it involves violent acts harming other human life that can violate government laws (2) it is intended to intimidate civilian masses (3) it affects the policy of any government by coercion (4) it influences the conduct of a government by kidnapping, mass destruction, or assassination. Radical groups have started using the Internet to disseminate information that aid their causes. The availability of terrorist related material on the Internet plays an important role in radicalization processes. Due to this increasing availability of content on social media websites (such as Twitter, Facebook and Reddit etc.) there is an urgent need to identify these radical tweets.\n\nIn the pro radical networks, large amount of information is carried and commanded by a limited number of individuals. Most of the radical groups have shifted their focus from mainstream media to digital and social media to broadcast the information to new or younger groups or individuals, who can get the information by searching through hashtags and further by following them.\n\n A. Data extraction\n\nExtraction of tweets is done from Twitter. Attributes associated to a single tweet are URLs, text, user mentions, hashtags, media files (image, audio and video), timestamp, number of retweets, likes etc. and the user information. The main focus was on text mining as storing media files would, firstly, need a lot of space and secondly, analysing media files for radical content would require additional machine learning techniques. The texts were collected without knowing the sentiment. For example, when collecting tweets on hashtag #Syria (which is in the list of top 10 most frequent hashtags), it is not known initially whether:\n\n- The tweet is posted by a person associated with terrorist organisation or not;\n- Someone abominates the very idea of radicalization, showing disbelief and expressing against a pro extremist person;\n- Someone is discussing something general related to Syria, not in context with terrorism.\n\n B. Preprocessing of data\n\nData preprocessing is a necessary step after data extraction.",
                    "score": 0.8471227130837955
                },
                {
                    "context": "Identifying Radical Social Media Posts using Machine Learning\n\nPreprint· June 2017\n\nDOI: 10.13140/RG.2.2.15311.53926",
                    "score": 0.8465088696224882
                },
                {
                    "context": "The most frequent 443 words were used as the features. The 10 most frequent words from these 443 were, “isis”, “monitor”, “imam”, “thanks”, “world”, “woman”, “group”, “saudi”, “attack”, “mischief”, “fighter”, “car”. Among the most frequent words used, we can notice the words that are related to radical activities (“isis”, “attack”), words that can or cannot relate to radical activities (“world”, “woman”, “car”) and also the word imam. The word imam refers to the person who leads prayers in a mosque. It is a word originated from Arabic language.\n\nThe 139 most frequent hashtags were used for the experiment. The 10 most frequent hashtags were, #ISIS, #IslamicState, #Taliban, #IS, #Wahhabism, #AlQaeda, #SaudiArabia, #ISIL, #Syria, #Daesh. It can be observed that all of the most frequent hashtags are related to radical groups and their activities. #ISIS, #IslamicState, #IS, #ISIL, #Daesh all signify the Sunni militant group. #AlQaeda and #Taliban also are militant groups, whereas #SaudiArabia and #Syria are the countries which are affected by these groups.\n\n B. Time Pattern Features (TF)\n\nThe date and time at which the tweet was posted for recognizing a pattern was used. The day of the week and the hour of day were used since other attributes like month were not relevant in our experiment since the data from 4 weeks. The considered attributes are:\n\n- Hour of day (Hour 0, Hour 1, Hour 2, …, Hour 23)\n- Day of week (Monday, Tuesday, …, Sunday)\n\nIn total 31 time pattern features were used, 24 for hours and 7 for days.\n\nFig. 1. Tweets tweeted at various hours of day\n\n V. EXPERIMENTAL RESULTS\n\nA tool called scikit learn was used for various classifications. It is an open source Python library for machine learning built using NumPy, SciPy, and matplotlib libraries. A dataset with 5,297 tweets was extracted using the extraction method as TT FEATURE dataset using a seed hashtag (#GameOfThrones). This dataset was called TT TEST [19] and the ratio between training data and testing was approximately 1:5. Different classification algorithms used were: Naive Bayes, SVM (Support Vector Machines),\n\n VI. CONCLUSION AND FUTURE WORK\n\nIn this work, supervised machine learning was used to identify radical social media posts. The major problem with this classification was manually labelling the test data as radical or not radical. The dataset extracted was dependent on the seed hashtags which were selected initially. In future more independence to dataset should be there. The texts, images and videos issued by various radical and extremists groups which are collected by intelligence agencies can also be used to.",
                    "score": 0.8295002038854179
                },
                {
                    "context": "improve the performance of the system. Moreover, this classification should be seen as a support to the manual checking of the tweets since the accuracy of no classifier is absolute 100% and there is a chance of wrong tweets being identified as radical. This is due to the dynamic nature of the tweets and the noise in tweets due to abbreviations, Internet slang and 140 character limit.\n\nThe untagged datasets used in the experiment (TT FEATURE, TT TRAIN and TT TEST) have been made public for future use which can be found on repository hosting website, GitHub [19]. The data is directly downloaded from Twitter using the Twitter API and is currently in JSON format. The obtained results are from a limited dataset, that too only from one social media website, Twitter. In future the experiment can be extended to a diverse and large dataset from multiple websites (like Facebook, YouTube, Reddit, etc.) and platforms. The URLs in the tweets which were ignored here can also be analysed to identify the nature of tweets. Also, considering non English languages tweets (like Arabic) can increase the reach of the classifier providing better results.\n\n VII. REFERENCES\n\n1. Michael Ashcroft, Ali Fisher, Lisa Kaati, Enghin Omer, Nico Prucha, “Detecting Jihadist Messages on Twitter”, Intelligence and Security Informatics Conference (EISIC), 2015 European\n2. “Dataset spotlight: How ISIS uses Twitter interview with Khuram Zaman” (http://www.voxpol.eu/dataset spotlight isis uses twitter interview khuram zaman), 2016\n3. Kirk Roberts, Michael A. Roach, Joseph Johnson, Josh Guthrie, Sanda M. Harabagiu D. Correa and A. Sureka, “EmpaTweet: Annotating and Detecting Emotions on Twitter”, LREC 2012\n4. Twitter, Inc.. Twitter Developer Documentation (https://dev.twitter.com/rest/public/search), 2017\n5. Google, scikit learn Machine Learning in Python, (http://scikit learn.org), 2017\n6. Pooja Wadhwa and Dr M.P.S Bhatia, “Tracking online radicalization using investigative data mining”, Communications (NCC), 2013\n7. A. Fisher and N. Prucha, “The call up: The roots of a resilient and persistent Jihadist presence on Twitter”, CTX Vol.4 No.3, 2014\n8. Emilio Ferrara, Wen Qiang Wang, Onur Varol, Alessandro Flammini and Aram Galstyan, “Predicting online extremism, content adopters, and interaction reciprocity”, arXiv:1605.00659v1, [cs.SI] 2 May 2016\n9. Walid Magdy, Kareem Darwish, and Ingmar Weber, “#FailedRevolutions: Using Twitter to Study the Antecedents of ISIS Support”, arXiv:1503.02401v1 [cs.SI] 9 Mar 2015\n10. Swati Agarwal, Ashish Sureka, “Learning to Classify Hate and Extremism Promoting Tweets”, 2014 IEEE Joint Intelligence and Security Informatics Conference\n11. Denzil Correa and Ashish Sureka, “Solutions to Detect and Analyze Online Radicalization: A Survey,” arXiv preprint arXiv:1301.4916, 2013\n12. S. Agarwal and A. Sureka, “A focused crawler for mining hate and extremism promoting videos on YouTube.”, Proceedings of the 25th ACM conference on Hypertext and social media, 2014, pp. 294–296\n13. A. Sureka and S. Agarwal, “Using KNN and SVM Based One Class Classifier for Detecting Online Radicalization on Twitter,” Distributed Computing and Internet Technology. Springer, 2015, pp. 431–442.\n14. NLTK Project, Natural Language Toolkit, (http://www.nltk.org/), 2017\n15. Penn Treebank P.O.S. (Part of speech) Tags, (https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)\n16. Ryan Kelly, PyEnchant A Spell checking Library for Python, (https://pythonhosted.org/pyenchant/), 2014\n17. Adam Badawy and Emilio Ferrara, “The Rise of Jihadist Propaganda on Social Networks”, ArXiv 2017\n18. J.M. Berger and Jonathon Morgan, “The ISIS Twitter Census Defining and describing the population of ISIS supporters on Twitter”, The Brookings Project on U.S. Relations with the Islamic World Analysis Paper | No. 20, March 2015\n19. Radicalization Twitter Dataset, (https://git.io/vHTUP), 2017",
                    "score": 0.6731826115112625
                },
                {
                    "context": "in order to make the data unique and non redundant. As tweets which have been retweeted by other users occurred multiple times in the dataset, thus duplicates were removed using the unique tweet ID from the Twitter API response. After that, the text was strictly restricted to English language. But the problem arose that a lot of the tweets extracted were in other languages (like Arabic). Many of the Twitter accounts had their primary language as Arabic (or languages other than English) and even if they were radical, could not be considered. As the results are preliminary, so to write a unicode to work on tweets in different languages is an extensive task and out of the scope of this experiment. Then, to clean the tweets’ texts, URLs were removed for the smooth processing of data and to reduce overhead. Stopwords were removed and tokenization was done.\n\n C. Classification of tweets using machine learning techniques\n\nSupervised machine learning classification is generally employed for processing a large quantity of data which cannot be done manually. Various algorithms can be implemented on these elucidations to make the classification of tweets as radical or not. A set of training data containing tweets which were 100% radical and tweets which were 100% non radical. A feature vector for each tweet was generated on the basis of a unique feature set. The feature vector contained the value as 1 or TRUE if that particular feature was present in the tweet, and 0 or FALSE if feature was absent. Using this training data, a system is made to learn using classification algorithms: (1) SVM (Support Vector Machine), (2) Naive Bayes, (3) Adaboost Classification and (4) Random Forest Classification using scikit learn (Python library for machine learning) [5].\n\n II. RELATED WORK\n\nMachine learning is the most common approach for classification, regression and clustering. Classification involves identification among various categories a particular object belongs to. Regression predicts a continuous valued attribute which is associated with an object. Clustering means grouping of objects which exhibit nearly similar properties.\n\nA lot of research in clustering was done in [6], a topic entity relationship graph was made. The most discussed topics were the central nodes. All the users who were talking about it, or have tweeted earlier were linked to that central hub in the form of a star topology using k means clustering. A burst rate was also taken into consideration i.e. if an account was linked to that topic in the past, now not posting anything or not in context with the topic was not considered. In [1] [7], a list consisting of 66 Twitter accounts which were identified as radical but were yet blocked by Twitter and the tweets from these accounts were taken as the training data. The system was made to learn accordingly and accuracies of each classifier (SVM, Naive Bayes and AdaBoost) were calculated. The problem with the list of Twitter accounts was, firstly, majority of tweets were in Arabic language and secondly, most of the accounts have been suspended by Twitter leaving not a single account good for this experiment’s consideration making it unfit for using it as training dataset.\n\nMany researchers are solicitous for depicting the phenomena of this social problem revolving around extremist propaganda. They use online data as a proxy to study the behavior of individuals and groups. In a 2016 study [8], the authors carried out three forecasting tasks: (1) Detection of extremist accounts, (2) To reckon normal user to adopt extremist content, (3) Predicting whether a normal user will retaliate contacts generated by the extremist account. Various machine learning tools are used to create a framework that generate features of multiple dimensions including network statistics, user metadata and temporal pattern of activity. Two scenarios were taken into account for this forecasting process: a time independent, post hoc prediction task on collected data, and a real time simulated prediction task. Further concluded by determining the emanating signals that provide a thorough feature analysis by prediction in different scenarios.\n\nA few researches worked on alternative data sources. Twitter data was used as a source archive [9], some studies were based on Arabic tweets and classified these as pro ISIS and anti ISIS. Provided with the Arab Twitter users (called tweeps in their research), the account history of users were known, a model was developed to examine the interest of both groups (pro ISIS and anti ISIS) before and after they started opposing or supporting ISIS. Trends of tweets or any literature were analysed to find out the motivations that made people to follow ISIS online (not considering whether they were willing to join ISIS or not), identifying ascertained injustices known as triggers. Their analysis was divided into two parts: (1) After collection of data, global trends were determined. This provided an insight into external affairs such as ‘videos of beheadings’ or ‘sites of terrorists camps’ (2) Individual Historic Analysis for the patterns of user history before supporting ISIS.",
                    "score": 0.6631305734644879
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific AI algorithm was utilized in the study, and how does it contribute to the overall findings presented in the article?",
                    "answer": "The study utilized several AI algorithms, including Naive Bayes, Support Vector Machines (SVM), AdaBoost, and Random Forest. These algorithms contribute to the overall findings by enabling the classification of social media posts as radical or non-radical based on linguistic structure and stylometric features. By employing these supervised machine learning techniques, the research aims to automate the detection of radical content in social media, addressing the challenges of manual identification and enhancing the efficiency of monitoring radicalization activities online."
                },
                {
                    "question": "[SQ] What are the key features used by the AI algorithms to classify social media posts?",
                    "answer": "The key features used by the AI algorithms to classify social media posts include the most frequent words and hashtags associated with radical activities, as well as time pattern features such as the hour of the day and the day of the week. The frequent words include terms related to radical groups and activities, while the hashtags predominantly signify various militant organizations. Additionally, the classification process involves analyzing the linguistic structure and stylometry of the posts."
                },
                {
                    "question": "[SQ] How does the performance of the utilized AI algorithms compare to traditional methods of detecting radical content?",
                    "answer": "The performance of the utilized AI algorithms, specifically supervised machine learning techniques like Naive Bayes, SVM, AdaBoost, and Random Forest, is designed to enhance the detection of radical content on social media compared to traditional methods. Traditional methods often rely on manual detection, which is nearly impossible due to the vast volume of posts and the dynamic nature of social media content. In contrast, the machine learning approach automates the classification process, allowing for the analysis of large datasets efficiently.\n\nWhile the AI algorithms can significantly improve the speed and scalability of detection, they are not infallible. The accuracy of these classifiers is not 100%, and there is a possibility of misclassifying non-radical content as radical. Therefore, the machine learning methods serve as a support tool for manual checking rather than a complete replacement. This combination aims to enhance the overall effectiveness of identifying radical posts while acknowledging the limitations inherent in both AI and traditional methods."
                },
                {
                    "question": "[SQ] What specific challenges in detecting radical content does the study aim to address with these AI algorithms?",
                    "answer": "The study aims to address several specific challenges in detecting radical content using AI algorithms. One major challenge is the manual detection of radical posts, which is nearly impossible due to the vast amount of content generated on social media platforms. The dynamic nature of tweets, which often include abbreviations, Internet slang, and are limited to 140 characters, adds complexity to the classification process. Additionally, the study highlights the difficulty in accurately labeling tweets as radical or non-radical, given that the context of a tweet can vary significantly. The presence of noise in the data, such as irrelevant content or tweets in different languages, further complicates the detection process. The proposed automated system aims to preprocess the data effectively and utilize machine learning classification techniques to improve the identification of radical posts while supporting manual verification to enhance accuracy."
                },
                {
                    "question": "[MQ] Which AI algorithms were employed in the study to classify social media posts as radical or non-radical, and what key features do they analyze to enhance the detection process?",
                    "answer": "The study employed several supervised machine learning classification algorithms to classify social media posts as radical or non-radical. These algorithms include Naive Bayes, Support Vector Machines (SVM), AdaBoost, and Random Forest. \n\nTo enhance the detection process, the key features analyzed include the linguistic structure of the posts, their stylometry, and time-based patterns. Specifically, the analysis focuses on the most frequent words and hashtags associated with radical activities, as well as temporal features such as the hour of the day and the day of the week when the tweets were posted. This combination of features aids in effectively distinguishing between radical and non-radical content."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0.6666666666666666,
                "semantic_similarity": 0.8919119671224285,
                "llm_context_precision_without_reference": 0.5437499999864062,
                "llm_context_precision_with_reference": 0.6676190476056951,
                "answer_relevancy": 0.8492728570942162,
                "answer_correctness": 0.22297799178060712
            },
            "deepeval": {
                "contextual_precision": 0.25,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.3448275862068966,
                "answer_relevancy": 0.1111111111111111,
                "faithfulness": 0.8571428571428571
            }
        },
    },
    {
        "id": 37,
        "job_id": 1,
        "file_id": 8,
        "question_id": 2,
        "status": "done",
        "answer_text": "The analysis focused on two main types of features: stylometric features and time pattern features. \n\nStylometric features included a range of linguistic characteristics derived from the tweets, specifically targeting the frequency of words and hashtags related to radical activities. This approach was justified as it allowed for the identification of significant words associated with radical content, enhancing the analysis of linguistic patterns.\n\nTime pattern features were based on the date and time of tweet postings, specifically examining the hour of the day and the day of the week. This selection was justified as it aimed to recognize patterns in tweet activity, providing insights into the timing of radical discussions.\n\nIn total, 613 features were utilized, combining both stylometric and time pattern features, to effectively classify tweets as radical or not radical, aligning with the research objectives of identifying radical social media posts.",
        "answer_encoded": "[response not coded] The analysis selected 613 features, including stylometric features related to linguistic characteristics of tweets and time pattern features based on the timing of tweet postings, to classify tweets as radical or not.",
        "answer_contexts": [
                {
                    "context": "The most frequent 443 words were used as the features. The 10 most frequent words from these 443 were, “isis”, “monitor”, “imam”, “thanks”, “world”, “woman”, “group”, “saudi”, “attack”, “mischief”, “fighter”, “car”. Among the most frequent words used, we can notice the words that are related to radical activities (“isis”, “attack”), words that can or cannot relate to radical activities (“world”, “woman”, “car”) and also the word imam. The word imam refers to the person who leads prayers in a mosque. It is a word originated from Arabic language.\n\nThe 139 most frequent hashtags were used for the experiment. The 10 most frequent hashtags were, #ISIS, #IslamicState, #Taliban, #IS, #Wahhabism, #AlQaeda, #SaudiArabia, #ISIL, #Syria, #Daesh. It can be observed that all of the most frequent hashtags are related to radical groups and their activities. #ISIS, #IslamicState, #IS, #ISIL, #Daesh all signify the Sunni militant group. #AlQaeda and #Taliban also are militant groups, whereas #SaudiArabia and #Syria are the countries which are affected by these groups.\n\n B. Time Pattern Features (TF)\n\nThe date and time at which the tweet was posted for recognizing a pattern was used. The day of the week and the hour of day were used since other attributes like month were not relevant in our experiment since the data from 4 weeks. The considered attributes are:\n\n- Hour of day (Hour 0, Hour 1, Hour 2, …, Hour 23)\n- Day of week (Monday, Tuesday, …, Sunday)\n\nIn total 31 time pattern features were used, 24 for hours and 7 for days.\n\nFig. 1. Tweets tweeted at various hours of day\n\n V. EXPERIMENTAL RESULTS\n\nA tool called scikit learn was used for various classifications. It is an open source Python library for machine learning built using NumPy, SciPy, and matplotlib libraries. A dataset with 5,297 tweets was extracted using the extraction method as TT FEATURE dataset using a seed hashtag (#GameOfThrones). This dataset was called TT TEST [19] and the ratio between training data and testing was approximately 1:5. Different classification algorithms used were: Naive Bayes, SVM (Support Vector Machines),\n\n VI. CONCLUSION AND FUTURE WORK\n\nIn this work, supervised machine learning was used to identify radical social media posts. The major problem with this classification was manually labelling the test data as radical or not radical. The dataset extracted was dependent on the seed hashtags which were selected initially. In future more independence to dataset should be there. The texts, images and videos issued by various radical and extremists groups which are collected by intelligence agencies can also be used to.",
                    "score": 0.8343398884357183
                },
                {
                    "context": "For all the noun words from tweets were stemmed and lemmatized using nltk.stem.wordnet (WordNet stemmer) package of NLTK library. The frequency for the base word was calculated in a Python dictionary. For the abbreviations like “Islamic State” and “IS” both represent the same thing but were considered as separate entities during the experiment. To consider only English noun words, a spell checker tool was used called PyEnchant. PyEnchant [16] is a Python library for spell checking. With correct parameters, it helps in identifying if a word is an English word or not.\n\nTest data for experiment was extracted using a few of the most popular hashtags (#IslamicState, #ISIS, #AlQaeda, #Wahhabism, #Taliban and #Daesh) as seed hashtags. All the tweets with at least one of the seed hashtags were extracted using the Twitter API for one week. 10,282 unique tweets were extracted (TT TRAIN PRO [19]). A random hashtag (which was safely assumed to be not about any radical discussion) was taken (#IPL). 15,200 unique tweets were extracted from this (TT TRAIN CON [19]). The dataset of these 25,482 tweets is called TT TRAIN [19].\n\nThe tweets in TT TRAIN dataset which were extracted from the seed hashtags were random in nature as they could be talking about these radical groups in a supportive way or opposing them. In order to classify them as radical or not radical, many of the tweets were manually classified and the remainder of the tweets were classified on the basis of the occurrence of other hashtags. The tweets extracted from the random hashtags were all safely considered to be not radical in nature. The tweets were then cleaned in a similar way as the tweets in TT FEATURE. Each of them was converted to a feature vector of size 613 in length having boolean values. They were assigned a value corresponding to their manual or assumed classification as TRUE for radical tweets and FALSE for non radical tweets.\n\n IV. FEATURES\n\nIn the experiment, a total of 613 features were considered which belonged to 2 different types of feature classes:\n\n- stylometric features (SF)\n- time pattern features (TF)",
                    "score": 0.7363280373635
                },
                {
                    "context": "Identifying Radical Social Media Posts using Machine Learning\n\n Prabhakar Gupta¹, Pulkit Varshney¹, M. P. S. Bhatia²\n\n¹ Division of Information Technology, Netaji Subhas Institute of Technology, Delhi, India\n\nprabhakar.gupta@nsitonline.in, pulkitvarshney186@gmail.com\n\n² Division of Computer Engineering, Netaji Subhas Institute of Technology, Delhi, India\n\nbhatia.mps@gmail.com\n\n Abstract\n\nRadicalization (like cyberterrorism) is one of the major concerns to all governments and law enforcement agencies to provide safety and security to their citizens. A lot of radical groups, extremists and insurgent organizations use social media platforms such as Facebook, Twitter, Reddit, YouTube etc. to post their ideology and propagate their message to their followers. Manual detection of these posts is nearly an impossible task. We propose an automated system for extracting data from Twitter employing investigative data mining technique using the hashtags used in the posts. The system preprocesses the data to clean it by tokenizing, stemming and lemmatization. Data is classified as radical or nonradical using supervised machine learning classification techniques (Naive Bayes, SVM, AdaBoost and Random Forest) with varying parameters. The idea is to classify posts by identifying the linguistic structure, their stylometry and detecting a time based pattern.\n\n Keywords\n\nRadicalization; Cyberterrorism; Machine Learning; Data Mining; Shorttext classification\n\n I. INTRODUCTION\n\nSince the late 1980s, the World Wide Web has become a highly powerful means of communication worldwide, reaching an ever growing audience. According to the FBI, international radicalization has following characteristics: (1) it involves violent acts harming other human life that can violate government laws (2) it is intended to intimidate civilian masses (3) it affects the policy of any government by coercion (4) it influences the conduct of a government by kidnapping, mass destruction, or assassination. Radical groups have started using the Internet to disseminate information that aid their causes. The availability of terrorist related material on the Internet plays an important role in radicalization processes. Due to this increasing availability of content on social media websites (such as Twitter, Facebook and Reddit etc.) there is an urgent need to identify these radical tweets.\n\nIn the pro radical networks, large amount of information is carried and commanded by a limited number of individuals. Most of the radical groups have shifted their focus from mainstream media to digital and social media to broadcast the information to new or younger groups or individuals, who can get the information by searching through hashtags and further by following them.\n\n A. Data extraction\n\nExtraction of tweets is done from Twitter. Attributes associated to a single tweet are URLs, text, user mentions, hashtags, media files (image, audio and video), timestamp, number of retweets, likes etc. and the user information. The main focus was on text mining as storing media files would, firstly, need a lot of space and secondly, analysing media files for radical content would require additional machine learning techniques. The texts were collected without knowing the sentiment. For example, when collecting tweets on hashtag #Syria (which is in the list of top 10 most frequent hashtags), it is not known initially whether:\n\n- The tweet is posted by a person associated with terrorist organisation or not;\n- Someone abominates the very idea of radicalization, showing disbelief and expressing against a pro extremist person;\n- Someone is discussing something general related to Syria, not in context with terrorism.\n\n B. Preprocessing of data\n\nData preprocessing is a necessary step after data extraction.",
                    "score": 0.470781824685483
                },
                {
                    "context": "improve the performance of the system. Moreover, this classification should be seen as a support to the manual checking of the tweets since the accuracy of no classifier is absolute 100% and there is a chance of wrong tweets being identified as radical. This is due to the dynamic nature of the tweets and the noise in tweets due to abbreviations, Internet slang and 140 character limit.\n\nThe untagged datasets used in the experiment (TT FEATURE, TT TRAIN and TT TEST) have been made public for future use which can be found on repository hosting website, GitHub [19]. The data is directly downloaded from Twitter using the Twitter API and is currently in JSON format. The obtained results are from a limited dataset, that too only from one social media website, Twitter. In future the experiment can be extended to a diverse and large dataset from multiple websites (like Facebook, YouTube, Reddit, etc.) and platforms. The URLs in the tweets which were ignored here can also be analysed to identify the nature of tweets. Also, considering non English languages tweets (like Arabic) can increase the reach of the classifier providing better results.\n\n VII. REFERENCES\n\n1. Michael Ashcroft, Ali Fisher, Lisa Kaati, Enghin Omer, Nico Prucha, “Detecting Jihadist Messages on Twitter”, Intelligence and Security Informatics Conference (EISIC), 2015 European\n2. “Dataset spotlight: How ISIS uses Twitter interview with Khuram Zaman” (http://www.voxpol.eu/dataset spotlight isis uses twitter interview khuram zaman), 2016\n3. Kirk Roberts, Michael A. Roach, Joseph Johnson, Josh Guthrie, Sanda M. Harabagiu D. Correa and A. Sureka, “EmpaTweet: Annotating and Detecting Emotions on Twitter”, LREC 2012\n4. Twitter, Inc.. Twitter Developer Documentation (https://dev.twitter.com/rest/public/search), 2017\n5. Google, scikit learn Machine Learning in Python, (http://scikit learn.org), 2017\n6. Pooja Wadhwa and Dr M.P.S Bhatia, “Tracking online radicalization using investigative data mining”, Communications (NCC), 2013\n7. A. Fisher and N. Prucha, “The call up: The roots of a resilient and persistent Jihadist presence on Twitter”, CTX Vol.4 No.3, 2014\n8. Emilio Ferrara, Wen Qiang Wang, Onur Varol, Alessandro Flammini and Aram Galstyan, “Predicting online extremism, content adopters, and interaction reciprocity”, arXiv:1605.00659v1, [cs.SI] 2 May 2016\n9. Walid Magdy, Kareem Darwish, and Ingmar Weber, “#FailedRevolutions: Using Twitter to Study the Antecedents of ISIS Support”, arXiv:1503.02401v1 [cs.SI] 9 Mar 2015\n10. Swati Agarwal, Ashish Sureka, “Learning to Classify Hate and Extremism Promoting Tweets”, 2014 IEEE Joint Intelligence and Security Informatics Conference\n11. Denzil Correa and Ashish Sureka, “Solutions to Detect and Analyze Online Radicalization: A Survey,” arXiv preprint arXiv:1301.4916, 2013\n12. S. Agarwal and A. Sureka, “A focused crawler for mining hate and extremism promoting videos on YouTube.”, Proceedings of the 25th ACM conference on Hypertext and social media, 2014, pp. 294–296\n13. A. Sureka and S. Agarwal, “Using KNN and SVM Based One Class Classifier for Detecting Online Radicalization on Twitter,” Distributed Computing and Internet Technology. Springer, 2015, pp. 431–442.\n14. NLTK Project, Natural Language Toolkit, (http://www.nltk.org/), 2017\n15. Penn Treebank P.O.S. (Part of speech) Tags, (https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)\n16. Ryan Kelly, PyEnchant A Spell checking Library for Python, (https://pythonhosted.org/pyenchant/), 2014\n17. Adam Badawy and Emilio Ferrara, “The Rise of Jihadist Propaganda on Social Networks”, ArXiv 2017\n18. J.M. Berger and Jonathon Morgan, “The ISIS Twitter Census Defining and describing the population of ISIS supporters on Twitter”, The Brookings Project on U.S. Relations with the Islamic World Analysis Paper | No. 20, March 2015\n19. Radicalization Twitter Dataset, (https://git.io/vHTUP), 2017",
                    "score": 0.3762734192922804
                },
                {
                    "context": "extraction, data classification and evaluating performance. In first stage, all the tweets that were in English language were extracted and combined to form a single unique dataset. Second stage consisted of the creation of training data based on hashtags, as hashtags are the best indicator of the sentiment of tweets. Tweets were labelled manually and recursively extended to find new hashtags based on some seed hashtags. Stage three involves data pre processing to remove the hashtags and @username. Stage four includes extraction of different features on the basis of data extracted. In stage five, on the basis of two independent classifiers, tweets were classified as supporting ISIS or not. To complete the process, the last stage involves creation of confusion matrix to judge the accuracy of above classifiers. The problem with this approach was that only the hashtags were considered for the classification parameters without considering the text or any other linguistic structure of the tweets since there are a lot of tweets without any hashtags and there are many tweets with more hashtags than just one.\n\n III. APPROACH FOR IDENTIFICATION\n\nTwitter Search REST API [4] was used for extracting the public tweets for the hashtags which are associated with the radical groups. A few seed hashtags (#ISIS, #IslamicState) were selected manually and all the tweets for those hashtags were extracted. The API only provides the data for 7 days so the process of extraction was repeated for 4 weeks, giving the data for roughly 1 month (mid February 2017 to mid March 2017). For the tweets extracted, the frequencies of all the hashtags were calculated and recursively the most frequent and unique hashtag was used as the new search query. This process was repeated for 18 more hashtags (apart from seed hashtags) giving around 57,698 tweets of which 48,644 tweets were unique. The tweets which didn’t have primary language as English were not considered regardless of their content. This dataset is called TT FEATURE [19]. After extracting tweets, the most popular hashtags are shown in Table I.\n\nThis data was used to extract the linguistic features and most popular hashtags. For extraction of these features, a tool called NLTK (Natural Language ToolKit) [14] was used. It is an open source suite of various libraries for statistical Natural Language Processing (NLP) for English. It is written in Python language.\n\nThe texts of these tweets were cleaned by removing the URLs, user mentions (@), hashtags (#) and the term ‘RT’ (Retweet). The clean text was, then, tokenized using nltk.tokenize package in the NLTK library giving us the POS (Part of Speech) tags for every word. Only the words with noun POS tags (NN, NNS, NNP, NNPS) [15] were considered. Many of the words had same meaning but occurred in different form like jihad, jihadi, jihadist and jihadology. The derivationally related forms and inflectional forms of a word were reduced to a common base word (“jihad” in this example). This technique is called stemming.\n\n TABLE I. MOST POPULAR HASHTAGS",
                    "score": 0.3644753310232508
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific features or characteristics were selected for analysis in the study, and how were they justified in the context of the research objectives?",
                    "answer": "The analysis in the study focused on two main types of features: stylometric features (SF) and time pattern features (TF). \n\nStylometric features included a range of linguistic characteristics derived from the tweets. These features were extracted using the NLTK library, which facilitated the cleaning of tweet texts by removing URLs, user mentions, hashtags, and the term 'RT' (Retweet). The cleaned text was then tokenized, and only words with noun part-of-speech tags were considered. This approach was justified as it allowed for the identification of significant words related to radical activities, such as \"isis,\" \"attack,\" and \"imam.\" Additionally, stemming was applied to reduce derivationally related forms of words to a common base, enhancing the analysis of linguistic patterns.\n\nTime pattern features were based on the date and time of tweet postings, specifically focusing on the hour of the day and the day of the week. This selection was justified as it aimed to recognize patterns in tweet activity, which could provide insights into the timing of radical discussions.\n\nIn total, 613 features were utilized, combining both stylometric and time pattern features, to effectively classify tweets as radical or not radical, aligning with the research objectives of identifying radical social media posts."
                },
                {
                    "question": "[SQ] What criteria were used to select the specific stylometric features for analysis in the study?",
                    "answer": "The selection of stylometric features for analysis was based on the frequency of words and hashtags related to radical activities. A total of 613 features were considered, with the most frequent 443 words being used as features. The ten most frequent words included terms directly associated with radical activities, while the hashtags selected were primarily those linked to known radical groups. Additionally, the features were derived from English noun words, which were processed through stemming and lemmatization to ensure consistency in representation."
                },
                {
                    "question": "[SQ] How were the time pattern features operationalized in the context of the research objectives?",
                    "answer": "The time pattern features were operationalized by analyzing the date and time at which tweets were posted. Specifically, the research focused on two attributes: the hour of the day, categorized from Hour 0 to Hour 23, and the day of the week, which included all seven days from Monday to Sunday. In total, 31 time pattern features were utilized, comprising 24 for the hours and 7 for the days, to recognize patterns in the timing of tweets related to radical activities."
                },
                {
                    "question": "[SQ] What statistical methods were employed to evaluate the significance of the selected features in classifying tweets?",
                    "answer": "The context does not specify any statistical methods used to evaluate the significance of the selected features in classifying tweets. It primarily discusses the extraction of features, the classification algorithms employed, and the process of labeling tweets, but does not detail any statistical evaluation techniques."
                },
                {
                    "question": "[MQ] What stylometric and time pattern features were selected for analysis in the study, and how were their selections justified in relation to identifying radical social media posts?",
                    "answer": "The analysis included a total of 613 features, categorized into two types: stylometric features and time pattern features. Stylometric features were derived from the linguistic structure of the tweets, focusing on the frequency and usage of specific words and hashtags that are indicative of radical content. This approach allows for the identification of patterns in language that may correlate with radicalization.\n\nTime pattern features were based on the timing of the tweets, specifically the hour of the day and the day of the week. This temporal analysis helps to recognize patterns in when radical posts are made, which can be crucial for understanding the behavior of users engaged in radical discussions. By examining these time attributes, the study aimed to identify trends that could signal increased radical activity during certain times.\n\nThe selection of these features was justified as they provide a comprehensive framework for classifying tweets as radical or non-radical, leveraging both the content of the posts and the timing of their publication."
                },
                {
                    "question": "[SQ] What specific linguistic characteristics were analyzed within the stylometric features to identify radical content?",
                    "answer": "The analysis of stylometric features focused on the frequency of specific words and hashtags associated with radical activities. The most frequent words included terms like \"isis,\" \"attack,\" and \"imam,\" which are directly related to radical content. Additionally, the presence of certain hashtags, such as #ISIS, #IslamicState, and #Taliban, was also considered, as they are linked to militant groups and their activities. These linguistic characteristics helped in distinguishing between radical and non-radical tweets."
                },
                {
                    "question": "[SQ] How did the study determine the relevance of the selected time pattern features in relation to radical social media activity?",
                    "answer": "The study determined the relevance of the selected time pattern features by analyzing the date and time at which tweets were posted. Specifically, it focused on the hour of the day and the day of the week, as these attributes were deemed significant for recognizing patterns in radical social media activity. A total of 31 time pattern features were utilized, comprising 24 for the hours and 7 for the days, allowing for a comprehensive examination of when radical posts were most frequently made. This approach aimed to identify any temporal trends associated with radical social media activity."
                },
                {
                    "question": "[SQ] What role did the frequency of specific words and hashtags play in the classification of tweets as radical or non-radical?",
                    "answer": "The frequency of specific words and hashtags was crucial in classifying tweets as radical or non-radical. The most frequent words, such as \"isis,\" \"attack,\" and \"imam,\" indicated a strong association with radical activities, while other words could have varying implications. Similarly, the most frequent hashtags, including #ISIS, #IslamicState, and #Taliban, were directly linked to radical groups and their ideologies. By analyzing the occurrence of these words and hashtags, the classification system could effectively identify tweets that were likely to promote or discuss radical content, thereby aiding in the differentiation between radical and non-radical posts."
                },
                {
                    "question": "[MQ] What specific stylometric and time pattern features were selected for analysis in the study, and how do these features contribute to identifying radical social media posts?",
                    "answer": "The analysis in the study focused on two types of features: stylometric features and time pattern features. \n\nStylometric features included a total of 613 features derived from the text of the tweets. These features were designed to capture the linguistic structure and stylistic elements of the posts, which can help in distinguishing between radical and non-radical content based on the way language is used.\n\nTime pattern features comprised 31 attributes, specifically 24 for the hour of the day and 7 for the day of the week. These features were utilized to recognize patterns in the timing of tweets, which can be indicative of certain behaviors or trends associated with radical posts.\n\nTogether, these features contribute to the identification of radical social media posts by enabling the classification algorithms to analyze both the content and the timing of the tweets, thereby improving the accuracy of detecting radicalization in social media communications."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0.8571428571428571,
                "semantic_similarity": 0.8648289543370411,
                "llm_context_precision_without_reference": 0.8121315192627746,
                "llm_context_precision_with_reference": 0.26666666665333333,
                "answer_relevancy": 0.8226573006458903,
                "answer_correctness": 0.30444253270190735
            },
            "deepeval": {
                "contextual_precision": 0.6666666666666666,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.26229508196721313,
                "answer_relevancy": 1.0,
                "faithfulness": 0.9166666666666666
            }
        },
    },
    {
        "id": 38,
        "job_id": 1,
        "file_id": 8,
        "question_id": 3,
        "status": "done",
        "answer_text": "The social network utilized for data collection in the analyzed article was Twitter.",
        "answer_encoded": "Twitter",
        "answer_contexts": [
                {
                    "context": "A few researches worked on alternative data sources. Twitter data was used as a source archive [9], some studies were based on Arabic tweets and classified these as pro ISIS and anti ISIS. Provided with the Arab Twitter users (called tweeps in their research), the account history of users were known, a model was developed to examine the interest of both groups (pro ISIS and anti ISIS) before and after they started opposing or supporting ISIS. Trends of tweets or any literature were analysed to find out the motivations that made people to follow ISIS online (not considering whether they were willing to join ISIS or not), identifying ascertained injustices known as triggers. Their analysis was divided into two parts: (1) After collection of data, global trends were determined. This provided an insight into external affairs such as ‘videos of beheadings’ or ‘sites of terrorists camps’ (2) Individual Historic Analysis for the patterns of user history before supporting ISIS. Limitations for [9], were: their data was biased to less openly hateful and less offensive users. Something less vivid than suspension of accounts that users themselves can delete their tweets. If an ISIS supporter tweets about Coldplay, now he can go back in time and delete his tweet. But expecting this kind of behaviour was limited. Another restriction was that Twitter only provides with 3200 tweets for a user, so individual historical analysis would not provide good results as complete history of a user is not available.\n\nAlong the same trend, interesting examples proposed by various researchers [10] [13] on different machine learning strategies aimed at detecting hate promotion, extremist support and cyber recruitment on various social media platforms like Tumblr, Twitter and YouTube [10]. Their training data was obtained by semi supervised learning methods and their framework mainly constituted features of content and metadata. Their research was divided into many stages primarily consists of six steps: data extraction, creation of training data, pre processing of data, feature set creation and",
                    "score": 0.8410307237490408
                },
                {
                    "context": "extraction, data classification and evaluating performance. In first stage, all the tweets that were in English language were extracted and combined to form a single unique dataset. Second stage consisted of the creation of training data based on hashtags, as hashtags are the best indicator of the sentiment of tweets. Tweets were labelled manually and recursively extended to find new hashtags based on some seed hashtags. Stage three involves data pre processing to remove the hashtags and @username. Stage four includes extraction of different features on the basis of data extracted. In stage five, on the basis of two independent classifiers, tweets were classified as supporting ISIS or not. To complete the process, the last stage involves creation of confusion matrix to judge the accuracy of above classifiers. The problem with this approach was that only the hashtags were considered for the classification parameters without considering the text or any other linguistic structure of the tweets since there are a lot of tweets without any hashtags and there are many tweets with more hashtags than just one.\n\n III. APPROACH FOR IDENTIFICATION\n\nTwitter Search REST API [4] was used for extracting the public tweets for the hashtags which are associated with the radical groups. A few seed hashtags (#ISIS, #IslamicState) were selected manually and all the tweets for those hashtags were extracted. The API only provides the data for 7 days so the process of extraction was repeated for 4 weeks, giving the data for roughly 1 month (mid February 2017 to mid March 2017). For the tweets extracted, the frequencies of all the hashtags were calculated and recursively the most frequent and unique hashtag was used as the new search query. This process was repeated for 18 more hashtags (apart from seed hashtags) giving around 57,698 tweets of which 48,644 tweets were unique. The tweets which didn’t have primary language as English were not considered regardless of their content. This dataset is called TT FEATURE [19]. After extracting tweets, the most popular hashtags are shown in Table I.\n\nThis data was used to extract the linguistic features and most popular hashtags. For extraction of these features, a tool called NLTK (Natural Language ToolKit) [14] was used. It is an open source suite of various libraries for statistical Natural Language Processing (NLP) for English. It is written in Python language.\n\nThe texts of these tweets were cleaned by removing the URLs, user mentions (@), hashtags (#) and the term ‘RT’ (Retweet). The clean text was, then, tokenized using nltk.tokenize package in the NLTK library giving us the POS (Part of Speech) tags for every word. Only the words with noun POS tags (NN, NNS, NNP, NNPS) [15] were considered. Many of the words had same meaning but occurred in different form like jihad, jihadi, jihadist and jihadology. The derivationally related forms and inflectional forms of a word were reduced to a common base word (“jihad” in this example). This technique is called stemming.\n\n TABLE I. MOST POPULAR HASHTAGS",
                    "score": 0.8195483198523998
                },
                {
                    "context": "improve the performance of the system. Moreover, this classification should be seen as a support to the manual checking of the tweets since the accuracy of no classifier is absolute 100% and there is a chance of wrong tweets being identified as radical. This is due to the dynamic nature of the tweets and the noise in tweets due to abbreviations, Internet slang and 140 character limit.\n\nThe untagged datasets used in the experiment (TT FEATURE, TT TRAIN and TT TEST) have been made public for future use which can be found on repository hosting website, GitHub [19]. The data is directly downloaded from Twitter using the Twitter API and is currently in JSON format. The obtained results are from a limited dataset, that too only from one social media website, Twitter. In future the experiment can be extended to a diverse and large dataset from multiple websites (like Facebook, YouTube, Reddit, etc.) and platforms. The URLs in the tweets which were ignored here can also be analysed to identify the nature of tweets. Also, considering non English languages tweets (like Arabic) can increase the reach of the classifier providing better results.\n\n VII. REFERENCES\n\n1. Michael Ashcroft, Ali Fisher, Lisa Kaati, Enghin Omer, Nico Prucha, “Detecting Jihadist Messages on Twitter”, Intelligence and Security Informatics Conference (EISIC), 2015 European\n2. “Dataset spotlight: How ISIS uses Twitter interview with Khuram Zaman” (http://www.voxpol.eu/dataset spotlight isis uses twitter interview khuram zaman), 2016\n3. Kirk Roberts, Michael A. Roach, Joseph Johnson, Josh Guthrie, Sanda M. Harabagiu D. Correa and A. Sureka, “EmpaTweet: Annotating and Detecting Emotions on Twitter”, LREC 2012\n4. Twitter, Inc.. Twitter Developer Documentation (https://dev.twitter.com/rest/public/search), 2017\n5. Google, scikit learn Machine Learning in Python, (http://scikit learn.org), 2017\n6. Pooja Wadhwa and Dr M.P.S Bhatia, “Tracking online radicalization using investigative data mining”, Communications (NCC), 2013\n7. A. Fisher and N. Prucha, “The call up: The roots of a resilient and persistent Jihadist presence on Twitter”, CTX Vol.4 No.3, 2014\n8. Emilio Ferrara, Wen Qiang Wang, Onur Varol, Alessandro Flammini and Aram Galstyan, “Predicting online extremism, content adopters, and interaction reciprocity”, arXiv:1605.00659v1, [cs.SI] 2 May 2016\n9. Walid Magdy, Kareem Darwish, and Ingmar Weber, “#FailedRevolutions: Using Twitter to Study the Antecedents of ISIS Support”, arXiv:1503.02401v1 [cs.SI] 9 Mar 2015\n10. Swati Agarwal, Ashish Sureka, “Learning to Classify Hate and Extremism Promoting Tweets”, 2014 IEEE Joint Intelligence and Security Informatics Conference\n11. Denzil Correa and Ashish Sureka, “Solutions to Detect and Analyze Online Radicalization: A Survey,” arXiv preprint arXiv:1301.4916, 2013\n12. S. Agarwal and A. Sureka, “A focused crawler for mining hate and extremism promoting videos on YouTube.”, Proceedings of the 25th ACM conference on Hypertext and social media, 2014, pp. 294–296\n13. A. Sureka and S. Agarwal, “Using KNN and SVM Based One Class Classifier for Detecting Online Radicalization on Twitter,” Distributed Computing and Internet Technology. Springer, 2015, pp. 431–442.\n14. NLTK Project, Natural Language Toolkit, (http://www.nltk.org/), 2017\n15. Penn Treebank P.O.S. (Part of speech) Tags, (https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)\n16. Ryan Kelly, PyEnchant A Spell checking Library for Python, (https://pythonhosted.org/pyenchant/), 2014\n17. Adam Badawy and Emilio Ferrara, “The Rise of Jihadist Propaganda on Social Networks”, ArXiv 2017\n18. J.M. Berger and Jonathon Morgan, “The ISIS Twitter Census Defining and describing the population of ISIS supporters on Twitter”, The Brookings Project on U.S. Relations with the Islamic World Analysis Paper | No. 20, March 2015\n19. Radicalization Twitter Dataset, (https://git.io/vHTUP), 2017",
                    "score": 0.8192921579849083
                },
                {
                    "context": "The most frequent 443 words were used as the features. The 10 most frequent words from these 443 were, “isis”, “monitor”, “imam”, “thanks”, “world”, “woman”, “group”, “saudi”, “attack”, “mischief”, “fighter”, “car”. Among the most frequent words used, we can notice the words that are related to radical activities (“isis”, “attack”), words that can or cannot relate to radical activities (“world”, “woman”, “car”) and also the word imam. The word imam refers to the person who leads prayers in a mosque. It is a word originated from Arabic language.\n\nThe 139 most frequent hashtags were used for the experiment. The 10 most frequent hashtags were, #ISIS, #IslamicState, #Taliban, #IS, #Wahhabism, #AlQaeda, #SaudiArabia, #ISIL, #Syria, #Daesh. It can be observed that all of the most frequent hashtags are related to radical groups and their activities. #ISIS, #IslamicState, #IS, #ISIL, #Daesh all signify the Sunni militant group. #AlQaeda and #Taliban also are militant groups, whereas #SaudiArabia and #Syria are the countries which are affected by these groups.\n\n B. Time Pattern Features (TF)\n\nThe date and time at which the tweet was posted for recognizing a pattern was used. The day of the week and the hour of day were used since other attributes like month were not relevant in our experiment since the data from 4 weeks. The considered attributes are:\n\n- Hour of day (Hour 0, Hour 1, Hour 2, …, Hour 23)\n- Day of week (Monday, Tuesday, …, Sunday)\n\nIn total 31 time pattern features were used, 24 for hours and 7 for days.\n\nFig. 1. Tweets tweeted at various hours of day\n\n V. EXPERIMENTAL RESULTS\n\nA tool called scikit learn was used for various classifications. It is an open source Python library for machine learning built using NumPy, SciPy, and matplotlib libraries. A dataset with 5,297 tweets was extracted using the extraction method as TT FEATURE dataset using a seed hashtag (#GameOfThrones). This dataset was called TT TEST [19] and the ratio between training data and testing was approximately 1:5. Different classification algorithms used were: Naive Bayes, SVM (Support Vector Machines),\n\n VI. CONCLUSION AND FUTURE WORK\n\nIn this work, supervised machine learning was used to identify radical social media posts. The major problem with this classification was manually labelling the test data as radical or not radical. The dataset extracted was dependent on the seed hashtags which were selected initially. In future more independence to dataset should be there. The texts, images and videos issued by various radical and extremists groups which are collected by intelligence agencies can also be used to.",
                    "score": 0.8146417707576535
                },
                {
                    "context": "in order to make the data unique and non redundant. As tweets which have been retweeted by other users occurred multiple times in the dataset, thus duplicates were removed using the unique tweet ID from the Twitter API response. After that, the text was strictly restricted to English language. But the problem arose that a lot of the tweets extracted were in other languages (like Arabic). Many of the Twitter accounts had their primary language as Arabic (or languages other than English) and even if they were radical, could not be considered. As the results are preliminary, so to write a unicode to work on tweets in different languages is an extensive task and out of the scope of this experiment. Then, to clean the tweets’ texts, URLs were removed for the smooth processing of data and to reduce overhead. Stopwords were removed and tokenization was done.\n\n C. Classification of tweets using machine learning techniques\n\nSupervised machine learning classification is generally employed for processing a large quantity of data which cannot be done manually. Various algorithms can be implemented on these elucidations to make the classification of tweets as radical or not. A set of training data containing tweets which were 100% radical and tweets which were 100% non radical. A feature vector for each tweet was generated on the basis of a unique feature set. The feature vector contained the value as 1 or TRUE if that particular feature was present in the tweet, and 0 or FALSE if feature was absent. Using this training data, a system is made to learn using classification algorithms: (1) SVM (Support Vector Machine), (2) Naive Bayes, (3) Adaboost Classification and (4) Random Forest Classification using scikit learn (Python library for machine learning) [5].\n\n II. RELATED WORK\n\nMachine learning is the most common approach for classification, regression and clustering. Classification involves identification among various categories a particular object belongs to. Regression predicts a continuous valued attribute which is associated with an object. Clustering means grouping of objects which exhibit nearly similar properties.\n\nA lot of research in clustering was done in [6], a topic entity relationship graph was made. The most discussed topics were the central nodes. All the users who were talking about it, or have tweeted earlier were linked to that central hub in the form of a star topology using k means clustering. A burst rate was also taken into consideration i.e. if an account was linked to that topic in the past, now not posting anything or not in context with the topic was not considered. In [1] [7], a list consisting of 66 Twitter accounts which were identified as radical but were yet blocked by Twitter and the tweets from these accounts were taken as the training data. The system was made to learn accordingly and accuracies of each classifier (SVM, Naive Bayes and AdaBoost) were calculated. The problem with the list of Twitter accounts was, firstly, majority of tweets were in Arabic language and secondly, most of the accounts have been suspended by Twitter leaving not a single account good for this experiment’s consideration making it unfit for using it as training dataset.\n\nMany researchers are solicitous for depicting the phenomena of this social problem revolving around extremist propaganda. They use online data as a proxy to study the behavior of individuals and groups. In a 2016 study [8], the authors carried out three forecasting tasks: (1) Detection of extremist accounts, (2) To reckon normal user to adopt extremist content, (3) Predicting whether a normal user will retaliate contacts generated by the extremist account. Various machine learning tools are used to create a framework that generate features of multiple dimensions including network statistics, user metadata and temporal pattern of activity. Two scenarios were taken into account for this forecasting process: a time independent, post hoc prediction task on collected data, and a real time simulated prediction task. Further concluded by determining the emanating signals that provide a thorough feature analysis by prediction in different scenarios.\n\nA few researches worked on alternative data sources. Twitter data was used as a source archive [9], some studies were based on Arabic tweets and classified these as pro ISIS and anti ISIS. Provided with the Arab Twitter users (called tweeps in their research), the account history of users were known, a model was developed to examine the interest of both groups (pro ISIS and anti ISIS) before and after they started opposing or supporting ISIS. Trends of tweets or any literature were analysed to find out the motivations that made people to follow ISIS online (not considering whether they were willing to join ISIS or not), identifying ascertained injustices known as triggers. Their analysis was divided into two parts: (1) After collection of data, global trends were determined. This provided an insight into external affairs such as ‘videos of beheadings’ or ‘sites of terrorists camps’ (2) Individual Historic Analysis for the patterns of user history before supporting ISIS.",
                    "score": 0.6595640025646171
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] Which social network or platform was utilized for data collection in the analyzed article?",
                    "answer": "The social network utilized for data collection in the analyzed article was Twitter."
                },
                {
                    "question": "[SQ] What specific data collection methods were employed on Twitter in the analyzed article?",
                    "answer": "The data collection methods employed on Twitter involved using the Twitter Search REST API to extract public tweets associated with specific hashtags related to radical groups, such as #ISIS and #IslamicState. The extraction process was repeated over a period of four weeks to gather data for roughly one month. During this period, the frequencies of all hashtags were calculated, and the most frequent and unique hashtags were used as new search queries. This iterative process resulted in the collection of approximately 57,698 tweets, of which 48,644 were unique. Additionally, tweets that were not in English were excluded from the dataset."
                },
                {
                    "question": "[SQ] How was the data from Twitter analyzed in the context of the article?",
                    "answer": "The data from Twitter was analyzed through a multi-step process that involved several stages. Initially, tweets were extracted using specific hashtags associated with radical groups. This extraction was repeated over a period of four weeks to gather a substantial dataset. The collected tweets were then cleaned by removing URLs, user mentions, hashtags, and retweet indicators to prepare the text for analysis.\n\nSubsequently, the analysis involved creating training data based on the content of the tweets, particularly focusing on hashtags as indicators of sentiment. The tweets were manually labeled, and various features were extracted from the cleaned text. A unique feature set was developed, which included the most frequent words and hashtags related to radical activities.\n\nMachine learning techniques were employed for classification, where the tweets were categorized as supporting or not supporting extremist ideologies. Different algorithms, such as Naive Bayes and Support Vector Machines, were utilized to process the data and evaluate the performance of the classification system. The results were assessed using confusion matrices to determine the accuracy of the classifiers. Overall, the analysis aimed to identify patterns and sentiments in the tweets related to extremist content."
                },
                {
                    "question": "[SQ] What was the time frame for data collection on Twitter in the analyzed article?",
                    "answer": "The data collection on Twitter was conducted over a period of approximately one month, specifically from mid-February 2017 to mid-March 2017."
                },
                {
                    "question": "[MQ] Which social network was utilized for data collection in the analyzed article, specifically involving the extraction of public tweets from Twitter over a four-week period using the Twitter Search REST API?",
                    "answer": "The social network utilized for data collection in the analyzed article was Twitter, where public tweets were extracted over a four-week period using the Twitter Search REST API."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 0.9999999999999996,
                "llm_context_precision_without_reference": 0.6592857142725286,
                "llm_context_precision_with_reference": 0.6592857142725286,
                "answer_relevancy": 0.8087136901956149,
                "answer_correctness": 0.9999999999999999
            },
            "deepeval": {
                "contextual_precision": 0.6666666666666666,
                "contextual_recall": 0.6470588235294118,
                "contextual_relevancy": 0.08888888888888889,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 39,
        "job_id": 1,
        "file_id": 8,
        "question_id": 4,
        "status": "done",
        "answer_text": "The size of the dataset analyzed in the article was 25,482 tweets.",
        "answer_encoded": "[response not coded] The analyzed dataset consisted of 25,482 tweets.",
        "answer_contexts": [
                {
                    "context": "For all the noun words from tweets were stemmed and lemmatized using nltk.stem.wordnet (WordNet stemmer) package of NLTK library. The frequency for the base word was calculated in a Python dictionary. For the abbreviations like “Islamic State” and “IS” both represent the same thing but were considered as separate entities during the experiment. To consider only English noun words, a spell checker tool was used called PyEnchant. PyEnchant [16] is a Python library for spell checking. With correct parameters, it helps in identifying if a word is an English word or not.\n\nTest data for experiment was extracted using a few of the most popular hashtags (#IslamicState, #ISIS, #AlQaeda, #Wahhabism, #Taliban and #Daesh) as seed hashtags. All the tweets with at least one of the seed hashtags were extracted using the Twitter API for one week. 10,282 unique tweets were extracted (TT TRAIN PRO [19]). A random hashtag (which was safely assumed to be not about any radical discussion) was taken (#IPL). 15,200 unique tweets were extracted from this (TT TRAIN CON [19]). The dataset of these 25,482 tweets is called TT TRAIN [19].\n\nThe tweets in TT TRAIN dataset which were extracted from the seed hashtags were random in nature as they could be talking about these radical groups in a supportive way or opposing them. In order to classify them as radical or not radical, many of the tweets were manually classified and the remainder of the tweets were classified on the basis of the occurrence of other hashtags. The tweets extracted from the random hashtags were all safely considered to be not radical in nature. The tweets were then cleaned in a similar way as the tweets in TT FEATURE. Each of them was converted to a feature vector of size 613 in length having boolean values. They were assigned a value corresponding to their manual or assumed classification as TRUE for radical tweets and FALSE for non radical tweets.\n\n IV. FEATURES\n\nIn the experiment, a total of 613 features were considered which belonged to 2 different types of feature classes:\n\n- stylometric features (SF)\n- time pattern features (TF)",
                    "score": 0.8239150348819075
                },
                {
                    "context": "improve the performance of the system. Moreover, this classification should be seen as a support to the manual checking of the tweets since the accuracy of no classifier is absolute 100% and there is a chance of wrong tweets being identified as radical. This is due to the dynamic nature of the tweets and the noise in tweets due to abbreviations, Internet slang and 140 character limit.\n\nThe untagged datasets used in the experiment (TT FEATURE, TT TRAIN and TT TEST) have been made public for future use which can be found on repository hosting website, GitHub [19]. The data is directly downloaded from Twitter using the Twitter API and is currently in JSON format. The obtained results are from a limited dataset, that too only from one social media website, Twitter. In future the experiment can be extended to a diverse and large dataset from multiple websites (like Facebook, YouTube, Reddit, etc.) and platforms. The URLs in the tweets which were ignored here can also be analysed to identify the nature of tweets. Also, considering non English languages tweets (like Arabic) can increase the reach of the classifier providing better results.\n\n VII. REFERENCES\n\n1. Michael Ashcroft, Ali Fisher, Lisa Kaati, Enghin Omer, Nico Prucha, “Detecting Jihadist Messages on Twitter”, Intelligence and Security Informatics Conference (EISIC), 2015 European\n2. “Dataset spotlight: How ISIS uses Twitter interview with Khuram Zaman” (http://www.voxpol.eu/dataset spotlight isis uses twitter interview khuram zaman), 2016\n3. Kirk Roberts, Michael A. Roach, Joseph Johnson, Josh Guthrie, Sanda M. Harabagiu D. Correa and A. Sureka, “EmpaTweet: Annotating and Detecting Emotions on Twitter”, LREC 2012\n4. Twitter, Inc.. Twitter Developer Documentation (https://dev.twitter.com/rest/public/search), 2017\n5. Google, scikit learn Machine Learning in Python, (http://scikit learn.org), 2017\n6. Pooja Wadhwa and Dr M.P.S Bhatia, “Tracking online radicalization using investigative data mining”, Communications (NCC), 2013\n7. A. Fisher and N. Prucha, “The call up: The roots of a resilient and persistent Jihadist presence on Twitter”, CTX Vol.4 No.3, 2014\n8. Emilio Ferrara, Wen Qiang Wang, Onur Varol, Alessandro Flammini and Aram Galstyan, “Predicting online extremism, content adopters, and interaction reciprocity”, arXiv:1605.00659v1, [cs.SI] 2 May 2016\n9. Walid Magdy, Kareem Darwish, and Ingmar Weber, “#FailedRevolutions: Using Twitter to Study the Antecedents of ISIS Support”, arXiv:1503.02401v1 [cs.SI] 9 Mar 2015\n10. Swati Agarwal, Ashish Sureka, “Learning to Classify Hate and Extremism Promoting Tweets”, 2014 IEEE Joint Intelligence and Security Informatics Conference\n11. Denzil Correa and Ashish Sureka, “Solutions to Detect and Analyze Online Radicalization: A Survey,” arXiv preprint arXiv:1301.4916, 2013\n12. S. Agarwal and A. Sureka, “A focused crawler for mining hate and extremism promoting videos on YouTube.”, Proceedings of the 25th ACM conference on Hypertext and social media, 2014, pp. 294–296\n13. A. Sureka and S. Agarwal, “Using KNN and SVM Based One Class Classifier for Detecting Online Radicalization on Twitter,” Distributed Computing and Internet Technology. Springer, 2015, pp. 431–442.\n14. NLTK Project, Natural Language Toolkit, (http://www.nltk.org/), 2017\n15. Penn Treebank P.O.S. (Part of speech) Tags, (https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)\n16. Ryan Kelly, PyEnchant A Spell checking Library for Python, (https://pythonhosted.org/pyenchant/), 2014\n17. Adam Badawy and Emilio Ferrara, “The Rise of Jihadist Propaganda on Social Networks”, ArXiv 2017\n18. J.M. Berger and Jonathon Morgan, “The ISIS Twitter Census Defining and describing the population of ISIS supporters on Twitter”, The Brookings Project on U.S. Relations with the Islamic World Analysis Paper | No. 20, March 2015\n19. Radicalization Twitter Dataset, (https://git.io/vHTUP), 2017",
                    "score": 0.6580033649778234
                },
                {
                    "context": "The most frequent 443 words were used as the features. The 10 most frequent words from these 443 were, “isis”, “monitor”, “imam”, “thanks”, “world”, “woman”, “group”, “saudi”, “attack”, “mischief”, “fighter”, “car”. Among the most frequent words used, we can notice the words that are related to radical activities (“isis”, “attack”), words that can or cannot relate to radical activities (“world”, “woman”, “car”) and also the word imam. The word imam refers to the person who leads prayers in a mosque. It is a word originated from Arabic language.\n\nThe 139 most frequent hashtags were used for the experiment. The 10 most frequent hashtags were, #ISIS, #IslamicState, #Taliban, #IS, #Wahhabism, #AlQaeda, #SaudiArabia, #ISIL, #Syria, #Daesh. It can be observed that all of the most frequent hashtags are related to radical groups and their activities. #ISIS, #IslamicState, #IS, #ISIL, #Daesh all signify the Sunni militant group. #AlQaeda and #Taliban also are militant groups, whereas #SaudiArabia and #Syria are the countries which are affected by these groups.\n\n B. Time Pattern Features (TF)\n\nThe date and time at which the tweet was posted for recognizing a pattern was used. The day of the week and the hour of day were used since other attributes like month were not relevant in our experiment since the data from 4 weeks. The considered attributes are:\n\n- Hour of day (Hour 0, Hour 1, Hour 2, …, Hour 23)\n- Day of week (Monday, Tuesday, …, Sunday)\n\nIn total 31 time pattern features were used, 24 for hours and 7 for days.\n\nFig. 1. Tweets tweeted at various hours of day\n\n V. EXPERIMENTAL RESULTS\n\nA tool called scikit learn was used for various classifications. It is an open source Python library for machine learning built using NumPy, SciPy, and matplotlib libraries. A dataset with 5,297 tweets was extracted using the extraction method as TT FEATURE dataset using a seed hashtag (#GameOfThrones). This dataset was called TT TEST [19] and the ratio between training data and testing was approximately 1:5. Different classification algorithms used were: Naive Bayes, SVM (Support Vector Machines),\n\n VI. CONCLUSION AND FUTURE WORK\n\nIn this work, supervised machine learning was used to identify radical social media posts. The major problem with this classification was manually labelling the test data as radical or not radical. The dataset extracted was dependent on the seed hashtags which were selected initially. In future more independence to dataset should be there. The texts, images and videos issued by various radical and extremists groups which are collected by intelligence agencies can also be used to.",
                    "score": 0.507979022359607
                },
                {
                    "context": "extraction, data classification and evaluating performance. In first stage, all the tweets that were in English language were extracted and combined to form a single unique dataset. Second stage consisted of the creation of training data based on hashtags, as hashtags are the best indicator of the sentiment of tweets. Tweets were labelled manually and recursively extended to find new hashtags based on some seed hashtags. Stage three involves data pre processing to remove the hashtags and @username. Stage four includes extraction of different features on the basis of data extracted. In stage five, on the basis of two independent classifiers, tweets were classified as supporting ISIS or not. To complete the process, the last stage involves creation of confusion matrix to judge the accuracy of above classifiers. The problem with this approach was that only the hashtags were considered for the classification parameters without considering the text or any other linguistic structure of the tweets since there are a lot of tweets without any hashtags and there are many tweets with more hashtags than just one.\n\n III. APPROACH FOR IDENTIFICATION\n\nTwitter Search REST API [4] was used for extracting the public tweets for the hashtags which are associated with the radical groups. A few seed hashtags (#ISIS, #IslamicState) were selected manually and all the tweets for those hashtags were extracted. The API only provides the data for 7 days so the process of extraction was repeated for 4 weeks, giving the data for roughly 1 month (mid February 2017 to mid March 2017). For the tweets extracted, the frequencies of all the hashtags were calculated and recursively the most frequent and unique hashtag was used as the new search query. This process was repeated for 18 more hashtags (apart from seed hashtags) giving around 57,698 tweets of which 48,644 tweets were unique. The tweets which didn’t have primary language as English were not considered regardless of their content. This dataset is called TT FEATURE [19]. After extracting tweets, the most popular hashtags are shown in Table I.\n\nThis data was used to extract the linguistic features and most popular hashtags. For extraction of these features, a tool called NLTK (Natural Language ToolKit) [14] was used. It is an open source suite of various libraries for statistical Natural Language Processing (NLP) for English. It is written in Python language.\n\nThe texts of these tweets were cleaned by removing the URLs, user mentions (@), hashtags (#) and the term ‘RT’ (Retweet). The clean text was, then, tokenized using nltk.tokenize package in the NLTK library giving us the POS (Part of Speech) tags for every word. Only the words with noun POS tags (NN, NNS, NNP, NNPS) [15] were considered. Many of the words had same meaning but occurred in different form like jihad, jihadi, jihadist and jihadology. The derivationally related forms and inflectional forms of a word were reduced to a common base word (“jihad” in this example). This technique is called stemming.\n\n TABLE I. MOST POPULAR HASHTAGS",
                    "score": 0.5000312609238527
                },
                {
                    "context": "Identifying Radical Social Media Posts using Machine Learning\n\n Prabhakar Gupta¹, Pulkit Varshney¹, M. P. S. Bhatia²\n\n¹ Division of Information Technology, Netaji Subhas Institute of Technology, Delhi, India\n\nprabhakar.gupta@nsitonline.in, pulkitvarshney186@gmail.com\n\n² Division of Computer Engineering, Netaji Subhas Institute of Technology, Delhi, India\n\nbhatia.mps@gmail.com\n\n Abstract\n\nRadicalization (like cyberterrorism) is one of the major concerns to all governments and law enforcement agencies to provide safety and security to their citizens. A lot of radical groups, extremists and insurgent organizations use social media platforms such as Facebook, Twitter, Reddit, YouTube etc. to post their ideology and propagate their message to their followers. Manual detection of these posts is nearly an impossible task. We propose an automated system for extracting data from Twitter employing investigative data mining technique using the hashtags used in the posts. The system preprocesses the data to clean it by tokenizing, stemming and lemmatization. Data is classified as radical or nonradical using supervised machine learning classification techniques (Naive Bayes, SVM, AdaBoost and Random Forest) with varying parameters. The idea is to classify posts by identifying the linguistic structure, their stylometry and detecting a time based pattern.\n\n Keywords\n\nRadicalization; Cyberterrorism; Machine Learning; Data Mining; Shorttext classification\n\n I. INTRODUCTION\n\nSince the late 1980s, the World Wide Web has become a highly powerful means of communication worldwide, reaching an ever growing audience. According to the FBI, international radicalization has following characteristics: (1) it involves violent acts harming other human life that can violate government laws (2) it is intended to intimidate civilian masses (3) it affects the policy of any government by coercion (4) it influences the conduct of a government by kidnapping, mass destruction, or assassination. Radical groups have started using the Internet to disseminate information that aid their causes. The availability of terrorist related material on the Internet plays an important role in radicalization processes. Due to this increasing availability of content on social media websites (such as Twitter, Facebook and Reddit etc.) there is an urgent need to identify these radical tweets.\n\nIn the pro radical networks, large amount of information is carried and commanded by a limited number of individuals. Most of the radical groups have shifted their focus from mainstream media to digital and social media to broadcast the information to new or younger groups or individuals, who can get the information by searching through hashtags and further by following them.\n\n A. Data extraction\n\nExtraction of tweets is done from Twitter. Attributes associated to a single tweet are URLs, text, user mentions, hashtags, media files (image, audio and video), timestamp, number of retweets, likes etc. and the user information. The main focus was on text mining as storing media files would, firstly, need a lot of space and secondly, analysing media files for radical content would require additional machine learning techniques. The texts were collected without knowing the sentiment. For example, when collecting tweets on hashtag #Syria (which is in the list of top 10 most frequent hashtags), it is not known initially whether:\n\n- The tweet is posted by a person associated with terrorist organisation or not;\n- Someone abominates the very idea of radicalization, showing disbelief and expressing against a pro extremist person;\n- Someone is discussing something general related to Syria, not in context with terrorism.\n\n B. Preprocessing of data\n\nData preprocessing is a necessary step after data extraction.",
                    "score": 0.33705057919307474
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What was the size of the dataset analyzed in the article?",
                    "answer": "The size of the dataset analyzed in the article was 25,482 tweets, which included 10,282 unique tweets extracted from seed hashtags related to radical discussions and 15,200 unique tweets extracted from a random hashtag assumed to be non-radical."
                },
                {
                    "question": "[SQ] What criteria were used to select the seed hashtags for the radical discussions?",
                    "answer": "The seed hashtags for radical discussions were selected based on their association with known radical groups and ideologies. Specifically, popular hashtags such as #ISIS, #IslamicState, #AlQaeda, #Wahhabism, and #Taliban were chosen as they are directly linked to extremist organizations and their activities. These hashtags served as indicators for extracting relevant tweets related to radical discussions."
                },
                {
                    "question": "[SQ] How were the tweets categorized as radical or non-radical in the analysis?",
                    "answer": "The tweets were categorized as radical or non-radical through a combination of manual classification and automated methods. Initially, many tweets were manually classified based on their content. For the remaining tweets, classification was performed based on the occurrence of specific hashtags associated with radical groups. Tweets extracted from seed hashtags related to radical activities were labeled as radical, while those from a random hashtag, assumed to be non-radical, were classified as non-radical. Each tweet was then converted into a feature vector, with values assigned to indicate whether they were classified as radical (TRUE) or non-radical (FALSE)."
                },
                {
                    "question": "[SQ] What was the time frame during which the tweets were collected for the dataset?",
                    "answer": "The tweets were collected over a period of roughly one month, specifically from mid-February 2017 to mid-March 2017."
                },
                {
                    "question": "[MQ] What was the total size of the analyzed dataset, including the 10,282 unique tweets from radical seed hashtags and 15,200 unique tweets from a random non-radical hashtag?",
                    "answer": "The total size of the analyzed dataset was 25,482 tweets, which includes 10,282 unique tweets from radical seed hashtags and 15,200 unique tweets from a random non-radical hashtag."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0.875,
                "semantic_similarity": 0.8250646855618414,
                "llm_context_precision_without_reference": 0.3373015872903439,
                "llm_context_precision_with_reference": 0.3373015872903439,
                "answer_relevancy": 0.8568086381427,
                "answer_correctness": 0.372932838057127
            },
            "deepeval": {
                "contextual_precision": 1.0,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.36363636363636365,
                "answer_relevancy": 1.0,
                "faithfulness": 0.6
            }
        },
    },
    {
        "id": 40,
        "job_id": 1,
        "file_id": 8,
        "question_id": 5,
        "status": "done",
        "answer_text": "The study evaluated the following performance metrics:\n\n- Citations for the specific work: 4\n- Reads for the specific work: 1,216\n- Total publications: 9\n- Total citations for all publications: 39\n- Specific publication: 1\n- Citations for the specific publication: 4",
        "answer_encoded": "[response not coded] The study's performance metrics included 4 citations for the specific work, 1,216 reads, 9 total publications, and 39 total citations across all publications.",
        "answer_contexts": [
                {
                    "context": "This table presents the number of citations and reads for a specific work, indicating its academic impact and audience engagement.,\nwith the following columns:\n- CITATIONS: The total number of times the work has been cited.\n- READS: The total number of times the work has been read.\n\n| CITATIONS | READS |\n|---|---|\n|4| 1,216 |",
                    "score": 0.8315004944322948
                },
                {
                    "context": "This table summarizes the number of publications and citations for two different categories: total publications and a specific publication.,\nwith the following columns:\n- Publications: Total number of publications and specific publications.\n- Citations: Total number of citations and citations for a specific publication.\n\n| 9 PUBLICATIONS | 39 CITATIONS |\n|---|---|\n| 1 PUBLICATION  | 4 CITATIONS  |",
                    "score": 0.8204547849367672
                },
                {
                    "context": "A. Stylometric Features (SF)\n\nAdaBoost and Random Forest Classification. SVM was tested over different values of its “kernel” parameter to get the optimum results for various kernels.",
                    "score": 0.6008640447236856
                },
                {
                    "context": "3 authors, including:\n\n- Prabhakar Gupta - Amazon\n- Pulkit Varshney - Stony Brook University",
                    "score": 0.4232683775992099
                },
                {
                    "context": "This table presents the frequency of the most common noun words and hashtags, indicating their occurrence counts.,\nwith the following table title:\nfrequent words,\nwith the following columns:\n- occurrence of most frequent noun words: 443\n- occurrence of most frequent hashtags: 139\n\n| frequent words | occurrence of most frequent noun words | 443 |\n|---|---|---|\n| hashtags       | occurrence of most frequent hashtags   |139|",
                    "score": 0.25665266045015106
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific performance metrics were evaluated in the study, and what were their corresponding values?",
                    "answer": "The study evaluated the following performance metrics:\n\n1. **Citations**: 4\n2. **Reads**: 1,216\n\nAdditionally, it included metrics related to publications and citations:\n\n- **Total Publications**: 9\n- **Total Citations**: 39\n- **Specific Publication**: 1\n- **Citations for Specific Publication**: 4\n\nThese metrics reflect the academic impact and audience engagement of the work."
                },
                {
                    "question": "[SQ] What were the methodologies used to collect the performance metrics in the study?",
                    "answer": "The methodologies used to collect performance metrics in the study involved several stages. Initially, tweets in English were extracted to form a unique dataset. This was followed by creating training data based on hashtags, which were identified as strong indicators of tweet sentiment. The tweets were manually labeled, and new hashtags were recursively identified based on seed hashtags.\n\nSubsequently, data preprocessing was conducted to remove hashtags and usernames. Various features were extracted from the cleaned data. Two independent classifiers were then employed to classify the tweets as supportive of ISIS or not. Finally, a confusion matrix was created to evaluate the accuracy of the classifiers, allowing for the assessment of the performance metrics."
                },
                {
                    "question": "[SQ] How do the evaluated performance metrics compare to those in similar studies?",
                    "answer": "The evaluated performance metrics in this study can be compared to those in similar studies by examining the methodologies and results reported in the references. Many studies focus on the classification of tweets related to extremism and radicalization, utilizing various machine learning techniques. The performance of classifiers, such as AdaBoost and Random Forest, is often assessed through metrics like accuracy, precision, recall, and F1-score. \n\nIn the context of this study, the performance metrics may vary based on the dataset used, the specific algorithms implemented, and the nature of the tweets analyzed. For instance, some studies may report higher accuracy due to larger and more diverse datasets or different feature extraction methods. Additionally, the dynamic nature of social media content can impact the effectiveness of classifiers, as noted in the discussion about the challenges posed by abbreviations and slang in tweets.\n\nTo draw a more precise comparison, one would need to analyze the specific performance metrics reported in the referenced studies and how they align with the findings of this work."
                },
                {
                    "question": "[SQ] What implications do the performance metrics have for future research or practice?",
                    "answer": "The performance metrics, such as the number of citations and reads, indicate the academic impact and audience engagement of the research. A higher number of citations suggests that the work is being referenced and utilized by other researchers, which can lead to further studies building upon its findings. The substantial number of reads indicates a strong interest in the topic, suggesting that future research could explore related areas or delve deeper into the themes presented. \n\nMoreover, the limitations highlighted in the research, such as biases in data collection and the constraints of social media platforms, imply that future studies should consider broader datasets and diverse sources to enhance the robustness of their findings. This could involve integrating data from multiple social media platforms and languages to provide a more comprehensive understanding of the phenomena being studied. Overall, these metrics can guide researchers in identifying impactful areas for exploration and improving methodologies for data collection and analysis."
                },
                {
                    "question": "[MQ] What performance metrics were evaluated in the study, including citations, reads, total publications, and their respective values?",
                    "answer": "The study evaluated the following performance metrics:\n\n- Citations: 4\n- Reads: 1,216\n- Total Publications: 9\n- Citations for a specific publication: 4"
                },
                {
                    "question": "[SQ] What is the significance of the number of reads in relation to the study's impact?",
                    "answer": "The number of reads indicates the level of audience engagement with the work, reflecting its reach and interest among readers. A higher number of reads suggests that the work is being accessed and considered by a larger audience, which can be an important factor in assessing its academic impact alongside the number of citations."
                },
                {
                    "question": "[SQ] How do the total publications compare to the average number of publications in similar studies?",
                    "answer": "The total number of publications is 9. To determine how this compares to the average number of publications in similar studies, specific data on the average number of publications in those studies would be required. Without that information, a direct comparison cannot be made."
                },
                {
                    "question": "[SQ] What trends can be observed in the citation metrics over time for this study?",
                    "answer": "The citation metrics indicate a total of 39 citations across 9 publications, with one specific publication receiving 4 citations. This suggests that while there is a moderate level of engagement with the overall body of work, individual publications may vary in their impact. The total number of reads for the specific work is significantly higher at 1,216, indicating that while the work is read frequently, it may not be cited as often. This discrepancy between reads and citations could suggest that the work is popular among readers but may not be perceived as highly influential or relevant for citation in academic contexts."
                },
                {
                    "question": "[MQ] What specific performance metrics, including citations, reads, total publications, and their respective values, were evaluated in the study?",
                    "answer": "The study evaluated the following performance metrics:\n\n- Citations for the specific work: 4\n- Reads for the specific work: 1,216\n- Total publications: 9\n- Total citations for all publications: 39\n- Specific publication: 1\n- Citations for the specific publication: 4"
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 1.0,
                "semantic_similarity": 0.8535166001091572,
                "llm_context_precision_without_reference": 0.6111111110805556,
                "llm_context_precision_with_reference": 0.6111111110958334,
                "answer_relevancy": 0.9071407984895723,
                "answer_correctness": 0.2133791500272893
            },
            "deepeval": {
                "contextual_precision": 0.6131313131313131,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.14473684210526316,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        }
    },
        {
        "id": 41,
        "job_id": 1,
        "file_id": 9,
        "question_id": 1,
        "status": "done",
        "answer_text": "The study utilized the Random Forest (RF) algorithm for classification tasks. This algorithm contributed to the overall findings by effectively distinguishing between radical and non-radical tweets, demonstrating high performance across various evaluation metrics such as accuracy, precision, recall, and F-measure. The results indicated that the RF model, particularly when combined with psychological features, was able to achieve robust classification results, highlighting the importance of contextual and psychological dimensions in detecting online radicalization.",
        "answer_encoded": "RF",
        "answer_contexts": [
                {
                    "context": "tend to require very large amounts of data to train. For the purpose of this study, we experimented with multiple classification algorithms, including RF, NN, SVM, and KNN and found that RF and NN produced the best performance. Due to space limitation, we only report results obtained using RF model. We configured the model to use 100 estimators trees with a maximum depth of 50, and we selected gini impurity for the split criteria. We used the out-of-bag samples (oob) score to estimate the generalization accuracy of the model. Additionally, since RF tends to be biased towards the majority class, we apply the cost sensitive learning method described earlier to make RF more suitable for imbalanced data [25].\n\nWe divided the dataset to training set (80%) and testing set 20%), where the testing set is held out for validation. We reported validation results using different combinations of the features categories (i.e., FT, FB, FP) and different evaluation metrics: accuracy, recall, precision, f-measure, and area under the ROC curve. Recall measures how many radical tweets we are able to detect, while precision measures how many radical tweets we can detect without falsely accusing anyone. For instance, if we identify every single tweet as radical, we will expose all radical tweets and thus obtain high recall, but at the same time, we will call everyone in the population a radical and thus obtain low precision. F-measure is the average of both precision and recall.\n\n C. Results\n\nExp 1: The classification results using the known-bad and random-good datasets are reported in Table I. The table shows the average accuracy, precision, recall and f-measure scores obtained from each feature category (FT, FP, FB) and their combination (FAll). We also compared the two textual models, and find that results obtained from using word embedding outperforms the use of n-grams tf-idf scores. This confirms that contextual information is important in detecting radicalization activities. Furthermore, our model performed best using the FP features across all metrics. This means that the model is able to distinguish between both radical and non-radical with high confidence using only FP.\n\nExp 2: In this experiment, we tested the performance of our classifier in distinguishing between radical and normal tweets that discusses ISIS-related topics. Although this task is more challenging given the similarity of the topic discussed in the two classes, we find that the model still achieves high performance. Table II shows the different metrics obtained from each feature category. The FT feature group obtains 80% accuracy, and 91%, 100% for FB and FP feature groups, respectively. The results are consistent with the ones obtained from the first experiment with the features from FP group contributing to the high accuracy of the model. The area under the Receiver Operator Characteristic (ROC) curve, which measures accuracy based on TP, and FP rates, is shown in Fig. 2 for each classification model.\n\n D. Features Significance\n\nWe investigated which features contribute most to the classification task to distinguish between radical and non-radical tweets. We used the mean decrease impurity method of random forests [28] to identify the most important features in each feature category. The ten most important features are shown in Table III. We found that the most important feature for distinguishing radical tweets is the psychological feature distance measure. This measures how similar the Twitter user is to the average psychological profile calculated from the propaganda magazine articles. Following this is the Us-them dichotomy which looks at the total number of pronouns used (I, they, we, you). This finding is in line with the tactics reported in the radicalization literature with regards to emphasizing the separation between the radical group and the world.\n\nFig. 2: ROC curve for Exp1 (top), Exp2 (bottom).",
                    "score": 0.8503343486950855
                },
                {
                    "context": "(6) If the tweet text contains any words with all capital characters, we record its existence in a new attribute, allCaps, and then normalize the text to lower-case and filter out any non-alphabetic characters. (7) We tokenize the cleansed tweet text into words, then we perform lemmatization, the process of reducing inflected words to their roots (lemma), and store the result in a vector.\n\n B. Experimental Set-up\n\nWe conducted two experiments using the datasets described in Section IV-A. Our hypothesis is that supporters of groups such as ISIS may exhibit similar textual and psychological properties when communicating in social media to the properties seen in the propaganda magazines. A tweet is considered radical if it promotes violence, racism, or supports violent behaviour. In Exp 1 we use the first two datasets, i.e., the known-bad and the random-good datasets to classify tweets to radical and normal classes. For Exp 2 we examine if our classifier can also distinguish between tweets that are discussing similar topics (ISIS related) by using the known-bad and the counterpoise datasets.\n\nThe classification task is binomial (binary) classification where the output of the model predicts whether the input tweet is considered radical or normal. In order to handle the imbalanced class problem in the dataset, there are multiple techniques suggested in the literature. Oversampling or undersampling of the minority/majority classes are common techniques. Another technique that is more related to the classification algorithm is cost sensitive learning, which penalizes the classification model for making a mistake on the minority class. This is achieved by applying a weighted cost on misclassifying of the minority class [25]. We will use the last approach to avoid downsampling of our dataset.\n\nPrevious research investigating similar problems reported better performances for Random Forest (RF) classifiers [26]. RF usually performs very well as it is scalable and is robust to outliers. RF typically outperforms decision trees as it has a hierarchical structure and is based on multiple trees. This allows RF to be able to model non-linear decision boundaries. Moreover, Neural Networks (NN) also produced good results when applied to problems related to image recognition, text and natural language processing [27]. However, they usually",
                    "score": 0.5170800688997859
                },
                {
                    "context": "This table presents the performance metrics of various feature extraction methods, including accuracy (AC), precision, recall, and F-measure. The methods evaluated include T (tf-idf), FT (w2v), FT, FB, FFP, and ALL, with FFP and ALL achieving the highest scores across all metrics.,\nwith the following columns:\n- Features: Different feature extraction methods evaluated.\n- AC: Accuracy of each feature extraction method.\n- Precision: Precision score for each method.\n- Recall: Recall score for each method.\n- F-measure: F-measure score for each method.\n\n| Features     | AC   | Precision | Recall | F-measure |\n|---|---|---|---|---|\n| T (tf − idf) |0.52|0.76|0.52|0.37|\n| FT (w2v)     |0.81|0.82|0.81|0.81|\n| FT           |0.84|0.84|0.84|0.84|\n| FB           |0.94|0.95|0.94|0.94|\n| FFP          |1.0|1.0|1.0|1.0|\n| ALL          |1.0|1.0|1.0|1.0|",
                    "score": 0.514239781514909
                },
                {
                    "context": "Moreover, among the top contributing features are behavioral features related to the number of mentions a single user makes, and their HITS hub and authority rank among their interaction network. This relates to how active the user is in interacting with other users and how much attention they receive from their community. This links to the objectives of those radical users in spreading their ideologies and reaching out to potential like-minded people. As for the category, we find that the use of word2vec embedding improves the performance in comparison with using the tf-idf features. Additionally, all bi-grams and tri-grams features did not contribute much to the classification; only uni-grams did.\n\nThis can be related to the differences in the writing styles when constructing sentences and phrases in articles and in the social media context (especially given the limitation of the number of words allowed by the Twitter platform). Additionally, the violent word ratio, longWords, and allCaps features are among the top contributing features from this category. This finding agrees to a large extent with observations from the literature regarding dealing with similar problems, where the use of dictionaries of violent words aids with the prediction of violent extremist narrative.\n\n V. CONCLUSION AND FUTURE WORK\n\nIn this paper, we identified different signals that can be utilized to detect evidence of online radicalization. We derived linguistic and psychological properties from propaganda published by ISIS for recruitment purposes. We utilize these properties to detect pro-ISIS tweets that are influenced by their ideology. Unlike previous efforts, these properties do not only focus on lexical keyword analysis of the messages, but also add a contextual and psychological dimension. We validated our approach in different experiments and the results show that this method is robust across multiple datasets. This system can aid law enforcement and OSN companies to better address such threats and help solve a challenging real-world problem. In future work, we aim to investigate if the model is resilient to different evasion techniques that users may adopt. We will also expand the analysis to other languages.\n\n REFERENCES\n\n[1] F. Morstatter, N. Lubold, H. Pon-Barry, J. Pfeffer, and H. Liu, “Finding eyewitness tweets during crises,” arXiv preprint arXiv:1403.1773, 2014.\n\n[2] A. Tumasjan, T. Sprenger, P. Sandner, and I. Welpe, “Predicting elections with twitter: What 140 characters reveal about political sentiment,” in Int. Conference on Web and Social Media, 2010.\n\n[3] C. Edwards and L. Gribbon, “Pathways to violent extremism in the digital era,” The RUSI Journal, vol. 158, no. 5, pp. 40–47, 2013.",
                    "score": 0.4147722996286898
                },
                {
                    "context": "This table presents the performance metrics of various feature extraction techniques, including Accuracy (AC), Precision, Recall, and F-measure.,\nwith the following columns:\n- Features: Different feature extraction methods used.\n- AC: Accuracy of the feature extraction methods.\n- Precision: Precision metric for each method.\n- Recall: Recall metric for each method.\n- F-measure: F-measure for evaluating the methods.\n\n| Features      | AC   | Precision | Recall | F-measure |\n|---|---|---|---|---|\n| FT (tf − idf) |0.56|0.69|0.56|0.48|\n| FT (w2v)      |0.73|0.73|0.73|0.73|\n| FT            |0.8|0.8|0.8|0.8|\n| FB            |0.91|0.92|0.91|0.91|\n| FP            |1.0|1.0|1.0|1.0|\n| FALL          |1.0|1.0|1.0|1.0|",
                    "score": 0.40957611669436755
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific AI algorithm was utilized in the study, and how does it contribute to the overall findings presented in the article?",
                    "answer": "The study utilized the Random Forest (RF) algorithm for classification tasks. This algorithm contributed to the overall findings by effectively distinguishing between radical and non-radical tweets, demonstrating high performance across various evaluation metrics such as accuracy, precision, recall, and F-measure. The results indicated that the RF model, particularly when combined with psychological features, was able to achieve robust classification results, highlighting the importance of contextual and psychological dimensions in detecting online radicalization."
                },
                {
                    "question": "[SQ] What are the key features used in the Random Forest algorithm for this study?",
                    "answer": "The key features used in the Random Forest algorithm for this study include:\n\n1. Radical psych-profile distance (FP)\n2. Us-Them dichotomy (FP)\n3. Number of mentions a user makes (FB)\n4. User rank (hub and authority) (FB)\n5. Sad emotion (FP)\n6. Risk driver (FP)\n7. All-caps count (FT)\n8. URL count (FT)\n9. Violent-word ratio (FT)\n10. Hash count (FT)\n\nThese features are categorized into psychological profiling, user behavior, and text analysis."
                },
                {
                    "question": "[SQ] How does the performance of the Random Forest algorithm compare to other AI algorithms used in similar studies?",
                    "answer": "The Random Forest algorithm demonstrated superior performance compared to other classification algorithms such as Neural Networks, Support Vector Machines, and K-Nearest Neighbors in the experiments conducted. Specifically, it was noted that Random Forest produced the best results in terms of accuracy, precision, recall, and F-measure when applied to the datasets used in the study. Additionally, previous research has indicated that Random Forest classifiers generally outperform other methods, particularly in tasks involving imbalanced data, due to their robustness and ability to model non-linear decision boundaries effectively."
                },
                {
                    "question": "[SQ] What specific evaluation metrics were used to assess the performance of the Random Forest model in this research?",
                    "answer": "The evaluation metrics used to assess the performance of the Random Forest model in this research included accuracy, recall, precision, f-measure, and area under the ROC curve."
                },
                {
                    "question": "[MQ] What role did the Random Forest algorithm play in the study's findings, particularly in distinguishing between radical and non-radical tweets, and what key features contributed to its performance?",
                    "answer": "The Random Forest algorithm was central to the study's findings, demonstrating strong performance in distinguishing between radical and non-radical tweets. It was configured with 100 estimators and a maximum depth of 50, utilizing gini impurity for the split criteria. The model's effectiveness was evaluated using out-of-bag samples to estimate generalization accuracy, and it was enhanced through cost-sensitive learning to address class imbalance.\n\nKey features that contributed to the performance of the Random Forest model included psychological features, particularly the psychological feature distance measure, which assessed the similarity of Twitter users to average psychological profiles derived from extremist propaganda. Additionally, the Us-them dichotomy, indicated by the use of pronouns, was significant. Behavioral features, such as the number of mentions a user makes and their authority rank within their interaction network, also played a crucial role. The use of word embeddings further improved the model's performance compared to traditional tf-idf features, highlighting the importance of contextual information in detecting radicalization activities."
                },
                {
                    "question": "[SQ] What specific configurations were used for the Random Forest algorithm in the study, and how did they impact its performance?",
                    "answer": "The Random Forest algorithm in the study was configured to use 100 estimators (trees) with a maximum depth of 50, and the split criteria selected was gini impurity. These configurations contributed to the model's performance by allowing it to effectively handle the classification task, particularly in distinguishing between radical and non-radical tweets. The use of out-of-bag samples (oob) score helped estimate the generalization accuracy, and the application of cost-sensitive learning addressed the bias towards the majority class, making the model more suitable for imbalanced data. Overall, these configurations enhanced the model's ability to achieve high accuracy and other performance metrics."
                },
                {
                    "question": "[SQ] How did the use of cost-sensitive learning enhance the Random Forest model's ability to distinguish between radical and non-radical tweets?",
                    "answer": "Cost-sensitive learning enhanced the Random Forest model's ability to distinguish between radical and non-radical tweets by addressing the issue of class imbalance in the dataset. This approach penalizes the model for misclassifying instances of the minority class (in this case, radical tweets), which helps to reduce bias towards the majority class. By applying a weighted cost on misclassifications, the model becomes more sensitive to the characteristics of radical tweets, improving its overall performance in accurately identifying them amidst a larger number of non-radical tweets. This adjustment allows for a more balanced consideration of both classes during the training process, leading to better detection of radical content."
                },
                {
                    "question": "[SQ] What role did word embeddings play in improving the Random Forest model's performance compared to traditional feature extraction methods?",
                    "answer": "Word embeddings significantly enhanced the performance of the Random Forest model by providing a more nuanced representation of textual data compared to traditional feature extraction methods like tf-idf. The use of word embeddings allowed the model to capture contextual relationships and semantic meanings within the text, leading to improved accuracy and effectiveness in distinguishing between radical and non-radical tweets. This was evidenced by the superior performance metrics achieved when using word embeddings, particularly in the feature category that utilized this approach, which outperformed the n-grams tf-idf scores."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 1.0000000000000004,
                "llm_context_precision_without_reference": 0.45833333331805554,
                "llm_context_precision_with_reference": 0.45833333331805554,
                "answer_relevancy": 0.0,
                "answer_correctness": 1.0
            },
            "deepeval": {
                "contextual_precision": 0.0,
                "contextual_recall": 0.0,
                "contextual_relevancy": 0.0,
                "answer_relevancy": 0.25,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 42,
        "job_id": 1,
        "file_id": 9,
        "question_id": 2,
        "status": "done",
        "answer_text": "The analysis focused on three categories of features: Radical Language, Psychological Signals, and Behavioral Features.\n\n1. **Radical Language**: This category examined the content of extremist propaganda, particularly from ISIS's Dabiq magazine, to identify topics, textual properties, and linguistic cues that characterize radical messages.\n\n2. **Psychological Signals**: Features in this category aimed to create psychological profiles based on the language used in extremist articles, incorporating emotional and topical categories derived from a dictionary-based tool.\n\n3. **Behavioral Features**: This category measured user behavior, including tweet frequency, followers/following ratio, and interactions with others through mentions and hashtags. A mention interaction graph was used to assess user influence within their networks.\n\nThese features were justified as they aimed to capture the essence of radical content and user behavior, aligning with the research objective of detecting radical activities on social media.",
        "answer_encoded": "[response not coded] The analysis selected features from three categories: Radical Language, Psychological Signals, and Behavioral Features to capture the essence of radical content and user behavior on social media.",
        "answer_contexts": [
                {
                    "context": "III. METHODOLOGY\n\nAs illustrated in Fig. 1, our approach consists of two main phases: Phase 1: Radical Properties Extraction, where articles from Dabiq extremist magazines are input into this step to perform two parallel tasks. In the first task, we build a language model using (i) Term-Frequency Inverse-Document-Frequency (TF-IDF) scores of uni-, bi-, and tri-grams, and (ii) Word embeddings generated from a word2vec model [16]. The output of this task is a radical corpus of top k-grams, and a word embedding model giving a vector representation for each word in the corpus. The second task seeks to create a psychological profile based on the language used in the extremist propaganda articles, consisting of a set of emotional and topical categories using LIWC dictionary-based tool. Phase 2: Tweet classification involves the use of the models generated from Phase 1 to engineer features related to radical activities. We identify three groups of features and then train a binary classifier to detect radical tweets.\n\n A. Feature Engineering\n\nFeature engineering is the process of exploring large spaces of heterogeneous features with the aim of discovering meaningful features that may aid in modeling the problem at hand. We explore three categories of information to identify relevant features to detect radical content. Some features are user-based while others are message-based. The three categories are: 1) Radical language (Textual features FT); 2) Psychological signals (Psychological features FP); and 3) Behavioural features (FB). In the following, we detail each of these categories.\n\n 1) Radical Language:\n\nIn order to understand how radical messages are constructed and used, as mentioned earlier, we analyze content of ISIS propaganda material published in Dabiq magazine. Dabiq is an online magazine published by ISIS terrorist groups with the purpose of recruiting people and promoting their propaganda and ideology. Using this data source, we investigate what topics, textual properties, and linguistic cues exist in these magazines. Our intuition is that...",
                    "score": 0.667371460015104
                },
                {
                    "context": "3) Behaviour Signals\n\nThis category consists of measuring behavioural features to capture different properties related to the user and their behaviour. This includes how active the user is (frequency of tweets posted) and the followers/following ratio. Additionally, we use features to capture users’ interactions with others through using hashtags, and engagement in discussions using mention action. To capture this, we construct the mention interaction graph (GM) from our dataset, such that GM = (U, E), where U represents the user nodes and E represents the set of edges. The graph GM is a directed graph, where an edge e exists between two user nodes A and B, if user A mentions user B. After constructing the graph, we measure the degree of influence each user has over their network using different centrality measures, such as degree centrality, betweenness centrality, and HITS-Hub. Such properties have been adopted in the research literature to study properties of cyber-criminal networks and their behaviour [23], [24].\n\n IV. EXPERIMENTS\n\n A. Dataset\n\nWe acquired a publicly available dataset of tweets posted by known pro-ISIS Twitter accounts that was published during the 2015 Paris attacks by Kaggle data science community4. The dataset consists of around 17, 000 tweets posted by more than 100 users. These tweets were labelled as being pro-ISIS by looking at specific indicators, such as a set of keywords used (in the user’s name, description, tweet text), their network of follower/following of other known radical accounts, and sharing of images of the ISIS flag or some radical leaders. To validate that these accounts are indeed malicious, we checked the current status of the users’ accounts in the dataset and found that most of them had been suspended by Twitter. This suggests that they did, in fact, possess a malicious behaviour that opposes the Twitter platform terms of use which caused them to be suspended. We filter out any tweets posted by existing active users and label this dataset as known-bad.\n\nTo model the normal behaviour, we collected a random sample of tweets from ten-trending topics in Twitter using the Twitter streaming API. These topics were related to news events and on-going social events (e.g., sports, music). We filter out any topics and keywords that may be connected to extremist views. This second dataset consists of around 8, 000 tweets published by around 1,000 users. A random sample of 200 tweets was manually verified to ascertain it did not contain radical views. We label this dataset as our random-good data.\n\nA third dataset is used which was acquired from Kaggle community5. This dataset is created to be a counterpoise to the pro-ISIS dataset (our known-bad) as it consists of tweets talking about topics concerning ISIS without being radical. It contains 122, 000 tweets from around 95, 000 users collected on two separate days. We verify that this dataset is indeed non radical by checking the status of users in Twitter and found that a subset (24, 000 users) was suspended. We remove those from the dataset and only keep users that are still active on Twitter. This dataset is labelled as counterpoise data.\n\nWe performed a series of preprocessing steps to clean the complete dataset and prepare it for feature extraction. These steps are: (1) We remove any duplicates and re-tweets from the dataset in order to reduce noise. (2) We remove tweets that have been authored by verified users accounts, as they are typically accounts associated with known public figures. (3) All stop words (e.g., and, or, the) and punctuation marks are removed from the text of the tweet. (4) If the tweet text contains a URL, we record the existence of the URL in a new attribute, hasURL, and then remove it from the tweet text. (5) If the tweet text contains emojis (e.g., :-), :), :P), we record the existence of the emoji in a new attribute, hasEmj, and then remove it from the tweet text. (6) If the tweet text contains any words with all capital characters, we record its existence in a new attribute, allCaps, and then normalize the text to lower-case and filter out any non-alphabetic characters. (7) We tokenize the cleansed tweet text into words, then we perform lemmatization, the process of reducing inflected words to their roots (lemma), and store the result in a vector.\n\n B. Experimental Set-up\n\nWe conducted two experiments using the datasets described in Section IV-A. Our hypothesis is that supporters of groups such as ISIS may exhibit similar textual and psychological properties when communicating in social media to the properties seen in the propaganda magazines. A tweet is considered radical if it promotes violence, racism, or supports violent behaviour.",
                    "score": 0.6651636058536422
                },
                {
                    "context": "Understanding the Radical Mind: Identifying Signals to Detect Extremist Content on Twitter\n\n Mariam Nouh∗, Jason R.C. Nurse†, and Michael Goldsmith∗\n\n ∗Department of Computer Science, University of Oxford, UK\n\n Email: {mariam.nouh, michael.goldsmith}@cs.ox.ac.uk\n\n †School of Computing, University of Kent, UK\n\n Email: j.r.c.nurse@kent.ac.uk\n\n Abstract\n\nThe Internet and, in particular, Online Social Networks have changed the way that terrorist and extremist groups can influence and radicalise individuals. Recent reports show that the mode of operation of these groups starts by exposing a wide audience to extremist material online, before migrating them to less open online platforms for further radicalization. Thus, identifying radical content online is crucial to limit the reach and spread of the extremist narrative. In this paper, our aim is to identify measures to automatically detect radical content in social media. We identify several signals, including textual, psychological and behavioural, that together allow for the classification of radical messages. Our contribution is three-fold: (1) we analyze propaganda material published by extremist groups and create a contextual text-based model of radical content, (2) we build a model of psychological properties inferred from these material, and (3) we evaluate these models on Twitter to determine the extent to which it is possible to automatically identify online radical tweets. Our results show that radical users do exhibit distinguishable textual, psychological, and behavioural properties. We find that the psychological properties are among the most distinguishing features. Additionally, our results show that textual models using vector embedding features significantly improve the detection over TF-IDF features. We validate our approach on two experiments achieving high accuracy. Our findings can be utilized as signals for detecting online radicalization activities.\n\n Index Terms\n\nradicalization, extremism, data mining, social media, machine learning, Twitter\n\n I. INTRODUCTION\n\nThe rise of Online Social Networks (OSN) has facilitated a wide application of its data as sensors for information to solve different problems. For example, Twitter data has been used for predicting election results, detecting the spread of flu epidemics, and a source for finding eye-witnesses during criminal incidents and crises. This phenomenon is possible due to the great overlap between our online and offline worlds. Such seamless shift between both worlds has also affected the modus operandi of cyber-criminals and extremist groups. They have benefited tremendously from the Internet and OSN platforms as it provides them with opportunities to spread their propaganda, widen their reach for victims, and facilitate potential recruitment opportunities. For instance, recent studies show that the Internet and social media played an important role in the increased amount of violent, right-wing extremism. Similarly, radical groups such as Al-Qaeda and ISIS have used social media to spread their propaganda and promoted their digital magazine, which inspired the Boston Marathon bombers in 2010.\n\nTo limit the reach of cyber-terrorists, several private and governmental organizations are policing online content and utilising big data technologies to minimize the damage and counter the spread of such information. For example, the UK launched a Counter Terrorism Internet Referral Unit in 2010 aiming to remove unlawful Internet content and it supports the police in investigating terrorist and radicalizing activities online. The Unit reports that among the most frequently referred links were those coming from several OSNs, such as Facebook and Twitter. Similarly, several OSNs are constantly working on detecting and removing users promoting extremist content. In 2018, Twitter announced that over 1.2 million accounts were suspended for terrorist content.\n\nRealizing the danger of violent extremism and radicalization and how it is becoming a major challenge to societies worldwide, many researchers have attempted to study the behaviour of pro-extremist users online. Looking at existing literature, we find that a number of existing studies incorporate methods to identify distinguishing properties that can aid in automatic detection of these users. However, many of them depend on performing a keyword-based textual analysis which, if used alone, may have several shortcomings, such as producing a large number of false positives and having a high dependency on the data being studied. In addition, it can be evaded using automated tools to adjust the writing style. Another angle for analyzing written text is by looking at the psychological properties that can be inferred regarding their authors. This is typically called psycholinguistics, where one examines how the use of the language can be indicative of different psychological states. Examples of such psychological properties include introversion, extroversion, sensitivity, and emotions. One of the tools that automates the process of extracting psychological meaning from text is the Linguistic Inquiry and Word Count (LIWC) tool. This approach has been used in the literature to study the behaviour of different groups and to predict their psychological states, such as predicting depression. More recently, it has also been applied to uncover different psychological properties of extremist groups and understand their intentions behind the recruitment campaigns.",
                    "score": 0.5106310222293761
                },
                {
                    "context": "The paper aims to study the effects of using new textual and psycholinguistic signals to detect extremist content online. These signals are developed based on insights gathered from analyzing propaganda material published by known extremist groups. In this study, we focus mainly on the ISIS group as they are one of the leading terrorist groups that utilise social media to share their propaganda and recruit individuals. We analyze the propaganda material they publish in their online English magazine called Dabiq, and use data-mining techniques to computationally uncover contextual text and psychological properties associated with these groups. From our analysis of these texts, we are able to extract a set of signals that provide some insight into the mindset of the radical group. This allows us to create a general radical profile that we apply as a signal to detect pro-ISIS supporters on Twitter. Our results show that these identified signals are indeed critical to help improve existing efforts to detect online radicalization.\n\n II. RELATED WORK\n\nIn recent years, there has been an increase in online accounts advocating and supporting terrorist groups such as ISIS [6]. This phenomenon has attracted researchers to study their online existence, and research ways to automatically detect these accounts and limit their spread. Ashcroft et al. [7] make an attempt to automatically detect Jihadist messages on Twitter. They adopt a machine-learning method to classify tweets as ISIS supporters or not. In the article, the authors focus on English tweets that contain a reference to a set of predefined English hashtags related to ISIS. Three different classes of features are used, including stylometric features, temporal features and sentiment features. However, one of the main limitations of their approach is that it is highly dependent on the data. Rowe and Saif [8] focused on studying Europe-based Twitter accounts in order to understand what happens before, during, and after they exhibit pro-ISIS behaviour. They define such behaviour as sharing of pro-ISIS content and/or using pro-ISIS terms. To achieve this, they use a term-based approach such that a user is considered to exhibit a radicalization behaviour if he/she uses more pro-ISIS terms than anti-ISIS terms. While such an approach seems effective in distinguishing radicalised users, it is unable to properly deal with lexical ambiguity (i.e., polysemy). Furthermore, in [12] the authors focused on detecting Twitter users who are involved with “Media Mujahideen”, a Jihadist group who distribute propaganda content online. They used a machine learning approach using a combination of data-dependent and data-independent features. Similar to [8] they used textual features as well as temporal features to classify tweets and accounts. The experiment was based on a limited set of Twitter accounts, which makes it difficult to generalize the results for a more complex and realistic scenario.\n\nRadicalization literature also looked at psychological factors involved with adopting such behaviour. Torok [13] used a grounded theory approach to develop an explanatory model for the radicalization process utilizing concepts of psychiatric power. Their findings show that the process typically starts with the social isolation of individuals. This isolation seems to be self-imposed as individuals tend to spend a long time engaging with radical content. This leads to the concept of homophily, the tendency to interact and associate with similar others. Through constant interaction with like-minded people, an individual gradually strengthens their mindset and progresses to more extreme levels. Similarly, they start to feel as being part of a group with a strong group identity which leads to group polarization. In psychology, group polarization occurs when discussion leads the group to adopt actions that are more extreme than the initial actions of the individual group members [14]. Moreover, the National Police Service Agency of the Netherlands developed a model to describe the phases a Jihadist may pass through before committing an act of terrorism [15]. These sequential phases of radicalism include strong links between the person’s psychological and emotional state (e.g., social alienation, depression, lack of confidence in authority) and their susceptibility to radicalization.\n\n III. METHODOLOGY\n\nAs illustrated in Fig. 1, our approach consists of two main phases: Phase 1: Radical Properties Extraction, where articles from Dabiq extremist magazines are input into this step to perform two parallel tasks. In the first task, we build a language model using (i) Term-Frequency Inverse-Document-Frequency (TF-IDF) scores of uni-, bi-, and tri-grams, and (ii) Word embeddings generated from a word2vec model [16]. The output of this task is a radical corpus of top k-grams, and a word embedding model giving a vector representation for each word in the corpus. The second task seeks to create a psychological profile based on the language used in the extremist propaganda articles, consisting of a set of emotional and topical categories using LIWC dictionary-based tool.",
                    "score": 0.5063267811919796
                },
                {
                    "context": "This table lists the top 10 features categorized by their types, including features related to psychological profiling, user behavior, and text analysis.,\nwith the following columns:\n- Top 10 Features: List of features ranked from 1 to 10.\n- Category: Type of feature, categorized as FP (Feature Profile), FB (Feature Behavior), or FT (Feature Text).\n\n| Top 10 Features |                                | Category |   |\n|---|---|---|---|\n|1| Radical psych-profile distance | FP       |   |\n|2| Us-Them dichotomy              | FP       |   |\n|3| # of mentions a user make      | FB       |   |\n|4| User rank (hub and authority)  | FB       |   |\n|5| Sad emotion                    | FP       |   |\n|6| Risk driver                    | FP       |   |\n|7| All-caps count                 | FT       |   |\n|8| URL count                      | FT       |   |\n|9| Violent-word ratio             | FT       |   |\n|10| Hash count                     | FT       |   |",
                    "score": 0.48782062354298394
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific features or characteristics were selected for analysis in the study, and how were they justified in the context of the research objectives?",
                    "answer": "The analysis focused on three categories of features: Radical Language, Psychological Signals, and Behavioural Features. \n\n1. **Radical Language (Textual features)**: This category involved examining the content of extremist propaganda, specifically from ISIS's Dabiq magazine. The aim was to identify topics, textual properties, and linguistic cues that characterize radical messages.\n\n2. **Psychological Signals (Psychological features)**: Features in this category were designed to create psychological profiles based on the language used in extremist articles. This included emotional and topical categories derived from a dictionary-based tool.\n\n3. **Behavioural Features**: This category measured user behavior, such as tweet frequency and the followers/following ratio. It also included interactions with others through mentions and hashtags, which were analyzed using a mention interaction graph to assess user influence within their networks.\n\nThese features were justified as they aimed to capture the essence of radical content and user behavior, aligning with the research objective of detecting radical activities on social media."
                },
                {
                    "question": "[SQ] What methodologies were employed to analyze the selected features in the study?",
                    "answer": "The study employed a two-phase approach for analyzing the selected features. \n\nIn Phase 1, known as Radical Properties Extraction, articles from Dabiq extremist magazines were processed through two parallel tasks. The first task involved building a language model using Term-Frequency Inverse-Document-Frequency (TF-IDF) scores of uni-, bi-, and tri-grams, along with word embeddings generated from a word2vec model. This resulted in a radical corpus of top k-grams and a word embedding model that provided vector representations for each word. The second task focused on creating a psychological profile based on the language used in the extremist propaganda articles, utilizing a LIWC dictionary-based tool to categorize emotional and topical elements.\n\nPhase 2 involved tweet classification, where the models generated from Phase 1 were used to engineer features related to radical activities. This phase included identifying three groups of features: radical language (textual features), psychological signals, and behavioral features. A binary classifier was then trained to detect radical tweets based on these engineered features."
                },
                {
                    "question": "[SQ] How were the psychological signals quantified and categorized in the research?",
                    "answer": "Psychological signals were quantified and categorized using the Linguistic Inquiry and Word Count (LIWC) tool, which assigns scores to various psychological, personality, and emotional categories. The analysis focused on several key areas: \n\n1. **Summary Variables**: These include measures such as analytical thinking, clout (expertise and confidence), tone (positive versus negative emotions), and authenticity (honesty versus guardedness).\n\n2. **Big Five Personality Traits**: This measures the five psychological properties known as OCEAN: Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism.\n\n3. **Emotional Analysis**: This assesses the presence of positive and negative emotions in the text, including specific emotions like anger, sadness, and anxiety.\n\n4. **Personal Drives**: This focuses on five personal drives: power, reward, risk, achievement, and affiliation.\n\n5. **Personal Pronouns**: The analysis counts the usage of first, second, and third-person pronouns in the text.\n\nFor each Twitter user, psychological profiles were calculated across these categories, and the Minkowski distance measure was used to determine the distance between these profiles and the average values derived from the extremist propaganda materials."
                },
                {
                    "question": "[SQ] What specific user behaviors were found to correlate with radical content engagement on social media?",
                    "answer": "User behaviors that correlate with radical content engagement on social media include the frequency of tweets posted, the followers/following ratio, and interactions with others through hashtags and mentions. Additionally, the construction of a mention interaction graph allows for measuring the degree of influence each user has within their network using centrality measures, such as degree centrality and betweenness centrality. These behaviors reflect how active users are in engaging with others and how much attention they receive, which is linked to their objectives in spreading ideologies and reaching like-minded individuals."
                },
                {
                    "question": "[MQ] What specific categories of features, including Radical Language, Psychological Signals, and Behavioral Features, were selected for analysis in the study, and how do they align with the research objectives of detecting radical activities on social media?",
                    "answer": "The study selected three specific categories of features for analysis: Radical Language, Psychological Signals, and Behavioral Features. \n\n1. **Radical Language**: This category focuses on the textual properties of messages, analyzing the content of extremist propaganda to identify linguistic cues and topics that characterize radical messages. This aligns with the research objective of understanding how radical messages are constructed and used, which is essential for detecting such content on social media.\n\n2. **Psychological Signals**: This category involves examining the psychological properties inferred from the language used in extremist materials. By utilizing tools like the Linguistic Inquiry and Word Count (LIWC), the study aims to uncover emotional and topical categories that reflect the psychological states of users. This aligns with the objective of identifying deeper psychological indicators that may signal radicalization.\n\n3. **Behavioral Features**: This category measures user behavior, such as tweet frequency, follower/following ratios, and interaction patterns with other users. By constructing a mention interaction graph, the study assesses the influence and engagement of users within their networks. This aligns with the research objective of understanding how user behavior can indicate radical activities and facilitate the spread of extremist ideologies.\n\nTogether, these categories provide a comprehensive framework for detecting radical activities on social media by combining linguistic, psychological, and behavioral insights."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0.896551724137931,
                "semantic_similarity": 0.8179690585601748,
                "llm_context_precision_without_reference": 0.7960362869381412,
                "llm_context_precision_with_reference": 0.37807747807117675,
                "answer_relevancy": 0.8495782381234287,
                "answer_correctness": 0.30794054050211267
            },
            "deepeval": {
                "contextual_precision": 0.875,
                "contextual_recall": 0.5,
                "contextual_relevancy": 0.5098039215686274,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 43,
        "job_id": 1,
        "file_id": 9,
        "question_id": 3,
        "status": "done",
        "answer_text": "The data collection was conducted using Twitter.",
        "answer_encoded": "Twitter",
        "answer_contexts": [
                {
                    "context": "3) Behaviour Signals\n\nThis category consists of measuring behavioural features to capture different properties related to the user and their behaviour. This includes how active the user is (frequency of tweets posted) and the followers/following ratio. Additionally, we use features to capture users’ interactions with others through using hashtags, and engagement in discussions using mention action. To capture this, we construct the mention interaction graph (GM) from our dataset, such that GM = (U, E), where U represents the user nodes and E represents the set of edges. The graph GM is a directed graph, where an edge e exists between two user nodes A and B, if user A mentions user B. After constructing the graph, we measure the degree of influence each user has over their network using different centrality measures, such as degree centrality, betweenness centrality, and HITS-Hub. Such properties have been adopted in the research literature to study properties of cyber-criminal networks and their behaviour [23], [24].\n\n IV. EXPERIMENTS\n\n A. Dataset\n\nWe acquired a publicly available dataset of tweets posted by known pro-ISIS Twitter accounts that was published during the 2015 Paris attacks by Kaggle data science community4. The dataset consists of around 17, 000 tweets posted by more than 100 users. These tweets were labelled as being pro-ISIS by looking at specific indicators, such as a set of keywords used (in the user’s name, description, tweet text), their network of follower/following of other known radical accounts, and sharing of images of the ISIS flag or some radical leaders. To validate that these accounts are indeed malicious, we checked the current status of the users’ accounts in the dataset and found that most of them had been suspended by Twitter. This suggests that they did, in fact, possess a malicious behaviour that opposes the Twitter platform terms of use which caused them to be suspended. We filter out any tweets posted by existing active users and label this dataset as known-bad.\n\nTo model the normal behaviour, we collected a random sample of tweets from ten-trending topics in Twitter using the Twitter streaming API. These topics were related to news events and on-going social events (e.g., sports, music). We filter out any topics and keywords that may be connected to extremist views. This second dataset consists of around 8, 000 tweets published by around 1,000 users. A random sample of 200 tweets was manually verified to ascertain it did not contain radical views. We label this dataset as our random-good data.\n\nA third dataset is used which was acquired from Kaggle community5. This dataset is created to be a counterpoise to the pro-ISIS dataset (our known-bad) as it consists of tweets talking about topics concerning ISIS without being radical. It contains 122, 000 tweets from around 95, 000 users collected on two separate days. We verify that this dataset is indeed non radical by checking the status of users in Twitter and found that a subset (24, 000 users) was suspended. We remove those from the dataset and only keep users that are still active on Twitter. This dataset is labelled as counterpoise data.\n\nWe performed a series of preprocessing steps to clean the complete dataset and prepare it for feature extraction. These steps are: (1) We remove any duplicates and re-tweets from the dataset in order to reduce noise. (2) We remove tweets that have been authored by verified users accounts, as they are typically accounts associated with known public figures. (3) All stop words (e.g., and, or, the) and punctuation marks are removed from the text of the tweet. (4) If the tweet text contains a URL, we record the existence of the URL in a new attribute, hasURL, and then remove it from the tweet text. (5) If the tweet text contains emojis (e.g., :-), :), :P), we record the existence of the emoji in a new attribute, hasEmj, and then remove it from the tweet text. (6) If the tweet text contains any words with all capital characters, we record its existence in a new attribute, allCaps, and then normalize the text to lower-case and filter out any non-alphabetic characters. (7) We tokenize the cleansed tweet text into words, then we perform lemmatization, the process of reducing inflected words to their roots (lemma), and store the result in a vector.\n\n B. Experimental Set-up\n\nWe conducted two experiments using the datasets described in Section IV-A. Our hypothesis is that supporters of groups such as ISIS may exhibit similar textual and psychological properties when communicating in social media to the properties seen in the propaganda magazines. A tweet is considered radical if it promotes violence, racism, or supports violent behaviour.",
                    "score": 0.81200181435575
                },
                {
                    "context": "The paper aims to study the effects of using new textual and psycholinguistic signals to detect extremist content online. These signals are developed based on insights gathered from analyzing propaganda material published by known extremist groups. In this study, we focus mainly on the ISIS group as they are one of the leading terrorist groups that utilise social media to share their propaganda and recruit individuals. We analyze the propaganda material they publish in their online English magazine called Dabiq, and use data-mining techniques to computationally uncover contextual text and psychological properties associated with these groups. From our analysis of these texts, we are able to extract a set of signals that provide some insight into the mindset of the radical group. This allows us to create a general radical profile that we apply as a signal to detect pro-ISIS supporters on Twitter. Our results show that these identified signals are indeed critical to help improve existing efforts to detect online radicalization.\n\n II. RELATED WORK\n\nIn recent years, there has been an increase in online accounts advocating and supporting terrorist groups such as ISIS [6]. This phenomenon has attracted researchers to study their online existence, and research ways to automatically detect these accounts and limit their spread. Ashcroft et al. [7] make an attempt to automatically detect Jihadist messages on Twitter. They adopt a machine-learning method to classify tweets as ISIS supporters or not. In the article, the authors focus on English tweets that contain a reference to a set of predefined English hashtags related to ISIS. Three different classes of features are used, including stylometric features, temporal features and sentiment features. However, one of the main limitations of their approach is that it is highly dependent on the data. Rowe and Saif [8] focused on studying Europe-based Twitter accounts in order to understand what happens before, during, and after they exhibit pro-ISIS behaviour. They define such behaviour as sharing of pro-ISIS content and/or using pro-ISIS terms. To achieve this, they use a term-based approach such that a user is considered to exhibit a radicalization behaviour if he/she uses more pro-ISIS terms than anti-ISIS terms. While such an approach seems effective in distinguishing radicalised users, it is unable to properly deal with lexical ambiguity (i.e., polysemy). Furthermore, in [12] the authors focused on detecting Twitter users who are involved with “Media Mujahideen”, a Jihadist group who distribute propaganda content online. They used a machine learning approach using a combination of data-dependent and data-independent features. Similar to [8] they used textual features as well as temporal features to classify tweets and accounts. The experiment was based on a limited set of Twitter accounts, which makes it difficult to generalize the results for a more complex and realistic scenario.\n\nRadicalization literature also looked at psychological factors involved with adopting such behaviour. Torok [13] used a grounded theory approach to develop an explanatory model for the radicalization process utilizing concepts of psychiatric power. Their findings show that the process typically starts with the social isolation of individuals. This isolation seems to be self-imposed as individuals tend to spend a long time engaging with radical content. This leads to the concept of homophily, the tendency to interact and associate with similar others. Through constant interaction with like-minded people, an individual gradually strengthens their mindset and progresses to more extreme levels. Similarly, they start to feel as being part of a group with a strong group identity which leads to group polarization. In psychology, group polarization occurs when discussion leads the group to adopt actions that are more extreme than the initial actions of the individual group members [14]. Moreover, the National Police Service Agency of the Netherlands developed a model to describe the phases a Jihadist may pass through before committing an act of terrorism [15]. These sequential phases of radicalism include strong links between the person’s psychological and emotional state (e.g., social alienation, depression, lack of confidence in authority) and their susceptibility to radicalization.\n\n III. METHODOLOGY\n\nAs illustrated in Fig. 1, our approach consists of two main phases: Phase 1: Radical Properties Extraction, where articles from Dabiq extremist magazines are input into this step to perform two parallel tasks. In the first task, we build a language model using (i) Term-Frequency Inverse-Document-Frequency (TF-IDF) scores of uni-, bi-, and tri-grams, and (ii) Word embeddings generated from a word2vec model [16]. The output of this task is a radical corpus of top k-grams, and a word embedding model giving a vector representation for each word in the corpus. The second task seeks to create a psychological profile based on the language used in the extremist propaganda articles, consisting of a set of emotional and topical categories using LIWC dictionary-based tool.",
                    "score": 0.8062105871669676
                },
                {
                    "context": "Moreover, among the top contributing features are behavioral features related to the number of mentions a single user makes, and their HITS hub and authority rank among their interaction network. This relates to how active the user is in interacting with other users and how much attention they receive from their community. This links to the objectives of those radical users in spreading their ideologies and reaching out to potential like-minded people. As for the category, we find that the use of word2vec embedding improves the performance in comparison with using the tf-idf features. Additionally, all bi-grams and tri-grams features did not contribute much to the classification; only uni-grams did.\n\nThis can be related to the differences in the writing styles when constructing sentences and phrases in articles and in the social media context (especially given the limitation of the number of words allowed by the Twitter platform). Additionally, the violent word ratio, longWords, and allCaps features are among the top contributing features from this category. This finding agrees to a large extent with observations from the literature regarding dealing with similar problems, where the use of dictionaries of violent words aids with the prediction of violent extremist narrative.\n\n V. CONCLUSION AND FUTURE WORK\n\nIn this paper, we identified different signals that can be utilized to detect evidence of online radicalization. We derived linguistic and psychological properties from propaganda published by ISIS for recruitment purposes. We utilize these properties to detect pro-ISIS tweets that are influenced by their ideology. Unlike previous efforts, these properties do not only focus on lexical keyword analysis of the messages, but also add a contextual and psychological dimension. We validated our approach in different experiments and the results show that this method is robust across multiple datasets. This system can aid law enforcement and OSN companies to better address such threats and help solve a challenging real-world problem. In future work, we aim to investigate if the model is resilient to different evasion techniques that users may adopt. We will also expand the analysis to other languages.\n\n REFERENCES\n\n[1] F. Morstatter, N. Lubold, H. Pon-Barry, J. Pfeffer, and H. Liu, “Finding eyewitness tweets during crises,” arXiv preprint arXiv:1403.1773, 2014.\n\n[2] A. Tumasjan, T. Sprenger, P. Sandner, and I. Welpe, “Predicting elections with twitter: What 140 characters reveal about political sentiment,” in Int. Conference on Web and Social Media, 2010.\n\n[3] C. Edwards and L. Gribbon, “Pathways to violent extremism in the digital era,” The RUSI Journal, vol. 158, no. 5, pp. 40–47, 2013.",
                    "score": 0.8051584457733505
                },
                {
                    "context": "Understanding the Radical Mind: Identifying Signals to Detect Extremist Content on Twitter\n\n Mariam Nouh∗, Jason R.C. Nurse†, and Michael Goldsmith∗\n\n ∗Department of Computer Science, University of Oxford, UK\n\n Email: {mariam.nouh, michael.goldsmith}@cs.ox.ac.uk\n\n †School of Computing, University of Kent, UK\n\n Email: j.r.c.nurse@kent.ac.uk\n\n Abstract\n\nThe Internet and, in particular, Online Social Networks have changed the way that terrorist and extremist groups can influence and radicalise individuals. Recent reports show that the mode of operation of these groups starts by exposing a wide audience to extremist material online, before migrating them to less open online platforms for further radicalization. Thus, identifying radical content online is crucial to limit the reach and spread of the extremist narrative. In this paper, our aim is to identify measures to automatically detect radical content in social media. We identify several signals, including textual, psychological and behavioural, that together allow for the classification of radical messages. Our contribution is three-fold: (1) we analyze propaganda material published by extremist groups and create a contextual text-based model of radical content, (2) we build a model of psychological properties inferred from these material, and (3) we evaluate these models on Twitter to determine the extent to which it is possible to automatically identify online radical tweets. Our results show that radical users do exhibit distinguishable textual, psychological, and behavioural properties. We find that the psychological properties are among the most distinguishing features. Additionally, our results show that textual models using vector embedding features significantly improve the detection over TF-IDF features. We validate our approach on two experiments achieving high accuracy. Our findings can be utilized as signals for detecting online radicalization activities.\n\n Index Terms\n\nradicalization, extremism, data mining, social media, machine learning, Twitter\n\n I. INTRODUCTION\n\nThe rise of Online Social Networks (OSN) has facilitated a wide application of its data as sensors for information to solve different problems. For example, Twitter data has been used for predicting election results, detecting the spread of flu epidemics, and a source for finding eye-witnesses during criminal incidents and crises. This phenomenon is possible due to the great overlap between our online and offline worlds. Such seamless shift between both worlds has also affected the modus operandi of cyber-criminals and extremist groups. They have benefited tremendously from the Internet and OSN platforms as it provides them with opportunities to spread their propaganda, widen their reach for victims, and facilitate potential recruitment opportunities. For instance, recent studies show that the Internet and social media played an important role in the increased amount of violent, right-wing extremism. Similarly, radical groups such as Al-Qaeda and ISIS have used social media to spread their propaganda and promoted their digital magazine, which inspired the Boston Marathon bombers in 2010.\n\nTo limit the reach of cyber-terrorists, several private and governmental organizations are policing online content and utilising big data technologies to minimize the damage and counter the spread of such information. For example, the UK launched a Counter Terrorism Internet Referral Unit in 2010 aiming to remove unlawful Internet content and it supports the police in investigating terrorist and radicalizing activities online. The Unit reports that among the most frequently referred links were those coming from several OSNs, such as Facebook and Twitter. Similarly, several OSNs are constantly working on detecting and removing users promoting extremist content. In 2018, Twitter announced that over 1.2 million accounts were suspended for terrorist content.\n\nRealizing the danger of violent extremism and radicalization and how it is becoming a major challenge to societies worldwide, many researchers have attempted to study the behaviour of pro-extremist users online. Looking at existing literature, we find that a number of existing studies incorporate methods to identify distinguishing properties that can aid in automatic detection of these users. However, many of them depend on performing a keyword-based textual analysis which, if used alone, may have several shortcomings, such as producing a large number of false positives and having a high dependency on the data being studied. In addition, it can be evaded using automated tools to adjust the writing style. Another angle for analyzing written text is by looking at the psychological properties that can be inferred regarding their authors. This is typically called psycholinguistics, where one examines how the use of the language can be indicative of different psychological states. Examples of such psychological properties include introversion, extroversion, sensitivity, and emotions. One of the tools that automates the process of extracting psychological meaning from text is the Linguistic Inquiry and Word Count (LIWC) tool. This approach has been used in the literature to study the behaviour of different groups and to predict their psychological states, such as predicting depression. More recently, it has also been applied to uncover different psychological properties of extremist groups and understand their intentions behind the recruitment campaigns.",
                    "score": 0.6440775746112486
                },
                {
                    "context": "(6) If the tweet text contains any words with all capital characters, we record its existence in a new attribute, allCaps, and then normalize the text to lower-case and filter out any non-alphabetic characters. (7) We tokenize the cleansed tweet text into words, then we perform lemmatization, the process of reducing inflected words to their roots (lemma), and store the result in a vector.\n\n B. Experimental Set-up\n\nWe conducted two experiments using the datasets described in Section IV-A. Our hypothesis is that supporters of groups such as ISIS may exhibit similar textual and psychological properties when communicating in social media to the properties seen in the propaganda magazines. A tweet is considered radical if it promotes violence, racism, or supports violent behaviour. In Exp 1 we use the first two datasets, i.e., the known-bad and the random-good datasets to classify tweets to radical and normal classes. For Exp 2 we examine if our classifier can also distinguish between tweets that are discussing similar topics (ISIS related) by using the known-bad and the counterpoise datasets.\n\nThe classification task is binomial (binary) classification where the output of the model predicts whether the input tweet is considered radical or normal. In order to handle the imbalanced class problem in the dataset, there are multiple techniques suggested in the literature. Oversampling or undersampling of the minority/majority classes are common techniques. Another technique that is more related to the classification algorithm is cost sensitive learning, which penalizes the classification model for making a mistake on the minority class. This is achieved by applying a weighted cost on misclassifying of the minority class [25]. We will use the last approach to avoid downsampling of our dataset.\n\nPrevious research investigating similar problems reported better performances for Random Forest (RF) classifiers [26]. RF usually performs very well as it is scalable and is robust to outliers. RF typically outperforms decision trees as it has a hierarchical structure and is based on multiple trees. This allows RF to be able to model non-linear decision boundaries. Moreover, Neural Networks (NN) also produced good results when applied to problems related to image recognition, text and natural language processing [27]. However, they usually",
                    "score": 0.6406939943062121
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] Which social network or platform was utilized for data collection in the analyzed article?",
                    "answer": "The data collection was conducted using Twitter."
                },
                {
                    "question": "[SQ] What specific data collection methods were employed on Twitter in the analyzed article?",
                    "answer": "The data collection methods employed involved acquiring a publicly available dataset of tweets from known pro-ISIS Twitter accounts, which was published during the 2015 Paris attacks. This dataset contained around 17,000 tweets from over 100 users, identified as pro-ISIS based on specific indicators such as keywords, follower/following networks, and shared images. Additionally, a random sample of tweets from ten trending topics on Twitter was collected using the Twitter streaming API, ensuring that topics related to extremist views were filtered out. This second dataset included approximately 8,000 tweets from around 1,000 users. A third dataset was also utilized, consisting of tweets discussing ISIS without being radical, which contained 122,000 tweets from about 95,000 users, with a verification process to ensure the users were active and not suspended."
                },
                {
                    "question": "[SQ] Were there any other social networks considered for data collection in the study?",
                    "answer": "No, the study focused specifically on data collected from Twitter, utilizing tweets from known pro-ISIS accounts and trending topics on the platform. Other social networks were not mentioned as part of the data collection process."
                },
                {
                    "question": "[SQ] How did the choice of Twitter impact the findings of the analyzed article?",
                    "answer": "The choice of Twitter as the platform for analysis significantly influenced the findings by providing a rich dataset of user interactions and content that reflects real-time communication patterns. The limitations of Twitter, such as character count restrictions, shaped the writing styles and linguistic features observed in the tweets. This context allowed for the identification of specific behavioral and psychological signals associated with radicalization, as users often express their ideologies concisely. Additionally, the platform's dynamics, including user engagement through mentions and hashtags, facilitated the exploration of interaction networks, which are crucial for understanding how radical content spreads. Overall, Twitter's unique characteristics enabled a focused examination of extremist narratives and user behaviors in a social media environment."
                },
                {
                    "question": "[MQ] Which specific datasets from Twitter were utilized for data collection in the analyzed article, particularly regarding pro-ISIS accounts and trending topics?",
                    "answer": "The analyzed article utilized three specific datasets from Twitter for data collection. The first dataset, labeled as known-bad, consisted of around 17,000 tweets posted by more than 100 known pro-ISIS Twitter accounts during the 2015 Paris attacks. The second dataset, referred to as random-good, was a random sample of around 8,000 tweets from approximately 1,000 users discussing ten trending topics unrelated to extremist views. The third dataset, labeled as counterpoise data, contained 122,000 tweets from around 95,000 users discussing topics concerning ISIS without being radical, verified by checking the status of users to ensure they were active and not associated with radical content."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 0.9999999999999996,
                "llm_context_precision_without_reference": 0.9428571428382857,
                "llm_context_precision_with_reference": 0.9428571428382857,
                "answer_relevancy": 0.8128478694179874,
                "answer_correctness": 0.9999999999999999
            },
            "deepeval": {
                "contextual_precision": 1.0,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.4205607476635514,
                "answer_relevancy": 0.25,
                "faithfulness": 0.9047619047619048
            }
        },
    },
    {
        "id": 44,
        "job_id": 1,
        "file_id": 9,
        "question_id": 4,
        "status": "done",
        "answer_text": "The dataset was divided into a training set comprising 80% of the data and a testing set that accounted for 20%.",
        "answer_encoded": "[response not coded] The analyzed dataset was divided into an 80% training set and a 20% testing set.",
        "answer_contexts": [
                {
                    "context": "tend to require very large amounts of data to train. For the purpose of this study, we experimented with multiple classification algorithms, including RF, NN, SVM, and KNN and found that RF and NN produced the best performance. Due to space limitation, we only report results obtained using RF model. We configured the model to use 100 estimators trees with a maximum depth of 50, and we selected gini impurity for the split criteria. We used the out-of-bag samples (oob) score to estimate the generalization accuracy of the model. Additionally, since RF tends to be biased towards the majority class, we apply the cost sensitive learning method described earlier to make RF more suitable for imbalanced data [25].\n\nWe divided the dataset to training set (80%) and testing set 20%), where the testing set is held out for validation. We reported validation results using different combinations of the features categories (i.e., FT, FB, FP) and different evaluation metrics: accuracy, recall, precision, f-measure, and area under the ROC curve. Recall measures how many radical tweets we are able to detect, while precision measures how many radical tweets we can detect without falsely accusing anyone. For instance, if we identify every single tweet as radical, we will expose all radical tweets and thus obtain high recall, but at the same time, we will call everyone in the population a radical and thus obtain low precision. F-measure is the average of both precision and recall.\n\n C. Results\n\nExp 1: The classification results using the known-bad and random-good datasets are reported in Table I. The table shows the average accuracy, precision, recall and f-measure scores obtained from each feature category (FT, FP, FB) and their combination (FAll). We also compared the two textual models, and find that results obtained from using word embedding outperforms the use of n-grams tf-idf scores. This confirms that contextual information is important in detecting radicalization activities. Furthermore, our model performed best using the FP features across all metrics. This means that the model is able to distinguish between both radical and non-radical with high confidence using only FP.\n\nExp 2: In this experiment, we tested the performance of our classifier in distinguishing between radical and normal tweets that discusses ISIS-related topics. Although this task is more challenging given the similarity of the topic discussed in the two classes, we find that the model still achieves high performance. Table II shows the different metrics obtained from each feature category. The FT feature group obtains 80% accuracy, and 91%, 100% for FB and FP feature groups, respectively. The results are consistent with the ones obtained from the first experiment with the features from FP group contributing to the high accuracy of the model. The area under the Receiver Operator Characteristic (ROC) curve, which measures accuracy based on TP, and FP rates, is shown in Fig. 2 for each classification model.\n\n D. Features Significance\n\nWe investigated which features contribute most to the classification task to distinguish between radical and non-radical tweets. We used the mean decrease impurity method of random forests [28] to identify the most important features in each feature category. The ten most important features are shown in Table III. We found that the most important feature for distinguishing radical tweets is the psychological feature distance measure. This measures how similar the Twitter user is to the average psychological profile calculated from the propaganda magazine articles. Following this is the Us-them dichotomy which looks at the total number of pronouns used (I, they, we, you). This finding is in line with the tactics reported in the radicalization literature with regards to emphasizing the separation between the radical group and the world.\n\nFig. 2: ROC curve for Exp1 (top), Exp2 (bottom).",
                    "score": 0.7797775015339101
                },
                {
                    "context": "TABLE I: Exp 1: Evaluation metrics across all feature groups",
                    "score": 0.7773898956268483
                },
                {
                    "context": "TABLE II: Exp 2: Evaluation metrics across all feature groups",
                    "score": 0.7765235411581238
                },
                {
                    "context": "(6) If the tweet text contains any words with all capital characters, we record its existence in a new attribute, allCaps, and then normalize the text to lower-case and filter out any non-alphabetic characters. (7) We tokenize the cleansed tweet text into words, then we perform lemmatization, the process of reducing inflected words to their roots (lemma), and store the result in a vector.\n\n B. Experimental Set-up\n\nWe conducted two experiments using the datasets described in Section IV-A. Our hypothesis is that supporters of groups such as ISIS may exhibit similar textual and psychological properties when communicating in social media to the properties seen in the propaganda magazines. A tweet is considered radical if it promotes violence, racism, or supports violent behaviour. In Exp 1 we use the first two datasets, i.e., the known-bad and the random-good datasets to classify tweets to radical and normal classes. For Exp 2 we examine if our classifier can also distinguish between tweets that are discussing similar topics (ISIS related) by using the known-bad and the counterpoise datasets.\n\nThe classification task is binomial (binary) classification where the output of the model predicts whether the input tweet is considered radical or normal. In order to handle the imbalanced class problem in the dataset, there are multiple techniques suggested in the literature. Oversampling or undersampling of the minority/majority classes are common techniques. Another technique that is more related to the classification algorithm is cost sensitive learning, which penalizes the classification model for making a mistake on the minority class. This is achieved by applying a weighted cost on misclassifying of the minority class [25]. We will use the last approach to avoid downsampling of our dataset.\n\nPrevious research investigating similar problems reported better performances for Random Forest (RF) classifiers [26]. RF usually performs very well as it is scalable and is robust to outliers. RF typically outperforms decision trees as it has a hierarchical structure and is based on multiple trees. This allows RF to be able to model non-linear decision boundaries. Moreover, Neural Networks (NN) also produced good results when applied to problems related to image recognition, text and natural language processing [27]. However, they usually",
                    "score": 0.4601757529746691
                },
                {
                    "context": "This table presents the performance metrics of various feature extraction methods, including accuracy (AC), precision, recall, and F-measure. The methods evaluated include T (tf-idf), FT (w2v), FT, FB, FFP, and ALL, with FFP and ALL achieving the highest scores across all metrics.,\nwith the following columns:\n- Features: Different feature extraction methods evaluated.\n- AC: Accuracy of each feature extraction method.\n- Precision: Precision score for each method.\n- Recall: Recall score for each method.\n- F-measure: F-measure score for each method.\n\n| Features     | AC   | Precision | Recall | F-measure |\n|---|---|---|---|---|\n| T (tf − idf) |0.52|0.76|0.52|0.37|\n| FT (w2v)     |0.81|0.82|0.81|0.81|\n| FT           |0.84|0.84|0.84|0.84|\n| FB           |0.94|0.95|0.94|0.94|\n| FFP          |1.0|1.0|1.0|1.0|\n| ALL          |1.0|1.0|1.0|1.0|",
                    "score": 0.45966669113574676
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What was the size of the dataset analyzed in the article?",
                    "answer": "The dataset was divided into a training set comprising 80% of the data and a testing set that accounted for 20%."
                },
                {
                    "question": "[SQ] What was the total number of samples in the dataset?",
                    "answer": "The total number of samples in the dataset is not explicitly stated in the provided information."
                },
                {
                    "question": "[SQ] How many samples were included in the training set?",
                    "answer": "The training set included 80% of the dataset."
                },
                {
                    "question": "[SQ] How many samples were included in the testing set?",
                    "answer": "The testing set included 20% of the total dataset."
                },
                {
                    "question": "[MQ] What is the proportion of the dataset allocated to the training and testing sets in the analysis?",
                    "answer": "The dataset is divided into 80% for the training set and 20% for the testing set."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 0.0,
                "faithfulness": 1.0,
                "semantic_similarity": 0.770183814724333,
                "llm_context_precision_without_reference": 0.0,
                "llm_context_precision_with_reference": 0.0,
                "answer_relevancy": 0.0,
                "answer_correctness": 0.19254595368108324
            },
            "deepeval": {
                "contextual_precision": 0.8528571428571429,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.043478260869565216,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 45,
        "job_id": 1,
        "file_id": 9,
        "question_id": 5,
        "status": "done",
        "answer_text": "The study evaluated the following performance metrics: Accuracy, Precision, Recall, and F-measure. The corresponding values for these metrics varied across different feature extraction methods. For instance, one method achieved an accuracy of 1.0, with precision, recall, and F-measure also at 1.0. Another method had an accuracy of 0.56, with precision at 0.69, recall at 0.56, and F-measure at 0.48. These values reflect the performance of each feature extraction technique across the evaluated metrics.",
        "answer_encoded": "[response not coded] The study's performance metrics included Accuracy (ranging from 0.56 to 1.0), Precision (0.69 to 1.0), Recall (0.56 to 1.0), and F-measure (0.48 to 1.0) across different feature extraction methods.",
        "answer_contexts": [
                {
                    "context": "This table presents the performance metrics of various feature extraction techniques, including Accuracy (AC), Precision, Recall, and F-measure.,\nwith the following columns:\n- Features: Different feature extraction methods used.\n- AC: Accuracy of the feature extraction methods.\n- Precision: Precision metric for each method.\n- Recall: Recall metric for each method.\n- F-measure: F-measure for evaluating the methods.\n\n| Features      | AC   | Precision | Recall | F-measure |\n|---|---|---|---|---|\n| FT (tf − idf) |0.56|0.69|0.56|0.48|\n| FT (w2v)      |0.73|0.73|0.73|0.73|\n| FT            |0.8|0.8|0.8|0.8|\n| FB            |0.91|0.92|0.91|0.91|\n| FP            |1.0|1.0|1.0|1.0|\n| FALL          |1.0|1.0|1.0|1.0|",
                    "score": 0.8639137897915503
                },
                {
                    "context": "This table presents the performance metrics of various feature extraction methods, including accuracy (AC), precision, recall, and F-measure. The methods evaluated include T (tf-idf), FT (w2v), FT, FB, FFP, and ALL, with FFP and ALL achieving the highest scores across all metrics.,\nwith the following columns:\n- Features: Different feature extraction methods evaluated.\n- AC: Accuracy of each feature extraction method.\n- Precision: Precision score for each method.\n- Recall: Recall score for each method.\n- F-measure: F-measure score for each method.\n\n| Features     | AC   | Precision | Recall | F-measure |\n|---|---|---|---|---|\n| T (tf − idf) |0.52|0.76|0.52|0.37|\n| FT (w2v)     |0.81|0.82|0.81|0.81|\n| FT           |0.84|0.84|0.84|0.84|\n| FB           |0.94|0.95|0.94|0.94|\n| FFP          |1.0|1.0|1.0|1.0|\n| ALL          |1.0|1.0|1.0|1.0|",
                    "score": 0.8582198004731122
                },
                {
                    "context": "TABLE I: Exp 1: Evaluation metrics across all feature groups",
                    "score": 0.6635010803803081
                },
                {
                    "context": "TABLE II: Exp 2: Evaluation metrics across all feature groups",
                    "score": 0.6603579977846981
                },
                {
                    "context": "tend to require very large amounts of data to train. For the purpose of this study, we experimented with multiple classification algorithms, including RF, NN, SVM, and KNN and found that RF and NN produced the best performance. Due to space limitation, we only report results obtained using RF model. We configured the model to use 100 estimators trees with a maximum depth of 50, and we selected gini impurity for the split criteria. We used the out-of-bag samples (oob) score to estimate the generalization accuracy of the model. Additionally, since RF tends to be biased towards the majority class, we apply the cost sensitive learning method described earlier to make RF more suitable for imbalanced data [25].\n\nWe divided the dataset to training set (80%) and testing set 20%), where the testing set is held out for validation. We reported validation results using different combinations of the features categories (i.e., FT, FB, FP) and different evaluation metrics: accuracy, recall, precision, f-measure, and area under the ROC curve. Recall measures how many radical tweets we are able to detect, while precision measures how many radical tweets we can detect without falsely accusing anyone. For instance, if we identify every single tweet as radical, we will expose all radical tweets and thus obtain high recall, but at the same time, we will call everyone in the population a radical and thus obtain low precision. F-measure is the average of both precision and recall.\n\n C. Results\n\nExp 1: The classification results using the known-bad and random-good datasets are reported in Table I. The table shows the average accuracy, precision, recall and f-measure scores obtained from each feature category (FT, FP, FB) and their combination (FAll). We also compared the two textual models, and find that results obtained from using word embedding outperforms the use of n-grams tf-idf scores. This confirms that contextual information is important in detecting radicalization activities. Furthermore, our model performed best using the FP features across all metrics. This means that the model is able to distinguish between both radical and non-radical with high confidence using only FP.\n\nExp 2: In this experiment, we tested the performance of our classifier in distinguishing between radical and normal tweets that discusses ISIS-related topics. Although this task is more challenging given the similarity of the topic discussed in the two classes, we find that the model still achieves high performance. Table II shows the different metrics obtained from each feature category. The FT feature group obtains 80% accuracy, and 91%, 100% for FB and FP feature groups, respectively. The results are consistent with the ones obtained from the first experiment with the features from FP group contributing to the high accuracy of the model. The area under the Receiver Operator Characteristic (ROC) curve, which measures accuracy based on TP, and FP rates, is shown in Fig. 2 for each classification model.\n\n D. Features Significance\n\nWe investigated which features contribute most to the classification task to distinguish between radical and non-radical tweets. We used the mean decrease impurity method of random forests [28] to identify the most important features in each feature category. The ten most important features are shown in Table III. We found that the most important feature for distinguishing radical tweets is the psychological feature distance measure. This measures how similar the Twitter user is to the average psychological profile calculated from the propaganda magazine articles. Following this is the Us-them dichotomy which looks at the total number of pronouns used (I, they, we, you). This finding is in line with the tactics reported in the radicalization literature with regards to emphasizing the separation between the radical group and the world.\n\nFig. 2: ROC curve for Exp1 (top), Exp2 (bottom).",
                    "score": 0.4985517811333259
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific performance metrics were evaluated in the study, and what were their corresponding values?",
                    "answer": "The study evaluated the following performance metrics: Accuracy (AC), Precision, Recall, and F-measure. The corresponding values for these metrics varied across different feature extraction methods. For example, one method achieved an accuracy of 1.0, with precision, recall, and F-measure also at 1.0. Another method had an accuracy of 0.56, with precision at 0.69, recall at 0.56, and F-measure at 0.48. The values reflect the performance of each feature extraction technique across these metrics."
                },
                {
                    "question": "[SQ] What were the different feature extraction methods used in the study?",
                    "answer": "The feature extraction methods used in the study include T (tf-idf), FT (w2v), FT, FB, FFP, and ALL."
                },
                {
                    "question": "[SQ] How did the performance metrics vary between the different feature extraction methods?",
                    "answer": "The performance metrics varied significantly among the different feature extraction methods. In the first experiment, the accuracy ranged from 0.56 for FT (tf-idf) to 1.0 for both FP and FALL, indicating that some methods performed much better than others. Precision, recall, and F-measure also showed similar trends, with FP and FALL achieving perfect scores across all metrics. In the second experiment, the accuracy for T (tf-idf) was 0.52, while FT (w2v) and FT had accuracies of 0.81 and 0.84, respectively. FB and FFP both reached 1.0 in accuracy, precision, recall, and F-measure, demonstrating that certain feature extraction methods consistently outperformed others across both experiments. Overall, the results suggest that the choice of feature extraction method has a substantial impact on the classification performance."
                },
                {
                    "question": "[SQ] Were there any other performance metrics evaluated in addition to Accuracy, Precision, Recall, and F-measure?",
                    "answer": "No, only Accuracy, Precision, Recall, and F-measure were evaluated as performance metrics."
                },
                {
                    "question": "[MQ] What were the values of Accuracy, Precision, Recall, and F-measure for the different feature extraction methods evaluated in the study?",
                    "answer": "The values for Accuracy, Precision, Recall, and F-measure for the different feature extraction methods evaluated are as follows:\n\n1. **T (tf-idf)**: \n   - Accuracy: 0.52\n   - Precision: 0.76\n   - Recall: 0.52\n   - F-measure: 0.37\n\n2. **FT (w2v)**: \n   - Accuracy: 0.81\n   - Precision: 0.82\n   - Recall: 0.81\n   - F-measure: 0.81\n\n3. **FT**: \n   - Accuracy: 0.84\n   - Precision: 0.84\n   - Recall: 0.84\n   - F-measure: 0.84\n\n4. **FB**: \n   - Accuracy: 0.94\n   - Precision: 0.95\n   - Recall: 0.94\n   - F-measure: 0.94\n\n5. **FFP**: \n   - Accuracy: 1.0\n   - Precision: 1.0\n   - Recall: 1.0\n   - F-measure: 1.0\n\n6. **ALL**: \n   - Accuracy: 1.0\n   - Precision: 1.0\n   - Recall: 1.0\n   - F-measure: 1.0\n\nAdditionally, for the first set of feature extraction methods:\n\n1. **FT (tf-idf)**: \n   - Accuracy: 0.56\n   - Precision: 0.69\n   - Recall: 0.56\n   - F-measure: 0.48\n\n2. **FT (w2v)**: \n   - Accuracy: 0.73\n   - Precision: 0.73\n   - Recall: 0.73\n   - F-measure: 0.73\n\n3. **FT**: \n   - Accuracy: 0.8\n   - Precision: 0.8\n   - Recall: 0.8\n   - F-measure: 0.8\n\n4. **FB**: \n   - Accuracy: 0.91\n   - Precision: 0.92\n   - Recall: 0.91\n   - F-measure: 0.91\n\n5. **FP**: \n   - Accuracy: 1.0\n   - Precision: 1.0\n   - Recall: 1.0\n   - F-measure: 1.0\n\n6. **FALL**: \n   - Accuracy: 1.0\n   - Precision: 1.0\n   - Recall: 1.0\n   - F-measure: 1.0"
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 1.0,
                "semantic_similarity": 0.7641411133992557,
                "llm_context_precision_without_reference": 0.9305555555400462,
                "llm_context_precision_with_reference": 0.4166666666458333,
                "answer_relevancy": 0.9095630971637177,
                "answer_correctness": 0.19103527834981393
            },
            "deepeval": {
                "contextual_precision": 0.25,
                "contextual_recall": 0.0,
                "contextual_relevancy": 0.022727272727272728,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        }
    },
    {
        "id": 46,
        "job_id": 1,
        "file_id": 10,
        "question_id": 1,
        "status": "done",
        "answer_text": "The study utilized a combination of statistical text classification methods, including Decision Trees, Neural Networks, and Support Vector Machines (SVM). These algorithms contributed to the overall findings by effectively classifying web data, particularly in detecting potential terrorist activities. The SVM classifier, in particular, demonstrated high accuracy rates when combined with various feature sets, indicating its effectiveness in handling complex text classification tasks. This approach allowed for a nuanced analysis of web content, enhancing the ability to identify and categorize relevant information from the Dark Web.",
        "answer_encoded": "SVM, Neural Networks, Decision Trees",
        "answer_contexts": [
                {
                    "context": "In Press, Accepted Manuscript, Available online 3 October 2015\n\nhttp://www.sciencedirect.com/science/article/pii/S092523121501396X\n\nIt is seen in Table 7 that the SVM classifier, followed by the KNN and the ELM, achieved the highest performance measures. These results emphasize the claim of superiority of SVM over other classifiers in the domain of DW analysis (Chen, 2007; Zheng et al., 2006). However, a more important conclusion that can be read from Table 7 is that the performance measures are proportionally increasing as the increase in the level of hybridization, in general. This result puts emphasize on our claim that the use of a feature set generated based on different ideas of significant terms will help in achieving higher classification performance. Moreover, it is noticeable that classification performance based on the UN hybridization function are higher than those based SD function, however the mean numbers of features are much less for the sets combined by the SD function than the sets combined by the UN function.\n\nThe classification performance measures achieved based on the NB and the DT classifiers are poor as seen in Table 7, these poor results are due to the high sparsity of feature sets. For more clarification of this point, it is known that DT classifier prefers the inputs where the attributes have many values (Quinlan, 1986). However, the NB classifier also suffers from some major back draws such as over‑fitting and underflow that cause the low performance (Chandra and Gupta, 2011).\n\n 6 Conclusion and future work\n\nThis paper introduced the HTW method for accurate terrorism activities detection in textual content. Using the different term‑weighting techniques, HTW combines small feature sets generated by the basic TF, DF, IDF, TF‑IDF, Glasgow, and Entropy term‑weighting techniques into one feature set in different views. Moreover, the UNION and Symmetric Difference combination functions were utilized as the hybridization functions. A selected balanced dataset downloaded from the DWFP is used in testing, evaluating and benchmarking the proposed method using many common text classifiers. The results show that it is possible to achieve higher classification performance by combining few small feature sets based on different assumptions about the most significant terms in the text. In addition, results show that the number of features in the combined feature set based on the Symmetric Difference function is significantly less than the number of features in the UNION function based feature set. Moreover, the benchmarking results support our assumption that a higher classification performance could be achieved by combining feature sets generated based on different assumptions about the most significant terms in the text. Our future work will focus on proposing a modified term‑weighting technique for achieving higher DW content detection accuracy in balanced and unbalanced datasets.\n\n Acknowledgments\n\nThe Universiti Teknologi Malaysia (UTM) under research grant 03H02 and Ministry of Science, Technology & Innovations Malaysia, under research grant 4S062 are hereby acknowledged for some of the facilities utilized during the course of this research work. Moreover, The AL‑QUDS OPEN UNIVERSITY – PALESTINE is acknowledged for supporting and funding the first author during his PhD study. Additionally, Dr. Mahmood Ashraf, Department of Computer Science, Federal Urdu University of Arts, Science and Technology, Islamabad, Pakistan, is acknowledged for his suggestions and contributions to this work.\n\n32",
                    "score": 0.6509042843616988
                },
                {
                    "context": "Boser, B. E., Guyon, I. M., and Vapnik, V. N. (1992). A training algorithm for optimal margin classifiers. Proceedings of the fifth annual workshop on Computational learning theory. July 27 ‑ 29, 1992. Pittsburgh, PA, USA, 144‑152.\n\nBoutemedjet, S., Bouguila, N., and Ziou, D. (2009). A Hybrid Feature Extraction Selection Approach for High‑Dimensional Non‑Gaussian Data Clustering. IEEE Transactions on Pattern Analysis and Machine Intelligence, 31(8), 1429‑1443.\n\nCeri, S., Bozzon, A., Brambilla, M., Valle, E., Fraternali, P., and Quarteroni, S. (2013). An Introduction to Information Retrieval. In S. Ceri, A. Bozzon, M. Brambilla, E. Valle, P. Fraternali, and S. Quarteroni (Eds.). Web Information Retrieval (pp. 3‑11). Berlin, Germany: Springer Berlin Heidelberg.\n\nChandra, B., and Gupta, M. (2011). Robust approach for estimating probabilities in Naïve–Bayes Classifier for gene expression data. Expert Systems with Applications, 38(3), 1293‑1298.\n\nChaurasia, N., Dhakar, M., Chharia, A., Tiwari, A., and Gupta, R. (2012). Exploring the Current Trends and Future Prospects in Terrorist Network Mining. Proceedings of The Second International Conference on Computer Science, Engineering and Applications (CCSEA 2012). May 26‑27, 2012. Delhi, India, 379–385.\n\nChen, C.‑M., Lee, H.‑M., and Chang, Y.‑J. (2009). Two novel feature selection approaches for web page classification. Expert Systems with Applications, 36(1), 260‑272.\n\nChen, D., Bourlard, H., and Thiran, J.‑P. (2001). Text identification in complex background using SVM. Proceedings of the International Conference on Computer Vision and Pattern Recognition. December 8‑14, 2001. Kauai, Hawaii, USA, 621‑626.\n\nChen, H. (2007). Exploring extremism and terrorism on the web: The Dark Web project. Proceedings of the Pacific Asia Workshop on Intelligence and Security Informatics (PAISI 2007). April 11‑12, 2007. Chengdu, China, 1‑20.",
                    "score": 0.3708704865944732
                },
                {
                    "context": "In Press, Accepted Manuscript, Available online 3 October 2015\n\nhttp://www.sciencedirect.com/science/article/pii/S092523121501396X\n\ntweets, etc. Experts filter the expanded list of URLs to reduce the collection and analyze irrelevant web pages. Finally, the extracted features are used to classify and analyze the web data.\n\nSimilarly, in content-based techniques, the content (especially textual content) of web pages is extracted and processed for classification or analysis. However, text content is the large category in web data and DW collection as mentioned earlier. Over the recent years, statistical text classification methods have been used intensively in detecting potential terrorist activities on the web, in which the text is represented as weighted features. The most common representation is the TF‑IDF term weighting technique, which is widely used to determine the significant words (features) in the text (Choi et al., 2014). However, many other statistical text representations are frequently used with text classification approaches to detect dark content such as lexical, syntactic, stylistic (Abbasi and Chen, 2005, 2008; Zheng et al., 2006), domain‑specific Bag of Words (BoW), Parts of Speech (PoS) (Greevy and Smeaton, 2004), and n‑grams (Chen, 2008a; Choi et al., 2011; Huang et al., 2010; Tianjun et al., 2009).\n\nA combination of such features is used in few studies. For example (Zheng et al., 2006) uses a feature set consisting of 270 features of four categories: lexical (character and word‑based), structural, syntactic, and content‑specific features to identify the authorship of an online message in English and Chinese language. By classifying the data using three different classification techniques namely, Decision trees, neural networks, and support vector machine. In the lexical character‑based features, the total number of characters, uppercase characters, digits, spaces, and frequency of letters special characters are all considered as features. However, the total number of words, short words, average word length, average sentence length in terms of character and words, and total number of different words are considered as word‑based features. In the category of structural features, the total number of lines, sentences, paragraphs, sentences per paragraph, words per paragraph and many other statistics are employed as features, while punctuations and 150 function words frequency are used as syntactic features and the frequency of eleven content‑specific keywords as content specific features. Zheng et al. (2006) reported the accuracy of the Support Vector Machine (SVM) classifier as the highest achieved accuracy with value of 97.69% and 83.33% based on the 270 feature for the English and Chinese datasets respectively.\n\nHowever, to address Arabic language specific issues such as infection, word elongation, and diacritics, an Arabic language parser is used in (Abbasi and Chen, 2005). A feature set of 418 features of the same categories as in (Zheng et al., 2006) were extracted from the bilingual (English and Arabic) documents. However, additional technical structural features such as font size, embedded images and hyperlinks were also included. In their experiments, feature sets were added incrementally to two classifiers (C4.5 and SVM). Abbasi and Chen (2005) reported that SVM classifier with combination of all feature sets performs the best in terms of accuracy (97% and 94.83%) on both English and Arabic datasets, respectively.\n\nIn (Chen, 2008b), n‑gram based features were used on the level of character, word, root, and collections, a set consisting of 7,556 features was extracted as indicators of documents from two Arabic forums Al Firdaws and Al Montada. A Recursive Feature Elimination (RFE) technique in conjunction with Information Gain (IG) heuristic were applied to reduce feature dimensions and identify the most appropriate and relevant features. However, the study aimed to measure the sentiment polarities expressed in selected radical international Jihadist.",
                    "score": 0.3704632383815956
                },
                {
                    "context": "This table presents performance measures of various hybridization functions and levels, comparing metrics such as F-measure and Accuracy across different algorithms including SVM, KNN, DT, NB, and ELM.,\nwith the following columns:\n- Performance Measure: The type of performance measure being evaluated.\n- Hybridization Function: The identifier for the hybridization function used.\n- Hybridization level: The level of hybridization applied.\n- Mean number of features*: The average number of features considered in the evaluation.\n- SVM: Performance metric for Support Vector Machine.\n- KNN: Performance metric for K-Nearest Neighbors.\n- DT: Performance metric for Decision Trees.\n- NB: Performance metric for Naive Bayes.\n- ELM: Performance metric for Extreme Learning Machine.\n\n| Performance Measure | Hybridization Function | Hybridization level | Mean number of features\\* | SVM   | KNN   | DT    | NB    | ELM   |       |       .1|       .2|       .3|       .4|       .5|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| F‑measure           | 1                      | 500                 |                           | 80.80 | 85.65 | 37.82 | 7.43  |83.42|       |       |       |       |       |       |\n|                     | 2                      | 690                 |                           | 90.10 | 86.48 | 44.09 | 1.88  |84.76|       |       |       |       |       |       |\n|                     | 3                      | 803                 |                           | 92.80 | 85.68 | 49.14 | 6.49  |85.44|       |       |       |       |       |       |\n|                     |                        |                     |                           |       | 4     | 909   | 92.20 |88.94| 41.74 | 11.04 | 86.97 |       |       |       |\n|                     |                        |                     |                           |       |       | 5     | 916   |90.0| 87.89 | 54.55 | 15.52 | 86.47 |       |       |\n|                     | UN                     | 1                   | 500                       | 80.80 | 85.65 | 37.82 | 7.43  |83.42|       |       |       |       |       |       |\n|                     |                        |                     |                           | 2     | 845   | 92.40 | 87.04 |54.4| 8.72  | 87.72 |       |       |       |       |\n|                     |                        | 3                   | 1094                      | 93.80 | 88.49 | 46.43 | 14.27 |89.31|       |       |       |       |       |       |\n|                     |                        | 4                   | 1283                      | 93.20 | 90.14 | 53.28 | 16.27 |89.98|       |       |       |       |       |       |\n|                     |                        | 5                   | 1431                      | 93.00 | 92.25 | 58.33 | 18.12 |90.43|       |       |       |       |       |       |\n| Accuracy            |                        |                     |                           |       |       |       |       |1.0| 500   | 77.80 | 83.88 | 50.00 | 50.48 | 81.82 |\n|                     | 2                      | 690                 |                           | 89.00 | 85.08 | 50.00 | 49.79 |83.36|       |       |       |       |       |       |\n|                     |                        |                     |                           |       | 3     | 803   | 92.70 |83.71| 50.00 | 50.53 | 84.66 |       |       |       |\n|                     |                        |                     |                           |       |       |       |       |4.0| 909   | 91.80 | 88.00 | 50.00 | 51.56 | 86.42 |\n|                     |                        |                     |                           |       |       | 5     | 916   |90.0| 87.10 | 50.00 | 53.20 | 86.60 |       |       |\n|                     | UN                     | 1                   | 500                       | 77.80 | 83.88 | 50.00 | 50.48 |81.82|       |       |       |       |       |       |\n|                     | 2                      | 845                 |                           | 91.80 | 84.99 | 50.00 | 49.77 |87.1|       |       |       |       |       |       |\n|                     |                        | 3                   | 1094                      | 93.60 | 86.78 | 50.00 | 50.16 |88.96|       |       |       |       |       |       |\n|                     |                        | 4                   | 1283                      | 93.00 | 88.98 | 50.00 | 50.60 |89.84|       |       |       |       |       |       |\n|                     |                        | 5                   | 1431                      | 93.00 | 91.80 | 50.00 | 51.20 |90.5|       |       |       |       |       |       |",
                    "score": 0.36981717667381137
                },
                {
                    "context": "In Press, Accepted Manuscript, Available online 3 October 2015\n\nhttp://www.sciencedirect.com/science/article/pii/S092523121501396X\n\nDark Web forums. Chen (2008b) reported that 22% of the features were included in the model and all sentiment classifiers demonstrated good results, with higher than 88% accuracy in sentiment polarities.\n\nBoW and PoS in addition to bi‑gram features were also used individually in (Greevy and Smeaton, 2004) to detect racism in text, where SVM was used as the classifier. Greevy and Smeaton (2004) conducted their experiments on four different datasets and reported that the highest classification accuracy was achieved based on the BoW using the polynomial function as the classifier kernel.\n\nHowever, the performance of such statistical methods and traditional frequency‑based term weighting schemes such as TF‑IDF in the domain of terrorist activities detection is reported to be insufficient (Choi et al., 2014; Greevy and Smeaton, 2004; Ran and Xianjiu, 2010). In general, the low performance of statistical methods in text classification comes from the inability of these methods to understand the semantic meanings of a text created by humans (Choi et al., 2014). Therefore, some other techniques are proposed to overcome the deficiency of individual statistical methods. Techniques proposed by (Choi and Kim, 2012; Choi et al., 2014; Hwang et al., 2011) utilize knowledge‑based tools that provide the conceptual hierarchy interconnections such as WordNet and Wikipedia to measure the semantic relations between concepts and determine the important features. However, the improvement in classification performance is not reported to be significant relative to the traditional statistical methods.\n\n 2.2 Term weighting techniques\n\nIn information retrieval, text classification, and web‑classification domains, term‑weighting techniques (also known as schemes of formulas) such as Term Frequency (TF), Document Frequency (DF), and Inverse Document Frequency (IDF) are widely used (Ran and Xianjiu, 2010) in addition to TF‑IDF, Entropy (Selamat and Omatu, 2004), and the Glasgow techniques. However, there are many other term‑weighting schemes were proposed and used in these domains (Crestani et al., 1998; Yang and Pedersen, 1997) such as Term Variance (TV) (Luying et al., 2005), Term Strength (TS) (Yang, 1995), Chi‑square (CHI) (Yanjun et al., 2008), Inverse Document Frequency (IDF) (Robertson, 2004), Information Gain (IG) (Luying et al., 2005; Quinlan, 1986), Odds Ratio (OR) (Mengle and Goharian, 2009), Gini Index (GI) (Shang et al., 2007), Improved Gini Index (GINI) (Mengle and Goharian, 2009), Mutual Information (MI) (Peng et al., 2005), and Balanced Term Weighting Scheme (BTWS) (Jung et al., 2001).\n\nThe Vector Space Model (VSM) which proposed by (Salton et al., 1975) is still a common and effective way for statistical representation of a corpus (collection) of documents. In VSM model, each document is considered as a vector of terms such that d = (t₁, t₂, ... , tₙ), and a corresponding weights vector w = (w₁,w₂,…, wₙ), where w₁,w₂,…, wₙ are the weights of t₁, t₂, ..., tₙ respectively, based on the used term weighting scheme. VSM model can be visualized as a two‑dimensional matrix, in which the rows represent documents and the columns represent terms (features) in the collection, as shown in Figure 1. In this section, we first introduce a simple example, then the mathematical formulations of the term weighting schemes in the scope of this study are listed, and finally, a brief discussion on each term weighting scheme is presented in addition to some calculations based on the given example.",
                    "score": 0.36980058089207457
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific AI algorithm was utilized in the study, and how does it contribute to the overall findings presented in the article?",
                    "answer": "The study utilized a combination of statistical text classification methods, including Decision Trees, Neural Networks, and Support Vector Machines (SVM). These algorithms contributed to the overall findings by effectively classifying web data, particularly in detecting potential terrorist activities. The SVM classifier, in particular, demonstrated high accuracy rates when combined with various feature sets, indicating its effectiveness in handling complex text classification tasks. This approach allowed for a nuanced analysis of web content, enhancing the ability to identify and categorize relevant information from the Dark Web."
                },
                {
                    "question": "[SQ] What were the specific feature sets used in conjunction with the SVM classifier?",
                    "answer": "The specific feature sets used in conjunction with the SVM classifier included small feature sets generated by various term-weighting techniques such as TF (Term Frequency), DF (Document Frequency), IDF (Inverse Document Frequency), TF-IDF, Glasgow, and Entropy. These feature sets were combined using hybridization functions, specifically the UNION and Symmetric Difference functions, to enhance classification performance."
                },
                {
                    "question": "[SQ] How did the performance of the Neural Networks compare to that of the Decision Trees in the study?",
                    "answer": "The performance of the Neural Networks (ELM) was generally superior to that of the Decision Trees (DT) in the study. The metrics for ELM consistently showed higher values across various hybridization functions and levels compared to those for DT. Specifically, while DT exhibited lower performance measures, particularly in F-measure and Accuracy, ELM achieved better results, indicating a more effective classification performance in the context of the study."
                },
                {
                    "question": "[SQ] What metrics were used to evaluate the accuracy of the AI algorithms in the study?",
                    "answer": "The metrics used to evaluate the accuracy of the AI algorithms in the study include accuracy, precision, recall, and F-measure."
                },
                {
                    "question": "[MQ] What combination of AI algorithms, including Decision Trees, Neural Networks, and Support Vector Machines, was used in the study, and how did their performance, particularly that of the SVM classifier with specific feature sets, contribute to the findings on detecting potential terrorist activities?",
                    "answer": "The study utilized a combination of Decision Trees, Neural Networks, and Support Vector Machines (SVM) for classifying data related to potential terrorist activities. The performance of these classifiers was evaluated using various feature sets derived from different term-weighting techniques. Notably, the SVM classifier demonstrated the highest accuracy, achieving significant performance measures when tested with a comprehensive feature set. This finding underscored the effectiveness of SVM in the domain of detecting terrorism-related content, particularly when combined with a diverse array of features that capture significant terms in the text. The results indicated that hybridizing feature sets from multiple term-weighting methods could enhance classification performance, thereby supporting the study's conclusions about the importance of feature selection in improving detection accuracy."
                },
                {
                    "question": "[SQ] What were the specific performance metrics achieved by the SVM classifier when using the different feature sets?",
                    "answer": "The performance metrics achieved by the SVM classifier using different feature sets are as follows:\n\n- For the F-measure with 500 features: 80.80\n- For the F-measure with 690 features: 90.10\n- For the F-measure with 803 features: 92.80\n- For the F-measure with 1094 features: 93.80\n- For the F-measure with 1283 features: 93.20\n- For the F-measure with 1431 features: 93.00\n\n- For accuracy with 500 features: 77.80\n- For accuracy with 690 features: 89.00\n- For accuracy with 803 features: 92.70\n- For accuracy with 909 features: 91.80\n- For accuracy with 916 features: 90.0\n- For accuracy with 845 features: 91.80\n- For accuracy with 1094 features: 93.60\n- For accuracy with 1283 features: 93.00\n- For accuracy with 1431 features: 93.00"
                },
                {
                    "question": "[SQ] How did the hybridization of feature sets impact the overall classification performance of the AI algorithms in the study?",
                    "answer": "The hybridization of feature sets significantly enhanced the overall classification performance of the AI algorithms in the study. It was observed that the classification F-measure performance improved when using combined term weighting techniques compared to individual schemes. Specifically, the performance based on the UNION hybridization function consistently outperformed that of the Symmetric Difference function, attributed to the larger number of features included in the combined feature set. \n\nAs the number of combined sets increased, the classification performance generally improved, indicating that a more discriminative feature set was formed by incorporating features based on diverse assumptions about significant terms in the text. However, it was also noted that some combinations resulted in higher F-measure performance than others, suggesting that the presence of noise features in certain sets could negatively affect classifier performance. \n\nOverall, the results underscored the importance of hybridization in achieving higher classification accuracy, with the SVM classifier showing the best performance, followed by KNN and ELM, while classifiers like Naive Bayes and Decision Trees exhibited poorer results due to the sparsity of feature sets."
                },
                {
                    "question": "[SQ] What challenges were encountered in the implementation of Decision Trees and Neural Networks compared to the SVM classifier?",
                    "answer": "The implementation of Decision Trees (DT) faced challenges primarily due to the high sparsity of feature sets, which negatively impacted classification performance. DT classifiers prefer inputs with many attribute values, and their effectiveness can diminish when dealing with sparse data. Additionally, while DTs are simple to interpret and develop, they function more like keyword-based filters in text classification, which may limit their adaptability.\n\nOn the other hand, Neural Networks (not explicitly detailed in the provided information) typically encounter challenges related to overfitting, especially when the training data is limited or not representative of the broader dataset. They also require careful tuning of parameters and architecture, which can complicate their implementation.\n\nIn contrast, the SVM classifier demonstrated superior performance measures, indicating that it is more robust in handling the complexities associated with text classification tasks, such as those found in the domain of DW analysis."
                },
                {
                    "question": "[MQ] What AI algorithms, specifically Decision Trees, Neural Networks, and Support Vector Machines (SVM), were utilized in the study for detecting potential terrorist activities, and how did the performance of the SVM classifier with various feature sets contribute to the overall findings?",
                    "answer": "The study utilized Decision Trees (DT), Neural Networks (NN), and Support Vector Machines (SVM) as classification techniques for detecting potential terrorist activities. The performance of the SVM classifier was notably superior, achieving the highest accuracy compared to the other classifiers. Specifically, the SVM classifier demonstrated significant effectiveness when combined with various feature sets generated from different term-weighting techniques. The results indicated that the classification performance improved as the level of hybridization of feature sets increased, supporting the notion that combining features based on diverse assumptions about significant terms enhances classification accuracy. This finding underscores the importance of feature set generation in achieving higher performance in text classification tasks related to detecting terrorist activities."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 0.7798961272979631,
                "llm_context_precision_without_reference": 0.0,
                "llm_context_precision_with_reference": 0.2926406926348398,
                "answer_relevancy": 0.0,
                "answer_correctness": 0.9449740318244908
            },
            "deepeval": {
                "contextual_precision": 0.25,
                "contextual_recall": 0.5,
                "contextual_relevancy": 0.1450381679389313,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 47,
        "job_id": 1,
        "file_id": 10,
        "question_id": 2,
        "status": "done",
        "answer_text": "A comprehensive set of features was selected for analysis, categorized into lexical, structural, syntactic, and content-specific characteristics. Lexical features included metrics such as total characters, uppercase characters, digits, and frequency of letters, along with word-based metrics like total words, average word length, and sentence length. Structural features encompassed statistics on lines, sentences, paragraphs, and words per paragraph. Syntactic features involved punctuation and the frequency of function words, while content-specific features focused on the frequency of certain keywords.\n\nThese features were justified by their effectiveness in classifying and analyzing web data, particularly for identifying authorship and detecting potential terrorist activities. The diverse combination of feature types aimed to enhance the accuracy of classification techniques, as evidenced by the high accuracy rates achieved with classifiers like Support Vector Machines (SVM) when utilizing these varied feature sets.",
        "answer_encoded": "[response not coded] A comprehensive set of features selected for analysis included lexical, structural, syntactic, and content-specific characteristics, aimed at enhancing classification accuracy for tasks like authorship identification and detecting potential terrorist activities.",
        "answer_contexts": [
                {
                    "context": "In Press, Accepted Manuscript, Available online 3 October 2015\n\nhttp://www.sciencedirect.com/science/article/pii/S092523121501396X\n\ntweets, etc. Experts filter the expanded list of URLs to reduce the collection and analyze irrelevant web pages. Finally, the extracted features are used to classify and analyze the web data.\n\nSimilarly, in content-based techniques, the content (especially textual content) of web pages is extracted and processed for classification or analysis. However, text content is the large category in web data and DW collection as mentioned earlier. Over the recent years, statistical text classification methods have been used intensively in detecting potential terrorist activities on the web, in which the text is represented as weighted features. The most common representation is the TF‑IDF term weighting technique, which is widely used to determine the significant words (features) in the text (Choi et al., 2014). However, many other statistical text representations are frequently used with text classification approaches to detect dark content such as lexical, syntactic, stylistic (Abbasi and Chen, 2005, 2008; Zheng et al., 2006), domain‑specific Bag of Words (BoW), Parts of Speech (PoS) (Greevy and Smeaton, 2004), and n‑grams (Chen, 2008a; Choi et al., 2011; Huang et al., 2010; Tianjun et al., 2009).\n\nA combination of such features is used in few studies. For example (Zheng et al., 2006) uses a feature set consisting of 270 features of four categories: lexical (character and word‑based), structural, syntactic, and content‑specific features to identify the authorship of an online message in English and Chinese language. By classifying the data using three different classification techniques namely, Decision trees, neural networks, and support vector machine. In the lexical character‑based features, the total number of characters, uppercase characters, digits, spaces, and frequency of letters special characters are all considered as features. However, the total number of words, short words, average word length, average sentence length in terms of character and words, and total number of different words are considered as word‑based features. In the category of structural features, the total number of lines, sentences, paragraphs, sentences per paragraph, words per paragraph and many other statistics are employed as features, while punctuations and 150 function words frequency are used as syntactic features and the frequency of eleven content‑specific keywords as content specific features. Zheng et al. (2006) reported the accuracy of the Support Vector Machine (SVM) classifier as the highest achieved accuracy with value of 97.69% and 83.33% based on the 270 feature for the English and Chinese datasets respectively.\n\nHowever, to address Arabic language specific issues such as infection, word elongation, and diacritics, an Arabic language parser is used in (Abbasi and Chen, 2005). A feature set of 418 features of the same categories as in (Zheng et al., 2006) were extracted from the bilingual (English and Arabic) documents. However, additional technical structural features such as font size, embedded images and hyperlinks were also included. In their experiments, feature sets were added incrementally to two classifiers (C4.5 and SVM). Abbasi and Chen (2005) reported that SVM classifier with combination of all feature sets performs the best in terms of accuracy (97% and 94.83%) on both English and Arabic datasets, respectively.\n\nIn (Chen, 2008b), n‑gram based features were used on the level of character, word, root, and collections, a set consisting of 7,556 features was extracted as indicators of documents from two Arabic forums Al Firdaws and Al Montada. A Recursive Feature Elimination (RFE) technique in conjunction with Information Gain (IG) heuristic were applied to reduce feature dimensions and identify the most appropriate and relevant features. However, the study aimed to measure the sentiment polarities expressed in selected radical international Jihadist.",
                    "score": 0.843346680792417
                },
                {
                    "context": "In Press, Accepted Manuscript, Available online 3 October 2015\n\nhttp://www.sciencedirect.com/science/article/pii/S092523121501396X\n\nDark Web forums. Chen (2008b) reported that 22% of the features were included in the model and all sentiment classifiers demonstrated good results, with higher than 88% accuracy in sentiment polarities.\n\nBoW and PoS in addition to bi‑gram features were also used individually in (Greevy and Smeaton, 2004) to detect racism in text, where SVM was used as the classifier. Greevy and Smeaton (2004) conducted their experiments on four different datasets and reported that the highest classification accuracy was achieved based on the BoW using the polynomial function as the classifier kernel.\n\nHowever, the performance of such statistical methods and traditional frequency‑based term weighting schemes such as TF‑IDF in the domain of terrorist activities detection is reported to be insufficient (Choi et al., 2014; Greevy and Smeaton, 2004; Ran and Xianjiu, 2010). In general, the low performance of statistical methods in text classification comes from the inability of these methods to understand the semantic meanings of a text created by humans (Choi et al., 2014). Therefore, some other techniques are proposed to overcome the deficiency of individual statistical methods. Techniques proposed by (Choi and Kim, 2012; Choi et al., 2014; Hwang et al., 2011) utilize knowledge‑based tools that provide the conceptual hierarchy interconnections such as WordNet and Wikipedia to measure the semantic relations between concepts and determine the important features. However, the improvement in classification performance is not reported to be significant relative to the traditional statistical methods.\n\n 2.2 Term weighting techniques\n\nIn information retrieval, text classification, and web‑classification domains, term‑weighting techniques (also known as schemes of formulas) such as Term Frequency (TF), Document Frequency (DF), and Inverse Document Frequency (IDF) are widely used (Ran and Xianjiu, 2010) in addition to TF‑IDF, Entropy (Selamat and Omatu, 2004), and the Glasgow techniques. However, there are many other term‑weighting schemes were proposed and used in these domains (Crestani et al., 1998; Yang and Pedersen, 1997) such as Term Variance (TV) (Luying et al., 2005), Term Strength (TS) (Yang, 1995), Chi‑square (CHI) (Yanjun et al., 2008), Inverse Document Frequency (IDF) (Robertson, 2004), Information Gain (IG) (Luying et al., 2005; Quinlan, 1986), Odds Ratio (OR) (Mengle and Goharian, 2009), Gini Index (GI) (Shang et al., 2007), Improved Gini Index (GINI) (Mengle and Goharian, 2009), Mutual Information (MI) (Peng et al., 2005), and Balanced Term Weighting Scheme (BTWS) (Jung et al., 2001).\n\nThe Vector Space Model (VSM) which proposed by (Salton et al., 1975) is still a common and effective way for statistical representation of a corpus (collection) of documents. In VSM model, each document is considered as a vector of terms such that d = (t₁, t₂, ... , tₙ), and a corresponding weights vector w = (w₁,w₂,…, wₙ), where w₁,w₂,…, wₙ are the weights of t₁, t₂, ..., tₙ respectively, based on the used term weighting scheme. VSM model can be visualized as a two‑dimensional matrix, in which the rows represent documents and the columns represent terms (features) in the collection, as shown in Figure 1. In this section, we first introduce a simple example, then the mathematical formulations of the term weighting schemes in the scope of this study are listed, and finally, a brief discussion on each term weighting scheme is presented in addition to some calculations based on the given example.",
                    "score": 0.4629465499533102
                },
                {
                    "context": "In Press, Accepted Manuscript, Available online 3 October 2015\n\nhttp://www.sciencedirect.com/science/article/pii/S092523121501396X\n\nothers to join extremism (Abbasi and Chen, 2007). Since September 11, 2001 (9/11), information technology researchers are studying and tracing these groups to prevent and reduce the potential terrorism in the world by analyzing different types of content of online resources related to such groups. The hidden and covert parts of the web used by terrorist or extremist groups online is referred as the Dark Web (DW) (Zhou et al., 2006). Generally, DW content is categorized into indexable and multimedia types. Multimedia content consist of images, audio, and video files while the indexable category consists of the static and dynamic text‑based files. Text content is the large category in web data (Choi et al., 2014) and in DW collection (Fu et al., 2010).\n\nThe effectiveness of terrorism detection by means of web analysis has been proven as it has been discovered that the group known as “Hamburg Cell” that was mainly responsible for the preparation of the September 11 attacks against the United States used Internet intensively (Corbin, 2003). Various statistical text classification based techniques were proposed for terrorism activities detection from web contents. The performance of text classification and DW detection methods is highly controlled by the feature selection technique rather than the classifier’s kernel function (Leopold and Kindermann, 2002). Generally, feature selection methods are the methods concern with selecting the most informative features (terms) from the entire feature space. However, selecting such features requires the features to be weighted and ranked by the weighting scheme (Choi et al., 2014). In the literature, many feature selection approaches based on different term weighting schemes (Liu et al., 2009) were proposed. The assumption behind these techniques is that during text classification and DW detection as well, texts contain some less important and uninformative terms. Therefore, removing these terms will not affect the quality of the classification (Efron et al., 2003). However, it will reduce the complexity and the required time as well as increasing the accuracy of the classification process (Wibowo and Williams, 2002).\n\nMany of feature selection methods, are based on a single term weighting scheme (Bharti and Singh, 2015) such as Term Frequency (TF), and Term Frequency – Inverse Document Frequency (TF‑IDF). Term weighting schemes are used frequently to rank the features (terms) of the text and determine the most relevant ones before classification (Choi et al., 2014). However, various ideas about the significant terms of the text are exist in the literature and lead to different term weighting techniques. For example, the TF weighting scheme supports the idea that the most significant term in the document is the most frequently mentioned term (Salton and Buckley, 1988). However, Document Frequency (DF) scheme is based on the idea that the term appears in more documents has a more significant (Chen et al., 2009). Moreover, other different term weighting schemes such as TF‑IDF, Entropy, and Glasgow support different assumptions of the significant terms as shown in section 2.2.\n\nHowever, the hybridized feature selection methods were proposed frequently in text classification domain, where various feature selection methods were combined in different hybridization forms (Bharti and Singh, 2015).",
                    "score": 0.37924129268428636
                },
                {
                    "context": "Studying Global Extremist Organizations' Internet Presence Using the DarkWeb Attribute System. In H. Chen, E. Reid, J. Sinai, A. Silke, and B. Ganor (Eds.). Terrorism Informatics (pp. 237‑266). USA: Springer.\n\nQuinlan, J. R. (1986). Induction of Decision Trees. Machine Learning, 1(1), 81‑106.\n\nRafrafi, A., Guigue, V., and Gallinari, P. (2012). Coping with the Document Frequency Bias in Sentiment Classification. Proceedings of the Sixth International AAAI Conference on Weblogs and Social Media (ICWSM). June 4–7, 2012. Dublin, Ireland, 314‑314.\n\nRan, L., and Xianjiu, G. (2010). An Improved Algorithm to Term Weighting in Text Classification. Proceedings of the International Conference on Multimedia Technology (ICMT). October 29‑31, 2010. Ningbo, China, 1‑3.\n\nRennie, J., Shih, L., Teevan, J., and Karger, D. (2003). Tackling the poor assumptions of Naive Bayes text classifiers. Proceedings of the Twentieth International Conference on Machine Learning (ICML). August 21‑24, 2003. Washington DC, USA, 616‑623.\n\nRobertson, S. (2004). Understanding inverse document frequency: on theoretical arguments for IDF. Journal of Documentation, 60(5), 503‑520.\n\nSaad, M. K., and Ashour, W. (2010). OSAC: Open Source Arabic Corpora. Proceedings of the 6th International Conference on Electrical and Computer Systems. November 25‑26, 2010. Lefke, Cyprus, 118‑123.\n\nSahu, B., and Mishra, D. (2012). A Novel Feature Selection Algorithm using Particle Swarm Optimization for Cancer Microarray Data. Procedia Engineering, 38, 27‑31.\n\nSalton, G., and Buckley, C. (1988). Term‑weighting approaches in automatic text retrieval. Information Processing & Management, 24(5), 513‑523.\n\nSalton, G., Wong, A., and Yang, C. (1975). A vector space model for automatic indexing. Communications of the ACM, 18(11), 613‑620.\n\nSam, L. Z., Maarof, M. A., and Selamat, A. (2006). Automated Web Pages Classification with Integration of Principal Component Analysis (PCA) and Independent Component Analysis (ICA) as Feature Reduction.",
                    "score": 0.3718494088394655
                },
                {
                    "context": "5.5 Statistical significance tests\n\nIn this subsection, the statistical tests are used to examine the significance of the differences in the means of classification performance on the one hand, and the differences in the number of features in the combined feature sets based on different hybridization function, on the other hand, in different views.",
                    "score": 0.35674663541904067
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific features or characteristics were selected for analysis in the study, and how were they justified in the context of the research objectives?",
                    "answer": "The study selected a comprehensive set of features for analysis, categorized into lexical, structural, syntactic, and content-specific features. Lexical features included character-based metrics such as total characters, uppercase characters, digits, and frequency of letters, as well as word-based metrics like total words, average word length, and sentence length. Structural features encompassed statistics on lines, sentences, paragraphs, and words per paragraph. Syntactic features involved punctuation and the frequency of function words, while content-specific features focused on the frequency of certain keywords.\n\nThese features were justified in the context of the research objectives by their ability to effectively classify and analyze web data, particularly in identifying authorship and detecting potential terrorist activities. The combination of various feature types aimed to enhance the accuracy of classification techniques, as demonstrated by the reported high accuracy rates achieved with classifiers like Support Vector Machines (SVM) when using these diverse feature sets."
                },
                {
                    "question": "[SQ] What criteria were used to select the specific features for analysis in the study?",
                    "answer": "The specific features for analysis in the study were selected based on their significance, utilizing methods such as the Top K weighted features selection. This approach involved identifying and selecting the features with the highest weights from the feature space to form the basis for classification. Additionally, various categories of features were considered, including lexical, structural, syntactic, and content-specific features, which encompassed a wide range of characteristics such as character and word counts, punctuation frequency, and specific keywords."
                },
                {
                    "question": "[SQ] How did the selected features contribute to the overall research objectives?",
                    "answer": "The selected features played a crucial role in enhancing the classification and analysis of web data, particularly in identifying potential terrorist activities and detecting dark content. By employing a variety of feature sets that included lexical, structural, syntactic, and content-specific characteristics, the research aimed to improve the accuracy of classification techniques. The combination of these features allowed for a more nuanced understanding of the textual content, leading to higher classification accuracy rates, as demonstrated by the reported results from various classifiers. Additionally, the use of hybridization functions to combine feature sets aimed to reduce dimensionality while maintaining the relevance of the features, further supporting the research objectives of effective data analysis and classification."
                },
                {
                    "question": "[SQ] Were there any alternative features considered for analysis, and why were they ultimately excluded?",
                    "answer": "Alternative features considered for analysis included lexical, structural, syntactic, and content-specific features, as well as various statistical text representations such as Bag of Words (BoW), Parts of Speech (PoS), and n-grams. However, the performance of traditional statistical methods and frequency-based term weighting schemes like TF-IDF was reported to be insufficient in detecting terrorist activities. This inadequacy stemmed from the inability of these methods to understand the semantic meanings of the text. Consequently, while these alternative features were explored, they were ultimately excluded in favor of hybridized methods that utilize a wider range of term weighting techniques to achieve higher classification performance."
                },
                {
                    "question": "[MQ] What categories of features, including lexical, structural, syntactic, and content-specific characteristics, were selected for analysis in the study, and how did their significance contribute to the research objectives of classifying web data and detecting potential terrorist activities?",
                    "answer": "The study selected a comprehensive set of features categorized into lexical, structural, syntactic, and content-specific characteristics for analysis. Lexical features included character-based metrics such as the total number of characters, uppercase characters, digits, and special characters, as well as word-based metrics like total words, average word length, and sentence length. Structural features encompassed statistics related to the organization of the text, such as the total number of lines, sentences, and paragraphs. Syntactic features focused on punctuation and the frequency of function words, while content-specific features involved the frequency of certain keywords relevant to the subject matter.\n\nThe significance of these features contributed to the research objectives by enabling a more nuanced classification of web data, particularly in detecting potential terrorist activities. By employing a diverse range of features, the study aimed to enhance the accuracy of classification methods, allowing for a better identification of relevant content associated with extremist activities. The combination of these features facilitated a deeper understanding of the textual data, ultimately improving the effectiveness of the classification process in identifying and analyzing threats in online environments."
                },
                {
                    "question": "[SQ] What specific lexical features were found to be most effective in detecting potential terrorist activities?",
                    "answer": "The specific lexical features found to be effective in detecting potential terrorist activities include the total number of characters, uppercase characters, digits, spaces, and the frequency of letters and special characters. Additionally, word-based features such as the total number of words, short words, average word length, average sentence length in terms of characters and words, and the total number of different words were also considered significant. These features contribute to the classification and analysis of web data related to terrorist activities."
                },
                {
                    "question": "[SQ] How did the structural features enhance the understanding of the organization of web data in the study?",
                    "answer": "Structural features enhanced the understanding of the organization of web data by utilizing the relationships between web data units, such as links among web pages and the structural characteristics of those pages. These features allowed for the classification and detection of dark content by employing techniques like Link-Based Bootstrapping (LBB), which expanded the initial list of URLs based on community structures inferred from interactions among online resources. By analyzing these structural elements, the study was able to filter and classify web data more effectively, thereby improving the detection of extremist content."
                },
                {
                    "question": "[SQ] What role did syntactic features play in improving the classification accuracy of the classifiers used in the research?",
                    "answer": "Syntactic features contributed to the classification accuracy by providing additional statistical information about the text. In the studies mentioned, syntactic features included the frequency of punctuation and function words, which helped to enhance the overall feature set used for classification. By incorporating these features alongside lexical and structural features, classifiers like Support Vector Machines (SVM) were able to achieve higher accuracy rates. The combination of various feature types, including syntactic features, allowed for a more comprehensive analysis of the text, ultimately leading to improved performance in detecting relevant content."
                },
                {
                    "question": "[MQ] What specific categories of features, including lexical, structural, syntactic, and content-specific characteristics, were selected for analysis in the study, and how did these features enhance the classification of web data related to potential terrorist activities?",
                    "answer": "The study identified several categories of features for analysis, including lexical, structural, syntactic, and content-specific characteristics. \n\n1. **Lexical Features**: These included character-based features such as the total number of characters, uppercase characters, digits, spaces, and frequency of letters and special characters. Word-based features encompassed the total number of words, short words, average word length, average sentence length, and the total number of different words.\n\n2. **Structural Features**: This category involved statistics such as the total number of lines, sentences, paragraphs, sentences per paragraph, and words per paragraph.\n\n3. **Syntactic Features**: These features included the frequency of punctuation marks and a set of function words.\n\n4. **Content-Specific Features**: This category focused on the frequency of specific keywords relevant to the content being analyzed.\n\nBy employing a combination of these features, the study aimed to enhance the classification of web data related to potential terrorist activities. The diverse feature set allowed for a more comprehensive analysis, improving the accuracy of classification methods such as Support Vector Machines (SVM) and other classifiers. The inclusion of various feature types helped in capturing different aspects of the text, leading to better identification of relevant content associated with terrorism."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 1.0,
                "semantic_similarity": 0.7633730173992631,
                "llm_context_precision_without_reference": 0.6707142857075786,
                "llm_context_precision_with_reference": 0.12132352940569853,
                "answer_relevancy": 0.9293585299978604,
                "answer_correctness": 0.19084325434981578
            },
            "deepeval": {
                "contextual_precision": 0.8611111111111112,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.2857142857142857,
                "answer_relevancy": 1.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 48,
        "job_id": 1,
        "file_id": 10,
        "question_id": 3,
        "status": "done",
        "answer_text": "The platform utilized for data collection in the analyzed article is the Dark Web Forum Portal (DWFP).",
        "answer_encoded": "DWFP",
        "answer_contexts": [
                {
                    "context": "In Press, Accepted Manuscript, Available online 3 October 2015\n\nhttp://www.sciencedirect.com/science/article/pii/S092523121501396X\n\n 4.1 Dataset\n\nTo test and evaluate the HTW method, an experiment was conducted. First, thousands of Arabic web pages were downloaded from the DWFP. DWFP is the largest collection of crawled terrorist‑related documents (Fu et al., 2010). The data on DWFP is collected from 17 Arabic forums, and many other forums in other languages such as English, German, French, and Russian languages (Fu et al., 2010). However, this research focuses on Arabic web pages. Therefore, a native Arabic domain expert labeled the web pages manually. The expert considered a document as dark, if the document contained material related to terrorist activities such as weapons or explosives manufacturing, attack planes, bombing, and other such activities, as shown in Figure 12Error! Reference source not found.. Then non‑dark files were added from the Open Source Arabic Corpora (OSAC) (Saad and Ashour, 2010). OSAC dataset includes 22,429 Arabic text documents collected from many websites, where the documents are distributed into 11 categories (History, Entertainments, Economics, Education & Family, Religious discussions, Heath, Sports, Astronomy, Stories, Low, and Cooking Recipes).\n\nHow makeContainers\n\n44 A J*y³ᶠ andExplosives Jyp &lt; DJ\n\n11-09-2013 ATary Password\n\nHow containers and explosives\n\n09/11/2013 Hureye How containers and explosives\n\nSenior media\n\nMaterials required to be obtained for the manufacture of explosives\n\n- Powdered sugar 1 and we get it from home\n- Potassium nitrate and we get them from shops selling agricultural tools used Xme and Chile sometimes called salt_\n- Agricultural sulfur yellow:\n- Ammonium nitrate\n- AlL ceamir the caxtic SUhetance for the treatment ofdisaaces af the urina n\n\nFigure 12 Dark content example\n\nFigure 12Error! Reference source not found. shows a snapshot of an Arabic dark forum page besides its Google based translation, in which the poster explains in details about explosives manufacturing. Although there is no regular structure or format of dark content on the web, dark content is widely presented in text format (Fu et al., 2010).\n\nThe dataset used for the experiments in this research is a balanced dataset, which consists of 1000 documents (50% of the documents are labeled as dark and 50% are non‑dark). In the literature, many existing DW detection studies such as (Aknine et al., 2005; Greevy and Smeaton, 2004) use a balanced dataset in which the\n\n23",
                    "score": 0.6672138900370522
                },
                {
                    "context": "In Press, Accepted Manuscript, Available online 3 October 2015\n\nhttp://www.sciencedirect.com/science/article/pii/S092523121501396X\n\nothers to join extremism (Abbasi and Chen, 2007). Since September 11, 2001 (9/11), information technology researchers are studying and tracing these groups to prevent and reduce the potential terrorism in the world by analyzing different types of content of online resources related to such groups. The hidden and covert parts of the web used by terrorist or extremist groups online is referred as the Dark Web (DW) (Zhou et al., 2006). Generally, DW content is categorized into indexable and multimedia types. Multimedia content consist of images, audio, and video files while the indexable category consists of the static and dynamic text‑based files. Text content is the large category in web data (Choi et al., 2014) and in DW collection (Fu et al., 2010).\n\nThe effectiveness of terrorism detection by means of web analysis has been proven as it has been discovered that the group known as “Hamburg Cell” that was mainly responsible for the preparation of the September 11 attacks against the United States used Internet intensively (Corbin, 2003). Various statistical text classification based techniques were proposed for terrorism activities detection from web contents. The performance of text classification and DW detection methods is highly controlled by the feature selection technique rather than the classifier’s kernel function (Leopold and Kindermann, 2002). Generally, feature selection methods are the methods concern with selecting the most informative features (terms) from the entire feature space. However, selecting such features requires the features to be weighted and ranked by the weighting scheme (Choi et al., 2014). In the literature, many feature selection approaches based on different term weighting schemes (Liu et al., 2009) were proposed. The assumption behind these techniques is that during text classification and DW detection as well, texts contain some less important and uninformative terms. Therefore, removing these terms will not affect the quality of the classification (Efron et al., 2003). However, it will reduce the complexity and the required time as well as increasing the accuracy of the classification process (Wibowo and Williams, 2002).\n\nMany of feature selection methods, are based on a single term weighting scheme (Bharti and Singh, 2015) such as Term Frequency (TF), and Term Frequency – Inverse Document Frequency (TF‑IDF). Term weighting schemes are used frequently to rank the features (terms) of the text and determine the most relevant ones before classification (Choi et al., 2014). However, various ideas about the significant terms of the text are exist in the literature and lead to different term weighting techniques. For example, the TF weighting scheme supports the idea that the most significant term in the document is the most frequently mentioned term (Salton and Buckley, 1988). However, Document Frequency (DF) scheme is based on the idea that the term appears in more documents has a more significant (Chen et al., 2009). Moreover, other different term weighting schemes such as TF‑IDF, Entropy, and Glasgow support different assumptions of the significant terms as shown in section 2.2.\n\nHowever, the hybridized feature selection methods were proposed frequently in text classification domain, where various feature selection methods were combined in different hybridization forms (Bharti and Singh, 2015).",
                    "score": 0.6495768740149828
                },
                {
                    "context": "This table outlines the components of a Dark Web Forum Portal, detailing various modules such as Multi-Threading, Downloader, Indexing, Storage, and Accessibility, among others.,\nwith the following table title:\nDark Web Forum Portal,\nwith the following columns:\n- Multi-Threading Module: None\n- Downloader Module: None\n- Index: None\n- Login Module: None\n- Indexing Module: None\n- Storage Module: None\n- Accessibility: None\n- Incremental Crawling Module: None\n\n| Dark Web Forum Portal  |                             |              |\n|---|---|---|\n| Multi-Threading Module | Downloader Module           |              |\n|                        | Index                       | Login Module |\n| Indexing Module        |                             |              |\n| Storage Module         |                             |              |\n| Accessibility          | Incremental Crawling Module |              |",
                    "score": 0.5665584344866719
                },
                {
                    "context": "In Press, Accepted Manuscript, Available online 3 October 2015\n\nhttp://www.sciencedirect.com/science/article/pii/S092523121501396X\n\n Methodology\n\nMethodology contains the processes that showed followed in case of applying HTW method for solving the general text classification problem.\n\n Application Specific Processes\n\nFirstly, web pages were collected from the Internet (part 1 of the framework). For this purpose, a special crawler was developed to download and store the web pages from the Dark Web Forum Portal (DWFP). The implemented crawler consisted of many modules as shown in Figure 7.",
                    "score": 0.5467764416703033
                },
                {
                    "context": "In Press, Accepted Manuscript, Available online 3 October 2015\n\nhttp://www.sciencedirect.com/science/article/pii/S092523121501396X\n\ntweets, etc. Experts filter the expanded list of URLs to reduce the collection and analyze irrelevant web pages. Finally, the extracted features are used to classify and analyze the web data.\n\nSimilarly, in content-based techniques, the content (especially textual content) of web pages is extracted and processed for classification or analysis. However, text content is the large category in web data and DW collection as mentioned earlier. Over the recent years, statistical text classification methods have been used intensively in detecting potential terrorist activities on the web, in which the text is represented as weighted features. The most common representation is the TF‑IDF term weighting technique, which is widely used to determine the significant words (features) in the text (Choi et al., 2014). However, many other statistical text representations are frequently used with text classification approaches to detect dark content such as lexical, syntactic, stylistic (Abbasi and Chen, 2005, 2008; Zheng et al., 2006), domain‑specific Bag of Words (BoW), Parts of Speech (PoS) (Greevy and Smeaton, 2004), and n‑grams (Chen, 2008a; Choi et al., 2011; Huang et al., 2010; Tianjun et al., 2009).\n\nA combination of such features is used in few studies. For example (Zheng et al., 2006) uses a feature set consisting of 270 features of four categories: lexical (character and word‑based), structural, syntactic, and content‑specific features to identify the authorship of an online message in English and Chinese language. By classifying the data using three different classification techniques namely, Decision trees, neural networks, and support vector machine. In the lexical character‑based features, the total number of characters, uppercase characters, digits, spaces, and frequency of letters special characters are all considered as features. However, the total number of words, short words, average word length, average sentence length in terms of character and words, and total number of different words are considered as word‑based features. In the category of structural features, the total number of lines, sentences, paragraphs, sentences per paragraph, words per paragraph and many other statistics are employed as features, while punctuations and 150 function words frequency are used as syntactic features and the frequency of eleven content‑specific keywords as content specific features. Zheng et al. (2006) reported the accuracy of the Support Vector Machine (SVM) classifier as the highest achieved accuracy with value of 97.69% and 83.33% based on the 270 feature for the English and Chinese datasets respectively.\n\nHowever, to address Arabic language specific issues such as infection, word elongation, and diacritics, an Arabic language parser is used in (Abbasi and Chen, 2005). A feature set of 418 features of the same categories as in (Zheng et al., 2006) were extracted from the bilingual (English and Arabic) documents. However, additional technical structural features such as font size, embedded images and hyperlinks were also included. In their experiments, feature sets were added incrementally to two classifiers (C4.5 and SVM). Abbasi and Chen (2005) reported that SVM classifier with combination of all feature sets performs the best in terms of accuracy (97% and 94.83%) on both English and Arabic datasets, respectively.\n\nIn (Chen, 2008b), n‑gram based features were used on the level of character, word, root, and collections, a set consisting of 7,556 features was extracted as indicators of documents from two Arabic forums Al Firdaws and Al Montada. A Recursive Feature Elimination (RFE) technique in conjunction with Information Gain (IG) heuristic were applied to reduce feature dimensions and identify the most appropriate and relevant features. However, the study aimed to measure the sentiment polarities expressed in selected radical international Jihadist.",
                    "score": 0.5459631997568435
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] Which social network or platform was utilized for data collection in the analyzed article?",
                    "answer": "The data collection in the analyzed article was conducted using a special crawler developed to download and store web pages from the Dark Web Forum Portal (DWFP)."
                },
                {
                    "question": "[SQ] What specific features of the Dark Web Forum Portal (DWFP) were targeted for data collection?",
                    "answer": "The data collection targeted Arabic web pages from the Dark Web Forum Portal (DWFP), focusing on documents related to terrorist activities such as weapons or explosives manufacturing, attack plans, and bombings. The dataset used for experiments included a balanced collection of 1000 documents, with 50% labeled as dark and 50% as non-dark. Additionally, the collection involved extracting features from various types of content, particularly textual content, which is significant in web data and DW collection."
                },
                {
                    "question": "[SQ] How was the special crawler developed for the data collection process?",
                    "answer": "The special crawler developed for the data collection process consisted of multiple modules. It included a Login Module responsible for passing login information to the Dark Web Forum Portal (DWFP) and establishing a connection. The Download Module worked in collaboration with Indexing and Storage modules in a multithreaded environment to download, index, and store documents from DWFP to local storage. Additionally, an Incremental Crawling Module was designed to resume downloading documents in case of a lost connection, following an incremental updating approach. This crawler was specifically tailored to collect web pages from the DWFP."
                },
                {
                    "question": "[SQ] What types of data were collected from the Dark Web Forum Portal (DWFP)?",
                    "answer": "The data collected from the Dark Web Forum Portal (DWFP) included thousands of Arabic web pages, specifically focusing on documents related to terrorist activities such as weapons or explosives manufacturing, attack plans, and bombings. Additionally, non-dark files were sourced from the Open Source Arabic Corpora (OSAC), which consists of Arabic text documents distributed across various categories like History, Entertainment, Economics, Education, Religious discussions, Health, Sports, Astronomy, Stories, Law, and Cooking Recipes."
                },
                {
                    "question": "[MQ] Which platform was utilized for data collection in the analyzed article, specifically focusing on the Dark Web Forum Portal (DWFP) for Arabic web pages related to terrorist activities?",
                    "answer": "The platform utilized for data collection in the analyzed article is the Dark Web Forum Portal (DWFP), which is the largest collection of crawled terrorist-related documents."
                },
                {
                    "question": "[SQ] What specific methodologies were employed in the data collection process from the Dark Web Forum Portal (DWFP)?",
                    "answer": "The data collection process from the Dark Web Forum Portal (DWFP) involved the development of a specialized crawler designed to download and store web pages. This crawler consisted of multiple modules, including a Login Module for establishing connections, a Download Module for retrieving documents, and Indexing and Storage modules for organizing and saving the data. Additionally, an Incremental Crawling Module was implemented to resume downloads in case of lost connections. The collected data primarily focused on Arabic web pages, which were manually labeled by a native Arabic domain expert to identify dark content related to terrorist activities."
                },
                {
                    "question": "[SQ] How does the data collected from the DWFP compare to other sources of Arabic web pages related to terrorist activities?",
                    "answer": "The data collected from the DWFP is specifically focused on terrorist-related documents and is derived from 17 Arabic forums, making it a targeted collection for analyzing dark content. In contrast, other sources of Arabic web pages, such as the Open Source Arabic Corpora (OSAC), include a broader range of topics, with documents categorized into various subjects like history, entertainment, and education. While DWFP emphasizes content related to terrorism, OSAC provides a more diverse dataset that includes non-dark content, thus offering a wider context for comparison. The DWFP's focus on dark content allows for a more concentrated analysis of terrorist activities, whereas other sources may dilute this focus with unrelated topics."
                },
                {
                    "question": "[SQ] What challenges were encountered during the data collection from the Dark Web Forum Portal (DWFP)?",
                    "answer": "The challenges encountered during data collection from the Dark Web Forum Portal (DWFP) include the need to manually label web pages to identify dark content, as the classification of documents as dark or non-dark relies on expert judgment regarding their relevance to terrorist activities. Additionally, the inherent imbalance in the amount of dark content compared to non-dark content on the web poses a challenge for effective detection and classification. The variability in the structure and format of dark content also complicates the data collection and classification processes."
                },
                {
                    "question": "[MQ] Which platform was specifically employed for data collection in the analyzed article, focusing on the Dark Web Forum Portal (DWFP) for Arabic web pages related to terrorist activities?",
                    "answer": "The platform specifically employed for data collection in the analyzed article is the Dark Web Forum Portal (DWFP), which is the largest collection of crawled terrorist-related documents."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0, #NaN
                "semantic_similarity": 0.8531503892477711,
                "llm_context_precision_without_reference": 0.5396825396645503,
                "llm_context_precision_with_reference": 0.5396825396645503,
                "answer_relevancy": 0.7000991494214873,
                "answer_correctness": 0.9632875973119428
            },
            "deepeval": {
                "contextual_precision": 0.6488095238095237,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.011904761904761904,
                "answer_relevancy": 0.0,
                "faithfulness": 1.0
            }
        },
    },
    {
        "id": 49,
        "job_id": 1,
        "file_id": 10,
        "question_id": 4,
        "status": "done",
        "answer_text": "The dataset analyzed in the article consisted of 1000 documents, with 50% labeled as dark and 50% as non-dark.",
        "answer_encoded": "[response not coded] The analyzed dataset consisted of 1000 documents, evenly split between dark and non-dark labels.",
        "answer_contexts": [
                {
                    "context": "In Press, Accepted Manuscript, Available online 3 October 2015\n\nhttp://www.sciencedirect.com/science/article/pii/S092523121501396X\n\nThe number of samples in both classes (Dark/non‑Dark) are equal. However, in reality, the amount of dark content on the web is much less than the non‑dark content (Correa and Sureka, 2013), therefore, the performance of dark content detection using imbalanced datasets will be the focus of our future work.\n\nAs in many of existing works, in this research, the DW detection problem is treated as a specific binary text classification problem, in which the dark content is to be distinguished from other topics. However, the dataset considered in this research reflects the general text classification problem as the dataset contains documents that belong to many various topics. Hence, even though the application area of this research is the DW detection, the proposed method is still applicable and valid for the general text classification problem, as the general text classification problem is frequently treated as multi binary classification problems. Furthermore, the proposed method is a statistical text classification approach, therefore the focus on Arabic text in this research will not limit the generalization of the method, as text is represented and analyzed statistically, which is the same paradigm followed by general statistical text classification approaches regardless of text underlying language.\n\n 4.2 Pre-processing\n\nDocuments in the dataset were pre‑processed. Pre‑processing included stop‑words removal based on the common Arabic stop word list1, filtering against non‑Arabic letters, numbers, symbols, and Latin text, and then stemming where the Larkey’s Light Stemmer algorithm (Larkey et al., 2007) is applied. The next step in the experiment was the representation of the documents in VSM model, based on different term‑weighting techniques A, B, C, D, and E, which stands for TF, DF, TF‑IDF, Glasgow, and Entropy weighting techniques, respectively. A special Java application was developed to perform the representation and weights calculation based on the Lucene 4.3 package2. As shown in Figure 6, the generated VSM matrices are named VSMA, VSMB, VSMC, VSMD, and VSME, and saved to the local storage to be used in the next step.\n\n 4.3 HTW application\n\nTo apply the HTW method, a series of experiments were conducted; the top 50 to 500 features (in intervals of 50 features) were selected from VSM matrixes as View 1, and then the remaining views were constructed by hybridizing the feature sets of View 1 based on two, three, four, and five sets. The total number of feature sets in different views is 31 sets of each top K features. The Rapid Miner software3 (v5.3) was used to handle the VSM matrices, however, the classifiers were implemented in Matlab to perform the classification based on the parameters specified in Error! Reference source not found.. The results of this experiment are shown and discussed in the next section.",
                    "score": 0.8412004633107795
                },
                {
                    "context": "In Press, Accepted Manuscript, Available online 3 October 2015\n\nhttp://www.sciencedirect.com/science/article/pii/S092523121501396X\n\n 4.1 Dataset\n\nTo test and evaluate the HTW method, an experiment was conducted. First, thousands of Arabic web pages were downloaded from the DWFP. DWFP is the largest collection of crawled terrorist‑related documents (Fu et al., 2010). The data on DWFP is collected from 17 Arabic forums, and many other forums in other languages such as English, German, French, and Russian languages (Fu et al., 2010). However, this research focuses on Arabic web pages. Therefore, a native Arabic domain expert labeled the web pages manually. The expert considered a document as dark, if the document contained material related to terrorist activities such as weapons or explosives manufacturing, attack planes, bombing, and other such activities, as shown in Figure 12Error! Reference source not found.. Then non‑dark files were added from the Open Source Arabic Corpora (OSAC) (Saad and Ashour, 2010). OSAC dataset includes 22,429 Arabic text documents collected from many websites, where the documents are distributed into 11 categories (History, Entertainments, Economics, Education & Family, Religious discussions, Heath, Sports, Astronomy, Stories, Low, and Cooking Recipes).\n\nHow makeContainers\n\n44 A J*y³ᶠ andExplosives Jyp &lt; DJ\n\n11-09-2013 ATary Password\n\nHow containers and explosives\n\n09/11/2013 Hureye How containers and explosives\n\nSenior media\n\nMaterials required to be obtained for the manufacture of explosives\n\n- Powdered sugar 1 and we get it from home\n- Potassium nitrate and we get them from shops selling agricultural tools used Xme and Chile sometimes called salt_\n- Agricultural sulfur yellow:\n- Ammonium nitrate\n- AlL ceamir the caxtic SUhetance for the treatment ofdisaaces af the urina n\n\nFigure 12 Dark content example\n\nFigure 12Error! Reference source not found. shows a snapshot of an Arabic dark forum page besides its Google based translation, in which the poster explains in details about explosives manufacturing. Although there is no regular structure or format of dark content on the web, dark content is widely presented in text format (Fu et al., 2010).\n\nThe dataset used for the experiments in this research is a balanced dataset, which consists of 1000 documents (50% of the documents are labeled as dark and 50% are non‑dark). In the literature, many existing DW detection studies such as (Aknine et al., 2005; Greevy and Smeaton, 2004) use a balanced dataset in which the\n\n23",
                    "score": 0.832585124996135
                },
                {
                    "context": "This table lists documents along with their content descriptions, highlighting themes such as brevity and darkness.,\nwith the following columns:\n- Document: Identifier for each document.\n- Content: Description of the content within each document.\n\n| Document | Content                                                  |\n|---|---|\n| Doc 1    | This document is short.                                  |\n| Doc 2    | This content is dark.                                    |\n| Doc 3    | This content in this document is dark.                   |\n| Doc 4    | We can detect this dark content, this terrorist content. |",
                    "score": 0.5068338567806259
                },
                {
                    "context": "This table presents the term frequency content for various documents, highlighting the prevalence of specific terms such as 'dark', 'detect', and 'terrorist' across four different documents.,\nwith the following columns:\n- Document: Identifier for each document.\n- Term can content: Frequency of the term 'can' in each document.\n- dark: Frequency of the term 'dark' in each document.\n- detect: Frequency of the term 'detect' in each document.\n- document: Frequency of the term 'document' in each document.\n- in: Frequency of the term 'in' in each document.\n- is: Frequency of the term 'is' in each document.\n- short: Frequency of the term 'short' in each document.\n- terrorist: Frequency of the term 'terrorist' in each document.\n- this: Frequency of the term 'this' in each document.\n- we: Frequency of the term 'we' in each document.\n\n| Document | Term can content | dark   | detect | document | in     | is | short  | terrorist | this   | we |\n|---|---|---|---|---|---|---|---|---|---|---|\n| Doc1     |0.8466|0.6438| 1.1931 |0.5|        |    |        |           |        |    |\n| Doc2     |0.6438|0.6438|        |0.6438|        |    | 0.5000 |           |        |    |\n| Doc3     |0.4292|0.4292| 0.5644 |0.7954| 0.4292 |    | 0.6667 |           |        |    |\n| Doc4     |0.6618|0.7143| 0.3571 |0.6618|        |    | 0.6618 | 0.5547    | 0.6618 |    |",
                    "score": 0.3795701285957883
                },
                {
                    "context": "In Press, Accepted Manuscript, Available online 3 October 2015\n\nhttp://www.sciencedirect.com/science/article/pii/S092523121501396X\n\ntweets, etc. Experts filter the expanded list of URLs to reduce the collection and analyze irrelevant web pages. Finally, the extracted features are used to classify and analyze the web data.\n\nSimilarly, in content-based techniques, the content (especially textual content) of web pages is extracted and processed for classification or analysis. However, text content is the large category in web data and DW collection as mentioned earlier. Over the recent years, statistical text classification methods have been used intensively in detecting potential terrorist activities on the web, in which the text is represented as weighted features. The most common representation is the TF‑IDF term weighting technique, which is widely used to determine the significant words (features) in the text (Choi et al., 2014). However, many other statistical text representations are frequently used with text classification approaches to detect dark content such as lexical, syntactic, stylistic (Abbasi and Chen, 2005, 2008; Zheng et al., 2006), domain‑specific Bag of Words (BoW), Parts of Speech (PoS) (Greevy and Smeaton, 2004), and n‑grams (Chen, 2008a; Choi et al., 2011; Huang et al., 2010; Tianjun et al., 2009).\n\nA combination of such features is used in few studies. For example (Zheng et al., 2006) uses a feature set consisting of 270 features of four categories: lexical (character and word‑based), structural, syntactic, and content‑specific features to identify the authorship of an online message in English and Chinese language. By classifying the data using three different classification techniques namely, Decision trees, neural networks, and support vector machine. In the lexical character‑based features, the total number of characters, uppercase characters, digits, spaces, and frequency of letters special characters are all considered as features. However, the total number of words, short words, average word length, average sentence length in terms of character and words, and total number of different words are considered as word‑based features. In the category of structural features, the total number of lines, sentences, paragraphs, sentences per paragraph, words per paragraph and many other statistics are employed as features, while punctuations and 150 function words frequency are used as syntactic features and the frequency of eleven content‑specific keywords as content specific features. Zheng et al. (2006) reported the accuracy of the Support Vector Machine (SVM) classifier as the highest achieved accuracy with value of 97.69% and 83.33% based on the 270 feature for the English and Chinese datasets respectively.\n\nHowever, to address Arabic language specific issues such as infection, word elongation, and diacritics, an Arabic language parser is used in (Abbasi and Chen, 2005). A feature set of 418 features of the same categories as in (Zheng et al., 2006) were extracted from the bilingual (English and Arabic) documents. However, additional technical structural features such as font size, embedded images and hyperlinks were also included. In their experiments, feature sets were added incrementally to two classifiers (C4.5 and SVM). Abbasi and Chen (2005) reported that SVM classifier with combination of all feature sets performs the best in terms of accuracy (97% and 94.83%) on both English and Arabic datasets, respectively.\n\nIn (Chen, 2008b), n‑gram based features were used on the level of character, word, root, and collections, a set consisting of 7,556 features was extracted as indicators of documents from two Arabic forums Al Firdaws and Al Montada. A Recursive Feature Elimination (RFE) technique in conjunction with Information Gain (IG) heuristic were applied to reduce feature dimensions and identify the most appropriate and relevant features. However, the study aimed to measure the sentiment polarities expressed in selected radical international Jihadist.",
                    "score": 0.25412135925475055
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What was the size of the dataset analyzed in the article?",
                    "answer": "The dataset analyzed in the article consisted of 1000 documents, with 50% labeled as dark and 50% as non-dark."
                },
                {
                    "question": "[SQ] What criteria were used to label the documents as dark or non-dark?",
                    "answer": "Documents were labeled as dark if they contained material related to terrorist activities, such as weapons or explosives manufacturing, attack plans, bombing, and similar topics. Non-dark documents were sourced from a collection that included various categories like history, entertainment, economics, education, and more."
                },
                {
                    "question": "[SQ] How were the 1000 documents selected for the dataset?",
                    "answer": "The 1000 documents for the dataset were selected to create a balanced dataset, consisting of 50% labeled as dark and 50% as non-dark. The dark documents were manually labeled by a native Arabic domain expert, who identified them based on their content related to terrorist activities. Non-dark documents were sourced from the Open Source Arabic Corpora (OSAC), which includes a variety of Arabic text documents across multiple categories."
                },
                {
                    "question": "[SQ] Was the dataset balanced in terms of other characteristics besides the dark and non-dark labels?",
                    "answer": "The dataset was balanced in terms of the number of samples for dark and non-dark documents, with 50% of the documents labeled as dark and 50% as non-dark. However, there is no indication in the provided information about other characteristics being balanced, such as the distribution of topics or other features within the dataset. Therefore, it can be concluded that while the dataset was balanced in terms of labels, there is no evidence to suggest it was balanced in other characteristics."
                },
                {
                    "question": "[MQ] What was the size of the analyzed dataset, which consisted of 1000 documents evenly split between 50% labeled as dark and 50% as non-dark?",
                    "answer": "The analyzed dataset consisted of 1000 documents, with 50% labeled as dark and 50% labeled as non-dark."
                },
                {
                    "question": "[SQ] What specific topics were covered in the dark documents of the dataset?",
                    "answer": "The dark documents in the dataset covered topics related to terrorist activities, including weapons or explosives manufacturing, attack plans, and bombing."
                },
                {
                    "question": "[SQ] How were the non-dark documents selected from the Open Source Arabic Corpora?",
                    "answer": "Non-dark documents were selected from the Open Source Arabic Corpora (OSAC) by including documents that were collected from various websites and categorized into 11 different topics. The selection process involved ensuring that these documents did not contain material related to terrorist activities, thus distinguishing them from the dark documents labeled by a native Arabic domain expert."
                },
                {
                    "question": "[SQ] What methods were used to ensure the accuracy of the labeling process for dark documents?",
                    "answer": "A native Arabic domain expert manually labeled the web pages to ensure the accuracy of the labeling process for dark documents. The expert defined a document as dark if it contained material related to terrorist activities, such as weapons or explosives manufacturing, attack plans, and bombings. This manual labeling process aimed to provide a reliable classification of the documents based on their content."
                },
                {
                    "question": "[MQ] What was the size of the analyzed dataset, which comprised 1000 documents evenly divided into 50% labeled as dark, related to terrorist activities, and 50% as non-dark, sourced from the Open Source Arabic Corpora?",
                    "answer": "The analyzed dataset consisted of 1000 documents, with 50% labeled as dark and 50% as non-dark."
                },
                {
                    "question": "[SQ] What was the process for selecting the dark documents in the dataset?",
                    "answer": "The selection of dark documents in the dataset involved manual labeling by a native Arabic domain expert. The expert identified a document as dark if it contained material related to terrorist activities, such as weapons or explosives manufacturing, attack plans, and bombings. This process ensured that the documents included in the dataset accurately reflected the characteristics of dark content."
                },
                {
                    "question": "[SQ] How were the non-dark documents verified to ensure they did not contain terrorist-related content?",
                    "answer": "The non-dark documents were verified by manually labeling them with the assistance of a native Arabic domain expert. This expert assessed the content of the documents to ensure they did not contain material related to terrorist activities, such as weapons or explosives manufacturing, attack plans, or bombings."
                },
                {
                    "question": "[SQ] What types of documents were included in the non-dark category from the Open Source Arabic Corpora?",
                    "answer": "The non-dark category from the Open Source Arabic Corpora includes documents distributed into 11 categories: History, Entertainments, Economics, Education & Family, Religious discussions, Health, Sports, Astronomy, Stories, Law, and Cooking Recipes."
                },
                {
                    "question": "[MQ] What was the size of the analyzed dataset, which consisted of 1000 documents evenly split between 50% labeled as dark, related to terrorist activities, and 50% as non-dark, sourced from the Open Source Arabic Corpora?",
                    "answer": "The analyzed dataset consisted of 1000 documents, with 50% labeled as dark and 50% as non-dark."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 1.0,
                "faithfulness": 0.8571428571428571,
                "semantic_similarity": 0.7959015122852882,
                "llm_context_precision_without_reference": 0.41933066932228275,
                "llm_context_precision_with_reference": 0.0909090909,
                "answer_relevancy": 0.9085278164229167,
                "answer_correctness": 0.298975378071322
            },
            "deepeval": {
                "contextual_precision": 1.0,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.030612244897959183,
                "answer_relevancy": 0.4,
                "faithfulness": 0.8333333333333334
            }
        },
    },
    {
        "id": 50,
        "job_id": 1,
        "file_id": 10,
        "question_id": 5,
        "status": "done",
        "answer_text": "The study evaluated the following performance metrics:\n\n1. **F-measure**:\n   - For the SD method: 100% at 100%, 95% at 95%, 90% at 90%, 85% at 85%, 80% at 80%, 75% at 75%, and 70% at 70%.\n   - For the UN method: Specific values were not provided.\n\n2. **Accuracy**:\n   - Various values were reported for different algorithms, including Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Decision Trees (DT), Naive Bayes (NB), and Extreme Learning Machine (ELM), with the highest accuracy being 100% for 1600 features.\n\n3. **Number of Features**:\n   - The mean number of features was reported for different hybridization levels, with specific values not detailed.\n\n4. **Statistical Comparisons**:\n   - T-statistics, degrees of freedom, and p-values were provided for comparisons between SD and UN methods, indicating the significance of differences in f-measure, accuracy, and features.",
        "answer_encoded": "[response not coded] The study reported F-measure values for the SD method ranging from 70% to 100%, with the highest accuracy of 100% for 1600 features, while specific values for the UN method and mean number of features were not detailed.",
        "answer_contexts": [
                {
                    "context": "This table presents performance measures of various hybridization functions and levels, comparing metrics such as F-measure and Accuracy across different algorithms including SVM, KNN, DT, NB, and ELM.,\nwith the following columns:\n- Performance Measure: The type of performance measure being evaluated.\n- Hybridization Function: The identifier for the hybridization function used.\n- Hybridization level: The level of hybridization applied.\n- Mean number of features*: The average number of features considered in the evaluation.\n- SVM: Performance metric for Support Vector Machine.\n- KNN: Performance metric for K-Nearest Neighbors.\n- DT: Performance metric for Decision Trees.\n- NB: Performance metric for Naive Bayes.\n- ELM: Performance metric for Extreme Learning Machine.\n\n| Performance Measure | Hybridization Function | Hybridization level | Mean number of features\\* | SVM   | KNN   | DT    | NB    | ELM   |       |       .1|       .2|       .3|       .4|       .5|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| F‑measure           | 1                      | 500                 |                           | 80.80 | 85.65 | 37.82 | 7.43  |83.42|       |       |       |       |       |       |\n|                     | 2                      | 690                 |                           | 90.10 | 86.48 | 44.09 | 1.88  |84.76|       |       |       |       |       |       |\n|                     | 3                      | 803                 |                           | 92.80 | 85.68 | 49.14 | 6.49  |85.44|       |       |       |       |       |       |\n|                     |                        |                     |                           |       | 4     | 909   | 92.20 |88.94| 41.74 | 11.04 | 86.97 |       |       |       |\n|                     |                        |                     |                           |       |       | 5     | 916   |90.0| 87.89 | 54.55 | 15.52 | 86.47 |       |       |\n|                     | UN                     | 1                   | 500                       | 80.80 | 85.65 | 37.82 | 7.43  |83.42|       |       |       |       |       |       |\n|                     |                        |                     |                           | 2     | 845   | 92.40 | 87.04 |54.4| 8.72  | 87.72 |       |       |       |       |\n|                     |                        | 3                   | 1094                      | 93.80 | 88.49 | 46.43 | 14.27 |89.31|       |       |       |       |       |       |\n|                     |                        | 4                   | 1283                      | 93.20 | 90.14 | 53.28 | 16.27 |89.98|       |       |       |       |       |       |\n|                     |                        | 5                   | 1431                      | 93.00 | 92.25 | 58.33 | 18.12 |90.43|       |       |       |       |       |       |\n| Accuracy            |                        |                     |                           |       |       |       |       |1.0| 500   | 77.80 | 83.88 | 50.00 | 50.48 | 81.82 |\n|                     | 2                      | 690                 |                           | 89.00 | 85.08 | 50.00 | 49.79 |83.36|       |       |       |       |       |       |\n|                     |                        |                     |                           |       | 3     | 803   | 92.70 |83.71| 50.00 | 50.53 | 84.66 |       |       |       |\n|                     |                        |                     |                           |       |       |       |       |4.0| 909   | 91.80 | 88.00 | 50.00 | 51.56 | 86.42 |\n|                     |                        |                     |                           |       |       | 5     | 916   |90.0| 87.10 | 50.00 | 53.20 | 86.60 |       |       |\n|                     | UN                     | 1                   | 500                       | 77.80 | 83.88 | 50.00 | 50.48 |81.82|       |       |       |       |       |       |\n|                     | 2                      | 845                 |                           | 91.80 | 84.99 | 50.00 | 49.77 |87.1|       |       |       |       |       |       |\n|                     |                        | 3                   | 1094                      | 93.60 | 86.78 | 50.00 | 50.16 |88.96|       |       |       |       |       |       |\n|                     |                        | 4                   | 1283                      | 93.00 | 88.98 | 50.00 | 50.60 |89.84|       |       |       |       |       |       |\n|                     |                        | 5                   | 1431                      | 93.00 | 91.80 | 50.00 | 51.20 |90.5|       |       |       |       |       |       |",
                    "score": 0.6335699418548224
                },
                {
                    "context": "50 100 150 200 250 300 350 400 450 500\n\nABCDE\n\nFigure 15 View based classification F‑measure performance based on different hybridization function\n\n27",
                    "score": 0.42412109528197306
                },
                {
                    "context": "* Significant at 0.01 level\n\n** Significant at 0.05 level\n\nMoreover, it is seen from Table 6, that the differences in means of accuracies achieved by different views are statistically significant at any number of features in the feature sets.\n\n 5.6 Benchmarking among classifiers\n\n Table 7\n\nshows the cross classifier benchmarking averaged performance measures, where the base feature sets consist of 500 features for each. The results of hybridization using different functions and levels are also shown. However, the hybridization level represents the number of combined sets.\n\n Table 7 ANOVA statistical significance test for classification performance between groups",
                    "score": 0.41801498836420126
                },
                {
                    "context": "This table presents the F-measure scores based on two different methods: SD (Standard Deviation) and UN (Unspecified). The scores are shown for various percentage thresholds ranging from 100% to 70%.,\nwith the following columns:\n- Percentage: Percentage thresholds from 100% to 70%.\n- SD based F‑measure: F-measure scores based on Standard Deviation.\n- UN based F‑measure: F-measure scores based on Unspecified method.\n\n|   |      | SD based F‑measure |   .1|   .2| UN based F‑measure |   .3|\n|---|---|---|---|---|---|---|\n|   | 100% | 100%               |   |   |                    |   |\n|   | 95%  | 95%                |   |   |                    |   |\n|   | 90%  | 90%                |   |   |                    |   |\n|   | 85%  | 85%                |   |   |                    |   |\n|   | 80%  | 80%                |   |   |                    |   |\n|   | 75%  | 75%                |   |   |                    |   |\n|   | 70%  | 70%                |   |   |                    |   |",
                    "score": 0.325420998315425
                },
                {
                    "context": "This table presents the F-measure scores based on two different methods: SD (Standard Deviation) and UN (Unspecified). The scores are shown at various percentage thresholds, indicating the performance of the methods at those levels.,\nwith the following columns:\n- Percentage: Percentage thresholds for evaluating F-measure.\n- SD based F‑measure: F-measure scores based on the SD method.\n- UN based F‑measure: F-measure scores based on the UN method.\n\n|   |      | SD based F‑measure |   .1|   .2| UN based F‑measure |   .3|\n|---|---|---|---|---|---|---|\n|   | 100% | 100%               |   |   |                    |   |\n|   | 95%  | 95%                |   |   |                    |   |\n|   | 90%  | 90%                |   |   |                    |   |\n|   | 85%  | 85%                |   |   |                    |   |\n|   | 80%  | 80%                |   |   |                    |   |\n|   | 75%  | 75%                |   |   |                    |   |\n|   | 70%  | 70%                |   |   |                    |   |",
                    "score": 0.32001833819364056
                }
            ],
        "answer_conversation": [
                {
                    "question": "[MQ] What specific performance metrics were evaluated in the study, and what were their corresponding values?",
                    "answer": "The study evaluated the following performance metrics:\n\n1. **F-measure**:\n   - For SD method: 100% at 100%, 95% at 95%, 90% at 90%, 85% at 85%, 80% at 80%, 75% at 75%, and 70% at 70%.\n   - For UN method: Corresponding values were not specified in the provided data.\n\n2. **Accuracy**:\n   - Various values were reported for different hybridization functions and levels, with specific performance metrics for algorithms such as SVM, KNN, DT, NB, and ELM.\n\n3. **Number of Features**:\n   - The mean number of features was reported for different hybridization levels, but specific values were not detailed in the provided data.\n\n4. **Statistical Comparisons**:\n   - T-statistics, degrees of freedom, and p-values were provided for comparisons between SD and UN methods across different views, indicating the significance of the differences observed in f-measure, accuracy, and features.\n\nThe specific values for accuracy and the mean number of features were not fully detailed in the provided data."
                },
                {
                    "question": "[SQ] What were the specific accuracy values reported for each algorithm evaluated in the study?",
                    "answer": "The specific accuracy values reported for each algorithm evaluated in the study are as follows:\n\n- Support Vector Machine (SVM): 80.80, 90.10, 92.80, 93.80, 93.20, 93.00\n- K-Nearest Neighbors (KNN): 85.65, 86.48, 85.68, 88.49, 90.14, 92.25\n- Decision Trees (DT): 37.82, 44.09, 49.14, 46.43, 53.28, 58.33\n- Naive Bayes (NB): 7.43, 1.88, 6.49, 14.27, 16.27, 18.12\n- Extreme Learning Machine (ELM): 83.42, 84.76, 85.44, 89.31, 89.98, 90.43\n\nAdditionally, accuracy values for different hybridization levels and functions were also reported, with the highest accuracy being 100% for 1600 features."
                },
                {
                    "question": "[SQ] Can you provide the mean number of features for each hybridization level mentioned in the study?",
                    "answer": "The mean number of features for each hybridization level mentioned in the study is as follows:\n\n- Hybridization level 1: 500\n- Hybridization level 2: 690\n- Hybridization level 3: 803\n- Hybridization level 4: 1094\n- Hybridization level 5: 1283\n- Hybridization level 6: 1431"
                },
                {
                    "question": "[SQ] What were the specific T-statistics, degrees of freedom, and p-values for the statistical comparisons between the SD and UN methods?",
                    "answer": "The specific t-statistics, degrees of freedom, and p-values for the statistical comparisons between the SD and UN methods are as follows:\n\n**View 2:**\n- SD f‑measure – UN f‑measure: t = -1.26271, df = 99, P value = 0.20966\n- SD accuracy – UN accuracy: t = -5.19673, df = 99, P value = 0.00000*\n- SD features – UN features: t = -9.08045, df = 99, P value = 0.00000*\n\n**View 3:**\n- SD f‑measure – UN f‑measure: t = -3.81888, df = 99, P value = 0.00023*\n- SD accuracy – UN accuracy: t = -3.47314, df = 99, P value = 0.00076*\n- SD features – UN features: t = -15.10313, df = 99, P value = 0.00000*\n\n**View 4:**\n- SD f‑measure – UN f‑measure: t = -1.57796, df = 49, P value = 0.12101\n- SD accuracy – UN accuracy: t = -1.32542, df = 49, P value = 0.19118\n- SD features – UN features: t = -12.48351, df = 49, P value = 0.00000*\n\n**View 5:**\n- SD f‑measure – UN f‑measure: t = 0.72761, df = 9, P value = 0.48535\n- SD accuracy – UN accuracy: t = 0.60984, df = 9, P value = 0.55705\n- SD features – UN features: t = -5.72256, df = 9, P value = 0.00029*"
                },
                {
                    "question": "[MQ] What performance metrics were evaluated in the study, including their specific values for F-measure, accuracy across different algorithms, and the mean number of features for each hybridization level?",
                    "answer": "The study evaluated two performance metrics: F-measure and Accuracy. \n\nFor the F-measure, the specific values across different algorithms and hybridization levels are as follows:\n\n- Hybridization Function 1 (500 features):\n  - SVM: 80.80\n  - KNN: 85.65\n  - DT: 37.82\n  - NB: 7.43\n  - ELM: 83.42\n\n- Hybridization Function 2 (690 features):\n  - SVM: 90.10\n  - KNN: 86.48\n  - DT: 44.09\n  - NB: 1.88\n  - ELM: 84.76\n\n- Hybridization Function 3 (803 features):\n  - SVM: 92.80\n  - KNN: 85.68\n  - DT: 49.14\n  - NB: 6.49\n  - ELM: 85.44\n\nFor the Accuracy metric, the values are as follows:\n\n- Hybridization Function 1 (500 features):\n  - SVM: 77.80\n  - KNN: 83.88\n  - NB: 50.48\n  - ELM: 81.82\n\n- Hybridization Function 2 (690 features):\n  - SVM: 89.00\n  - KNN: 85.08\n  - NB: 49.79\n  - ELM: 83.36\n\n- Hybridization Function 3 (803 features):\n  - SVM: 92.70\n  - KNN: 83.71\n  - NB: 50.53\n  - ELM: 84.66\n\nThe mean number of features for each hybridization level varies, with specific values provided for different functions and levels, such as 500, 690, 803, and others up to 1431 features."
                },
                {
                    "question": "[SQ] What were the specific F-measure values for the UN method across different hybridization levels?",
                    "answer": "The specific F-measure values for the UN method across different hybridization levels are as follows:\n\n- Level 1 (500 features): 80.80\n- Level 2 (690 features): 90.10\n- Level 3 (803 features): 92.80\n- Level 4 (1094 features): 93.80\n- Level 5 (1283 features): 93.20\n- Level 6 (1431 features): 93.00"
                },
                {
                    "question": "[SQ] Can you provide a summary of the accuracy values for each algorithm at the highest hybridization level?",
                    "answer": "At the highest hybridization level, the accuracy values for each algorithm are as follows:\n\n- Support Vector Machine (SVM): 93.00\n- K-Nearest Neighbors (KNN): 91.80\n- Decision Trees (DT): 50.00\n- Naive Bayes (NB): 51.20\n- Extreme Learning Machine (ELM): 90.50"
                },
                {
                    "question": "[SQ] What statistical significance was observed in the comparisons of F-measure between the SD and UN methods?",
                    "answer": "The comparisons of F-measure between the SD and UN methods revealed that the differences were statistically significant in View 3, with a p-value of 0.00023. In all other views, the differences in f-measure means were not significant."
                }
            ],
        "evaluation": {
            "ragas": {
                "context_recall": 0.0,
                "faithfulness": 0.7142857142857143,
                "semantic_similarity": 0.7338336922447571,
                "llm_context_precision_without_reference": 0.9379514004451475,
                "llm_context_precision_with_reference": 0.19999999998,
                "answer_relevancy": 0.9589009792363322,
                "answer_correctness": 0.18345842306118929
            },
            "deepeval": {
                "contextual_precision": 0.5333333333333333,
                "contextual_recall": 1.0,
                "contextual_relevancy": 0.6694915254237288,
                "answer_relevancy": 1.0,
                "faithfulness": 0.7241379310344828
            }
        }
    },
]